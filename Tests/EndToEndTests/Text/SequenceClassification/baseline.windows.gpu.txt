CPU info:
    CPU Model Name: Intel(R) Xeon(R) CPU E5-2630 v2 @ 2.60GHz
    Hardware threads: 24
    Total Memory: 268381192 kB
-------------------------------------------------------------------
=== Running /cygdrive/c/jenkins/workspace/CNTK-Test-Windows-W1/x64/debug/cntk.exe configFile=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SequenceClassification\Config/seqcla.cntk currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SequenceClassification\Data RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160713043153.833416\Text_SequenceClassification@debug_gpu DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SequenceClassification\Data ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SequenceClassification\Config OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160713043153.833416\Text_SequenceClassification@debug_gpu DeviceId=0 timestamping=true
-------------------------------------------------------------------
Build info: 

		Built time: Jul 13 2016 03:39:41
		Last modified date: Fri Jul  8 10:29:45 2016
		Build type: Debug
		Build target: GPU
		With 1bit-SGD: no
		Math lib: mkl
		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.5
		CUB_PATH: C:\src\cub-1.4.1
		CUDNN_PATH: c:\NVIDIA\cudnn-4.0\cuda
		Build Branch: HEAD
		Build SHA1: 50bb4c8afbc87c14548a5b5f315a064186a5cb5f
		Built by svcphil on liana-08-w
		Build Path: c:\jenkins\workspace\CNTK-Build-Windows\Source\CNTK\
-------------------------------------------------------------------
Changed current directory to C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SequenceClassification\Data
07/13/2016 04:43:57: -------------------------------------------------------------------
07/13/2016 04:43:57: Build info: 

07/13/2016 04:43:57: 		Built time: Jul 13 2016 03:39:41
07/13/2016 04:43:57: 		Last modified date: Fri Jul  8 10:29:45 2016
07/13/2016 04:43:57: 		Build type: Debug
07/13/2016 04:43:57: 		Build target: GPU
07/13/2016 04:43:57: 		With 1bit-SGD: no
07/13/2016 04:43:57: 		Math lib: mkl
07/13/2016 04:43:57: 		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.5
07/13/2016 04:43:57: 		CUB_PATH: C:\src\cub-1.4.1
07/13/2016 04:43:57: 		CUDNN_PATH: c:\NVIDIA\cudnn-4.0\cuda
07/13/2016 04:43:57: 		Build Branch: HEAD
07/13/2016 04:43:57: 		Build SHA1: 50bb4c8afbc87c14548a5b5f315a064186a5cb5f
07/13/2016 04:43:57: 		Built by svcphil on liana-08-w
07/13/2016 04:43:57: 		Build Path: c:\jenkins\workspace\CNTK-Build-Windows\Source\CNTK\
07/13/2016 04:43:57: -------------------------------------------------------------------
07/13/2016 04:43:58: -------------------------------------------------------------------
07/13/2016 04:43:58: GPU info:

07/13/2016 04:43:58: 		Device[0]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3072 MB
07/13/2016 04:43:58: 		Device[1]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3072 MB
07/13/2016 04:43:58: 		Device[2]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3072 MB
07/13/2016 04:43:58: 		Device[3]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3072 MB
07/13/2016 04:43:58: -------------------------------------------------------------------

07/13/2016 04:43:58: Running on DPHAIM-24 at 2016/07/13 04:43:58
07/13/2016 04:43:58: Command line: 
C:\jenkins\workspace\CNTK-Test-Windows-W1\x64\debug\cntk.exe  configFile=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SequenceClassification\Config/seqcla.cntk  currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SequenceClassification\Data  RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160713043153.833416\Text_SequenceClassification@debug_gpu  DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SequenceClassification\Data  ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SequenceClassification\Config  OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160713043153.833416\Text_SequenceClassification@debug_gpu  DeviceId=0  timestamping=true



07/13/2016 04:43:58: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
07/13/2016 04:43:58: RootDir = ".."
ConfigDir = "$RootDir$/Config"
DataDir   = "$RootDir$/Data"
OutputDir = "$RootDir$/Output"
ModelDir  = "$OutputDir$/Models"
command=Train 
deviceId = $DeviceId$
modelPath="$ModelDir$/seqcla.dnn"
Train=[
    action="train"
    run=BrainScriptNetworkBuilder
    BrainScriptNetworkBuilder=[
        Layers = [
            EmbeddingLayer(input, vocabSize, embeddingDim, embeddingPath) = [
                embedding = Transpose(LearnableParameter(vocabSize, embeddingDim, learningRateMultiplier = 0.0, init = 'fromFile', initFromFilePath = embeddingPath))          
                lookup = GatherPacked(features, embedding)
            ].lookup
            DenseLayer(input, inputSize, outputSize, activation) = [
               z = BFF(input, outputSize, inputSize).z
               act = activation(z)
            ].act
            LSTMLayer (input, inputSize, outputSize, cellSize, selector) = [ 
               lstm = BS.RNNs.RecurrentLSTMP (outputSize, cellDim=cellSize, input, inputDim=inputSize).h
               result = selector(lstm)
            ].result
        ]        
        // LSTM params
        lstmDim = 25
        cellDim = 25
        // model
        numLabels = 5        
        vocab = 2000
        embedDim = 50        
        // set up features and labels
        t = DynamicAxis()
features = Input(1, dynamicAxis=t)   
labels   = Input(numLabels)          
        // load the pre-learned word embedding matrix
        l1 = Layers.EmbeddingLayer(features, vocab, embedDim, 'embeddingmatrix.txt')
        l2 = Layers.LSTMLayer(l1, embedDim, lstmDim, cellDim, BS.Sequences.Last)
        l3 = Layers.DenseLayer(l2, lstmDim, numLabels, Pass)
        out = Pass(l3, tag='output')   
        // Make sure the trainer understands that the time dimension of l3 is actually the same as that of labels.
        l3p = ReconcileDynamicAxis(l3, labels)
        // training criteria
        ce  = CrossEntropyWithSoftmax(labels, l3p, tag='criterion')   // this is the training objective
        err = ErrorPrediction        (labels, l3p, tag='evaluation')  // this also gets tracked
    ]
    SGD = [	
        epochSize = 0
        minibatchSize = 200
        maxEpochs = 5
        momentumPerMB = 0.9
        learningRatesPerMB = 0.1
        keepCheckPointFiles = true
    ]
    reader = [
        readerType = "CNTKTextFormatReader"
        file = "$DataDir$/Train.txt"            
        input = [            
            features=[
                alias = "x"                
                dim = 1               
                format = "dense"
            ]
            labels=[
                alias = "y"                
                dim = 5           
                format = "dense"
            ]
        ]
   ]    
outputPath = "$OutputDir$/output.txt"        
]
Write=[
    action="test"
    run=BrainScriptNetworkBuilder
    format = [
      sequencePrologue=%d\t|w.shape %x\n%d\t|w\s
      sampleSeparator=\n%d\t|w\s
      elementSeparator=\s
    ]
    modelFile = "$ModelDir$/seqcla.dnn"    
    reader = [
            readerType = "CNTKTextFormatReader"
            file = "$DataDir$/Train.txt"            
            input = [            
                features=[
                    alias = "x"                
                    dim = 1               
                    format = "dense"
                ]
                labels=[
                    alias = "y"                
                    dim = 5           
                    format = "dense"
                ]
            ]
   ]    
outputPath = "$OutputDir$/output.txt"        
]
currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SequenceClassification\Data
RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160713043153.833416\Text_SequenceClassification@debug_gpu
DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SequenceClassification\Data
ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SequenceClassification\Config
OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160713043153.833416\Text_SequenceClassification@debug_gpu
DeviceId=0
timestamping=true

07/13/2016 04:43:58: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<

07/13/2016 04:43:58: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
07/13/2016 04:43:58: RootDir = ".."
ConfigDir = "../Config"
DataDir   = "../Data"
OutputDir = "../Output"
ModelDir  = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160713043153.833416\Text_SequenceClassification@debug_gpu/Models"
command=Train 
deviceId = 0
modelPath="C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160713043153.833416\Text_SequenceClassification@debug_gpu/Models/seqcla.dnn"
Train=[
    action="train"
    run=BrainScriptNetworkBuilder
    BrainScriptNetworkBuilder=[
        Layers = [
            EmbeddingLayer(input, vocabSize, embeddingDim, embeddingPath) = [
                embedding = Transpose(LearnableParameter(vocabSize, embeddingDim, learningRateMultiplier = 0.0, init = 'fromFile', initFromFilePath = embeddingPath))          
                lookup = GatherPacked(features, embedding)
            ].lookup
            DenseLayer(input, inputSize, outputSize, activation) = [
               z = BFF(input, outputSize, inputSize).z
               act = activation(z)
            ].act
            LSTMLayer (input, inputSize, outputSize, cellSize, selector) = [ 
               lstm = BS.RNNs.RecurrentLSTMP (outputSize, cellDim=cellSize, input, inputDim=inputSize).h
               result = selector(lstm)
            ].result
        ]        
        // LSTM params
        lstmDim = 25
        cellDim = 25
        // model
        numLabels = 5        
        vocab = 2000
        embedDim = 50        
        // set up features and labels
        t = DynamicAxis()
features = Input(1, dynamicAxis=t)   
labels   = Input(numLabels)          
        // load the pre-learned word embedding matrix
        l1 = Layers.EmbeddingLayer(features, vocab, embedDim, 'embeddingmatrix.txt')
        l2 = Layers.LSTMLayer(l1, embedDim, lstmDim, cellDim, BS.Sequences.Last)
        l3 = Layers.DenseLayer(l2, lstmDim, numLabels, Pass)
        out = Pass(l3, tag='output')   
        // Make sure the trainer understands that the time dimension of l3 is actually the same as that of labels.
        l3p = ReconcileDynamicAxis(l3, labels)
        // training criteria
        ce  = CrossEntropyWithSoftmax(labels, l3p, tag='criterion')   // this is the training objective
        err = ErrorPrediction        (labels, l3p, tag='evaluation')  // this also gets tracked
    ]
    SGD = [	
        epochSize = 0
        minibatchSize = 200
        maxEpochs = 5
        momentumPerMB = 0.9
        learningRatesPerMB = 0.1
        keepCheckPointFiles = true
    ]
    reader = [
        readerType = "CNTKTextFormatReader"
        file = "C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SequenceClassification\Data/Train.txt"            
        input = [            
            features=[
                alias = "x"                
                dim = 1               
                format = "dense"
            ]
            labels=[
                alias = "y"                
                dim = 5           
                format = "dense"
            ]
        ]
   ]    
outputPath = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160713043153.833416\Text_SequenceClassification@debug_gpu/output.txt"        
]
Write=[
    action="test"
    run=BrainScriptNetworkBuilder
    format = [
      sequencePrologue=%d\t|w.shape %x\n%d\t|w\s
      sampleSeparator=\n%d\t|w\s
      elementSeparator=\s
    ]
    modelFile = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160713043153.833416\Text_SequenceClassification@debug_gpu/Models/seqcla.dnn"    
    reader = [
            readerType = "CNTKTextFormatReader"
            file = "C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SequenceClassification\Data/Train.txt"            
            input = [            
                features=[
                    alias = "x"                
                    dim = 1               
                    format = "dense"
                ]
                labels=[
                    alias = "y"                
                    dim = 5           
                    format = "dense"
                ]
            ]
   ]    
outputPath = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160713043153.833416\Text_SequenceClassification@debug_gpu/output.txt"        
]
currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SequenceClassification\Data
RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160713043153.833416\Text_SequenceClassification@debug_gpu
DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SequenceClassification\Data
ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SequenceClassification\Config
OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160713043153.833416\Text_SequenceClassification@debug_gpu
DeviceId=0
timestamping=true

07/13/2016 04:43:58: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<

07/13/2016 04:43:58: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
configparameters: seqcla.cntk:command=Train
configparameters: seqcla.cntk:ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SequenceClassification\Config
configparameters: seqcla.cntk:currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SequenceClassification\Data
configparameters: seqcla.cntk:DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SequenceClassification\Data
configparameters: seqcla.cntk:deviceId=0
configparameters: seqcla.cntk:ModelDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160713043153.833416\Text_SequenceClassification@debug_gpu/Models
configparameters: seqcla.cntk:modelPath=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160713043153.833416\Text_SequenceClassification@debug_gpu/Models/seqcla.dnn
configparameters: seqcla.cntk:OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160713043153.833416\Text_SequenceClassification@debug_gpu
configparameters: seqcla.cntk:RootDir=..
configparameters: seqcla.cntk:RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160713043153.833416\Text_SequenceClassification@debug_gpu
configparameters: seqcla.cntk:timestamping=true
configparameters: seqcla.cntk:Train=[
    action="train"
    run=BrainScriptNetworkBuilder
    BrainScriptNetworkBuilder=[
        Layers = [
            EmbeddingLayer(input, vocabSize, embeddingDim, embeddingPath) = [
                embedding = Transpose(LearnableParameter(vocabSize, embeddingDim, learningRateMultiplier = 0.0, init = 'fromFile', initFromFilePath = embeddingPath))          
                lookup = GatherPacked(features, embedding)
            ].lookup
            DenseLayer(input, inputSize, outputSize, activation) = [
               z = BFF(input, outputSize, inputSize).z
               act = activation(z)
            ].act
            LSTMLayer (input, inputSize, outputSize, cellSize, selector) = [ 
               lstm = BS.RNNs.RecurrentLSTMP (outputSize, cellDim=cellSize, input, inputDim=inputSize).h
               result = selector(lstm)
            ].result
        ]        
        // LSTM params
        lstmDim = 25
        cellDim = 25
        // model
        numLabels = 5        
        vocab = 2000
        embedDim = 50        
        // set up features and labels
        t = DynamicAxis()
features = Input(1, dynamicAxis=t)   
labels   = Input(numLabels)          
        // load the pre-learned word embedding matrix
        l1 = Layers.EmbeddingLayer(features, vocab, embedDim, 'embeddingmatrix.txt')
        l2 = Layers.LSTMLayer(l1, embedDim, lstmDim, cellDim, BS.Sequences.Last)
        l3 = Layers.DenseLayer(l2, lstmDim, numLabels, Pass)
        out = Pass(l3, tag='output')   
        // Make sure the trainer understands that the time dimension of l3 is actually the same as that of labels.
        l3p = ReconcileDynamicAxis(l3, labels)
        // training criteria
        ce  = CrossEntropyWithSoftmax(labels, l3p, tag='criterion')   // this is the training objective
        err = ErrorPrediction        (labels, l3p, tag='evaluation')  // this also gets tracked
    ]
    SGD = [	
        epochSize = 0
        minibatchSize = 200
        maxEpochs = 5
        momentumPerMB = 0.9
        learningRatesPerMB = 0.1
        keepCheckPointFiles = true
    ]
    reader = [
        readerType = "CNTKTextFormatReader"
        file = "C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SequenceClassification\Data/Train.txt"            
        input = [            
            features=[
                alias = "x"                
                dim = 1               
                format = "dense"
            ]
            labels=[
                alias = "y"                
                dim = 5           
                format = "dense"
            ]
        ]
   ]    
outputPath = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160713043153.833416\Text_SequenceClassification@debug_gpu/output.txt"        
]

configparameters: seqcla.cntk:Write=[
    action="test"
    run=BrainScriptNetworkBuilder
    format = [
      sequencePrologue=%d\t|w.shape %x\n%d\t|w\s
      sampleSeparator=\n%d\t|w\s
      elementSeparator=\s
    ]
    modelFile = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160713043153.833416\Text_SequenceClassification@debug_gpu/Models/seqcla.dnn"    
    reader = [
            readerType = "CNTKTextFormatReader"
            file = "C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SequenceClassification\Data/Train.txt"            
            input = [            
                features=[
                    alias = "x"                
                    dim = 1               
                    format = "dense"
                ]
                labels=[
                    alias = "y"                
                    dim = 5           
                    format = "dense"
                ]
            ]
   ]    
outputPath = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160713043153.833416\Text_SequenceClassification@debug_gpu/output.txt"        
]

07/13/2016 04:43:58: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
07/13/2016 04:43:58: Commands: Train
07/13/2016 04:43:58: Precision = "float"
07/13/2016 04:43:58: CNTKModelPath: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160713043153.833416\Text_SequenceClassification@debug_gpu/Models/seqcla.dnn
07/13/2016 04:43:58: CNTKCommandTrainInfo: Train : 5
07/13/2016 04:43:58: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 5

07/13/2016 04:43:58: ##############################################################################
07/13/2016 04:43:58: #                                                                            #
07/13/2016 04:43:58: # Action "train"                                                             #
07/13/2016 04:43:58: #                                                                            #
07/13/2016 04:43:58: ##############################################################################

07/13/2016 04:43:58: CNTKCommandTrainBegin: Train

07/13/2016 04:43:59: Creating virgin network.

Post-processing network...

4 roots:
	ce = CrossEntropyWithSoftmax()
	err = ErrorPrediction()
	out = Pass()
	t = DynamicAxis()

Loop[0] --> Loop_l2.lstm.lstmState._privateInnards.ht -> 25 nodes

	l2.lstm.prevState.h	l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[1]	l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0]
	l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[1]	l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0]	l2.lstm.prevState.c
	l2.lstm.lstmState._privateInnards.ft._.PlusArgs[1]	l2.lstm.lstmState._privateInnards.ft._	l2.lstm.lstmState._privateInnards.ft
	l2.lstm.lstmState._privateInnards.bft	l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[1]	l2.lstm.lstmState._privateInnards.it._.PlusArgs[0]
	l2.lstm.lstmState._privateInnards.it._.PlusArgs[1]	l2.lstm.lstmState._privateInnards.it._	l2.lstm.lstmState._privateInnards.it
	l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[1]	l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z	l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1]
	l2.lstm.lstmState._privateInnards.bit	l2.lstm.lstmState._privateInnards.ct	l2.lstm.lstmState._privateInnards.ot._.PlusArgs[1]
	l2.lstm.lstmState._privateInnards.ot._	l2.lstm.lstmState._privateInnards.ot	l2.lstm.lstmState._privateInnards.ht.ElementTimesArgs[1]
	l2.lstm.lstmState._privateInnards.ht

Validating network. 71 nodes to process in pass 1.

Validating --> labels = InputValue() :  -> [5 x *]
Validating --> l3.z.W = LearnableParameter() :  -> [5 x 25]
Validating --> l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[0].PlusArgs[0] = LearnableParameter() :  -> [25]
Validating --> l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[0].PlusArgs[1].TimesArgs[0] = LearnableParameter() :  -> [25 x 50]
Validating --> features = InputValue() :  -> [1 x t]
Validating --> l1.embedding.x = LearnableParameter() :  -> [2000 x 50]
Validating --> l1.embedding = TransposeDimensions (l1.embedding.x) : [2000 x 50] -> [50 x 2000]
Validating --> l1.lookup = GatherPacked (features, l1.embedding) : [1 x t], [50 x 2000] -> [50 x t]
Validating --> l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[0].PlusArgs[1] = Times (l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[0].PlusArgs[1].TimesArgs[0], l1.lookup) : [25 x 50], [50 x t] -> [25 x t]
Validating --> l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[0] = Plus (l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[0].PlusArgs[0], l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[0].PlusArgs[1]) : [25], [25 x t] -> [25 x t]
Validating --> l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[1].TimesArgs[0] = LearnableParameter() :  -> [25 x 25]
Validating --> l2.lstm.lstmState._privateInnards.ot._.PlusArgs[1].ElementTimesArgs[0] = LearnableParameter() :  -> [25]
Validating --> l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[0].PlusArgs[0] = LearnableParameter() :  -> [25]
Validating --> l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[0].PlusArgs[1].TimesArgs[0] = LearnableParameter() :  -> [25 x 50]
Validating --> l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[0].PlusArgs[1] = Times (l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[0].PlusArgs[1].TimesArgs[0], l1.lookup) : [25 x 50], [50 x t] -> [25 x t]
Validating --> l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[0] = Plus (l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[0].PlusArgs[0], l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[0].PlusArgs[1]) : [25], [25 x t] -> [25 x t]
Validating --> l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[1].TimesArgs[0] = LearnableParameter() :  -> [25 x 25]
Validating --> l2.lstm.lstmState._privateInnards.ft._.PlusArgs[1].ElementTimesArgs[0] = LearnableParameter() :  -> [25]
Validating --> l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[0].PlusArgs[0] = LearnableParameter() :  -> [25]
Validating --> l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[0].PlusArgs[1].TimesArgs[0] = LearnableParameter() :  -> [25 x 50]
Validating --> l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[0].PlusArgs[1] = Times (l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[0].PlusArgs[1].TimesArgs[0], l1.lookup) : [25 x 50], [50 x t] -> [25 x t]
Validating --> l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[0] = Plus (l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[0].PlusArgs[0], l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[0].PlusArgs[1]) : [25], [25 x t] -> [25 x t]
Validating --> l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[1].TimesArgs[0] = LearnableParameter() :  -> [25 x 25]
Validating --> l2.lstm.lstmState._privateInnards.it._.PlusArgs[1].ElementTimesArgs[0] = LearnableParameter() :  -> [25]
Validating --> l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[0].PlusArgs[0] = LearnableParameter() :  -> [25]
Validating --> l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[0].PlusArgs[1].TimesArgs[0] = LearnableParameter() :  -> [25 x 50]
Validating --> l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[0].PlusArgs[1] = Times (l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[0].PlusArgs[1].TimesArgs[0], l1.lookup) : [25 x 50], [50 x t] -> [25 x t]
Validating --> l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[0] = Plus (l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[0].PlusArgs[0], l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[0].PlusArgs[1]) : [25], [25 x t] -> [25 x t]
Validating --> l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[1].TimesArgs[0] = LearnableParameter() :  -> [25 x 25]
Validating --> l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[1] = Times (l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[1].TimesArgs[0], l2.lstm.prevState.h) : [25 x 25], [0] -> [25]
Validating --> l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0] = Plus (l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[0], l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[1]) : [25 x t], [25] -> [25 x t]
Validating --> l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[1] = Times (l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[1].TimesArgs[0], l2.lstm.prevState.h) : [25 x 25], [0] -> [25]
Validating --> l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0] = Plus (l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[0], l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[1]) : [25 x t], [25] -> [25 x t]
Validating --> l2.lstm.lstmState._privateInnards.ft._.PlusArgs[1] = ElementTimes (l2.lstm.lstmState._privateInnards.ft._.PlusArgs[1].ElementTimesArgs[0], l2.lstm.prevState.c) : [25], [0] -> [25]
Validating --> l2.lstm.lstmState._privateInnards.ft._ = Plus (l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0], l2.lstm.lstmState._privateInnards.ft._.PlusArgs[1]) : [25 x t], [25] -> [25 x t]
Validating --> l2.lstm.lstmState._privateInnards.ft = Sigmoid (l2.lstm.lstmState._privateInnards.ft._) : [25 x t] -> [25 x t]
Validating --> l2.lstm.lstmState._privateInnards.bft = ElementTimes (l2.lstm.lstmState._privateInnards.ft, l2.lstm.prevState.c) : [25 x t], [0] -> [25 x t]
Validating --> l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[1] = Times (l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[1].TimesArgs[0], l2.lstm.prevState.h) : [25 x 25], [0] -> [25]
Validating --> l2.lstm.lstmState._privateInnards.it._.PlusArgs[0] = Plus (l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[0], l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[1]) : [25 x t], [25] -> [25 x t]
Validating --> l2.lstm.lstmState._privateInnards.it._.PlusArgs[1] = ElementTimes (l2.lstm.lstmState._privateInnards.it._.PlusArgs[1].ElementTimesArgs[0], l2.lstm.prevState.c) : [25], [0] -> [25]
Validating --> l2.lstm.lstmState._privateInnards.it._ = Plus (l2.lstm.lstmState._privateInnards.it._.PlusArgs[0], l2.lstm.lstmState._privateInnards.it._.PlusArgs[1]) : [25 x t], [25] -> [25 x t]
Validating --> l2.lstm.lstmState._privateInnards.it = Sigmoid (l2.lstm.lstmState._privateInnards.it._) : [25 x t] -> [25 x t]
Validating --> l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[1] = Times (l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[1].TimesArgs[0], l2.lstm.prevState.h) : [25 x 25], [0] -> [25]
Validating --> l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z = Plus (l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[0], l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[1]) : [25 x t], [25] -> [25 x t]
Validating --> l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1] = Tanh (l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z) : [25 x t] -> [25 x t]
Validating --> l2.lstm.lstmState._privateInnards.bit = ElementTimes (l2.lstm.lstmState._privateInnards.it, l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1]) : [25 x t], [25 x t] -> [25 x t]
Validating --> l2.lstm.lstmState._privateInnards.ct = Plus (l2.lstm.lstmState._privateInnards.bft, l2.lstm.lstmState._privateInnards.bit) : [25 x t], [25 x t] -> [25 x t]
Validating --> l2.lstm.lstmState._privateInnards.ot._.PlusArgs[1] = ElementTimes (l2.lstm.lstmState._privateInnards.ot._.PlusArgs[1].ElementTimesArgs[0], l2.lstm.lstmState._privateInnards.ct) : [25], [25 x t] -> [25 x t]
Validating --> l2.lstm.lstmState._privateInnards.ot._ = Plus (l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0], l2.lstm.lstmState._privateInnards.ot._.PlusArgs[1]) : [25 x t], [25 x t] -> [25 x t]
Validating --> l2.lstm.lstmState._privateInnards.ot = Sigmoid (l2.lstm.lstmState._privateInnards.ot._) : [25 x t] -> [25 x t]
Validating --> l2.lstm.lstmState._privateInnards.ht.ElementTimesArgs[1] = Tanh (l2.lstm.lstmState._privateInnards.ct) : [25 x t] -> [25 x t]
Validating --> l2.lstm.lstmState._privateInnards.ht = ElementTimes (l2.lstm.lstmState._privateInnards.ot, l2.lstm.lstmState._privateInnards.ht.ElementTimesArgs[1]) : [25 x t], [25 x t] -> [25 x t]
Validating --> l2.result.beginFlags.input.z.ElementTimesArgs[0] = Slice (l2.lstm.lstmState._privateInnards.ht) : [25 x t] -> [1 x t]
Validating --> BS.Constants.Zero = LearnableParameter() :  -> [1]
Validating --> l2.result.beginFlags.input.z = ElementTimes (l2.result.beginFlags.input.z.ElementTimesArgs[0], BS.Constants.Zero) : [1 x t], [1] -> [1 x t]
Validating --> l2.result.beginFlags.input = SumColumnElements (l2.result.beginFlags.input.z) : [1 x t] -> [1 x t]
Validating --> l2.result.beginFlags = FutureValue (l2.result.beginFlags.input) : [1 x t] -> [1 x t]
Validating --> l2.result.out.indexSequence.indexSequence = Where (l2.result.beginFlags) : [1 x t] -> [1 x WhereNodeAxis]
Validating --> l2.result.out.indexSequence = PackedIndex (l2.lstm.lstmState._privateInnards.ht, l2.result.out.indexSequence.indexSequence) : [25 x t], [1 x WhereNodeAxis] -> [1 x WhereNodeAxis]
Validating --> l2.result.out = GatherPacked (l2.result.out.indexSequence, l2.lstm.lstmState._privateInnards.ht) : [1 x WhereNodeAxis], [25 x t] -> [25 x WhereNodeAxis]
Validating --> l3.z.z.PlusArgs[0] = Times (l3.z.W, l2.result.out) : [5 x 25], [25 x WhereNodeAxis] -> [5 x WhereNodeAxis]
Validating --> l3.z.B = LearnableParameter() :  -> [5 x 1]
Validating --> l3.z.z = Plus (l3.z.z.PlusArgs[0], l3.z.B) : [5 x WhereNodeAxis], [5 x 1] -> [5 x 1 x WhereNodeAxis]
Validating --> l3.act = Pass (l3.z.z) : [5 x 1 x WhereNodeAxis] -> [5 x 1 x WhereNodeAxis]
Validating --> l3p = ReconcileDynamicAxis (l3.act, labels) : [5 x 1 x WhereNodeAxis], [5 x *] -> [5 x 1 x *]
Validating --> ce = CrossEntropyWithSoftmax (labels, l3p) : [5 x *], [5 x 1 x *] -> [1]
Validating --> err = ErrorPrediction (labels, l3p) : [5 x *], [5 x 1 x *] -> [1]
Validating --> out = Pass (l3.act) : [5 x 1 x WhereNodeAxis] -> [5 x 1 x WhereNodeAxis]
Validating --> t = DynamicAxis() :  -> [1 x 1 x t]

Validating network. 49 nodes to process in pass 2.

Validating --> l2.lstm.prevState.h = PastValue (l2.lstm.lstmState._privateInnards.ht) : [25 x t] -> [25 x t]
Validating --> l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[1] = Times (l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[1].TimesArgs[0], l2.lstm.prevState.h) : [25 x 25], [25 x t] -> [25 x t]
Validating --> l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[1] = Times (l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[1].TimesArgs[0], l2.lstm.prevState.h) : [25 x 25], [25 x t] -> [25 x t]
Validating --> l2.lstm.prevState.c = PastValue (l2.lstm.lstmState._privateInnards.ct) : [25 x t] -> [25 x t]
Validating --> l2.lstm.lstmState._privateInnards.ft._.PlusArgs[1] = ElementTimes (l2.lstm.lstmState._privateInnards.ft._.PlusArgs[1].ElementTimesArgs[0], l2.lstm.prevState.c) : [25], [25 x t] -> [25 x t]
Validating --> l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[1] = Times (l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[1].TimesArgs[0], l2.lstm.prevState.h) : [25 x 25], [25 x t] -> [25 x t]
Validating --> l2.lstm.lstmState._privateInnards.it._.PlusArgs[1] = ElementTimes (l2.lstm.lstmState._privateInnards.it._.PlusArgs[1].ElementTimesArgs[0], l2.lstm.prevState.c) : [25], [25 x t] -> [25 x t]
Validating --> l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[1] = Times (l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[1].TimesArgs[0], l2.lstm.prevState.h) : [25 x 25], [25 x t] -> [25 x t]

Validating network. 8 nodes to process in pass 3.


Validating network, final pass.



69 out of 71 nodes do not share the minibatch layout with the input data.

Post-processing network complete.

07/13/2016 04:44:02: Created model with 71 nodes on GPU 0.

07/13/2016 04:44:02: Training criterion node(s):
07/13/2016 04:44:02: 	ce = CrossEntropyWithSoftmax

07/13/2016 04:44:02: Evaluation criterion node(s):

07/13/2016 04:44:02: 	err = ErrorPrediction


Allocating matrices for forward and/or backward propagation.

Memory Sharing Structure:

0000000000000000: {[BS.Constants.Zero Gradient[1]] [err Gradient[1]] [features Gradient[1 x t]] [l1.embedding Gradient[50 x 2000]] [l1.embedding.x Gradient[2000 x 50]] [l1.lookup Gradient[50 x t]] [labels Gradient[5 x *]] [out Gradient[5 x 1 x WhereNodeAxis]] [t Gradient[1 x 1 x t]] [t Value[1 x 1 x t]] }
000000C695085B60: {[l2.lstm.lstmState._privateInnards.ft._.PlusArgs[1] Value[25 x t]] }
000000C695085C30: {[l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[1].TimesArgs[0] Value[25 x 25]] }
000000C695085D00: {[l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[0].PlusArgs[0] Gradient[25]] [l2.lstm.prevState.h Value[25 x t]] }
000000C695085EA0: {[l2.lstm.lstmState._privateInnards.bft Value[25 x t]] }
000000C695086040: {[l2.lstm.lstmState._privateInnards.ot._.PlusArgs[1].ElementTimesArgs[0] Value[25]] }
000000C695086110: {[l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[1] Value[25 x t]] }
000000C6950862B0: {[l2.lstm.lstmState._privateInnards.ft._ Value[25 x t]] }
000000C695086380: {[l2.lstm.lstmState._privateInnards.it._.PlusArgs[0] Value[25 x t]] }
000000C695086450: {[l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z Value[25 x t]] }
000000C695086520: {[l2.lstm.lstmState._privateInnards.ot._.PlusArgs[1] Value[25 x t]] }
000000C6950866C0: {[l2.lstm.lstmState._privateInnards.ot Value[25 x t]] }
000000C695086790: {[l2.lstm.lstmState._privateInnards.ht.ElementTimesArgs[1] Value[25 x t]] }
000000C695086860: {[l2.lstm.lstmState._privateInnards.ht Value[25 x t]] }
000000C695086930: {[l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[1].TimesArgs[0] Value[25 x 25]] }
000000C695086A00: {[l2.lstm.lstmState._privateInnards.ot._ Value[25 x t]] }
000000C695086AD0: {[l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[0].PlusArgs[1].TimesArgs[0] Value[25 x 50]] }
000000C695086BA0: {[l2.lstm.lstmState._privateInnards.ct Value[25 x t]] }
000000C695086E10: {[features Value[1 x t]] }
000000C695086EE0: {[l1.embedding.x Value[2000 x 50]] }
000000C695086FB0: {[l2.lstm.lstmState._privateInnards.it._ Value[25 x t]] }
000000C695087080: {[l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1] Value[25 x t]] }
000000C695087150: {[l2.result.out.indexSequence Value[1 x WhereNodeAxis]] }
000000C695087220: {[l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[0].PlusArgs[0] Value[25]] }
000000C6950872F0: {[l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[0].PlusArgs[0] Value[25]] }
000000C6950873C0: {[l2.lstm.lstmState._privateInnards.it._.PlusArgs[1] Value[25 x t]] }
000000C695087560: {[l2.lstm.lstmState._privateInnards.ft Value[25 x t]] }
000000C695087630: {[l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[1] Value[25 x t]] }
000000C6950877D0: {[l3.z.W Value[5 x 25]] }
000000C6950878A0: {[l2.lstm.lstmState._privateInnards.it Value[25 x t]] }
000000C695087970: {[l2.lstm.lstmState._privateInnards.bit Value[25 x t]] }
000000C695087A40: {[l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[0].PlusArgs[1].TimesArgs[0] Value[25 x 50]] }
000000C697C3A140: {[l2.lstm.lstmState._privateInnards.it._.PlusArgs[1].ElementTimesArgs[0] Value[25]] }
000000C697C3A210: {[l2.result.out.indexSequence.indexSequence Value[1 x WhereNodeAxis]] }
000000C697C3A2E0: {[l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[0] Value[25 x t]] [l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[0].PlusArgs[1].TimesArgs[0] Gradient[25 x 50]] }
000000C697C3A3B0: {[l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0] Value[25 x t]] }
000000C697C3A480: {[l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[0].PlusArgs[1] Value[25 x t]] }
000000C697C3A620: {[out Value[5 x 1 x WhereNodeAxis]] }
000000C697C3A6F0: {[l3.z.B Value[5 x 1]] }
000000C697C3A7C0: {[l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0] Value[25 x t]] }
000000C697C3A890: {[l2.lstm.lstmState._privateInnards.ft._.PlusArgs[1].ElementTimesArgs[0] Value[25]] }
000000C697C3A960: {[l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[0].PlusArgs[1].TimesArgs[0] Value[25 x 50]] }
000000C697C3ACA0: {[l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[0].PlusArgs[1] Value[25 x t]] [l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[0].PlusArgs[0] Gradient[25]] }
000000C697C3AD70: {[BS.Constants.Zero Value[1]] }
000000C697C3AF10: {[l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[0].PlusArgs[1].TimesArgs[0] Value[25 x 50]] }
000000C697C3AFE0: {[l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[0].PlusArgs[1] Value[25 x t]] [l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[0].PlusArgs[0] Gradient[25]] }
000000C697C3B0B0: {[err Value[1]] }
000000C697C3B180: {[l1.embedding Value[50 x 2000]] }
000000C697C3B250: {[l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[0].PlusArgs[0] Gradient[25]] [l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[0].PlusArgs[1] Value[25 x t]] }
000000C697C3B320: {[l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[0] Value[25 x t]] [l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[0].PlusArgs[1].TimesArgs[0] Gradient[25 x 50]] }
000000C697C3B4C0: {[l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[0].PlusArgs[0] Value[25]] }
000000C697C3B590: {[l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[1].TimesArgs[0] Value[25 x 25]] }
000000C697C3B660: {[l1.lookup Value[50 x t]] }
000000C697C3B730: {[l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[0] Value[25 x t]] [l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[0].PlusArgs[1].TimesArgs[0] Gradient[25 x 50]] }
000000C697C3B800: {[l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[0] Value[25 x t]] [l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[0].PlusArgs[1].TimesArgs[0] Gradient[25 x 50]] }
000000C697C3B8D0: {[l2.lstm.prevState.c Value[25 x t]] }
000000C697C3B9A0: {[l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[0].PlusArgs[0] Value[25]] }
000000C697C3BB40: {[l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[1] Value[25 x t]] }
000000C697C3BC10: {[l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[1].TimesArgs[0] Value[25 x 25]] }
000000C697C3BDB0: {[l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[1] Value[25 x t]] }
000000C697C3BE80: {[ce Value[1]] }
000000C697C3BF50: {[l2.lstm.lstmState._privateInnards.ot._ Gradient[25 x t]] [l2.result.beginFlags Value[1 x t]] [l2.result.beginFlags.input.z Gradient[1 x t]] }
000000C697C740C0: {[ce Gradient[1]] }
000000C697C74190: {[l2.lstm.lstmState._privateInnards.ht.ElementTimesArgs[1] Gradient[25 x t]] [l2.result.beginFlags.input Value[1 x t]] [l2.result.beginFlags.input.z.ElementTimesArgs[0] Gradient[1 x t]] }
000000C697C74260: {[l2.lstm.lstmState._privateInnards.bit Gradient[25 x t]] }
000000C697C74330: {[l2.lstm.lstmState._privateInnards.it._.PlusArgs[0] Gradient[25 x t]] }
000000C697C744D0: {[l2.lstm.lstmState._privateInnards.ot._.PlusArgs[1] Gradient[25 x t]] [l2.result.beginFlags Gradient[1 x t]] [l2.result.out.indexSequence Gradient[1 x WhereNodeAxis]] [l3.z.z.PlusArgs[0] Value[5 x WhereNodeAxis]] }
000000C697C745A0: {[l2.lstm.lstmState._privateInnards.it Gradient[25 x t]] }
000000C697C74670: {[l3.z.W Gradient[5 x 25]] [l3.z.z Value[5 x 1 x WhereNodeAxis]] }
000000C697C74740: {[l2.lstm.lstmState._privateInnards.ot Gradient[25 x t]] [l2.result.beginFlags.input.z.ElementTimesArgs[0] Value[1 x t]] }
000000C697C74810: {[l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[1].TimesArgs[0] Gradient[25 x 25]] }
000000C697C748E0: {[l2.lstm.lstmState._privateInnards.ot._.PlusArgs[1].ElementTimesArgs[0] Gradient[25]] [l2.result.out Gradient[25 x WhereNodeAxis]] [l3.z.z Gradient[5 x 1 x WhereNodeAxis]] [l3p Value[5 x 1 x *]] }
000000C697C749B0: {[l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[0] Gradient[25 x t]] }
000000C697C74A80: {[l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[1].TimesArgs[0] Gradient[25 x 25]] }
000000C697C74B50: {[l2.lstm.lstmState._privateInnards.ht Gradient[25 x t]] [l3.act Value[5 x 1 x WhereNodeAxis]] [l3.z.z.PlusArgs[0] Gradient[5 x WhereNodeAxis]] }
000000C697C74C20: {[l2.lstm.prevState.c Gradient[25 x t]] }
000000C697C74CF0: {[l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1] Gradient[25 x t]] }
000000C697C74F60: {[l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[0] Gradient[25 x t]] }
000000C697C75030: {[l2.lstm.lstmState._privateInnards.bft Gradient[25 x t]] [l3p Gradient[5 x 1 x *]] }
000000C697C75100: {[l2.lstm.lstmState._privateInnards.ft Gradient[25 x t]] }
000000C697C751D0: {[l2.lstm.lstmState._privateInnards.ct Gradient[25 x t]] [l2.result.beginFlags.input.z Value[1 x t]] }
000000C697C752A0: {[l3.act Gradient[5 x 1 x WhereNodeAxis]] [l3.z.B Gradient[5 x 1]] }
000000C697C75440: {[l2.lstm.lstmState._privateInnards.ft._ Gradient[25 x t]] }
000000C697C75510: {[l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[0].PlusArgs[1] Gradient[25 x t]] [l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[0].PlusArgs[1] Gradient[25 x t]] [l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[0].PlusArgs[1] Gradient[25 x t]] [l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[0].PlusArgs[1] Gradient[25 x t]] [l2.lstm.prevState.h Gradient[25 x t]] }
000000C697C755E0: {[l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[1] Gradient[25 x t]] }
000000C697C756B0: {[l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0] Gradient[25 x t]] }
000000C697C75780: {[l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[1] Gradient[25 x t]] }
000000C697C75850: {[l2.lstm.lstmState._privateInnards.ft._.PlusArgs[1] Gradient[25 x t]] }
000000C697C759F0: {[l2.lstm.lstmState._privateInnards.ft._.PlusArgs[1].ElementTimesArgs[0] Gradient[25]] }
000000C697C75AC0: {[l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[0] Gradient[25 x t]] }
000000C697C75B90: {[l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0] Gradient[25 x t]] [l2.result.beginFlags.input Gradient[1 x t]] [l2.result.out Value[25 x WhereNodeAxis]] [l2.result.out.indexSequence.indexSequence Gradient[1 x WhereNodeAxis]] }
000000C697C75C60: {[l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z Gradient[25 x t]] }
000000C697C75E00: {[l2.lstm.lstmState._privateInnards.it._ Gradient[25 x t]] }
000000C697C75ED0: {[l2.lstm.lstmState._privateInnards.it._.PlusArgs[1] Gradient[25 x t]] }
000000C697C75FA0: {[l2.lstm.lstmState._privateInnards.it._.PlusArgs[1].ElementTimesArgs[0] Gradient[25]] }
000000C697C7ED30: {[l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[1].TimesArgs[0] Gradient[25 x 25]] }
000000C697C7F7C0: {[l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[0] Gradient[25 x t]] }
000000C697C80590: {[l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[1] Gradient[25 x t]] }
000000C697C80C10: {[l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[1] Gradient[25 x t]] }
000000C697C80E80: {[l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[1].TimesArgs[0] Gradient[25 x 25]] }
000000C6FCC337D0: {[labels Value[5 x *]] }

07/13/2016 04:44:02: No PreCompute nodes found, skipping PreCompute step.

07/13/2016 04:44:02: Starting Epoch 1: learning rate per sample = 0.000500  effective momentum = 0.900000  momentum as time constant = 1898.2 samples
BlockRandomizer::StartEpoch: epoch 0: frames [0..5433] (first sequence at sample 0), data subset 0 of 1

07/13/2016 04:44:02: Starting minibatch loop.
WARNING: The same matrix with dim [1, 47] has been transferred between different devices for 20 times.
07/13/2016 04:44:05: Finished Epoch[ 1 of 5]: [Training] ce = 1.58162725 * 1247; err = 0.48596632 * 1247; totalSamplesSeen = 1247; learningRatePerSample = 0.00050000002; epochTime=3.30526s
07/13/2016 04:44:05: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160713043153.833416\Text_SequenceClassification@debug_gpu/Models/seqcla.dnn.1'

07/13/2016 04:44:05: Starting Epoch 2: learning rate per sample = 0.000500  effective momentum = 0.900000  momentum as time constant = 1898.2 samples
BlockRandomizer::StartEpoch: epoch 1: frames [5433..10866] (first sequence at sample 5433), data subset 0 of 1

07/13/2016 04:44:05: Starting minibatch loop.
07/13/2016 04:44:08: Finished Epoch[ 2 of 5]: [Training] ce = 1.49505924 * 1247; err = 0.44667201 * 1247; totalSamplesSeen = 2494; learningRatePerSample = 0.00050000002; epochTime=2.8819s
07/13/2016 04:44:08: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160713043153.833416\Text_SequenceClassification@debug_gpu/Models/seqcla.dnn.2'

07/13/2016 04:44:08: Starting Epoch 3: learning rate per sample = 0.000500  effective momentum = 0.900000  momentum as time constant = 1898.2 samples
BlockRandomizer::StartEpoch: epoch 2: frames [10866..16299] (first sequence at sample 10866), data subset 0 of 1

07/13/2016 04:44:08: Starting minibatch loop.
07/13/2016 04:44:11: Finished Epoch[ 3 of 5]: [Training] ce = 1.42226891 * 1247; err = 0.44667201 * 1247; totalSamplesSeen = 3741; learningRatePerSample = 0.00050000002; epochTime=2.90767s
07/13/2016 04:44:11: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160713043153.833416\Text_SequenceClassification@debug_gpu/Models/seqcla.dnn.3'

07/13/2016 04:44:11: Starting Epoch 4: learning rate per sample = 0.000500  effective momentum = 0.900000  momentum as time constant = 1898.2 samples
BlockRandomizer::StartEpoch: epoch 3: frames [16299..21732] (first sequence at sample 16299), data subset 0 of 1

07/13/2016 04:44:11: Starting minibatch loop.
07/13/2016 04:44:14: Finished Epoch[ 4 of 5]: [Training] ce = 1.36981823 * 1247; err = 0.44667201 * 1247; totalSamplesSeen = 4988; learningRatePerSample = 0.00050000002; epochTime=2.89412s
07/13/2016 04:44:14: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160713043153.833416\Text_SequenceClassification@debug_gpu/Models/seqcla.dnn.4'

07/13/2016 04:44:14: Starting Epoch 5: learning rate per sample = 0.000500  effective momentum = 0.900000  momentum as time constant = 1898.2 samples
BlockRandomizer::StartEpoch: epoch 4: frames [21732..27165] (first sequence at sample 21732), data subset 0 of 1

07/13/2016 04:44:14: Starting minibatch loop.
07/13/2016 04:44:17: Finished Epoch[ 5 of 5]: [Training] ce = 1.33148531 * 1247; err = 0.44667201 * 1247; totalSamplesSeen = 6235; learningRatePerSample = 0.00050000002; epochTime=2.89135s
07/13/2016 04:44:17: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160713043153.833416\Text_SequenceClassification@debug_gpu/Models/seqcla.dnn'
07/13/2016 04:44:17: CNTKCommandTrainEnd: Train

07/13/2016 04:44:17: Action "train" complete.

07/13/2016 04:44:17: __COMPLETED__
=== Deleting last epoch data
==== Re-running from checkpoint
=== Running /cygdrive/c/jenkins/workspace/CNTK-Test-Windows-W1/x64/debug/cntk.exe configFile=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SequenceClassification\Config/seqcla.cntk currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SequenceClassification\Data RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160713043153.833416\Text_SequenceClassification@debug_gpu DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SequenceClassification\Data ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SequenceClassification\Config OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160713043153.833416\Text_SequenceClassification@debug_gpu DeviceId=0 timestamping=true makeMode=true
-------------------------------------------------------------------
Build info: 

		Built time: Jul 13 2016 03:39:41
		Last modified date: Fri Jul  8 10:29:45 2016
		Build type: Debug
		Build target: GPU
		With 1bit-SGD: no
		Math lib: mkl
		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.5
		CUB_PATH: C:\src\cub-1.4.1
		CUDNN_PATH: c:\NVIDIA\cudnn-4.0\cuda
		Build Branch: HEAD
		Build SHA1: 50bb4c8afbc87c14548a5b5f315a064186a5cb5f
		Built by svcphil on liana-08-w
		Build Path: c:\jenkins\workspace\CNTK-Build-Windows\Source\CNTK\
-------------------------------------------------------------------
Changed current directory to C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SequenceClassification\Data
07/13/2016 04:44:20: -------------------------------------------------------------------
07/13/2016 04:44:20: Build info: 

07/13/2016 04:44:20: 		Built time: Jul 13 2016 03:39:41
07/13/2016 04:44:20: 		Last modified date: Fri Jul  8 10:29:45 2016
07/13/2016 04:44:20: 		Build type: Debug
07/13/2016 04:44:20: 		Build target: GPU
07/13/2016 04:44:20: 		With 1bit-SGD: no
07/13/2016 04:44:20: 		Math lib: mkl
07/13/2016 04:44:20: 		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.5
07/13/2016 04:44:20: 		CUB_PATH: C:\src\cub-1.4.1
07/13/2016 04:44:20: 		CUDNN_PATH: c:\NVIDIA\cudnn-4.0\cuda
07/13/2016 04:44:20: 		Build Branch: HEAD
07/13/2016 04:44:20: 		Build SHA1: 50bb4c8afbc87c14548a5b5f315a064186a5cb5f
07/13/2016 04:44:20: 		Built by svcphil on liana-08-w
07/13/2016 04:44:20: 		Build Path: c:\jenkins\workspace\CNTK-Build-Windows\Source\CNTK\
07/13/2016 04:44:20: -------------------------------------------------------------------
07/13/2016 04:44:23: -------------------------------------------------------------------
07/13/2016 04:44:23: GPU info:

07/13/2016 04:44:23: 		Device[0]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3072 MB
07/13/2016 04:44:23: 		Device[1]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3072 MB
07/13/2016 04:44:23: 		Device[2]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3072 MB
07/13/2016 04:44:23: 		Device[3]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3072 MB
07/13/2016 04:44:23: -------------------------------------------------------------------

07/13/2016 04:44:23: Running on DPHAIM-24 at 2016/07/13 04:44:23
07/13/2016 04:44:23: Command line: 
C:\jenkins\workspace\CNTK-Test-Windows-W1\x64\debug\cntk.exe  configFile=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SequenceClassification\Config/seqcla.cntk  currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SequenceClassification\Data  RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160713043153.833416\Text_SequenceClassification@debug_gpu  DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SequenceClassification\Data  ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SequenceClassification\Config  OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160713043153.833416\Text_SequenceClassification@debug_gpu  DeviceId=0  timestamping=true  makeMode=true



07/13/2016 04:44:23: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
07/13/2016 04:44:23: RootDir = ".."
ConfigDir = "$RootDir$/Config"
DataDir   = "$RootDir$/Data"
OutputDir = "$RootDir$/Output"
ModelDir  = "$OutputDir$/Models"
command=Train 
deviceId = $DeviceId$
modelPath="$ModelDir$/seqcla.dnn"
Train=[
    action="train"
    run=BrainScriptNetworkBuilder
    BrainScriptNetworkBuilder=[
        Layers = [
            EmbeddingLayer(input, vocabSize, embeddingDim, embeddingPath) = [
                embedding = Transpose(LearnableParameter(vocabSize, embeddingDim, learningRateMultiplier = 0.0, init = 'fromFile', initFromFilePath = embeddingPath))          
                lookup = GatherPacked(features, embedding)
            ].lookup
            DenseLayer(input, inputSize, outputSize, activation) = [
               z = BFF(input, outputSize, inputSize).z
               act = activation(z)
            ].act
            LSTMLayer (input, inputSize, outputSize, cellSize, selector) = [ 
               lstm = BS.RNNs.RecurrentLSTMP (outputSize, cellDim=cellSize, input, inputDim=inputSize).h
               result = selector(lstm)
            ].result
        ]        
        // LSTM params
        lstmDim = 25
        cellDim = 25
        // model
        numLabels = 5        
        vocab = 2000
        embedDim = 50        
        // set up features and labels
        t = DynamicAxis()
features = Input(1, dynamicAxis=t)   
labels   = Input(numLabels)          
        // load the pre-learned word embedding matrix
        l1 = Layers.EmbeddingLayer(features, vocab, embedDim, 'embeddingmatrix.txt')
        l2 = Layers.LSTMLayer(l1, embedDim, lstmDim, cellDim, BS.Sequences.Last)
        l3 = Layers.DenseLayer(l2, lstmDim, numLabels, Pass)
        out = Pass(l3, tag='output')   
        // Make sure the trainer understands that the time dimension of l3 is actually the same as that of labels.
        l3p = ReconcileDynamicAxis(l3, labels)
        // training criteria
        ce  = CrossEntropyWithSoftmax(labels, l3p, tag='criterion')   // this is the training objective
        err = ErrorPrediction        (labels, l3p, tag='evaluation')  // this also gets tracked
    ]
    SGD = [	
        epochSize = 0
        minibatchSize = 200
        maxEpochs = 5
        momentumPerMB = 0.9
        learningRatesPerMB = 0.1
        keepCheckPointFiles = true
    ]
    reader = [
        readerType = "CNTKTextFormatReader"
        file = "$DataDir$/Train.txt"            
        input = [            
            features=[
                alias = "x"                
                dim = 1               
                format = "dense"
            ]
            labels=[
                alias = "y"                
                dim = 5           
                format = "dense"
            ]
        ]
   ]    
outputPath = "$OutputDir$/output.txt"        
]
Write=[
    action="test"
    run=BrainScriptNetworkBuilder
    format = [
      sequencePrologue=%d\t|w.shape %x\n%d\t|w\s
      sampleSeparator=\n%d\t|w\s
      elementSeparator=\s
    ]
    modelFile = "$ModelDir$/seqcla.dnn"    
    reader = [
            readerType = "CNTKTextFormatReader"
            file = "$DataDir$/Train.txt"            
            input = [            
                features=[
                    alias = "x"                
                    dim = 1               
                    format = "dense"
                ]
                labels=[
                    alias = "y"                
                    dim = 5           
                    format = "dense"
                ]
            ]
   ]    
outputPath = "$OutputDir$/output.txt"        
]
currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SequenceClassification\Data
RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160713043153.833416\Text_SequenceClassification@debug_gpu
DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SequenceClassification\Data
ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SequenceClassification\Config
OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160713043153.833416\Text_SequenceClassification@debug_gpu
DeviceId=0
timestamping=true
makeMode=true

07/13/2016 04:44:23: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<

07/13/2016 04:44:23: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
07/13/2016 04:44:23: RootDir = ".."
ConfigDir = "../Config"
DataDir   = "../Data"
OutputDir = "../Output"
ModelDir  = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160713043153.833416\Text_SequenceClassification@debug_gpu/Models"
command=Train 
deviceId = 0
modelPath="C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160713043153.833416\Text_SequenceClassification@debug_gpu/Models/seqcla.dnn"
Train=[
    action="train"
    run=BrainScriptNetworkBuilder
    BrainScriptNetworkBuilder=[
        Layers = [
            EmbeddingLayer(input, vocabSize, embeddingDim, embeddingPath) = [
                embedding = Transpose(LearnableParameter(vocabSize, embeddingDim, learningRateMultiplier = 0.0, init = 'fromFile', initFromFilePath = embeddingPath))          
                lookup = GatherPacked(features, embedding)
            ].lookup
            DenseLayer(input, inputSize, outputSize, activation) = [
               z = BFF(input, outputSize, inputSize).z
               act = activation(z)
            ].act
            LSTMLayer (input, inputSize, outputSize, cellSize, selector) = [ 
               lstm = BS.RNNs.RecurrentLSTMP (outputSize, cellDim=cellSize, input, inputDim=inputSize).h
               result = selector(lstm)
            ].result
        ]        
        // LSTM params
        lstmDim = 25
        cellDim = 25
        // model
        numLabels = 5        
        vocab = 2000
        embedDim = 50        
        // set up features and labels
        t = DynamicAxis()
features = Input(1, dynamicAxis=t)   
labels   = Input(numLabels)          
        // load the pre-learned word embedding matrix
        l1 = Layers.EmbeddingLayer(features, vocab, embedDim, 'embeddingmatrix.txt')
        l2 = Layers.LSTMLayer(l1, embedDim, lstmDim, cellDim, BS.Sequences.Last)
        l3 = Layers.DenseLayer(l2, lstmDim, numLabels, Pass)
        out = Pass(l3, tag='output')   
        // Make sure the trainer understands that the time dimension of l3 is actually the same as that of labels.
        l3p = ReconcileDynamicAxis(l3, labels)
        // training criteria
        ce  = CrossEntropyWithSoftmax(labels, l3p, tag='criterion')   // this is the training objective
        err = ErrorPrediction        (labels, l3p, tag='evaluation')  // this also gets tracked
    ]
    SGD = [	
        epochSize = 0
        minibatchSize = 200
        maxEpochs = 5
        momentumPerMB = 0.9
        learningRatesPerMB = 0.1
        keepCheckPointFiles = true
    ]
    reader = [
        readerType = "CNTKTextFormatReader"
        file = "C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SequenceClassification\Data/Train.txt"            
        input = [            
            features=[
                alias = "x"                
                dim = 1               
                format = "dense"
            ]
            labels=[
                alias = "y"                
                dim = 5           
                format = "dense"
            ]
        ]
   ]    
outputPath = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160713043153.833416\Text_SequenceClassification@debug_gpu/output.txt"        
]
Write=[
    action="test"
    run=BrainScriptNetworkBuilder
    format = [
      sequencePrologue=%d\t|w.shape %x\n%d\t|w\s
      sampleSeparator=\n%d\t|w\s
      elementSeparator=\s
    ]
    modelFile = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160713043153.833416\Text_SequenceClassification@debug_gpu/Models/seqcla.dnn"    
    reader = [
            readerType = "CNTKTextFormatReader"
            file = "C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SequenceClassification\Data/Train.txt"            
            input = [            
                features=[
                    alias = "x"                
                    dim = 1               
                    format = "dense"
                ]
                labels=[
                    alias = "y"                
                    dim = 5           
                    format = "dense"
                ]
            ]
   ]    
outputPath = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160713043153.833416\Text_SequenceClassification@debug_gpu/output.txt"        
]
currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SequenceClassification\Data
RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160713043153.833416\Text_SequenceClassification@debug_gpu
DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SequenceClassification\Data
ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SequenceClassification\Config
OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160713043153.833416\Text_SequenceClassification@debug_gpu
DeviceId=0
timestamping=true
makeMode=true

07/13/2016 04:44:23: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<

07/13/2016 04:44:23: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
configparameters: seqcla.cntk:command=Train
configparameters: seqcla.cntk:ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SequenceClassification\Config
configparameters: seqcla.cntk:currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SequenceClassification\Data
configparameters: seqcla.cntk:DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SequenceClassification\Data
configparameters: seqcla.cntk:deviceId=0
configparameters: seqcla.cntk:makeMode=true
configparameters: seqcla.cntk:ModelDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160713043153.833416\Text_SequenceClassification@debug_gpu/Models
configparameters: seqcla.cntk:modelPath=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160713043153.833416\Text_SequenceClassification@debug_gpu/Models/seqcla.dnn
configparameters: seqcla.cntk:OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160713043153.833416\Text_SequenceClassification@debug_gpu
configparameters: seqcla.cntk:RootDir=..
configparameters: seqcla.cntk:RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160713043153.833416\Text_SequenceClassification@debug_gpu
configparameters: seqcla.cntk:timestamping=true
configparameters: seqcla.cntk:Train=[
    action="train"
    run=BrainScriptNetworkBuilder
    BrainScriptNetworkBuilder=[
        Layers = [
            EmbeddingLayer(input, vocabSize, embeddingDim, embeddingPath) = [
                embedding = Transpose(LearnableParameter(vocabSize, embeddingDim, learningRateMultiplier = 0.0, init = 'fromFile', initFromFilePath = embeddingPath))          
                lookup = GatherPacked(features, embedding)
            ].lookup
            DenseLayer(input, inputSize, outputSize, activation) = [
               z = BFF(input, outputSize, inputSize).z
               act = activation(z)
            ].act
            LSTMLayer (input, inputSize, outputSize, cellSize, selector) = [ 
               lstm = BS.RNNs.RecurrentLSTMP (outputSize, cellDim=cellSize, input, inputDim=inputSize).h
               result = selector(lstm)
            ].result
        ]        
        // LSTM params
        lstmDim = 25
        cellDim = 25
        // model
        numLabels = 5        
        vocab = 2000
        embedDim = 50        
        // set up features and labels
        t = DynamicAxis()
features = Input(1, dynamicAxis=t)   
labels   = Input(numLabels)          
        // load the pre-learned word embedding matrix
        l1 = Layers.EmbeddingLayer(features, vocab, embedDim, 'embeddingmatrix.txt')
        l2 = Layers.LSTMLayer(l1, embedDim, lstmDim, cellDim, BS.Sequences.Last)
        l3 = Layers.DenseLayer(l2, lstmDim, numLabels, Pass)
        out = Pass(l3, tag='output')   
        // Make sure the trainer understands that the time dimension of l3 is actually the same as that of labels.
        l3p = ReconcileDynamicAxis(l3, labels)
        // training criteria
        ce  = CrossEntropyWithSoftmax(labels, l3p, tag='criterion')   // this is the training objective
        err = ErrorPrediction        (labels, l3p, tag='evaluation')  // this also gets tracked
    ]
    SGD = [	
        epochSize = 0
        minibatchSize = 200
        maxEpochs = 5
        momentumPerMB = 0.9
        learningRatesPerMB = 0.1
        keepCheckPointFiles = true
    ]
    reader = [
        readerType = "CNTKTextFormatReader"
        file = "C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SequenceClassification\Data/Train.txt"            
        input = [            
            features=[
                alias = "x"                
                dim = 1               
                format = "dense"
            ]
            labels=[
                alias = "y"                
                dim = 5           
                format = "dense"
            ]
        ]
   ]    
outputPath = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160713043153.833416\Text_SequenceClassification@debug_gpu/output.txt"        
]

configparameters: seqcla.cntk:Write=[
    action="test"
    run=BrainScriptNetworkBuilder
    format = [
      sequencePrologue=%d\t|w.shape %x\n%d\t|w\s
      sampleSeparator=\n%d\t|w\s
      elementSeparator=\s
    ]
    modelFile = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160713043153.833416\Text_SequenceClassification@debug_gpu/Models/seqcla.dnn"    
    reader = [
            readerType = "CNTKTextFormatReader"
            file = "C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SequenceClassification\Data/Train.txt"            
            input = [            
                features=[
                    alias = "x"                
                    dim = 1               
                    format = "dense"
                ]
                labels=[
                    alias = "y"                
                    dim = 5           
                    format = "dense"
                ]
            ]
   ]    
outputPath = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160713043153.833416\Text_SequenceClassification@debug_gpu/output.txt"        
]

07/13/2016 04:44:23: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
07/13/2016 04:44:23: Commands: Train
07/13/2016 04:44:23: Precision = "float"
07/13/2016 04:44:23: CNTKModelPath: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160713043153.833416\Text_SequenceClassification@debug_gpu/Models/seqcla.dnn
07/13/2016 04:44:23: CNTKCommandTrainInfo: Train : 5
07/13/2016 04:44:23: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 5

07/13/2016 04:44:23: ##############################################################################
07/13/2016 04:44:23: #                                                                            #
07/13/2016 04:44:23: # Action "train"                                                             #
07/13/2016 04:44:23: #                                                                            #
07/13/2016 04:44:23: ##############################################################################

07/13/2016 04:44:23: CNTKCommandTrainBegin: Train

07/13/2016 04:44:23: Starting from checkpoint. Loading network from 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160713043153.833416\Text_SequenceClassification@debug_gpu/Models/seqcla.dnn.4'.

Post-processing network...

4 roots:
	ce = CrossEntropyWithSoftmax()
	err = ErrorPrediction()
	out = Pass()
	t = DynamicAxis()

Loop[0] --> Loop_l2.lstm.lstmState._privateInnards.ht -> 25 nodes

	l2.lstm.prevState.h	l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[1]	l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0]
	l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[1]	l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0]	l2.lstm.prevState.c
	l2.lstm.lstmState._privateInnards.ft._.PlusArgs[1]	l2.lstm.lstmState._privateInnards.ft._	l2.lstm.lstmState._privateInnards.ft
	l2.lstm.lstmState._privateInnards.bft	l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[1]	l2.lstm.lstmState._privateInnards.it._.PlusArgs[0]
	l2.lstm.lstmState._privateInnards.it._.PlusArgs[1]	l2.lstm.lstmState._privateInnards.it._	l2.lstm.lstmState._privateInnards.it
	l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[1]	l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z	l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1]
	l2.lstm.lstmState._privateInnards.bit	l2.lstm.lstmState._privateInnards.ct	l2.lstm.lstmState._privateInnards.ot._.PlusArgs[1]
	l2.lstm.lstmState._privateInnards.ot._	l2.lstm.lstmState._privateInnards.ot	l2.lstm.lstmState._privateInnards.ht.ElementTimesArgs[1]
	l2.lstm.lstmState._privateInnards.ht

Validating network. 71 nodes to process in pass 1.

Validating --> labels = InputValue() :  -> [5 x *]
Validating --> l3.z.W = LearnableParameter() :  -> [5 x 25]
Validating --> l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[0].PlusArgs[0] = LearnableParameter() :  -> [25]
Validating --> l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[0].PlusArgs[1].TimesArgs[0] = LearnableParameter() :  -> [25 x 50]
Validating --> features = InputValue() :  -> [1 x t1]
Validating --> l1.embedding.x = LearnableParameter() :  -> [2000 x 50]
Validating --> l1.embedding = TransposeDimensions (l1.embedding.x) : [2000 x 50] -> [50 x 2000]
Validating --> l1.lookup = GatherPacked (features, l1.embedding) : [1 x t1], [50 x 2000] -> [50 x t1]
Validating --> l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[0].PlusArgs[1] = Times (l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[0].PlusArgs[1].TimesArgs[0], l1.lookup) : [25 x 50], [50 x t1] -> [25 x t1]
Validating --> l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[0] = Plus (l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[0].PlusArgs[0], l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[0].PlusArgs[1]) : [25], [25 x t1] -> [25 x t1]
Validating --> l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[1].TimesArgs[0] = LearnableParameter() :  -> [25 x 25]
Validating --> l2.lstm.lstmState._privateInnards.ot._.PlusArgs[1].ElementTimesArgs[0] = LearnableParameter() :  -> [25]
Validating --> l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[0].PlusArgs[0] = LearnableParameter() :  -> [25]
Validating --> l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[0].PlusArgs[1].TimesArgs[0] = LearnableParameter() :  -> [25 x 50]
Validating --> l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[0].PlusArgs[1] = Times (l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[0].PlusArgs[1].TimesArgs[0], l1.lookup) : [25 x 50], [50 x t1] -> [25 x t1]
Validating --> l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[0] = Plus (l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[0].PlusArgs[0], l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[0].PlusArgs[1]) : [25], [25 x t1] -> [25 x t1]
Validating --> l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[1].TimesArgs[0] = LearnableParameter() :  -> [25 x 25]
Validating --> l2.lstm.lstmState._privateInnards.ft._.PlusArgs[1].ElementTimesArgs[0] = LearnableParameter() :  -> [25]
Validating --> l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[0].PlusArgs[0] = LearnableParameter() :  -> [25]
Validating --> l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[0].PlusArgs[1].TimesArgs[0] = LearnableParameter() :  -> [25 x 50]
Validating --> l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[0].PlusArgs[1] = Times (l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[0].PlusArgs[1].TimesArgs[0], l1.lookup) : [25 x 50], [50 x t1] -> [25 x t1]
Validating --> l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[0] = Plus (l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[0].PlusArgs[0], l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[0].PlusArgs[1]) : [25], [25 x t1] -> [25 x t1]
Validating --> l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[1].TimesArgs[0] = LearnableParameter() :  -> [25 x 25]
Validating --> l2.lstm.lstmState._privateInnards.it._.PlusArgs[1].ElementTimesArgs[0] = LearnableParameter() :  -> [25]
Validating --> l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[0].PlusArgs[0] = LearnableParameter() :  -> [25]
Validating --> l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[0].PlusArgs[1].TimesArgs[0] = LearnableParameter() :  -> [25 x 50]
Validating --> l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[0].PlusArgs[1] = Times (l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[0].PlusArgs[1].TimesArgs[0], l1.lookup) : [25 x 50], [50 x t1] -> [25 x t1]
Validating --> l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[0] = Plus (l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[0].PlusArgs[0], l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[0].PlusArgs[1]) : [25], [25 x t1] -> [25 x t1]
Validating --> l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[1].TimesArgs[0] = LearnableParameter() :  -> [25 x 25]
Validating --> l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[1] = Times (l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[1].TimesArgs[0], l2.lstm.prevState.h) : [25 x 25], [25] -> [25]
Validating --> l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0] = Plus (l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[0], l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[1]) : [25 x t1], [25] -> [25 x t1]
Validating --> l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[1] = Times (l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[1].TimesArgs[0], l2.lstm.prevState.h) : [25 x 25], [25] -> [25]
Validating --> l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0] = Plus (l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[0], l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[1]) : [25 x t1], [25] -> [25 x t1]
Validating --> l2.lstm.lstmState._privateInnards.ft._.PlusArgs[1] = ElementTimes (l2.lstm.lstmState._privateInnards.ft._.PlusArgs[1].ElementTimesArgs[0], l2.lstm.prevState.c) : [25], [25] -> [25]
Validating --> l2.lstm.lstmState._privateInnards.ft._ = Plus (l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0], l2.lstm.lstmState._privateInnards.ft._.PlusArgs[1]) : [25 x t1], [25] -> [25 x t1]
Validating --> l2.lstm.lstmState._privateInnards.ft = Sigmoid (l2.lstm.lstmState._privateInnards.ft._) : [25 x t1] -> [25 x t1]
Validating --> l2.lstm.lstmState._privateInnards.bft = ElementTimes (l2.lstm.lstmState._privateInnards.ft, l2.lstm.prevState.c) : [25 x t1], [25] -> [25 x t1]
Validating --> l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[1] = Times (l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[1].TimesArgs[0], l2.lstm.prevState.h) : [25 x 25], [25] -> [25]
Validating --> l2.lstm.lstmState._privateInnards.it._.PlusArgs[0] = Plus (l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[0], l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[1]) : [25 x t1], [25] -> [25 x t1]
Validating --> l2.lstm.lstmState._privateInnards.it._.PlusArgs[1] = ElementTimes (l2.lstm.lstmState._privateInnards.it._.PlusArgs[1].ElementTimesArgs[0], l2.lstm.prevState.c) : [25], [25] -> [25]
Validating --> l2.lstm.lstmState._privateInnards.it._ = Plus (l2.lstm.lstmState._privateInnards.it._.PlusArgs[0], l2.lstm.lstmState._privateInnards.it._.PlusArgs[1]) : [25 x t1], [25] -> [25 x t1]
Validating --> l2.lstm.lstmState._privateInnards.it = Sigmoid (l2.lstm.lstmState._privateInnards.it._) : [25 x t1] -> [25 x t1]
Validating --> l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[1] = Times (l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[1].TimesArgs[0], l2.lstm.prevState.h) : [25 x 25], [25] -> [25]
Validating --> l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z = Plus (l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[0], l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[1]) : [25 x t1], [25] -> [25 x t1]
Validating --> l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1] = Tanh (l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z) : [25 x t1] -> [25 x t1]
Validating --> l2.lstm.lstmState._privateInnards.bit = ElementTimes (l2.lstm.lstmState._privateInnards.it, l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1]) : [25 x t1], [25 x t1] -> [25 x t1]
Validating --> l2.lstm.lstmState._privateInnards.ct = Plus (l2.lstm.lstmState._privateInnards.bft, l2.lstm.lstmState._privateInnards.bit) : [25 x t1], [25 x t1] -> [25 x t1]
Validating --> l2.lstm.lstmState._privateInnards.ot._.PlusArgs[1] = ElementTimes (l2.lstm.lstmState._privateInnards.ot._.PlusArgs[1].ElementTimesArgs[0], l2.lstm.lstmState._privateInnards.ct) : [25], [25 x t1] -> [25 x t1]
Validating --> l2.lstm.lstmState._privateInnards.ot._ = Plus (l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0], l2.lstm.lstmState._privateInnards.ot._.PlusArgs[1]) : [25 x t1], [25 x t1] -> [25 x t1]
Validating --> l2.lstm.lstmState._privateInnards.ot = Sigmoid (l2.lstm.lstmState._privateInnards.ot._) : [25 x t1] -> [25 x t1]
Validating --> l2.lstm.lstmState._privateInnards.ht.ElementTimesArgs[1] = Tanh (l2.lstm.lstmState._privateInnards.ct) : [25 x t1] -> [25 x t1]
Validating --> l2.lstm.lstmState._privateInnards.ht = ElementTimes (l2.lstm.lstmState._privateInnards.ot, l2.lstm.lstmState._privateInnards.ht.ElementTimesArgs[1]) : [25 x t1], [25 x t1] -> [25 x t1]
Validating --> l2.result.beginFlags.input.z.ElementTimesArgs[0] = Slice (l2.lstm.lstmState._privateInnards.ht) : [25 x t1] -> [1 x t1]
Validating --> BS.Constants.Zero = LearnableParameter() :  -> [1]
Validating --> l2.result.beginFlags.input.z = ElementTimes (l2.result.beginFlags.input.z.ElementTimesArgs[0], BS.Constants.Zero) : [1 x t1], [1] -> [1 x t1]
Validating --> l2.result.beginFlags.input = SumColumnElements (l2.result.beginFlags.input.z) : [1 x t1] -> [1 x t1]
Validating --> l2.result.beginFlags = FutureValue (l2.result.beginFlags.input) : [1 x t1] -> [1 x t1]
Validating --> l2.result.out.indexSequence.indexSequence = Where (l2.result.beginFlags) : [1 x t1] -> [1 x WhereNodeAxis]
Validating --> l2.result.out.indexSequence = PackedIndex (l2.lstm.lstmState._privateInnards.ht, l2.result.out.indexSequence.indexSequence) : [25 x t1], [1 x WhereNodeAxis] -> [1 x WhereNodeAxis]
Validating --> l2.result.out = GatherPacked (l2.result.out.indexSequence, l2.lstm.lstmState._privateInnards.ht) : [1 x WhereNodeAxis], [25 x t1] -> [25 x WhereNodeAxis]
Validating --> l3.z.z.PlusArgs[0] = Times (l3.z.W, l2.result.out) : [5 x 25], [25 x WhereNodeAxis] -> [5 x WhereNodeAxis]
Validating --> l3.z.B = LearnableParameter() :  -> [5 x 1]
Validating --> l3.z.z = Plus (l3.z.z.PlusArgs[0], l3.z.B) : [5 x WhereNodeAxis], [5 x 1] -> [5 x 1 x WhereNodeAxis]
Validating --> l3.act = Pass (l3.z.z) : [5 x 1 x WhereNodeAxis] -> [5 x 1 x WhereNodeAxis]
Validating --> l3p = ReconcileDynamicAxis (l3.act, labels) : [5 x 1 x WhereNodeAxis], [5 x *] -> [5 x 1 x *]
Validating --> ce = CrossEntropyWithSoftmax (labels, l3p) : [5 x *], [5 x 1 x *] -> [1]
Validating --> err = ErrorPrediction (labels, l3p) : [5 x *], [5 x 1 x *] -> [1]
Validating --> out = Pass (l3.act) : [5 x 1 x WhereNodeAxis] -> [5 x 1 x WhereNodeAxis]
Validating --> t = DynamicAxis() :  -> [1 x 1 x t1]

Validating network. 49 nodes to process in pass 2.

Validating --> l2.lstm.prevState.h = PastValue (l2.lstm.lstmState._privateInnards.ht) : [25 x t1] -> [25 x t1]
Validating --> l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[1] = Times (l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[1].TimesArgs[0], l2.lstm.prevState.h) : [25 x 25], [25 x t1] -> [25 x t1]
Validating --> l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[1] = Times (l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[1].TimesArgs[0], l2.lstm.prevState.h) : [25 x 25], [25 x t1] -> [25 x t1]
Validating --> l2.lstm.prevState.c = PastValue (l2.lstm.lstmState._privateInnards.ct) : [25 x t1] -> [25 x t1]
Validating --> l2.lstm.lstmState._privateInnards.ft._.PlusArgs[1] = ElementTimes (l2.lstm.lstmState._privateInnards.ft._.PlusArgs[1].ElementTimesArgs[0], l2.lstm.prevState.c) : [25], [25 x t1] -> [25 x t1]
Validating --> l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[1] = Times (l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[1].TimesArgs[0], l2.lstm.prevState.h) : [25 x 25], [25 x t1] -> [25 x t1]
Validating --> l2.lstm.lstmState._privateInnards.it._.PlusArgs[1] = ElementTimes (l2.lstm.lstmState._privateInnards.it._.PlusArgs[1].ElementTimesArgs[0], l2.lstm.prevState.c) : [25], [25 x t1] -> [25 x t1]
Validating --> l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[1] = Times (l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[1].TimesArgs[0], l2.lstm.prevState.h) : [25 x 25], [25 x t1] -> [25 x t1]

Validating network. 8 nodes to process in pass 3.


Validating network, final pass.



69 out of 71 nodes do not share the minibatch layout with the input data.

Post-processing network complete.

07/13/2016 04:44:24: Loaded model with 71 nodes on GPU 0.

07/13/2016 04:44:24: Training criterion node(s):
07/13/2016 04:44:24: 	ce = CrossEntropyWithSoftmax

07/13/2016 04:44:24: Evaluation criterion node(s):

07/13/2016 04:44:24: 	err = ErrorPrediction


Allocating matrices for forward and/or backward propagation.

Memory Sharing Structure:

0000000000000000: {[BS.Constants.Zero Gradient[1]] [err Gradient[1]] [features Gradient[1 x t1]] [l1.embedding Gradient[50 x 2000]] [l1.embedding.x Gradient[2000 x 50]] [l1.lookup Gradient[50 x t1]] [labels Gradient[5 x *]] [out Gradient[5 x 1 x WhereNodeAxis]] [t Gradient[1 x 1 x t1]] [t Value[1 x 1 x t1]] }
00000008F1E5EB70: {[BS.Constants.Zero Value[1]] }
00000008F22EE2E0: {[l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[0].PlusArgs[0] Gradient[25]] [l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[0].PlusArgs[1] Value[25 x t1]] }
00000008F22EE3B0: {[l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[1] Value[25 x t1]] }
00000008F22EE480: {[l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[0].PlusArgs[1] Value[25 x t1]] }
00000008F22EE550: {[l2.lstm.lstmState._privateInnards.ft Value[25 x t1]] }
00000008F22EE620: {[l2.lstm.lstmState._privateInnards.it._.PlusArgs[0] Value[25 x t1]] }
00000008F22EE6F0: {[l2.lstm.lstmState._privateInnards.ft._ Value[25 x t1]] }
00000008F22EE7C0: {[l2.lstm.lstmState._privateInnards.ot Value[25 x t1]] }
00000008F22EE890: {[l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[0].PlusArgs[1] Value[25 x t1]] [l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[0].PlusArgs[0] Gradient[25]] }
00000008F22EE960: {[err Value[1]] }
00000008F22EEA30: {[l2.lstm.lstmState._privateInnards.ct Value[25 x t1]] }
00000008F22EEB00: {[labels Value[5 x *]] }
00000008F22EEBD0: {[l1.embedding Value[50 x 2000]] }
00000008F22EECA0: {[l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[0].PlusArgs[1] Value[25 x t1]] [l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[0].PlusArgs[0] Gradient[25]] }
00000008F22EED70: {[l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[1] Value[25 x t1]] }
00000008F22EEE40: {[l2.lstm.lstmState._privateInnards.ht.ElementTimesArgs[1] Value[25 x t1]] }
00000008F22EEF10: {[l2.lstm.lstmState._privateInnards.ht Value[25 x t1]] }
00000008F22EEFE0: {[l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[1] Value[25 x t1]] }
00000008F22EF0B0: {[l2.lstm.lstmState._privateInnards.ot Gradient[25 x t1]] [l2.result.beginFlags.input.z.ElementTimesArgs[0] Value[1 x t1]] }
00000008F22EF180: {[l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1] Value[25 x t1]] }
00000008F22EF250: {[l2.lstm.lstmState._privateInnards.ot._ Value[25 x t1]] }
00000008F22EF320: {[l2.lstm.lstmState._privateInnards.bft Value[25 x t1]] }
00000008F22EF3F0: {[l2.lstm.lstmState._privateInnards.ft._.PlusArgs[1] Value[25 x t1]] }
00000008F22EF4C0: {[l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0] Value[25 x t1]] }
00000008F22EF590: {[l2.lstm.lstmState._privateInnards.it Value[25 x t1]] }
00000008F22EF660: {[l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0] Value[25 x t1]] }
00000008F22EF730: {[l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[0] Value[25 x t1]] [l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[0].PlusArgs[1].TimesArgs[0] Gradient[25 x 50]] }
00000008F22EF800: {[l1.lookup Value[50 x t1]] }
00000008F22EF8D0: {[l2.lstm.lstmState._privateInnards.bit Value[25 x t1]] }
00000008F22EF9A0: {[l2.lstm.lstmState._privateInnards.ot._.PlusArgs[1] Value[25 x t1]] }
00000008F22EFA70: {[l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[1] Value[25 x t1]] }
00000008F22EFB40: {[out Value[5 x 1 x WhereNodeAxis]] }
00000008F22EFC10: {[l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[0] Value[25 x t1]] [l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[0].PlusArgs[1].TimesArgs[0] Gradient[25 x 50]] }
00000008F22EFCE0: {[l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z Value[25 x t1]] }
00000008F22EFDB0: {[ce Value[1]] }
00000008F22EFE80: {[l2.lstm.lstmState._privateInnards.it._ Value[25 x t1]] }
00000008F22EFF50: {[l3.z.W Value[5 x 25]] }
00000008F22F0020: {[l2.lstm.lstmState._privateInnards.it._.PlusArgs[1] Value[25 x t1]] }
00000008F22F00F0: {[l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[0] Value[25 x t1]] [l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[0].PlusArgs[1].TimesArgs[0] Gradient[25 x 50]] }
00000008F22F01C0: {[l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[0] Value[25 x t1]] [l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[0].PlusArgs[1].TimesArgs[0] Gradient[25 x 50]] }
00000008F26F99A0: {[l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[1].TimesArgs[0] Value[25 x 25]] }
00000008F26F9C10: {[l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[0].PlusArgs[0] Value[25]] }
00000008F26F9CE0: {[features Value[1 x t1]] }
00000008F26F9F50: {[l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[1].TimesArgs[0] Value[25 x 25]] }
00000008F26FA020: {[l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[0].PlusArgs[0] Value[25]] }
00000008F26FA500: {[l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[1].TimesArgs[0] Value[25 x 25]] }
00000008F26FA5D0: {[l2.lstm.lstmState._privateInnards.it._.PlusArgs[1].ElementTimesArgs[0] Value[25]] }
00000008F26FA770: {[l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[1].TimesArgs[0] Value[25 x 25]] }
00000008F26FA840: {[l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[0].PlusArgs[1].TimesArgs[0] Value[25 x 50]] }
00000008F26FA9E0: {[l2.lstm.prevState.c Value[25 x t1]] }
00000008F26FAAB0: {[l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[0].PlusArgs[0] Gradient[25]] [l2.lstm.prevState.h Value[25 x t1]] }
00000008F26FAB80: {[l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[0].PlusArgs[1].TimesArgs[0] Value[25 x 50]] }
00000008F26FAC50: {[l2.lstm.lstmState._privateInnards.ot._.PlusArgs[1].ElementTimesArgs[0] Value[25]] }
00000008F26FAD20: {[l2.result.out.indexSequence Value[1 x WhereNodeAxis]] }
00000008F26FADF0: {[l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[0].PlusArgs[0] Value[25]] }
00000008F26FB060: {[l2.result.out.indexSequence.indexSequence Value[1 x WhereNodeAxis]] }
00000008F26FB130: {[l2.lstm.lstmState._privateInnards.ot._ Gradient[25 x t1]] [l2.result.beginFlags Value[1 x t1]] [l2.result.beginFlags.input.z Gradient[1 x t1]] }
00000008F26FB200: {[l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[0].PlusArgs[0] Value[25]] }
00000008F26FB2D0: {[l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[0].PlusArgs[1].TimesArgs[0] Value[25 x 50]] }
00000008F26FB3A0: {[l1.embedding.x Value[2000 x 50]] }
00000008F26FB470: {[l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[0].PlusArgs[1].TimesArgs[0] Value[25 x 50]] }
00000008F26FB610: {[l3.z.B Value[5 x 1]] }
00000008F26FB6E0: {[l2.lstm.lstmState._privateInnards.ft._.PlusArgs[1].ElementTimesArgs[0] Value[25]] }
00000008F2896170: {[l3.act Gradient[5 x 1 x WhereNodeAxis]] [l3.z.B Gradient[5 x 1]] }
00000008F2896240: {[l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[0] Gradient[25 x t1]] }
00000008F2896310: {[l2.lstm.prevState.c Gradient[25 x t1]] }
00000008F28963E0: {[l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[1] Gradient[25 x t1]] }
00000008F2896720: {[l2.lstm.lstmState._privateInnards.it._.PlusArgs[1].ElementTimesArgs[0] Gradient[25]] }
00000008F28967F0: {[l2.lstm.lstmState._privateInnards.bit Gradient[25 x t1]] }
00000008F28968C0: {[l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[1].TimesArgs[0] Gradient[25 x 25]] }
00000008F2896990: {[l2.lstm.lstmState._privateInnards.ct Gradient[25 x t1]] [l2.result.beginFlags.input.z Value[1 x t1]] }
00000008F2896A60: {[l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[0] Gradient[25 x t1]] }
00000008F2896B30: {[l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[0].PlusArgs[1] Gradient[25 x t1]] [l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[0].PlusArgs[1] Gradient[25 x t1]] [l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[0].PlusArgs[1] Gradient[25 x t1]] [l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[0].PlusArgs[1] Gradient[25 x t1]] [l2.lstm.prevState.h Gradient[25 x t1]] }
00000008F2896C00: {[l2.lstm.lstmState._privateInnards.ht Gradient[25 x t1]] [l3.act Value[5 x 1 x WhereNodeAxis]] [l3.z.z.PlusArgs[0] Gradient[5 x WhereNodeAxis]] }
00000008F2896CD0: {[l2.lstm.lstmState._privateInnards.ot._.PlusArgs[1] Gradient[25 x t1]] [l2.result.beginFlags Gradient[1 x t1]] [l2.result.out.indexSequence Gradient[1 x WhereNodeAxis]] [l3.z.z.PlusArgs[0] Value[5 x WhereNodeAxis]] }
00000008F2896E70: {[l3.z.W Gradient[5 x 25]] [l3.z.z Value[5 x 1 x WhereNodeAxis]] }
00000008F2896F40: {[l2.lstm.lstmState._privateInnards.it Gradient[25 x t1]] }
00000008F2897010: {[l2.lstm.lstmState._privateInnards.ft._ Gradient[25 x t1]] }
00000008F28971B0: {[l2.lstm.lstmState._privateInnards.ft._.PlusArgs[1] Gradient[25 x t1]] }
00000008F2897280: {[l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0] Gradient[25 x t1]] [l2.result.beginFlags.input Gradient[1 x t1]] [l2.result.out Value[25 x WhereNodeAxis]] [l2.result.out.indexSequence.indexSequence Gradient[1 x WhereNodeAxis]] }
00000008F2897350: {[l2.lstm.lstmState._privateInnards.it._ Gradient[25 x t1]] }
00000008F2897420: {[l2.lstm.lstmState._privateInnards.ft._.PlusArgs[1].ElementTimesArgs[0] Gradient[25]] }
00000008F28974F0: {[l2.lstm.lstmState._privateInnards.ft Gradient[25 x t1]] }
00000008F28975C0: {[l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[0] Gradient[25 x t1]] }
00000008F2897760: {[l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1] Gradient[25 x t1]] }
00000008F2897830: {[l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[1].TimesArgs[0] Gradient[25 x 25]] }
00000008F2897900: {[l2.lstm.lstmState._privateInnards.it._.PlusArgs[1] Gradient[25 x t1]] }
00000008F28979D0: {[ce Gradient[1]] }
00000008F2897AA0: {[l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0] Gradient[25 x t1]] }
00000008F2897B70: {[l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[1] Gradient[25 x t1]] }
00000008F2897C40: {[l2.lstm.lstmState._privateInnards.bft Gradient[25 x t1]] [l3p Gradient[5 x 1 x *]] }
00000008F2897D10: {[l2.lstm.lstmState._privateInnards.it._.PlusArgs[0] Gradient[25 x t1]] }
00000008F2897DE0: {[l2.lstm.lstmState._privateInnards.ot._.PlusArgs[1].ElementTimesArgs[0] Gradient[25]] [l2.result.out Gradient[25 x WhereNodeAxis]] [l3.z.z Gradient[5 x 1 x WhereNodeAxis]] [l3p Value[5 x 1 x *]] }
00000008F2897EB0: {[l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z Gradient[25 x t1]] }
00000008F2897F80: {[l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[1] Gradient[25 x t1]] }
00000008F2898050: {[l2.lstm.lstmState._privateInnards.ht.ElementTimesArgs[1] Gradient[25 x t1]] [l2.result.beginFlags.input Value[1 x t1]] [l2.result.beginFlags.input.z.ElementTimesArgs[0] Gradient[1 x t1]] }
00000008F289A810: {[l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[0] Gradient[25 x t1]] }
00000008F289B920: {[l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[1].TimesArgs[0] Gradient[25 x 25]] }
00000008F289BC60: {[l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[1] Gradient[25 x t1]] }
00000008F289C480: {[l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[1].TimesArgs[0] Gradient[25 x 25]] }

07/13/2016 04:44:24: No PreCompute nodes found, skipping PreCompute step.

07/13/2016 04:44:24: Starting Epoch 5: learning rate per sample = 0.000500  effective momentum = 0.900000  momentum as time constant = 1898.2 samples
BlockRandomizer::StartEpoch: epoch 4: frames [21732..27165] (first sequence at sample 21732), data subset 0 of 1

07/13/2016 04:44:24: Starting minibatch loop.
WARNING: The same matrix with dim [1, 44] has been transferred between different devices for 20 times.
07/13/2016 04:44:27: Finished Epoch[ 5 of 5]: [Training] ce = 1.33148531 * 1247; err = 0.44667201 * 1247; totalSamplesSeen = 6235; learningRatePerSample = 0.00050000002; epochTime=3.50112s
07/13/2016 04:44:27: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160713043153.833416\Text_SequenceClassification@debug_gpu/Models/seqcla.dnn'
07/13/2016 04:44:27: CNTKCommandTrainEnd: Train

07/13/2016 04:44:27: Action "train" complete.

07/13/2016 04:44:27: __COMPLETED__
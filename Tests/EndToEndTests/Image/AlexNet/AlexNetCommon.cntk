# Note: reader configuration comes from AlexNet.cntk or AlexNetComposite.cntk, depending on the test
ModelDir = "$RunDir$/models"

ndlMacros=$ConfigDir$/Macros.ndl

precision=float
deviceId=Auto

command=Train

parallelTrain=false

traceLevel=1
numMBsToShowResult=100

Train=[
    action=train
    modelPath=$ModelDir$/AlexNet

    BrainScriptNetworkBuilder = {
        imageShape = 3:224:224
        labelDim = 1000
        
        model = Sequential (
            ConvolutionalLayer {64, (11:11), stride=(4:4), pad = true} : ReLU : 
            MaxPoolingLayer    {(3:3), stride=(2:2)} :
            ConvolutionalLayer {192, (5:5), pad = true} : ReLU : 
            MaxPoolingLayer    {(3:3), stride=(2:2)} :
            ConvolutionalLayer {384, (3:3), pad = true} : ReLU : 
            ConvolutionalLayer {256, (3:3), pad = true} : ReLU : 
            ConvolutionalLayer {256, (3:3), pad = true} : ReLU : 
            MaxPoolingLayer    {(3:3), stride=(2:2)} :
            DenseLayer         {4096, activation=ReLU} : Dropout :
            DenseLayer         {4096, activation=ReLU} : Dropout :
            LinearLayer        {labelDim}
        )

        # inputs
        features = Input {imageShape}
        labels = Input {labelDim}

        # transpose features (50176 = 224 * 224)
        flatFeatures = NewReshape (features, (3:50176))
        transFeatures = Transpose(flatFeatures)
        newFeatures = NewReshape (transFeatures, (224:224:3))
        
        # apply model to features
        ol = model (newFeatures)

        # loss and error computation
        ce   = CrossEntropyWithSoftmax (labels, ol)
        errs = ClassificationError (labels, ol)

        # declare special nodes
        featureNodes    = (features)
        labelNodes      = (labels)
        criterionNodes  = (ce)
        evaluationNodes = (errs)
        outputNodes     = (ol)
    }
    
    SGD=[
        epochSize=0
        minibatchSize=16
        learningRatesPerMB=0.01*20:0.003*12:0.001*28:0.0003
        momentumPerMB=0.9
        maxEpochs=3
        gradUpdateType=None
        L2RegWeight=0.0005
        dropoutRate=0*5:0.5
        
        ParallelTrain=[
            parallelizationMethod=DataParallelSGD
            distributedMBReading=true
            parallelizationStartEpoch=1
            DataParallelSGD=[
                gradientBits=1
            ]
        ]
        
        numMBsToShowResult=1
    ]
]


AddTop5Eval=[    
    action=edit
    CurModel=$ModelDir$/AlexNet
    NewModel=$ModelDir$/AlexNet.Top5
    editPath=$ConfigDir$/add_top5_layer.mel
]

Test=[
    action=test
    modelPath=$ModelDir$/AlexNet.Top5
    # Set minibatch size for testing.
    minibatchSize=16

     NDLNetworkBuilder=[
        networkDescription=$ConfigDir$/AlexNet.ndl
    ]
]

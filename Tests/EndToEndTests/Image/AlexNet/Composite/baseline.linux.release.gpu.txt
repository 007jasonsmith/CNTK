CPU info:
    CPU Model Name: Intel(R) Xeon(R) CPU E5-2630 v2 @ 2.60GHz
    Hardware threads: 24
    Total Memory: 264172964 kB
-------------------------------------------------------------------
Copying test data to local directory
=== Running /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/build/gpu/release/bin/cntk configFile=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Image/AlexNet/AlexNetCommon.cntk currentDirectory=/tmp/cntk-test-20160713122133.128226/Image_AlexNet@release_gpu/TestData RunDir=/tmp/cntk-test-20160713122133.128226/Image_AlexNet@release_gpu DataDir=/tmp/cntk-test-20160713122133.128226/Image_AlexNet@release_gpu/TestData ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Image/AlexNet OutputDir=/tmp/cntk-test-20160713122133.128226/Image_AlexNet@release_gpu DeviceId=0 timestamping=true configFile=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Image/AlexNet/AlexNet.cntk
-------------------------------------------------------------------
Build info: 

		Built time: Jul 13 2016 12:01:30
		Last modified date: Tue Jul 12 04:28:35 2016
		Build type: release
		Build target: GPU
		With 1bit-SGD: no
		Math lib: mkl
		CUDA_PATH: /usr/local/cuda-7.5
		CUB_PATH: /usr/local/cub-1.4.1
		CUDNN_PATH: /usr/local/cudnn-4.0
		Build Branch: HEAD
		Build SHA1: 50bb4c8afbc87c14548a5b5f315a064186a5cb5f
		Built by philly on 2bc22072e267
		Build Path: /home/philly/jenkins/workspace/CNTK-Build-Linux
-------------------------------------------------------------------
Changed current directory to /tmp/cntk-test-20160713122133.128226/Image_AlexNet@release_gpu/TestData
07/13/2016 12:21:35: -------------------------------------------------------------------
07/13/2016 12:21:35: Build info: 

07/13/2016 12:21:35: 		Built time: Jul 13 2016 12:01:30
07/13/2016 12:21:35: 		Last modified date: Tue Jul 12 04:28:35 2016
07/13/2016 12:21:35: 		Build type: release
07/13/2016 12:21:35: 		Build target: GPU
07/13/2016 12:21:35: 		With 1bit-SGD: no
07/13/2016 12:21:35: 		Math lib: mkl
07/13/2016 12:21:35: 		CUDA_PATH: /usr/local/cuda-7.5
07/13/2016 12:21:35: 		CUB_PATH: /usr/local/cub-1.4.1
07/13/2016 12:21:35: 		CUDNN_PATH: /usr/local/cudnn-4.0
07/13/2016 12:21:35: 		Build Branch: HEAD
07/13/2016 12:21:35: 		Build SHA1: 50bb4c8afbc87c14548a5b5f315a064186a5cb5f
07/13/2016 12:21:35: 		Built by philly on 2bc22072e267
07/13/2016 12:21:35: 		Build Path: /home/philly/jenkins/workspace/CNTK-Build-Linux
07/13/2016 12:21:35: -------------------------------------------------------------------
07/13/2016 12:21:36: -------------------------------------------------------------------
07/13/2016 12:21:36: GPU info:

07/13/2016 12:21:36: 		Device[0]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3071 MB
07/13/2016 12:21:36: 		Device[1]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3071 MB
07/13/2016 12:21:36: 		Device[2]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3071 MB
07/13/2016 12:21:36: 		Device[3]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3071 MB
07/13/2016 12:21:36: -------------------------------------------------------------------

07/13/2016 12:21:36: Running on localhost at 2016/07/13 12:21:36
07/13/2016 12:21:36: Command line: 
/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/build/gpu/release/bin/cntk  configFile=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Image/AlexNet/AlexNetCommon.cntk  currentDirectory=/tmp/cntk-test-20160713122133.128226/Image_AlexNet@release_gpu/TestData  RunDir=/tmp/cntk-test-20160713122133.128226/Image_AlexNet@release_gpu  DataDir=/tmp/cntk-test-20160713122133.128226/Image_AlexNet@release_gpu/TestData  ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Image/AlexNet  OutputDir=/tmp/cntk-test-20160713122133.128226/Image_AlexNet@release_gpu  DeviceId=0  timestamping=true  configFile=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Image/AlexNet/AlexNet.cntk



07/13/2016 12:21:36: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
07/13/2016 12:21:36: ModelDir = "$RunDir$/models"
ndlMacros=$ConfigDir$/Macros.ndl
precision=float
deviceId=Auto
command=Train:AddTop5Eval:Test
parallelTrain=false
traceLevel=1
numMBsToShowResult=100
Train=[
    action=train
    modelPath=$ModelDir$/AlexNet
    NDLNetworkBuilder=[
        networkDescription=$ConfigDir$/AlexNet.ndl
    ]
    SGD=[
        epochSize=0
        minibatchSize=16
        learningRatesPerMB=0.01*20:0.003*12:0.001*28:0.0003
        momentumPerMB=0.9
        maxEpochs=3
        gradUpdateType=None
        L2RegWeight=0.0005
        dropoutRate=0*5:0.5
        ParallelTrain=[
            parallelizationMethod=DataParallelSGD
            distributedMBReading=true
            parallelizationStartEpoch=1
            DataParallelSGD=[
                gradientBits=1
            ]
        ]
        numMBsToShowResult=100
    ]
]
AddTop5Eval=[    
    action=edit
    CurModel=$ModelDir$/AlexNet
    NewModel=$ModelDir$/AlexNet.Top5
    editPath=$ConfigDir$/add_top5_layer.mel
]
Test=[
    action=test
    modelPath=$ModelDir$/AlexNet.Top5
    minibatchSize=16
     NDLNetworkBuilder=[
        networkDescription=$ConfigDir$/AlexNet.ndl
    ]
]
currentDirectory=/tmp/cntk-test-20160713122133.128226/Image_AlexNet@release_gpu/TestData
RunDir=/tmp/cntk-test-20160713122133.128226/Image_AlexNet@release_gpu
DataDir=/tmp/cntk-test-20160713122133.128226/Image_AlexNet@release_gpu/TestData
ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Image/AlexNet
OutputDir=/tmp/cntk-test-20160713122133.128226/Image_AlexNet@release_gpu
DeviceId=0
timestamping=true
Train=[
    reader=[
        readerType=ImageReader
        file=$ConfigDir$/train_map.txt
        randomize=Auto
        features=[
            width=224
            height=224
            channels=3
            cropType=Random
            cropRatio=0.875
            jitterType=UniRatio
            interpolations=Linear
            meanFile=$ConfigDir$/ImageNet1K_mean.xml
        ]
        labels=[
            labelDim=1000
        ]
    ]    
]
Test=[    
    reader=[
        readerType=ImageReader
        file=$ConfigDir$/val_map.txt
        randomize=None
        features=[
            width=224
            height=224
            channels=3
            cropType=Center
            meanFile=$ConfigDir$/ImageNet1K_mean.xml
        ]
        labels=[
            labelDim=1000
        ]
    ]    
]

07/13/2016 12:21:36: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<

07/13/2016 12:21:36: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
07/13/2016 12:21:36: ModelDir = "/tmp/cntk-test-20160713122133.128226/Image_AlexNet@release_gpu/models"
ndlMacros=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Image/AlexNet/Macros.ndl
precision=float
deviceId=Auto
command=Train:AddTop5Eval:Test
parallelTrain=false
traceLevel=1
numMBsToShowResult=100
Train=[
    action=train
    modelPath=/tmp/cntk-test-20160713122133.128226/Image_AlexNet@release_gpu/models/AlexNet
    NDLNetworkBuilder=[
        networkDescription=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Image/AlexNet/AlexNet.ndl
    ]
    SGD=[
        epochSize=0
        minibatchSize=16
        learningRatesPerMB=0.01*20:0.003*12:0.001*28:0.0003
        momentumPerMB=0.9
        maxEpochs=3
        gradUpdateType=None
        L2RegWeight=0.0005
        dropoutRate=0*5:0.5
        ParallelTrain=[
            parallelizationMethod=DataParallelSGD
            distributedMBReading=true
            parallelizationStartEpoch=1
            DataParallelSGD=[
                gradientBits=1
            ]
        ]
        numMBsToShowResult=100
    ]
]
AddTop5Eval=[    
    action=edit
    CurModel=/tmp/cntk-test-20160713122133.128226/Image_AlexNet@release_gpu/models/AlexNet
    NewModel=/tmp/cntk-test-20160713122133.128226/Image_AlexNet@release_gpu/models/AlexNet.Top5
    editPath=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Image/AlexNet/add_top5_layer.mel
]
Test=[
    action=test
    modelPath=/tmp/cntk-test-20160713122133.128226/Image_AlexNet@release_gpu/models/AlexNet.Top5
    minibatchSize=16
     NDLNetworkBuilder=[
        networkDescription=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Image/AlexNet/AlexNet.ndl
    ]
]
currentDirectory=/tmp/cntk-test-20160713122133.128226/Image_AlexNet@release_gpu/TestData
RunDir=/tmp/cntk-test-20160713122133.128226/Image_AlexNet@release_gpu
DataDir=/tmp/cntk-test-20160713122133.128226/Image_AlexNet@release_gpu/TestData
ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Image/AlexNet
OutputDir=/tmp/cntk-test-20160713122133.128226/Image_AlexNet@release_gpu
DeviceId=0
timestamping=true
Train=[
    reader=[
        readerType=ImageReader
        file=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Image/AlexNet/train_map.txt
        randomize=Auto
        features=[
            width=224
            height=224
            channels=3
            cropType=Random
            cropRatio=0.875
            jitterType=UniRatio
            interpolations=Linear
            meanFile=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Image/AlexNet/ImageNet1K_mean.xml
        ]
        labels=[
            labelDim=1000
        ]
    ]    
]
Test=[    
    reader=[
        readerType=ImageReader
        file=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Image/AlexNet/val_map.txt
        randomize=None
        features=[
            width=224
            height=224
            channels=3
            cropType=Center
            meanFile=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Image/AlexNet/ImageNet1K_mean.xml
        ]
        labels=[
            labelDim=1000
        ]
    ]    
]

07/13/2016 12:21:36: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<

07/13/2016 12:21:36: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
configparameters: AlexNet.cntk:AddTop5Eval=[    
    action=edit
    CurModel=/tmp/cntk-test-20160713122133.128226/Image_AlexNet@release_gpu/models/AlexNet
    NewModel=/tmp/cntk-test-20160713122133.128226/Image_AlexNet@release_gpu/models/AlexNet.Top5
    editPath=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Image/AlexNet/add_top5_layer.mel
]

configparameters: AlexNet.cntk:command=Train:AddTop5Eval:Test
configparameters: AlexNet.cntk:ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Image/AlexNet
configparameters: AlexNet.cntk:currentDirectory=/tmp/cntk-test-20160713122133.128226/Image_AlexNet@release_gpu/TestData
configparameters: AlexNet.cntk:DataDir=/tmp/cntk-test-20160713122133.128226/Image_AlexNet@release_gpu/TestData
configparameters: AlexNet.cntk:deviceId=0
configparameters: AlexNet.cntk:ModelDir=/tmp/cntk-test-20160713122133.128226/Image_AlexNet@release_gpu/models
configparameters: AlexNet.cntk:ndlMacros=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Image/AlexNet/Macros.ndl
configparameters: AlexNet.cntk:numMBsToShowResult=100
configparameters: AlexNet.cntk:OutputDir=/tmp/cntk-test-20160713122133.128226/Image_AlexNet@release_gpu
configparameters: AlexNet.cntk:parallelTrain=false
configparameters: AlexNet.cntk:precision=float
configparameters: AlexNet.cntk:RunDir=/tmp/cntk-test-20160713122133.128226/Image_AlexNet@release_gpu
configparameters: AlexNet.cntk:Test=[
    action=test
    modelPath=/tmp/cntk-test-20160713122133.128226/Image_AlexNet@release_gpu/models/AlexNet.Top5
    minibatchSize=16
     NDLNetworkBuilder=[
        networkDescription=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Image/AlexNet/AlexNet.ndl
    ]
] [    
    reader=[
        readerType=ImageReader
        file=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Image/AlexNet/val_map.txt
        randomize=None
        features=[
            width=224
            height=224
            channels=3
            cropType=Center
            meanFile=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Image/AlexNet/ImageNet1K_mean.xml
        ]
        labels=[
            labelDim=1000
        ]
    ]    
]

configparameters: AlexNet.cntk:timestamping=true
configparameters: AlexNet.cntk:traceLevel=1
configparameters: AlexNet.cntk:Train=[
    action=train
    modelPath=/tmp/cntk-test-20160713122133.128226/Image_AlexNet@release_gpu/models/AlexNet
    NDLNetworkBuilder=[
        networkDescription=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Image/AlexNet/AlexNet.ndl
    ]
    SGD=[
        epochSize=0
        minibatchSize=16
        learningRatesPerMB=0.01*20:0.003*12:0.001*28:0.0003
        momentumPerMB=0.9
        maxEpochs=3
        gradUpdateType=None
        L2RegWeight=0.0005
        dropoutRate=0*5:0.5
        ParallelTrain=[
            parallelizationMethod=DataParallelSGD
            distributedMBReading=true
            parallelizationStartEpoch=1
            DataParallelSGD=[
                gradientBits=1
            ]
        ]
        numMBsToShowResult=100
    ]
] [
    reader=[
        readerType=ImageReader
        file=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Image/AlexNet/train_map.txt
        randomize=Auto
        features=[
            width=224
            height=224
            channels=3
            cropType=Random
            cropRatio=0.875
            jitterType=UniRatio
            interpolations=Linear
            meanFile=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Image/AlexNet/ImageNet1K_mean.xml
        ]
        labels=[
            labelDim=1000
        ]
    ]    
]

07/13/2016 12:21:36: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
07/13/2016 12:21:36: Commands: Train AddTop5Eval Test
07/13/2016 12:21:36: Precision = "float"
07/13/2016 12:21:36: CNTKModelPath: /tmp/cntk-test-20160713122133.128226/Image_AlexNet@release_gpu/models/AlexNet
07/13/2016 12:21:36: CNTKCommandTrainInfo: Train : 3
07/13/2016 12:21:36: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 3

07/13/2016 12:21:36: ##############################################################################
07/13/2016 12:21:36: #                                                                            #
07/13/2016 12:21:36: # Action "train"                                                             #
07/13/2016 12:21:36: #                                                                            #
07/13/2016 12:21:36: ##############################################################################

07/13/2016 12:21:36: CNTKCommandTrainBegin: Train
NDLBuilder Using GPU 0
useParallelTrain option is not enabled. ParallelTrain config will be ignored.
07/13/2016 12:21:36: Creating virgin network.
SetGaussianRandomValue (GPU): creating curand object with seed 1, sizeof(ElemType)==4

Post-processing network...

3 roots:
	OutputNodes.z = Plus()
	ce = CrossEntropyWithSoftmax()
	err = ErrorPrediction()

Validating network. 48 nodes to process in pass 1.

Validating --> OutputNodes.W = LearnableParameter() :  -> [1000 x 4096]
Validating --> h2.W = LearnableParameter() :  -> [4096 x 4096]
Validating --> h1.W = LearnableParameter() :  -> [4096 x 6 x 6 x 256]
Validating --> conv5.W = LearnableParameter() :  -> [256 x 2304]
Validating --> conv4.W = LearnableParameter() :  -> [256 x 3456]
Validating --> conv3.W = LearnableParameter() :  -> [384 x 1728]
Validating --> conv2.W = LearnableParameter() :  -> [192 x 1600]
Validating --> conv1.W = LearnableParameter() :  -> [64 x 363]
Validating --> features = InputValue() :  -> [224 x 224 x 3 x *]
Validating --> conv1.c = Convolution (conv1.W, features) : [64 x 363], [224 x 224 x 3 x *] -> [56 x 56 x 64 x *]
Validating --> conv1.b = LearnableParameter() :  -> [1 x 1 x 64]
Validating --> conv1.z = Plus (conv1.c, conv1.b) : [56 x 56 x 64 x *], [1 x 1 x 64] -> [56 x 56 x 64 x *]
Validating --> conv1.y = RectifiedLinear (conv1.z) : [56 x 56 x 64 x *] -> [56 x 56 x 64 x *]
Validating --> pool1 = MaxPooling (conv1.y) : [56 x 56 x 64 x *] -> [27 x 27 x 64 x *]
Validating --> conv2.c = Convolution (conv2.W, pool1) : [192 x 1600], [27 x 27 x 64 x *] -> [27 x 27 x 192 x *]
Validating --> conv2.b = LearnableParameter() :  -> [1 x 1 x 192]
Validating --> conv2.z = Plus (conv2.c, conv2.b) : [27 x 27 x 192 x *], [1 x 1 x 192] -> [27 x 27 x 192 x *]
Validating --> conv2.y = RectifiedLinear (conv2.z) : [27 x 27 x 192 x *] -> [27 x 27 x 192 x *]
Validating --> pool2 = MaxPooling (conv2.y) : [27 x 27 x 192 x *] -> [13 x 13 x 192 x *]
Validating --> conv3.c = Convolution (conv3.W, pool2) : [384 x 1728], [13 x 13 x 192 x *] -> [13 x 13 x 384 x *]
Validating --> conv3.b = LearnableParameter() :  -> [1 x 1 x 384]
Validating --> conv3.z = Plus (conv3.c, conv3.b) : [13 x 13 x 384 x *], [1 x 1 x 384] -> [13 x 13 x 384 x *]
Validating --> conv3.y = RectifiedLinear (conv3.z) : [13 x 13 x 384 x *] -> [13 x 13 x 384 x *]
Validating --> conv4.c = Convolution (conv4.W, conv3.y) : [256 x 3456], [13 x 13 x 384 x *] -> [13 x 13 x 256 x *]
Validating --> conv4.b = LearnableParameter() :  -> [1 x 1 x 256]
Validating --> conv4.z = Plus (conv4.c, conv4.b) : [13 x 13 x 256 x *], [1 x 1 x 256] -> [13 x 13 x 256 x *]
Validating --> conv4.y = RectifiedLinear (conv4.z) : [13 x 13 x 256 x *] -> [13 x 13 x 256 x *]
Validating --> conv5.c = Convolution (conv5.W, conv4.y) : [256 x 2304], [13 x 13 x 256 x *] -> [13 x 13 x 256 x *]
Validating --> conv5.b = LearnableParameter() :  -> [1 x 1 x 256]
Validating --> conv5.z = Plus (conv5.c, conv5.b) : [13 x 13 x 256 x *], [1 x 1 x 256] -> [13 x 13 x 256 x *]
Validating --> conv5.y = RectifiedLinear (conv5.z) : [13 x 13 x 256 x *] -> [13 x 13 x 256 x *]
Validating --> pool3 = MaxPooling (conv5.y) : [13 x 13 x 256 x *] -> [6 x 6 x 256 x *]
Validating --> h1.t = Times (h1.W, pool3) : [4096 x 6 x 6 x 256], [6 x 6 x 256 x *] -> [4096 x *]
Validating --> h1.b = LearnableParameter() :  -> [4096]
Validating --> h1.z = Plus (h1.t, h1.b) : [4096 x *], [4096] -> [4096 x *]
Validating --> h1.y = RectifiedLinear (h1.z) : [4096 x *] -> [4096 x *]
Validating --> h1_d = Dropout (h1.y) : [4096 x *] -> [4096 x *]
Validating --> h2.t = Times (h2.W, h1_d) : [4096 x 4096], [4096 x *] -> [4096 x *]
Validating --> h2.b = LearnableParameter() :  -> [4096]
Validating --> h2.z = Plus (h2.t, h2.b) : [4096 x *], [4096] -> [4096 x *]
Validating --> h2.y = RectifiedLinear (h2.z) : [4096 x *] -> [4096 x *]
Validating --> h2_d = Dropout (h2.y) : [4096 x *] -> [4096 x *]
Validating --> OutputNodes.t = Times (OutputNodes.W, h2_d) : [1000 x 4096], [4096 x *] -> [1000 x *]
Validating --> OutputNodes.b = LearnableParameter() :  -> [1000]
Validating --> OutputNodes.z = Plus (OutputNodes.t, OutputNodes.b) : [1000 x *], [1000] -> [1000 x *]
Validating --> labels = InputValue() :  -> [1000 x *]
Validating --> ce = CrossEntropyWithSoftmax (labels, OutputNodes.z) : [1000 x *], [1000 x *] -> [1]
Validating --> err = ErrorPrediction (labels, OutputNodes.z) : [1000 x *], [1000 x *] -> [1]

Validating network. 30 nodes to process in pass 2.


Validating network, final pass.


conv1.c: using cuDNN convolution engine for geometry: Input: 224 x 224 x 3, Output: 56 x 56 x 64, Kernel: 11 x 11 x 3, Map: 1 x 1 x 64, Stride: 4 x 4 x 3, Sharing: (1), AutoPad: (1), LowerPad: 0, UpperPad: 0.

pool1: using cuDNN convolution engine for geometry: Input: 56 x 56 x 64, Output: 27 x 27 x 64, Kernel: 3 x 3 x 1, Map: 1, Stride: 2 x 2 x 1, Sharing: (1), AutoPad: (0), LowerPad: 0, UpperPad: 0.

conv2.c: using cuDNN convolution engine for geometry: Input: 27 x 27 x 64, Output: 27 x 27 x 192, Kernel: 5 x 5 x 64, Map: 1 x 1 x 192, Stride: 1 x 1 x 64, Sharing: (1), AutoPad: (1), LowerPad: 0, UpperPad: 0.

pool2: using cuDNN convolution engine for geometry: Input: 27 x 27 x 192, Output: 13 x 13 x 192, Kernel: 3 x 3 x 1, Map: 1, Stride: 2 x 2 x 1, Sharing: (1), AutoPad: (0), LowerPad: 0, UpperPad: 0.

conv3.c: using cuDNN convolution engine for geometry: Input: 13 x 13 x 192, Output: 13 x 13 x 384, Kernel: 3 x 3 x 192, Map: 1 x 1 x 384, Stride: 1 x 1 x 192, Sharing: (1), AutoPad: (1), LowerPad: 0, UpperPad: 0.

conv4.c: using cuDNN convolution engine for geometry: Input: 13 x 13 x 384, Output: 13 x 13 x 256, Kernel: 3 x 3 x 384, Map: 1 x 1 x 256, Stride: 1 x 1 x 384, Sharing: (1), AutoPad: (1), LowerPad: 0, UpperPad: 0.

conv5.c: using cuDNN convolution engine for geometry: Input: 13 x 13 x 256, Output: 13 x 13 x 256, Kernel: 3 x 3 x 256, Map: 1 x 1 x 256, Stride: 1 x 1 x 256, Sharing: (1), AutoPad: (1), LowerPad: 0, UpperPad: 0.

pool3: using cuDNN convolution engine for geometry: Input: 13 x 13 x 256, Output: 6 x 6 x 256, Kernel: 3 x 3 x 1, Map: 1, Stride: 2 x 2 x 1, Sharing: (1), AutoPad: (0), LowerPad: 0, UpperPad: 0.


18 out of 48 nodes do not share the minibatch layout with the input data.

Post-processing network complete.

07/13/2016 12:21:36: Created model with 48 nodes on GPU 0.

07/13/2016 12:21:36: Training criterion node(s):
07/13/2016 12:21:36: 	ce = CrossEntropyWithSoftmax

07/13/2016 12:21:36: Evaluation criterion node(s):

07/13/2016 12:21:36: 	err = ErrorPrediction


Allocating matrices for forward and/or backward propagation.

Memory Sharing Structure:

(nil): {[err Gradient[1]] [features Gradient[224 x 224 x 3 x *]] [labels Gradient[1000 x *]] }
0x7f9f167a8d68: {[conv1.c Gradient[56 x 56 x 64 x *]] [conv1.y Value[56 x 56 x 64 x *]] }
0x7f9f167a8ec8: {[conv1.W Gradient[64 x 363]] [conv1.z Value[56 x 56 x 64 x *]] }
0x7f9f167a90c8: {[conv1.z Gradient[56 x 56 x 64 x *]] [pool1 Value[27 x 27 x 64 x *]] }
0x7f9f167a9498: {[conv1.c Value[56 x 56 x 64 x *]] }
0x7f9f167aa1c8: {[conv2.c Gradient[27 x 27 x 192 x *]] [conv2.y Value[27 x 27 x 192 x *]] }
0x7f9f167aa388: {[conv2.z Gradient[27 x 27 x 192 x *]] [pool1 Gradient[27 x 27 x 64 x *]] [pool2 Value[13 x 13 x 192 x *]] }
0x7f9f167aa548: {[conv3.c Value[13 x 13 x 384 x *]] }
0x7f9f167aa708: {[conv2.b Gradient[1 x 1 x 192]] [conv2.y Gradient[27 x 27 x 192 x *]] }
0x7f9f167aa8c8: {[conv3.W Gradient[384 x 1728]] [conv3.z Value[13 x 13 x 384 x *]] }
0x7f9f1699bb58: {[OutputNodes.z Value[1000 x *]] }
0x7f9f169a5498: {[conv3.c Gradient[13 x 13 x 384 x *]] [conv3.y Value[13 x 13 x 384 x *]] }
0x7f9f169a5658: {[conv4.c Value[13 x 13 x 256 x *]] }
0x7f9f169a5818: {[conv3.z Gradient[13 x 13 x 384 x *]] [pool2 Gradient[13 x 13 x 192 x *]] }
0x7f9f169a59d8: {[conv4.W Gradient[256 x 3456]] [conv4.z Value[13 x 13 x 256 x *]] }
0x7f9f169a5b98: {[conv4.c Gradient[13 x 13 x 256 x *]] [conv4.y Value[13 x 13 x 256 x *]] }
0x7f9f169a5d58: {[conv5.c Value[13 x 13 x 256 x *]] }
0x7f9f169a5f18: {[conv3.b Gradient[1 x 1 x 384]] [conv3.y Gradient[13 x 13 x 384 x *]] [conv4.z Gradient[13 x 13 x 256 x *]] }
0x7f9f169a60d8: {[conv5.W Gradient[256 x 2304]] [conv5.z Value[13 x 13 x 256 x *]] }
0x7f9f169a6298: {[conv5.c Gradient[13 x 13 x 256 x *]] [conv5.y Value[13 x 13 x 256 x *]] }
0x7f9f169a6458: {[conv4.b Gradient[1 x 1 x 256]] [conv4.y Gradient[13 x 13 x 256 x *]] [conv5.z Gradient[13 x 13 x 256 x *]] [pool3 Value[6 x 6 x 256 x *]] }
0x7f9f169a6618: {[conv5.b Gradient[1 x 1 x 256]] [conv5.y Gradient[13 x 13 x 256 x *]] [h1.t Value[4096 x *]] }
0x7f9f169a67d8: {[h1.W Gradient[4096 x 6 x 6 x 256]] [h1.z Value[4096 x *]] }
0x7f9f169a6998: {[h1.t Gradient[4096 x *]] [h1.y Value[4096 x *]] }
0x7f9f169a6b58: {[h1_d Value[4096 x *]] }
0x7f9f169a6d18: {[h1.z Gradient[4096 x *]] [pool3 Gradient[6 x 6 x 256 x *]] }
0x7f9f169a6ed8: {[h1.b Gradient[4096]] [h1.y Gradient[4096 x *]] [h2.t Value[4096 x *]] }
0x7f9f169a7098: {[h2.W Gradient[4096 x 4096]] [h2.z Value[4096 x *]] }
0x7f9f169a7258: {[h2.t Gradient[4096 x *]] [h2.y Value[4096 x *]] }
0x7f9f169a7418: {[h2_d Value[4096 x *]] }
0x7f9f169a75d8: {[h1_d Gradient[4096 x *]] [h2.z Gradient[4096 x *]] }
0x7f9f169a7798: {[OutputNodes.t Value[1000 x *]] [h2.b Gradient[4096]] [h2.y Gradient[4096 x *]] }
0x7f9f169a8458: {[ce Gradient[1]] }
0x7f9f169a8618: {[OutputNodes.W Gradient[1000 x 4096]] [OutputNodes.z Gradient[1000 x *]] }
0x7f9f169a87d8: {[OutputNodes.t Gradient[1000 x *]] }
0x7f9f169a8998: {[OutputNodes.b Gradient[1000]] }
0x7f9f169a8b58: {[h2_d Gradient[4096 x *]] }
0x7f9f1efb7178: {[err Value[1]] }
0x7f9f20c832f8: {[conv2.c Value[27 x 27 x 192 x *]] }
0x7f9f20c84908: {[ce Value[1]] }
0x7f9f2155e028: {[conv2.W Value[192 x 1600]] }
0x7f9f2155ef68: {[conv2.b Value[1 x 1 x 192]] }
0x7f9f215609f8: {[conv3.W Value[384 x 1728]] }
0x7f9f21561938: {[conv3.b Value[1 x 1 x 384]] }
0x7f9f21562ee8: {[conv4.W Value[256 x 3456]] }
0x7f9f21564278: {[conv4.b Value[1 x 1 x 256]] }
0x7f9f21565888: {[conv5.W Value[256 x 2304]] }
0x7f9f21566878: {[conv5.b Value[1 x 1 x 256]] }
0x7f9f21568078: {[h1.W Value[4096 x 6 x 6 x 256]] }
0x7f9f21568ed8: {[h1.b Value[4096]] }
0x7f9f2156a028: {[h2.W Value[4096 x 4096]] }
0x7f9f2156b718: {[h2.b Value[4096]] }
0x7f9f2156c2a8: {[OutputNodes.W Value[1000 x 4096]] }
0x7f9f2156d808: {[OutputNodes.b Value[1000]] }
0x7f9f2157d768: {[labels Value[1000 x *]] }
0x7f9f2157e458: {[conv1.W Value[64 x 363]] }
0x7f9f2157f5f8: {[conv1.b Value[1 x 1 x 64]] }
0x7f9f2791c128: {[conv1.b Gradient[1 x 1 x 64]] [conv1.y Gradient[56 x 56 x 64 x *]] }
0x7f9f2791c2e8: {[conv2.W Gradient[192 x 1600]] [conv2.z Value[27 x 27 x 192 x *]] }
0x7f9f27982a58: {[features Value[224 x 224 x 3 x *]] }

07/13/2016 12:21:36: No PreCompute nodes found, skipping PreCompute step.

07/13/2016 12:21:39: Starting Epoch 1: learning rate per sample = 0.000625  effective momentum = 0.900000  momentum as time constant = 151.9 samples
BlockRandomizer::StartEpoch: epoch 0: frames [0..2999] (first sequence at sample 0), data subset 0 of 1

07/13/2016 12:21:39: Starting minibatch loop.
07/13/2016 12:21:45:  Epoch[ 1 of 3]-Minibatch[   1- 100]: ce = 7.40928162 * 1600; err = 1.00000000 * 1600; time = 6.5219s; samplesPerSecond = 245.3
07/13/2016 12:21:50: Finished Epoch[ 1 of 3]: [Training] ce = 7.22442181 * 2999; err = 0.99966656 * 2999; totalSamplesSeen = 2999; learningRatePerSample = 0.00062499999; epochTime=11.602s
07/13/2016 12:21:53: SGD: Saving checkpoint model '/tmp/cntk-test-20160713122133.128226/Image_AlexNet@release_gpu/models/AlexNet.1'

07/13/2016 12:21:55: Starting Epoch 2: learning rate per sample = 0.000625  effective momentum = 0.900000  momentum as time constant = 151.9 samples
BlockRandomizer::StartEpoch: epoch 1: frames [2999..5998] (first sequence at sample 2999), data subset 0 of 1

07/13/2016 12:21:55: Starting minibatch loop.
07/13/2016 12:22:01:  Epoch[ 2 of 3]-Minibatch[   1- 100, 100.00%]: ce = 6.91552551 * 1600; err = 0.99937500 * 1600; time = 5.5979s; samplesPerSecond = 285.8
07/13/2016 12:22:06: Finished Epoch[ 2 of 3]: [Training] ce = 6.92512804 * 2999; err = 0.99799933 * 2999; totalSamplesSeen = 5998; learningRatePerSample = 0.00062499999; epochTime=10.7305s
07/13/2016 12:22:08: SGD: Saving checkpoint model '/tmp/cntk-test-20160713122133.128226/Image_AlexNet@release_gpu/models/AlexNet.2'

07/13/2016 12:22:10: Starting Epoch 3: learning rate per sample = 0.000625  effective momentum = 0.900000  momentum as time constant = 151.9 samples
BlockRandomizer::StartEpoch: epoch 2: frames [5998..8997] (first sequence at sample 5998), data subset 0 of 1

07/13/2016 12:22:10: Starting minibatch loop.
07/13/2016 12:22:16:  Epoch[ 3 of 3]-Minibatch[   1- 100, 100.00%]: ce = 6.87563110 * 1600; err = 0.99875000 * 1600; time = 5.7184s; samplesPerSecond = 279.8
07/13/2016 12:22:21: Finished Epoch[ 3 of 3]: [Training] ce = 6.88505674 * 2999; err = 0.99833278 * 2999; totalSamplesSeen = 8997; learningRatePerSample = 0.00062499999; epochTime=10.7695s
07/13/2016 12:22:23: SGD: Saving checkpoint model '/tmp/cntk-test-20160713122133.128226/Image_AlexNet@release_gpu/models/AlexNet'
07/13/2016 12:22:26: CNTKCommandTrainEnd: Train

07/13/2016 12:22:26: Action "train" complete.


07/13/2016 12:22:26: ##############################################################################
07/13/2016 12:22:26: #                                                                            #
07/13/2016 12:22:26: # Action "edit"                                                              #
07/13/2016 12:22:26: #                                                                            #
07/13/2016 12:22:26: ##############################################################################


Post-processing network...

3 roots:
	OutputNodes.z = Plus()
	ce = CrossEntropyWithSoftmax()
	err = ErrorPrediction()

Validating network. 48 nodes to process in pass 1.

Validating --> OutputNodes.W = LearnableParameter() :  -> [1000 x 4096]
Validating --> h2.W = LearnableParameter() :  -> [4096 x 4096]
Validating --> h1.W = LearnableParameter() :  -> [4096 x 6 x 6 x 256]
Validating --> conv5.W = LearnableParameter() :  -> [256 x 2304]
Validating --> conv4.W = LearnableParameter() :  -> [256 x 3456]
Validating --> conv3.W = LearnableParameter() :  -> [384 x 1728]
Validating --> conv2.W = LearnableParameter() :  -> [192 x 1600]
Validating --> conv1.W = LearnableParameter() :  -> [64 x 363]
Validating --> features = InputValue() :  -> [224 x 224 x 3 x *1]
Validating --> conv1.c = Convolution (conv1.W, features) : [64 x 363], [224 x 224 x 3 x *1] -> [56 x 56 x 64 x *1]
Validating --> conv1.b = LearnableParameter() :  -> [1 x 1 x 64]
Validating --> conv1.z = Plus (conv1.c, conv1.b) : [56 x 56 x 64 x *1], [1 x 1 x 64] -> [56 x 56 x 64 x *1]
Validating --> conv1.y = RectifiedLinear (conv1.z) : [56 x 56 x 64 x *1] -> [56 x 56 x 64 x *1]
Validating --> pool1 = MaxPooling (conv1.y) : [56 x 56 x 64 x *1] -> [27 x 27 x 64 x *1]
Validating --> conv2.c = Convolution (conv2.W, pool1) : [192 x 1600], [27 x 27 x 64 x *1] -> [27 x 27 x 192 x *1]
Validating --> conv2.b = LearnableParameter() :  -> [1 x 1 x 192]
Validating --> conv2.z = Plus (conv2.c, conv2.b) : [27 x 27 x 192 x *1], [1 x 1 x 192] -> [27 x 27 x 192 x *1]
Validating --> conv2.y = RectifiedLinear (conv2.z) : [27 x 27 x 192 x *1] -> [27 x 27 x 192 x *1]
Validating --> pool2 = MaxPooling (conv2.y) : [27 x 27 x 192 x *1] -> [13 x 13 x 192 x *1]
Validating --> conv3.c = Convolution (conv3.W, pool2) : [384 x 1728], [13 x 13 x 192 x *1] -> [13 x 13 x 384 x *1]
Validating --> conv3.b = LearnableParameter() :  -> [1 x 1 x 384]
Validating --> conv3.z = Plus (conv3.c, conv3.b) : [13 x 13 x 384 x *1], [1 x 1 x 384] -> [13 x 13 x 384 x *1]
Validating --> conv3.y = RectifiedLinear (conv3.z) : [13 x 13 x 384 x *1] -> [13 x 13 x 384 x *1]
Validating --> conv4.c = Convolution (conv4.W, conv3.y) : [256 x 3456], [13 x 13 x 384 x *1] -> [13 x 13 x 256 x *1]
Validating --> conv4.b = LearnableParameter() :  -> [1 x 1 x 256]
Validating --> conv4.z = Plus (conv4.c, conv4.b) : [13 x 13 x 256 x *1], [1 x 1 x 256] -> [13 x 13 x 256 x *1]
Validating --> conv4.y = RectifiedLinear (conv4.z) : [13 x 13 x 256 x *1] -> [13 x 13 x 256 x *1]
Validating --> conv5.c = Convolution (conv5.W, conv4.y) : [256 x 2304], [13 x 13 x 256 x *1] -> [13 x 13 x 256 x *1]
Validating --> conv5.b = LearnableParameter() :  -> [1 x 1 x 256]
Validating --> conv5.z = Plus (conv5.c, conv5.b) : [13 x 13 x 256 x *1], [1 x 1 x 256] -> [13 x 13 x 256 x *1]
Validating --> conv5.y = RectifiedLinear (conv5.z) : [13 x 13 x 256 x *1] -> [13 x 13 x 256 x *1]
Validating --> pool3 = MaxPooling (conv5.y) : [13 x 13 x 256 x *1] -> [6 x 6 x 256 x *1]
Validating --> h1.t = Times (h1.W, pool3) : [4096 x 6 x 6 x 256], [6 x 6 x 256 x *1] -> [4096 x *1]
Validating --> h1.b = LearnableParameter() :  -> [4096]
Validating --> h1.z = Plus (h1.t, h1.b) : [4096 x *1], [4096] -> [4096 x *1]
Validating --> h1.y = RectifiedLinear (h1.z) : [4096 x *1] -> [4096 x *1]
Validating --> h1_d = Dropout (h1.y) : [4096 x *1] -> [4096 x *1]
Validating --> h2.t = Times (h2.W, h1_d) : [4096 x 4096], [4096 x *1] -> [4096 x *1]
Validating --> h2.b = LearnableParameter() :  -> [4096]
Validating --> h2.z = Plus (h2.t, h2.b) : [4096 x *1], [4096] -> [4096 x *1]
Validating --> h2.y = RectifiedLinear (h2.z) : [4096 x *1] -> [4096 x *1]
Validating --> h2_d = Dropout (h2.y) : [4096 x *1] -> [4096 x *1]
Validating --> OutputNodes.t = Times (OutputNodes.W, h2_d) : [1000 x 4096], [4096 x *1] -> [1000 x *1]
Validating --> OutputNodes.b = LearnableParameter() :  -> [1000]
Validating --> OutputNodes.z = Plus (OutputNodes.t, OutputNodes.b) : [1000 x *1], [1000] -> [1000 x *1]
Validating --> labels = InputValue() :  -> [1000 x *1]
Validating --> ce = CrossEntropyWithSoftmax (labels, OutputNodes.z) : [1000 x *1], [1000 x *1] -> [1]
Validating --> err = ErrorPrediction (labels, OutputNodes.z) : [1000 x *1], [1000 x *1] -> [1]

Validating network. 30 nodes to process in pass 2.


Validating network, final pass.


conv1.c: using GEMM convolution engine for geometry: Input: 224 x 224 x 3, Output: 56 x 56 x 64, Kernel: 11 x 11 x 3, Map: 1 x 1 x 64, Stride: 4 x 4 x 3, Sharing: (1), AutoPad: (1), LowerPad: 0, UpperPad: 0.

pool1: using GEMM convolution engine for geometry: Input: 56 x 56 x 64, Output: 27 x 27 x 64, Kernel: 3 x 3 x 1, Map: 1, Stride: 2 x 2 x 1, Sharing: (1), AutoPad: (0), LowerPad: 0, UpperPad: 0.

conv2.c: using GEMM convolution engine for geometry: Input: 27 x 27 x 64, Output: 27 x 27 x 192, Kernel: 5 x 5 x 64, Map: 1 x 1 x 192, Stride: 1 x 1 x 64, Sharing: (1), AutoPad: (1), LowerPad: 0, UpperPad: 0.

pool2: using GEMM convolution engine for geometry: Input: 27 x 27 x 192, Output: 13 x 13 x 192, Kernel: 3 x 3 x 1, Map: 1, Stride: 2 x 2 x 1, Sharing: (1), AutoPad: (0), LowerPad: 0, UpperPad: 0.

conv3.c: using GEMM convolution engine for geometry: Input: 13 x 13 x 192, Output: 13 x 13 x 384, Kernel: 3 x 3 x 192, Map: 1 x 1 x 384, Stride: 1 x 1 x 192, Sharing: (1), AutoPad: (1), LowerPad: 0, UpperPad: 0.

conv4.c: using GEMM convolution engine for geometry: Input: 13 x 13 x 384, Output: 13 x 13 x 256, Kernel: 3 x 3 x 384, Map: 1 x 1 x 256, Stride: 1 x 1 x 384, Sharing: (1), AutoPad: (1), LowerPad: 0, UpperPad: 0.

conv5.c: using GEMM convolution engine for geometry: Input: 13 x 13 x 256, Output: 13 x 13 x 256, Kernel: 3 x 3 x 256, Map: 1 x 1 x 256, Stride: 1 x 1 x 256, Sharing: (1), AutoPad: (1), LowerPad: 0, UpperPad: 0.

pool3: using GEMM convolution engine for geometry: Input: 13 x 13 x 256, Output: 6 x 6 x 256, Kernel: 3 x 3 x 1, Map: 1, Stride: 2 x 2 x 1, Sharing: (1), AutoPad: (0), LowerPad: 0, UpperPad: 0.


18 out of 48 nodes do not share the minibatch layout with the input data.

Post-processing network complete.


Post-processing network...

4 roots:
	OutputNodes.z = Plus()
	ce = CrossEntropyWithSoftmax()
	err = ErrorPrediction()
	errTop5 = ErrorPrediction()

Validating network. 50 nodes to process in pass 1.

Validating --> OutputNodes.W = LearnableParameter() :  -> [1000 x 4096]
Validating --> h2.W = LearnableParameter() :  -> [4096 x 4096]
Validating --> h1.W = LearnableParameter() :  -> [4096 x 6 x 6 x 256]
Validating --> conv5.W = LearnableParameter() :  -> [256 x 2304]
Validating --> conv4.W = LearnableParameter() :  -> [256 x 3456]
Validating --> conv3.W = LearnableParameter() :  -> [384 x 1728]
Validating --> conv2.W = LearnableParameter() :  -> [192 x 1600]
Validating --> conv1.W = LearnableParameter() :  -> [64 x 363]
Validating --> features = InputValue() :  -> [224 x 224 x 3 x *1]
Validating --> conv1.c = Convolution (conv1.W, features) : [64 x 363], [224 x 224 x 3 x *1] -> [56 x 56 x 64 x *1]
Validating --> conv1.b = LearnableParameter() :  -> [1 x 1 x 64]
Validating --> conv1.z = Plus (conv1.c, conv1.b) : [56 x 56 x 64 x *1], [1 x 1 x 64] -> [56 x 56 x 64 x *1]
Validating --> conv1.y = RectifiedLinear (conv1.z) : [56 x 56 x 64 x *1] -> [56 x 56 x 64 x *1]
Validating --> pool1 = MaxPooling (conv1.y) : [56 x 56 x 64 x *1] -> [27 x 27 x 64 x *1]
Validating --> conv2.c = Convolution (conv2.W, pool1) : [192 x 1600], [27 x 27 x 64 x *1] -> [27 x 27 x 192 x *1]
Validating --> conv2.b = LearnableParameter() :  -> [1 x 1 x 192]
Validating --> conv2.z = Plus (conv2.c, conv2.b) : [27 x 27 x 192 x *1], [1 x 1 x 192] -> [27 x 27 x 192 x *1]
Validating --> conv2.y = RectifiedLinear (conv2.z) : [27 x 27 x 192 x *1] -> [27 x 27 x 192 x *1]
Validating --> pool2 = MaxPooling (conv2.y) : [27 x 27 x 192 x *1] -> [13 x 13 x 192 x *1]
Validating --> conv3.c = Convolution (conv3.W, pool2) : [384 x 1728], [13 x 13 x 192 x *1] -> [13 x 13 x 384 x *1]
Validating --> conv3.b = LearnableParameter() :  -> [1 x 1 x 384]
Validating --> conv3.z = Plus (conv3.c, conv3.b) : [13 x 13 x 384 x *1], [1 x 1 x 384] -> [13 x 13 x 384 x *1]
Validating --> conv3.y = RectifiedLinear (conv3.z) : [13 x 13 x 384 x *1] -> [13 x 13 x 384 x *1]
Validating --> conv4.c = Convolution (conv4.W, conv3.y) : [256 x 3456], [13 x 13 x 384 x *1] -> [13 x 13 x 256 x *1]
Validating --> conv4.b = LearnableParameter() :  -> [1 x 1 x 256]
Validating --> conv4.z = Plus (conv4.c, conv4.b) : [13 x 13 x 256 x *1], [1 x 1 x 256] -> [13 x 13 x 256 x *1]
Validating --> conv4.y = RectifiedLinear (conv4.z) : [13 x 13 x 256 x *1] -> [13 x 13 x 256 x *1]
Validating --> conv5.c = Convolution (conv5.W, conv4.y) : [256 x 2304], [13 x 13 x 256 x *1] -> [13 x 13 x 256 x *1]
Validating --> conv5.b = LearnableParameter() :  -> [1 x 1 x 256]
Validating --> conv5.z = Plus (conv5.c, conv5.b) : [13 x 13 x 256 x *1], [1 x 1 x 256] -> [13 x 13 x 256 x *1]
Validating --> conv5.y = RectifiedLinear (conv5.z) : [13 x 13 x 256 x *1] -> [13 x 13 x 256 x *1]
Validating --> pool3 = MaxPooling (conv5.y) : [13 x 13 x 256 x *1] -> [6 x 6 x 256 x *1]
Validating --> h1.t = Times (h1.W, pool3) : [4096 x 6 x 6 x 256], [6 x 6 x 256 x *1] -> [4096 x *1]
Validating --> h1.b = LearnableParameter() :  -> [4096]
Validating --> h1.z = Plus (h1.t, h1.b) : [4096 x *1], [4096] -> [4096 x *1]
Validating --> h1.y = RectifiedLinear (h1.z) : [4096 x *1] -> [4096 x *1]
Validating --> h1_d = Dropout (h1.y) : [4096 x *1] -> [4096 x *1]
Validating --> h2.t = Times (h2.W, h1_d) : [4096 x 4096], [4096 x *1] -> [4096 x *1]
Validating --> h2.b = LearnableParameter() :  -> [4096]
Validating --> h2.z = Plus (h2.t, h2.b) : [4096 x *1], [4096] -> [4096 x *1]
Validating --> h2.y = RectifiedLinear (h2.z) : [4096 x *1] -> [4096 x *1]
Validating --> h2_d = Dropout (h2.y) : [4096 x *1] -> [4096 x *1]
Validating --> OutputNodes.t = Times (OutputNodes.W, h2_d) : [1000 x 4096], [4096 x *1] -> [1000 x *1]
Validating --> OutputNodes.b = LearnableParameter() :  -> [1000]
Validating --> OutputNodes.z = Plus (OutputNodes.t, OutputNodes.b) : [1000 x *1], [1000] -> [1000 x *1]
Validating --> labels = InputValue() :  -> [1000 x *1]
Validating --> ce = CrossEntropyWithSoftmax (labels, OutputNodes.z) : [1000 x *1], [1000 x *1] -> [1]
Validating --> err = ErrorPrediction (labels, OutputNodes.z) : [1000 x *1], [1000 x *1] -> [1]
Validating --> unnamed137 = LearnableParameter() :  -> [1 x 1]
Validating --> errTop5 = ErrorPrediction (labels, OutputNodes.z, unnamed137) : [1000 x *1], [1000 x *1], [1 x 1] -> [1]

Validating network. 31 nodes to process in pass 2.


Validating network, final pass.



20 out of 50 nodes do not share the minibatch layout with the input data.

Post-processing network complete.


07/13/2016 12:22:30: Action "edit" complete.


07/13/2016 12:22:30: ##############################################################################
07/13/2016 12:22:30: #                                                                            #
07/13/2016 12:22:30: # Action "test"                                                              #
07/13/2016 12:22:30: #                                                                            #
07/13/2016 12:22:30: ##############################################################################

NDLBuilder Using GPU 0

Post-processing network...

3 roots:
	OutputNodes.z = Plus()
	ce = CrossEntropyWithSoftmax()
	err = ErrorPrediction()

Validating network. 48 nodes to process in pass 1.

Validating --> OutputNodes.W = LearnableParameter() :  -> [1000 x 4096]
Validating --> h2.W = LearnableParameter() :  -> [4096 x 4096]
Validating --> h1.W = LearnableParameter() :  -> [4096 x 6 x 6 x 256]
Validating --> conv5.W = LearnableParameter() :  -> [256 x 2304]
Validating --> conv4.W = LearnableParameter() :  -> [256 x 3456]
Validating --> conv3.W = LearnableParameter() :  -> [384 x 1728]
Validating --> conv2.W = LearnableParameter() :  -> [192 x 1600]
Validating --> conv1.W = LearnableParameter() :  -> [64 x 363]
Validating --> features = InputValue() :  -> [224 x 224 x 3 x *2]
Validating --> conv1.c = Convolution (conv1.W, features) : [64 x 363], [224 x 224 x 3 x *2] -> [56 x 56 x 64 x *2]
Validating --> conv1.b = LearnableParameter() :  -> [1 x 1 x 64]
Validating --> conv1.z = Plus (conv1.c, conv1.b) : [56 x 56 x 64 x *2], [1 x 1 x 64] -> [56 x 56 x 64 x *2]
Validating --> conv1.y = RectifiedLinear (conv1.z) : [56 x 56 x 64 x *2] -> [56 x 56 x 64 x *2]
Validating --> pool1 = MaxPooling (conv1.y) : [56 x 56 x 64 x *2] -> [27 x 27 x 64 x *2]
Validating --> conv2.c = Convolution (conv2.W, pool1) : [192 x 1600], [27 x 27 x 64 x *2] -> [27 x 27 x 192 x *2]
Validating --> conv2.b = LearnableParameter() :  -> [1 x 1 x 192]
Validating --> conv2.z = Plus (conv2.c, conv2.b) : [27 x 27 x 192 x *2], [1 x 1 x 192] -> [27 x 27 x 192 x *2]
Validating --> conv2.y = RectifiedLinear (conv2.z) : [27 x 27 x 192 x *2] -> [27 x 27 x 192 x *2]
Validating --> pool2 = MaxPooling (conv2.y) : [27 x 27 x 192 x *2] -> [13 x 13 x 192 x *2]
Validating --> conv3.c = Convolution (conv3.W, pool2) : [384 x 1728], [13 x 13 x 192 x *2] -> [13 x 13 x 384 x *2]
Validating --> conv3.b = LearnableParameter() :  -> [1 x 1 x 384]
Validating --> conv3.z = Plus (conv3.c, conv3.b) : [13 x 13 x 384 x *2], [1 x 1 x 384] -> [13 x 13 x 384 x *2]
Validating --> conv3.y = RectifiedLinear (conv3.z) : [13 x 13 x 384 x *2] -> [13 x 13 x 384 x *2]
Validating --> conv4.c = Convolution (conv4.W, conv3.y) : [256 x 3456], [13 x 13 x 384 x *2] -> [13 x 13 x 256 x *2]
Validating --> conv4.b = LearnableParameter() :  -> [1 x 1 x 256]
Validating --> conv4.z = Plus (conv4.c, conv4.b) : [13 x 13 x 256 x *2], [1 x 1 x 256] -> [13 x 13 x 256 x *2]
Validating --> conv4.y = RectifiedLinear (conv4.z) : [13 x 13 x 256 x *2] -> [13 x 13 x 256 x *2]
Validating --> conv5.c = Convolution (conv5.W, conv4.y) : [256 x 2304], [13 x 13 x 256 x *2] -> [13 x 13 x 256 x *2]
Validating --> conv5.b = LearnableParameter() :  -> [1 x 1 x 256]
Validating --> conv5.z = Plus (conv5.c, conv5.b) : [13 x 13 x 256 x *2], [1 x 1 x 256] -> [13 x 13 x 256 x *2]
Validating --> conv5.y = RectifiedLinear (conv5.z) : [13 x 13 x 256 x *2] -> [13 x 13 x 256 x *2]
Validating --> pool3 = MaxPooling (conv5.y) : [13 x 13 x 256 x *2] -> [6 x 6 x 256 x *2]
Validating --> h1.t = Times (h1.W, pool3) : [4096 x 6 x 6 x 256], [6 x 6 x 256 x *2] -> [4096 x *2]
Validating --> h1.b = LearnableParameter() :  -> [4096]
Validating --> h1.z = Plus (h1.t, h1.b) : [4096 x *2], [4096] -> [4096 x *2]
Validating --> h1.y = RectifiedLinear (h1.z) : [4096 x *2] -> [4096 x *2]
Validating --> h1_d = Dropout (h1.y) : [4096 x *2] -> [4096 x *2]
Validating --> h2.t = Times (h2.W, h1_d) : [4096 x 4096], [4096 x *2] -> [4096 x *2]
Validating --> h2.b = LearnableParameter() :  -> [4096]
Validating --> h2.z = Plus (h2.t, h2.b) : [4096 x *2], [4096] -> [4096 x *2]
Validating --> h2.y = RectifiedLinear (h2.z) : [4096 x *2] -> [4096 x *2]
Validating --> h2_d = Dropout (h2.y) : [4096 x *2] -> [4096 x *2]
Validating --> OutputNodes.t = Times (OutputNodes.W, h2_d) : [1000 x 4096], [4096 x *2] -> [1000 x *2]
Validating --> OutputNodes.b = LearnableParameter() :  -> [1000]
Validating --> OutputNodes.z = Plus (OutputNodes.t, OutputNodes.b) : [1000 x *2], [1000] -> [1000 x *2]
Validating --> labels = InputValue() :  -> [1000 x *2]
Validating --> ce = CrossEntropyWithSoftmax (labels, OutputNodes.z) : [1000 x *2], [1000 x *2] -> [1]
Validating --> err = ErrorPrediction (labels, OutputNodes.z) : [1000 x *2], [1000 x *2] -> [1]

Validating network. 30 nodes to process in pass 2.


Validating network, final pass.


conv1.c: using cuDNN convolution engine for geometry: Input: 224 x 224 x 3, Output: 56 x 56 x 64, Kernel: 11 x 11 x 3, Map: 1 x 1 x 64, Stride: 4 x 4 x 3, Sharing: (1), AutoPad: (1), LowerPad: 0, UpperPad: 0.

pool1: using cuDNN convolution engine for geometry: Input: 56 x 56 x 64, Output: 27 x 27 x 64, Kernel: 3 x 3 x 1, Map: 1, Stride: 2 x 2 x 1, Sharing: (1), AutoPad: (0), LowerPad: 0, UpperPad: 0.

conv2.c: using cuDNN convolution engine for geometry: Input: 27 x 27 x 64, Output: 27 x 27 x 192, Kernel: 5 x 5 x 64, Map: 1 x 1 x 192, Stride: 1 x 1 x 64, Sharing: (1), AutoPad: (1), LowerPad: 0, UpperPad: 0.

pool2: using cuDNN convolution engine for geometry: Input: 27 x 27 x 192, Output: 13 x 13 x 192, Kernel: 3 x 3 x 1, Map: 1, Stride: 2 x 2 x 1, Sharing: (1), AutoPad: (0), LowerPad: 0, UpperPad: 0.

conv3.c: using cuDNN convolution engine for geometry: Input: 13 x 13 x 192, Output: 13 x 13 x 384, Kernel: 3 x 3 x 192, Map: 1 x 1 x 384, Stride: 1 x 1 x 192, Sharing: (1), AutoPad: (1), LowerPad: 0, UpperPad: 0.

conv4.c: using cuDNN convolution engine for geometry: Input: 13 x 13 x 384, Output: 13 x 13 x 256, Kernel: 3 x 3 x 384, Map: 1 x 1 x 256, Stride: 1 x 1 x 384, Sharing: (1), AutoPad: (1), LowerPad: 0, UpperPad: 0.

conv5.c: using cuDNN convolution engine for geometry: Input: 13 x 13 x 256, Output: 13 x 13 x 256, Kernel: 3 x 3 x 256, Map: 1 x 1 x 256, Stride: 1 x 1 x 256, Sharing: (1), AutoPad: (1), LowerPad: 0, UpperPad: 0.

pool3: using cuDNN convolution engine for geometry: Input: 13 x 13 x 256, Output: 6 x 6 x 256, Kernel: 3 x 3 x 1, Map: 1, Stride: 2 x 2 x 1, Sharing: (1), AutoPad: (0), LowerPad: 0, UpperPad: 0.


18 out of 48 nodes do not share the minibatch layout with the input data.

Post-processing network complete.

evalNodeNames are not specified, using all the default evalnodes and training criterion nodes.


Allocating matrices for forward and/or backward propagation.

Memory Sharing Structure:

(nil): {[OutputNodes.W Gradient[1000 x 4096]] [OutputNodes.b Gradient[1000]] [OutputNodes.t Gradient[1000 x *2]] [OutputNodes.z Gradient[1000 x *2]] [ce Gradient[1]] [conv1.W Gradient[64 x 363]] [conv1.b Gradient[1 x 1 x 64]] [conv1.c Gradient[56 x 56 x 64 x *2]] [conv1.y Gradient[56 x 56 x 64 x *2]] [conv1.z Gradient[56 x 56 x 64 x *2]] [conv2.W Gradient[192 x 1600]] [conv2.b Gradient[1 x 1 x 192]] [conv2.c Gradient[27 x 27 x 192 x *2]] [conv2.y Gradient[27 x 27 x 192 x *2]] [conv2.z Gradient[27 x 27 x 192 x *2]] [conv3.W Gradient[384 x 1728]] [conv3.b Gradient[1 x 1 x 384]] [conv3.c Gradient[13 x 13 x 384 x *2]] [conv3.y Gradient[13 x 13 x 384 x *2]] [conv3.z Gradient[13 x 13 x 384 x *2]] [conv4.W Gradient[256 x 3456]] [conv4.b Gradient[1 x 1 x 256]] [conv4.c Gradient[13 x 13 x 256 x *2]] [conv4.y Gradient[13 x 13 x 256 x *2]] [conv4.z Gradient[13 x 13 x 256 x *2]] [conv5.W Gradient[256 x 2304]] [conv5.b Gradient[1 x 1 x 256]] [conv5.c Gradient[13 x 13 x 256 x *2]] [conv5.y Gradient[13 x 13 x 256 x *2]] [conv5.z Gradient[13 x 13 x 256 x *2]] [err Gradient[1]] [features Gradient[224 x 224 x 3 x *2]] [h1.W Gradient[4096 x 6 x 6 x 256]] [h1.b Gradient[4096]] [h1.t Gradient[4096 x *2]] [h1.y Gradient[4096 x *2]] [h1.z Gradient[4096 x *2]] [h1_d Gradient[4096 x *2]] [h2.W Gradient[4096 x 4096]] [h2.b Gradient[4096]] [h2.t Gradient[4096 x *2]] [h2.y Gradient[4096 x *2]] [h2.z Gradient[4096 x *2]] [h2_d Gradient[4096 x *2]] [labels Gradient[1000 x *2]] [pool1 Gradient[27 x 27 x 64 x *2]] [pool2 Gradient[13 x 13 x 192 x *2]] [pool3 Gradient[6 x 6 x 256 x *2]] }
0x7f9efb529df8: {[conv3.c Value[13 x 13 x 384 x *2]] }
0x7f9efb52bc38: {[h2_d Value[4096 x *2]] }
0x7f9efb533378: {[conv5.c Value[13 x 13 x 256 x *2]] }
0x7f9efb5334b8: {[h1.t Value[4096 x *2]] }
0x7f9efb5340f8: {[pool2 Value[13 x 13 x 192 x *2]] }
0x7f9efb536ad8: {[labels Value[1000 x *2]] }
0x7f9efb538f68: {[OutputNodes.t Value[1000 x *2]] }
0x7f9efb539668: {[err Value[1]] }
0x7f9efb53af98: {[conv2.y Value[27 x 27 x 192 x *2]] }
0x7f9efb53cd48: {[h2.t Value[4096 x *2]] }
0x7f9efb53e188: {[ce Value[1]] }
0x7f9efb53e2e8: {[h1_d Value[4096 x *2]] }
0x7f9efb540698: {[conv2.c Value[27 x 27 x 192 x *2]] }
0x7f9efb541ec8: {[h1.y Value[4096 x *2]] }
0x7f9efb541fb8: {[conv1.c Value[56 x 56 x 64 x *2]] }
0x7f9efb5420c8: {[pool3 Value[6 x 6 x 256 x *2]] }
0x7f9efb5438a8: {[conv2.z Value[27 x 27 x 192 x *2]] }
0x7f9efb5442d8: {[pool1 Value[27 x 27 x 64 x *2]] }
0x7f9efb5481f8: {[conv1.y Value[56 x 56 x 64 x *2]] }
0x7f9efb54a238: {[conv3.z Value[13 x 13 x 384 x *2]] }
0x7f9efb54a6b8: {[h2.y Value[4096 x *2]] }
0x7f9efb54a9e8: {[conv1.z Value[56 x 56 x 64 x *2]] }
0x7f9efb54ab88: {[h2.z Value[4096 x *2]] }
0x7f9efb54ada8: {[conv4.c Value[13 x 13 x 256 x *2]] }
0x7f9efb54cd38: {[h1.z Value[4096 x *2]] }
0x7f9efb5518e8: {[conv4.z Value[13 x 13 x 256 x *2]] }
0x7f9efb551a58: {[conv3.y Value[13 x 13 x 384 x *2]] }
0x7f9efb551d78: {[features Value[224 x 224 x 3 x *2]] }
0x7f9efb551f28: {[conv4.y Value[13 x 13 x 256 x *2]] }
0x7f9efb552d38: {[conv1.W Value[64 x 363]] }
0x7f9efb553578: {[conv1.b Value[1 x 1 x 64]] }
0x7f9efb554c38: {[conv2.W Value[192 x 1600]] }
0x7f9efb555cc8: {[conv2.b Value[1 x 1 x 192]] }
0x7f9efb5574d8: {[conv3.W Value[384 x 1728]] }
0x7f9efb558658: {[conv3.b Value[1 x 1 x 384]] }
0x7f9efb5598e8: {[conv4.W Value[256 x 3456]] }
0x7f9efb55ac78: {[conv4.b Value[1 x 1 x 256]] }
0x7f9efb55be68: {[conv5.W Value[256 x 2304]] }
0x7f9efb55d2f8: {[conv5.b Value[1 x 1 x 256]] }
0x7f9efb55ec38: {[h1.W Value[4096 x 6 x 6 x 256]] }
0x7f9efb55f7a8: {[h1.b Value[4096]] }
0x7f9efb560bd8: {[h2.W Value[4096 x 4096]] }
0x7f9efb561ef8: {[h2.b Value[4096]] }
0x7f9efb562b08: {[OutputNodes.W Value[1000 x 4096]] }
0x7f9efb564208: {[OutputNodes.b Value[1000]] }
0x7f9efb566908: {[OutputNodes.z Value[1000 x *2]] }
0x7f9efb56af18: {[conv5.z Value[13 x 13 x 256 x *2]] }
0x7f9efb56afb8: {[conv5.y Value[13 x 13 x 256 x *2]] }

07/13/2016 12:22:31: Minibatch[1-32]: err = 0.99800000 * 500; ce = 7.32804747 * 500
07/13/2016 12:22:31: Final Results: Minibatch[1-32]: err = 0.99800000 * 500; ce = 7.32804747 * 500; perplexity = 1522.40633004

07/13/2016 12:22:31: Action "test" complete.

07/13/2016 12:22:31: __COMPLETED__
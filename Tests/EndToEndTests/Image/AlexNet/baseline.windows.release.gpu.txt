CPU info:
    CPU Model Name: Intel(R) Xeon(R) CPU E5-2630 v2 @ 2.60GHz
    Hardware threads: 24
    Total Memory: 268381192 kB
-------------------------------------------------------------------
Copying test data to local directory
=== Running /cygdrive/c/jenkins/workspace/CNTK-Test-Windows-W1/x64/release/cntk.exe configFile=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Image\AlexNet/AlexNetCommon.cntk currentDirectory=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714052910.364117\Image_AlexNet@release_gpu\TestData RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714052910.364117\Image_AlexNet@release_gpu DataDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714052910.364117\Image_AlexNet@release_gpu\TestData ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Image\AlexNet OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714052910.364117\Image_AlexNet@release_gpu DeviceId=0 timestamping=true configFile=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Image\AlexNet/AlexNet.cntk
-------------------------------------------------------------------
Build info: 

		Built time: Jul 14 2016 05:09:49
		Last modified date: Fri Jul  8 10:29:39 2016
		Build type: Release
		Build target: GPU
		With 1bit-SGD: no
		Math lib: mkl
		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.5
		CUB_PATH: C:\src\cub-1.4.1
		CUDNN_PATH: c:\NVIDIA\cudnn-4.0\cuda
		Build Branch: HEAD
		Build SHA1: 72bee394bf461e8f6f0feb593a8416c05f481957
		Built by svcphil on DPHAIM-24
		Build Path: c:\jenkins\workspace\CNTK-Build-Windows\Source\CNTK\
-------------------------------------------------------------------
Changed current directory to C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714052910.364117\Image_AlexNet@release_gpu\TestData
07/14/2016 05:29:38: -------------------------------------------------------------------
07/14/2016 05:29:38: Build info: 

07/14/2016 05:29:38: 		Built time: Jul 14 2016 05:09:49
07/14/2016 05:29:38: 		Last modified date: Fri Jul  8 10:29:39 2016
07/14/2016 05:29:38: 		Build type: Release
07/14/2016 05:29:38: 		Build target: GPU
07/14/2016 05:29:38: 		With 1bit-SGD: no
07/14/2016 05:29:38: 		Math lib: mkl
07/14/2016 05:29:38: 		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.5
07/14/2016 05:29:38: 		CUB_PATH: C:\src\cub-1.4.1
07/14/2016 05:29:38: 		CUDNN_PATH: c:\NVIDIA\cudnn-4.0\cuda
07/14/2016 05:29:38: 		Build Branch: HEAD
07/14/2016 05:29:38: 		Build SHA1: 72bee394bf461e8f6f0feb593a8416c05f481957
07/14/2016 05:29:38: 		Built by svcphil on DPHAIM-24
07/14/2016 05:29:38: 		Build Path: c:\jenkins\workspace\CNTK-Build-Windows\Source\CNTK\
07/14/2016 05:29:38: -------------------------------------------------------------------
07/14/2016 05:29:39: -------------------------------------------------------------------
07/14/2016 05:29:39: GPU info:

07/14/2016 05:29:39: 		Device[0]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3072 MB
07/14/2016 05:29:39: 		Device[1]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3072 MB
07/14/2016 05:29:39: 		Device[2]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3072 MB
07/14/2016 05:29:39: -------------------------------------------------------------------

07/14/2016 05:29:39: Running on DPHAIM-25 at 2016/07/14 05:29:39
07/14/2016 05:29:39: Command line: 
C:\jenkins\workspace\CNTK-Test-Windows-W1\x64\release\cntk.exe  configFile=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Image\AlexNet/AlexNetCommon.cntk  currentDirectory=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714052910.364117\Image_AlexNet@release_gpu\TestData  RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714052910.364117\Image_AlexNet@release_gpu  DataDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714052910.364117\Image_AlexNet@release_gpu\TestData  ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Image\AlexNet  OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714052910.364117\Image_AlexNet@release_gpu  DeviceId=0  timestamping=true  configFile=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Image\AlexNet/AlexNet.cntk



07/14/2016 05:29:39: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
07/14/2016 05:29:39: ModelDir = "$RunDir$/models"
ndlMacros=$ConfigDir$/Macros.ndl
precision=float
deviceId=Auto
command=Train:AddTop5Eval:Test
parallelTrain=false
traceLevel=1
numMBsToShowResult=100
Train=[
    action=train
    modelPath=$ModelDir$/AlexNet
    NDLNetworkBuilder=[
        networkDescription=$ConfigDir$/AlexNet.ndl
    ]
    SGD=[
        epochSize=0
        minibatchSize=16
        learningRatesPerMB=0.01*20:0.003*12:0.001*28:0.0003
        momentumPerMB=0.9
        maxEpochs=3
        gradUpdateType=None
        L2RegWeight=0.0005
        dropoutRate=0*5:0.5
        ParallelTrain=[
            parallelizationMethod=DataParallelSGD
            distributedMBReading=true
            parallelizationStartEpoch=1
            DataParallelSGD=[
                gradientBits=1
            ]
        ]
        numMBsToShowResult=100
    ]
]
AddTop5Eval=[    
    action=edit
    CurModel=$ModelDir$/AlexNet
    NewModel=$ModelDir$/AlexNet.Top5
    editPath=$ConfigDir$/add_top5_layer.mel
]
Test=[
    action=test
    modelPath=$ModelDir$/AlexNet.Top5
    minibatchSize=16
     NDLNetworkBuilder=[
        networkDescription=$ConfigDir$/AlexNet.ndl
    ]
]
currentDirectory=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714052910.364117\Image_AlexNet@release_gpu\TestData
RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714052910.364117\Image_AlexNet@release_gpu
DataDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714052910.364117\Image_AlexNet@release_gpu\TestData
ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Image\AlexNet
OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714052910.364117\Image_AlexNet@release_gpu
DeviceId=0
timestamping=true
Train=[
    reader=[
        readerType=ImageReader
        file=$ConfigDir$/train_map.txt
        randomize=Auto
        features=[
            width=224
            height=224
            channels=3
            cropType=Random
            cropRatio=0.875
            jitterType=UniRatio
            interpolations=Linear
            meanFile=$ConfigDir$/ImageNet1K_mean.xml
        ]
        labels=[
            labelDim=1000
        ]
    ]    
]
Test=[    
    reader=[
        readerType=ImageReader
        file=$ConfigDir$/val_map.txt
        randomize=None
        features=[
            width=224
            height=224
            channels=3
            cropType=Center
            meanFile=$ConfigDir$/ImageNet1K_mean.xml
        ]
        labels=[
            labelDim=1000
        ]
    ]    
]

07/14/2016 05:29:39: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<

07/14/2016 05:29:39: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
07/14/2016 05:29:39: ModelDir = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714052910.364117\Image_AlexNet@release_gpu/models"
ndlMacros=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Image\AlexNet/Macros.ndl
precision=float
deviceId=Auto
command=Train:AddTop5Eval:Test
parallelTrain=false
traceLevel=1
numMBsToShowResult=100
Train=[
    action=train
    modelPath=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714052910.364117\Image_AlexNet@release_gpu/models/AlexNet
    NDLNetworkBuilder=[
        networkDescription=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Image\AlexNet/AlexNet.ndl
    ]
    SGD=[
        epochSize=0
        minibatchSize=16
        learningRatesPerMB=0.01*20:0.003*12:0.001*28:0.0003
        momentumPerMB=0.9
        maxEpochs=3
        gradUpdateType=None
        L2RegWeight=0.0005
        dropoutRate=0*5:0.5
        ParallelTrain=[
            parallelizationMethod=DataParallelSGD
            distributedMBReading=true
            parallelizationStartEpoch=1
            DataParallelSGD=[
                gradientBits=1
            ]
        ]
        numMBsToShowResult=100
    ]
]
AddTop5Eval=[    
    action=edit
    CurModel=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714052910.364117\Image_AlexNet@release_gpu/models/AlexNet
    NewModel=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714052910.364117\Image_AlexNet@release_gpu/models/AlexNet.Top5
    editPath=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Image\AlexNet/add_top5_layer.mel
]
Test=[
    action=test
    modelPath=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714052910.364117\Image_AlexNet@release_gpu/models/AlexNet.Top5
    minibatchSize=16
     NDLNetworkBuilder=[
        networkDescription=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Image\AlexNet/AlexNet.ndl
    ]
]
currentDirectory=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714052910.364117\Image_AlexNet@release_gpu\TestData
RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714052910.364117\Image_AlexNet@release_gpu
DataDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714052910.364117\Image_AlexNet@release_gpu\TestData
ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Image\AlexNet
OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714052910.364117\Image_AlexNet@release_gpu
DeviceId=0
timestamping=true
Train=[
    reader=[
        readerType=ImageReader
        file=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Image\AlexNet/train_map.txt
        randomize=Auto
        features=[
            width=224
            height=224
            channels=3
            cropType=Random
            cropRatio=0.875
            jitterType=UniRatio
            interpolations=Linear
            meanFile=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Image\AlexNet/ImageNet1K_mean.xml
        ]
        labels=[
            labelDim=1000
        ]
    ]    
]
Test=[    
    reader=[
        readerType=ImageReader
        file=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Image\AlexNet/val_map.txt
        randomize=None
        features=[
            width=224
            height=224
            channels=3
            cropType=Center
            meanFile=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Image\AlexNet/ImageNet1K_mean.xml
        ]
        labels=[
            labelDim=1000
        ]
    ]    
]

07/14/2016 05:29:39: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<

07/14/2016 05:29:39: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
configparameters: AlexNet.cntk:AddTop5Eval=[    
    action=edit
    CurModel=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714052910.364117\Image_AlexNet@release_gpu/models/AlexNet
    NewModel=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714052910.364117\Image_AlexNet@release_gpu/models/AlexNet.Top5
    editPath=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Image\AlexNet/add_top5_layer.mel
]

configparameters: AlexNet.cntk:command=Train:AddTop5Eval:Test
configparameters: AlexNet.cntk:ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Image\AlexNet
configparameters: AlexNet.cntk:currentDirectory=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714052910.364117\Image_AlexNet@release_gpu\TestData
configparameters: AlexNet.cntk:DataDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714052910.364117\Image_AlexNet@release_gpu\TestData
configparameters: AlexNet.cntk:deviceId=0
configparameters: AlexNet.cntk:ModelDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714052910.364117\Image_AlexNet@release_gpu/models
configparameters: AlexNet.cntk:ndlMacros=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Image\AlexNet/Macros.ndl
configparameters: AlexNet.cntk:numMBsToShowResult=100
configparameters: AlexNet.cntk:OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714052910.364117\Image_AlexNet@release_gpu
configparameters: AlexNet.cntk:parallelTrain=false
configparameters: AlexNet.cntk:precision=float
configparameters: AlexNet.cntk:RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714052910.364117\Image_AlexNet@release_gpu
configparameters: AlexNet.cntk:Test=[
    action=test
    modelPath=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714052910.364117\Image_AlexNet@release_gpu/models/AlexNet.Top5
    minibatchSize=16
     NDLNetworkBuilder=[
        networkDescription=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Image\AlexNet/AlexNet.ndl
    ]
] [    
    reader=[
        readerType=ImageReader
        file=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Image\AlexNet/val_map.txt
        randomize=None
        features=[
            width=224
            height=224
            channels=3
            cropType=Center
            meanFile=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Image\AlexNet/ImageNet1K_mean.xml
        ]
        labels=[
            labelDim=1000
        ]
    ]    
]

configparameters: AlexNet.cntk:timestamping=true
configparameters: AlexNet.cntk:traceLevel=1
configparameters: AlexNet.cntk:Train=[
    action=train
    modelPath=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714052910.364117\Image_AlexNet@release_gpu/models/AlexNet
    NDLNetworkBuilder=[
        networkDescription=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Image\AlexNet/AlexNet.ndl
    ]
    SGD=[
        epochSize=0
        minibatchSize=16
        learningRatesPerMB=0.01*20:0.003*12:0.001*28:0.0003
        momentumPerMB=0.9
        maxEpochs=3
        gradUpdateType=None
        L2RegWeight=0.0005
        dropoutRate=0*5:0.5
        ParallelTrain=[
            parallelizationMethod=DataParallelSGD
            distributedMBReading=true
            parallelizationStartEpoch=1
            DataParallelSGD=[
                gradientBits=1
            ]
        ]
        numMBsToShowResult=100
    ]
] [
    reader=[
        readerType=ImageReader
        file=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Image\AlexNet/train_map.txt
        randomize=Auto
        features=[
            width=224
            height=224
            channels=3
            cropType=Random
            cropRatio=0.875
            jitterType=UniRatio
            interpolations=Linear
            meanFile=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Image\AlexNet/ImageNet1K_mean.xml
        ]
        labels=[
            labelDim=1000
        ]
    ]    
]

07/14/2016 05:29:39: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
07/14/2016 05:29:39: Commands: Train AddTop5Eval Test
07/14/2016 05:29:39: Precision = "float"
07/14/2016 05:29:39: CNTKModelPath: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714052910.364117\Image_AlexNet@release_gpu/models/AlexNet
07/14/2016 05:29:39: CNTKCommandTrainInfo: Train : 3
07/14/2016 05:29:39: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 3

07/14/2016 05:29:39: ##############################################################################
07/14/2016 05:29:39: #                                                                            #
07/14/2016 05:29:39: # Action "train"                                                             #
07/14/2016 05:29:39: #                                                                            #
07/14/2016 05:29:39: ##############################################################################

07/14/2016 05:29:39: CNTKCommandTrainBegin: Train
NDLBuilder Using GPU 0
useParallelTrain option is not enabled. ParallelTrain config will be ignored.
07/14/2016 05:29:39: Creating virgin network.
Microsoft::MSR::CNTK::GPUMatrix<ElemType>::SetGaussianRandomValue (GPU): creating curand object with seed 1, sizeof(ElemType)==4

Post-processing network...

3 roots:
	OutputNodes.z = Plus()
	ce = CrossEntropyWithSoftmax()
	err = ErrorPrediction()

Validating network. 48 nodes to process in pass 1.

Validating --> OutputNodes.W = LearnableParameter() :  -> [1000 x 4096]
Validating --> h2.W = LearnableParameter() :  -> [4096 x 4096]
Validating --> h1.W = LearnableParameter() :  -> [4096 x 6 x 6 x 256]
Validating --> conv5.W = LearnableParameter() :  -> [256 x 2304]
Validating --> conv4.W = LearnableParameter() :  -> [256 x 3456]
Validating --> conv3.W = LearnableParameter() :  -> [384 x 1728]
Validating --> conv2.W = LearnableParameter() :  -> [192 x 1600]
Validating --> conv1.W = LearnableParameter() :  -> [64 x 363]
Validating --> features = InputValue() :  -> [224 x 224 x 3 x *]
Validating --> conv1.c = Convolution (conv1.W, features) : [64 x 363], [224 x 224 x 3 x *] -> [56 x 56 x 64 x *]
Validating --> conv1.b = LearnableParameter() :  -> [1 x 1 x 64]
Validating --> conv1.z = Plus (conv1.c, conv1.b) : [56 x 56 x 64 x *], [1 x 1 x 64] -> [56 x 56 x 64 x *]
Validating --> conv1.y = RectifiedLinear (conv1.z) : [56 x 56 x 64 x *] -> [56 x 56 x 64 x *]
Validating --> pool1 = MaxPooling (conv1.y) : [56 x 56 x 64 x *] -> [27 x 27 x 64 x *]
Validating --> conv2.c = Convolution (conv2.W, pool1) : [192 x 1600], [27 x 27 x 64 x *] -> [27 x 27 x 192 x *]
Validating --> conv2.b = LearnableParameter() :  -> [1 x 1 x 192]
Validating --> conv2.z = Plus (conv2.c, conv2.b) : [27 x 27 x 192 x *], [1 x 1 x 192] -> [27 x 27 x 192 x *]
Validating --> conv2.y = RectifiedLinear (conv2.z) : [27 x 27 x 192 x *] -> [27 x 27 x 192 x *]
Validating --> pool2 = MaxPooling (conv2.y) : [27 x 27 x 192 x *] -> [13 x 13 x 192 x *]
Validating --> conv3.c = Convolution (conv3.W, pool2) : [384 x 1728], [13 x 13 x 192 x *] -> [13 x 13 x 384 x *]
Validating --> conv3.b = LearnableParameter() :  -> [1 x 1 x 384]
Validating --> conv3.z = Plus (conv3.c, conv3.b) : [13 x 13 x 384 x *], [1 x 1 x 384] -> [13 x 13 x 384 x *]
Validating --> conv3.y = RectifiedLinear (conv3.z) : [13 x 13 x 384 x *] -> [13 x 13 x 384 x *]
Validating --> conv4.c = Convolution (conv4.W, conv3.y) : [256 x 3456], [13 x 13 x 384 x *] -> [13 x 13 x 256 x *]
Validating --> conv4.b = LearnableParameter() :  -> [1 x 1 x 256]
Validating --> conv4.z = Plus (conv4.c, conv4.b) : [13 x 13 x 256 x *], [1 x 1 x 256] -> [13 x 13 x 256 x *]
Validating --> conv4.y = RectifiedLinear (conv4.z) : [13 x 13 x 256 x *] -> [13 x 13 x 256 x *]
Validating --> conv5.c = Convolution (conv5.W, conv4.y) : [256 x 2304], [13 x 13 x 256 x *] -> [13 x 13 x 256 x *]
Validating --> conv5.b = LearnableParameter() :  -> [1 x 1 x 256]
Validating --> conv5.z = Plus (conv5.c, conv5.b) : [13 x 13 x 256 x *], [1 x 1 x 256] -> [13 x 13 x 256 x *]
Validating --> conv5.y = RectifiedLinear (conv5.z) : [13 x 13 x 256 x *] -> [13 x 13 x 256 x *]
Validating --> pool3 = MaxPooling (conv5.y) : [13 x 13 x 256 x *] -> [6 x 6 x 256 x *]
Validating --> h1.t = Times (h1.W, pool3) : [4096 x 6 x 6 x 256], [6 x 6 x 256 x *] -> [4096 x *]
Validating --> h1.b = LearnableParameter() :  -> [4096]
Validating --> h1.z = Plus (h1.t, h1.b) : [4096 x *], [4096] -> [4096 x *]
Validating --> h1.y = RectifiedLinear (h1.z) : [4096 x *] -> [4096 x *]
Validating --> h1_d = Dropout (h1.y) : [4096 x *] -> [4096 x *]
Validating --> h2.t = Times (h2.W, h1_d) : [4096 x 4096], [4096 x *] -> [4096 x *]
Validating --> h2.b = LearnableParameter() :  -> [4096]
Validating --> h2.z = Plus (h2.t, h2.b) : [4096 x *], [4096] -> [4096 x *]
Validating --> h2.y = RectifiedLinear (h2.z) : [4096 x *] -> [4096 x *]
Validating --> h2_d = Dropout (h2.y) : [4096 x *] -> [4096 x *]
Validating --> OutputNodes.t = Times (OutputNodes.W, h2_d) : [1000 x 4096], [4096 x *] -> [1000 x *]
Validating --> OutputNodes.b = LearnableParameter() :  -> [1000]
Validating --> OutputNodes.z = Plus (OutputNodes.t, OutputNodes.b) : [1000 x *], [1000] -> [1000 x *]
Validating --> labels = InputValue() :  -> [1000 x *]
Validating --> ce = CrossEntropyWithSoftmax (labels, OutputNodes.z) : [1000 x *], [1000 x *] -> [1]
Validating --> err = ErrorPrediction (labels, OutputNodes.z) : [1000 x *], [1000 x *] -> [1]

Validating network. 30 nodes to process in pass 2.


Validating network, final pass.


conv1.c: using cuDNN convolution engine for geometry: Input: 224 x 224 x 3, Output: 56 x 56 x 64, Kernel: 11 x 11 x 3, Map: 1 x 1 x 64, Stride: 4 x 4 x 3, Sharing: (1), AutoPad: (1), LowerPad: 0, UpperPad: 0.

pool1: using cuDNN convolution engine for geometry: Input: 56 x 56 x 64, Output: 27 x 27 x 64, Kernel: 3 x 3 x 1, Map: 1, Stride: 2 x 2 x 1, Sharing: (1), AutoPad: (0), LowerPad: 0, UpperPad: 0.

conv2.c: using cuDNN convolution engine for geometry: Input: 27 x 27 x 64, Output: 27 x 27 x 192, Kernel: 5 x 5 x 64, Map: 1 x 1 x 192, Stride: 1 x 1 x 64, Sharing: (1), AutoPad: (1), LowerPad: 0, UpperPad: 0.

pool2: using cuDNN convolution engine for geometry: Input: 27 x 27 x 192, Output: 13 x 13 x 192, Kernel: 3 x 3 x 1, Map: 1, Stride: 2 x 2 x 1, Sharing: (1), AutoPad: (0), LowerPad: 0, UpperPad: 0.

conv3.c: using cuDNN convolution engine for geometry: Input: 13 x 13 x 192, Output: 13 x 13 x 384, Kernel: 3 x 3 x 192, Map: 1 x 1 x 384, Stride: 1 x 1 x 192, Sharing: (1), AutoPad: (1), LowerPad: 0, UpperPad: 0.

conv4.c: using cuDNN convolution engine for geometry: Input: 13 x 13 x 384, Output: 13 x 13 x 256, Kernel: 3 x 3 x 384, Map: 1 x 1 x 256, Stride: 1 x 1 x 384, Sharing: (1), AutoPad: (1), LowerPad: 0, UpperPad: 0.

conv5.c: using cuDNN convolution engine for geometry: Input: 13 x 13 x 256, Output: 13 x 13 x 256, Kernel: 3 x 3 x 256, Map: 1 x 1 x 256, Stride: 1 x 1 x 256, Sharing: (1), AutoPad: (1), LowerPad: 0, UpperPad: 0.

pool3: using cuDNN convolution engine for geometry: Input: 13 x 13 x 256, Output: 6 x 6 x 256, Kernel: 3 x 3 x 1, Map: 1, Stride: 2 x 2 x 1, Sharing: (1), AutoPad: (0), LowerPad: 0, UpperPad: 0.


18 out of 48 nodes do not share the minibatch layout with the input data.

Post-processing network complete.

07/14/2016 05:29:40: Created model with 48 nodes on GPU 0.

07/14/2016 05:29:40: Training criterion node(s):
07/14/2016 05:29:40: 	ce = CrossEntropyWithSoftmax

07/14/2016 05:29:40: Evaluation criterion node(s):

07/14/2016 05:29:40: 	err = ErrorPrediction


Allocating matrices for forward and/or backward propagation.

Memory Sharing Structure:

0000000000000000: {[err Gradient[1]] [features Gradient[224 x 224 x 3 x *]] [labels Gradient[1000 x *]] }
00000075DBB72BB0: {[conv1.b Value[1 x 1 x 64]] }
00000075DBB72ED0: {[features Value[224 x 224 x 3 x *]] }
00000075DBB745F0: {[conv1.W Value[64 x 363]] }
00000075DBB747D0: {[labels Value[1000 x *]] }
00000075ED0C5F50: {[conv5.W Value[256 x 2304]] }
00000075ED0C5FF0: {[h1.b Value[4096]] }
00000075ED0C6090: {[conv2.W Value[192 x 1600]] }
00000075ED0C6450: {[conv3.b Value[1 x 1 x 384]] }
00000075ED0C6950: {[conv3.W Value[384 x 1728]] }
00000075ED0C6A90: {[conv4.b Value[1 x 1 x 256]] }
00000075ED0C6D10: {[h1.W Value[4096 x 6 x 6 x 256]] }
00000075ED0C6EF0: {[conv2.b Value[1 x 1 x 192]] }
00000075ED0C7030: {[h2.W Value[4096 x 4096]] }
00000075ED0C7210: {[h2.b Value[4096]] }
00000075ED0C73F0: {[conv4.W Value[256 x 3456]] }
00000075ED0C75D0: {[conv5.b Value[1 x 1 x 256]] }
00000075ED0C77B0: {[OutputNodes.W Value[1000 x 4096]] }
00000075ED0C7DF0: {[OutputNodes.b Value[1000]] }
00000075F9E74380: {[OutputNodes.b Gradient[1000]] }
00000075F9E74560: {[conv1.z Gradient[56 x 56 x 64 x *]] [pool1 Value[27 x 27 x 64 x *]] }
00000075F9E74600: {[conv2.c Value[27 x 27 x 192 x *]] }
00000075F9E746A0: {[ce Value[1]] }
00000075F9E74740: {[conv2.b Gradient[1 x 1 x 192]] [conv2.y Gradient[27 x 27 x 192 x *]] }
00000075F9E747E0: {[conv4.c Value[13 x 13 x 256 x *]] }
00000075F9E74880: {[conv2.c Gradient[27 x 27 x 192 x *]] [conv2.y Value[27 x 27 x 192 x *]] }
00000075F9E74920: {[h1.W Gradient[4096 x 6 x 6 x 256]] [h1.z Value[4096 x *]] }
00000075F9E749C0: {[conv2.z Gradient[27 x 27 x 192 x *]] [pool1 Gradient[27 x 27 x 64 x *]] [pool2 Value[13 x 13 x 192 x *]] }
00000075F9E74A60: {[conv5.W Gradient[256 x 2304]] [conv5.z Value[13 x 13 x 256 x *]] }
00000075F9E74B00: {[h1.z Gradient[4096 x *]] [pool3 Gradient[6 x 6 x 256 x *]] }
00000075F9E74C40: {[OutputNodes.t Value[1000 x *]] [h2.b Gradient[4096]] [h2.y Gradient[4096 x *]] }
00000075F9E74D80: {[h2_d Gradient[4096 x *]] }
00000075F9E74F60: {[conv3.c Gradient[13 x 13 x 384 x *]] [conv3.y Value[13 x 13 x 384 x *]] }
00000075F9E75000: {[OutputNodes.W Gradient[1000 x 4096]] [OutputNodes.z Gradient[1000 x *]] }
00000075F9E751E0: {[h2_d Value[4096 x *]] }
00000075F9E75280: {[conv5.b Gradient[1 x 1 x 256]] [conv5.y Gradient[13 x 13 x 256 x *]] [h1.t Value[4096 x *]] }
00000075F9E75460: {[OutputNodes.z Value[1000 x *]] }
00000075F9E75500: {[err Value[1]] }
00000075F9E75640: {[conv4.W Gradient[256 x 3456]] [conv4.z Value[13 x 13 x 256 x *]] }
00000075F9E756E0: {[conv4.b Gradient[1 x 1 x 256]] [conv4.y Gradient[13 x 13 x 256 x *]] [conv5.z Gradient[13 x 13 x 256 x *]] [pool3 Value[6 x 6 x 256 x *]] }
00000075F9E758C0: {[conv1.b Gradient[1 x 1 x 64]] [conv1.y Gradient[56 x 56 x 64 x *]] }
00000075F9E75B40: {[conv3.W Gradient[384 x 1728]] [conv3.z Value[13 x 13 x 384 x *]] }
00000075F9E75BE0: {[conv5.c Gradient[13 x 13 x 256 x *]] [conv5.y Value[13 x 13 x 256 x *]] }
00000075F9E75C80: {[h2.W Gradient[4096 x 4096]] [h2.z Value[4096 x *]] }
00000075F9E75DC0: {[conv1.W Gradient[64 x 363]] [conv1.z Value[56 x 56 x 64 x *]] }
00000075F9E75E60: {[conv2.W Gradient[192 x 1600]] [conv2.z Value[27 x 27 x 192 x *]] }
00000075F9E75F00: {[conv1.c Value[56 x 56 x 64 x *]] }
00000075F9E75FA0: {[conv3.z Gradient[13 x 13 x 384 x *]] [pool2 Gradient[13 x 13 x 192 x *]] }
00000075F9E76040: {[h1.t Gradient[4096 x *]] [h1.y Value[4096 x *]] }
00000075F9E760E0: {[OutputNodes.t Gradient[1000 x *]] }
00000075F9E76220: {[conv3.c Value[13 x 13 x 384 x *]] }
00000075F9E762C0: {[conv3.b Gradient[1 x 1 x 384]] [conv3.y Gradient[13 x 13 x 384 x *]] [conv4.z Gradient[13 x 13 x 256 x *]] }
00000075F9E76360: {[h1_d Value[4096 x *]] }
00000075F9E76400: {[h2.t Gradient[4096 x *]] [h2.y Value[4096 x *]] }
00000075F9E764A0: {[h1.b Gradient[4096]] [h1.y Gradient[4096 x *]] [h2.t Value[4096 x *]] }
00000075F9E765E0: {[conv4.c Gradient[13 x 13 x 256 x *]] [conv4.y Value[13 x 13 x 256 x *]] }
00000075F9E76680: {[conv1.c Gradient[56 x 56 x 64 x *]] [conv1.y Value[56 x 56 x 64 x *]] }
00000075F9E769A0: {[conv5.c Value[13 x 13 x 256 x *]] }
00000075F9E76A40: {[h1_d Gradient[4096 x *]] [h2.z Gradient[4096 x *]] }
00000075F9E76AE0: {[ce Gradient[1]] }

07/14/2016 05:29:40: No PreCompute nodes found, skipping PreCompute step.

07/14/2016 05:29:43: Starting Epoch 1: learning rate per sample = 0.000625  effective momentum = 0.900000  momentum as time constant = 151.9 samples
BlockRandomizer::StartEpoch: epoch 0: frames [0..2999] (first sequence at sample 0), data subset 0 of 1

07/14/2016 05:29:43: Starting minibatch loop.
07/14/2016 05:29:52:  Epoch[ 1 of 3]-Minibatch[   1- 100]: ce = 7.43084106 * 1600; err = 1.00000000 * 1600; time = 8.6662s; samplesPerSecond = 184.6
07/14/2016 05:29:58: Finished Epoch[ 1 of 3]: [Training] ce = 7.24046297 * 2999; err = 0.99933311 * 2999; totalSamplesSeen = 2999; learningRatePerSample = 0.00062499999; epochTime=14.5058s
07/14/2016 05:30:01: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714052910.364117\Image_AlexNet@release_gpu/models/AlexNet.1'

07/14/2016 05:30:04: Starting Epoch 2: learning rate per sample = 0.000625  effective momentum = 0.900000  momentum as time constant = 151.9 samples
BlockRandomizer::StartEpoch: epoch 1: frames [2999..5998] (first sequence at sample 2999), data subset 0 of 1

07/14/2016 05:30:04: Starting minibatch loop.
07/14/2016 05:30:11:  Epoch[ 2 of 3]-Minibatch[   1- 100, 100.00%]: ce = 6.90477295 * 1600; err = 0.99750000 * 1600; time = 6.7376s; samplesPerSecond = 237.5
07/14/2016 05:30:17: Finished Epoch[ 2 of 3]: [Training] ce = 6.91899709 * 2999; err = 0.99799933 * 2999; totalSamplesSeen = 5998; learningRatePerSample = 0.00062499999; epochTime=12.6276s
07/14/2016 05:30:20: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714052910.364117\Image_AlexNet@release_gpu/models/AlexNet.2'

07/14/2016 05:30:23: Starting Epoch 3: learning rate per sample = 0.000625  effective momentum = 0.900000  momentum as time constant = 151.9 samples
BlockRandomizer::StartEpoch: epoch 2: frames [5998..8997] (first sequence at sample 5998), data subset 0 of 1

07/14/2016 05:30:23: Starting minibatch loop.
07/14/2016 05:30:30:  Epoch[ 3 of 3]-Minibatch[   1- 100, 100.00%]: ce = 6.87016174 * 1600; err = 0.99875000 * 1600; time = 6.9253s; samplesPerSecond = 231.0
07/14/2016 05:30:36: Finished Epoch[ 3 of 3]: [Training] ce = 6.88057803 * 2999; err = 0.99799933 * 2999; totalSamplesSeen = 8997; learningRatePerSample = 0.00062499999; epochTime=12.746s
07/14/2016 05:30:39: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714052910.364117\Image_AlexNet@release_gpu/models/AlexNet'
07/14/2016 05:30:42: CNTKCommandTrainEnd: Train

07/14/2016 05:30:42: Action "train" complete.


07/14/2016 05:30:42: ##############################################################################
07/14/2016 05:30:42: #                                                                            #
07/14/2016 05:30:42: # Action "edit"                                                              #
07/14/2016 05:30:42: #                                                                            #
07/14/2016 05:30:42: ##############################################################################


Post-processing network...

3 roots:
	OutputNodes.z = Plus()
	ce = CrossEntropyWithSoftmax()
	err = ErrorPrediction()

Validating network. 48 nodes to process in pass 1.

Validating --> OutputNodes.W = LearnableParameter() :  -> [1000 x 4096]
Validating --> h2.W = LearnableParameter() :  -> [4096 x 4096]
Validating --> h1.W = LearnableParameter() :  -> [4096 x 6 x 6 x 256]
Validating --> conv5.W = LearnableParameter() :  -> [256 x 2304]
Validating --> conv4.W = LearnableParameter() :  -> [256 x 3456]
Validating --> conv3.W = LearnableParameter() :  -> [384 x 1728]
Validating --> conv2.W = LearnableParameter() :  -> [192 x 1600]
Validating --> conv1.W = LearnableParameter() :  -> [64 x 363]
Validating --> features = InputValue() :  -> [224 x 224 x 3 x *1]
Validating --> conv1.c = Convolution (conv1.W, features) : [64 x 363], [224 x 224 x 3 x *1] -> [56 x 56 x 64 x *1]
Validating --> conv1.b = LearnableParameter() :  -> [1 x 1 x 64]
Validating --> conv1.z = Plus (conv1.c, conv1.b) : [56 x 56 x 64 x *1], [1 x 1 x 64] -> [56 x 56 x 64 x *1]
Validating --> conv1.y = RectifiedLinear (conv1.z) : [56 x 56 x 64 x *1] -> [56 x 56 x 64 x *1]
Validating --> pool1 = MaxPooling (conv1.y) : [56 x 56 x 64 x *1] -> [27 x 27 x 64 x *1]
Validating --> conv2.c = Convolution (conv2.W, pool1) : [192 x 1600], [27 x 27 x 64 x *1] -> [27 x 27 x 192 x *1]
Validating --> conv2.b = LearnableParameter() :  -> [1 x 1 x 192]
Validating --> conv2.z = Plus (conv2.c, conv2.b) : [27 x 27 x 192 x *1], [1 x 1 x 192] -> [27 x 27 x 192 x *1]
Validating --> conv2.y = RectifiedLinear (conv2.z) : [27 x 27 x 192 x *1] -> [27 x 27 x 192 x *1]
Validating --> pool2 = MaxPooling (conv2.y) : [27 x 27 x 192 x *1] -> [13 x 13 x 192 x *1]
Validating --> conv3.c = Convolution (conv3.W, pool2) : [384 x 1728], [13 x 13 x 192 x *1] -> [13 x 13 x 384 x *1]
Validating --> conv3.b = LearnableParameter() :  -> [1 x 1 x 384]
Validating --> conv3.z = Plus (conv3.c, conv3.b) : [13 x 13 x 384 x *1], [1 x 1 x 384] -> [13 x 13 x 384 x *1]
Validating --> conv3.y = RectifiedLinear (conv3.z) : [13 x 13 x 384 x *1] -> [13 x 13 x 384 x *1]
Validating --> conv4.c = Convolution (conv4.W, conv3.y) : [256 x 3456], [13 x 13 x 384 x *1] -> [13 x 13 x 256 x *1]
Validating --> conv4.b = LearnableParameter() :  -> [1 x 1 x 256]
Validating --> conv4.z = Plus (conv4.c, conv4.b) : [13 x 13 x 256 x *1], [1 x 1 x 256] -> [13 x 13 x 256 x *1]
Validating --> conv4.y = RectifiedLinear (conv4.z) : [13 x 13 x 256 x *1] -> [13 x 13 x 256 x *1]
Validating --> conv5.c = Convolution (conv5.W, conv4.y) : [256 x 2304], [13 x 13 x 256 x *1] -> [13 x 13 x 256 x *1]
Validating --> conv5.b = LearnableParameter() :  -> [1 x 1 x 256]
Validating --> conv5.z = Plus (conv5.c, conv5.b) : [13 x 13 x 256 x *1], [1 x 1 x 256] -> [13 x 13 x 256 x *1]
Validating --> conv5.y = RectifiedLinear (conv5.z) : [13 x 13 x 256 x *1] -> [13 x 13 x 256 x *1]
Validating --> pool3 = MaxPooling (conv5.y) : [13 x 13 x 256 x *1] -> [6 x 6 x 256 x *1]
Validating --> h1.t = Times (h1.W, pool3) : [4096 x 6 x 6 x 256], [6 x 6 x 256 x *1] -> [4096 x *1]
Validating --> h1.b = LearnableParameter() :  -> [4096]
Validating --> h1.z = Plus (h1.t, h1.b) : [4096 x *1], [4096] -> [4096 x *1]
Validating --> h1.y = RectifiedLinear (h1.z) : [4096 x *1] -> [4096 x *1]
Validating --> h1_d = Dropout (h1.y) : [4096 x *1] -> [4096 x *1]
Validating --> h2.t = Times (h2.W, h1_d) : [4096 x 4096], [4096 x *1] -> [4096 x *1]
Validating --> h2.b = LearnableParameter() :  -> [4096]
Validating --> h2.z = Plus (h2.t, h2.b) : [4096 x *1], [4096] -> [4096 x *1]
Validating --> h2.y = RectifiedLinear (h2.z) : [4096 x *1] -> [4096 x *1]
Validating --> h2_d = Dropout (h2.y) : [4096 x *1] -> [4096 x *1]
Validating --> OutputNodes.t = Times (OutputNodes.W, h2_d) : [1000 x 4096], [4096 x *1] -> [1000 x *1]
Validating --> OutputNodes.b = LearnableParameter() :  -> [1000]
Validating --> OutputNodes.z = Plus (OutputNodes.t, OutputNodes.b) : [1000 x *1], [1000] -> [1000 x *1]
Validating --> labels = InputValue() :  -> [1000 x *1]
Validating --> ce = CrossEntropyWithSoftmax (labels, OutputNodes.z) : [1000 x *1], [1000 x *1] -> [1]
Validating --> err = ErrorPrediction (labels, OutputNodes.z) : [1000 x *1], [1000 x *1] -> [1]

Validating network. 30 nodes to process in pass 2.


Validating network, final pass.


conv1.c: using GEMM convolution engine for geometry: Input: 224 x 224 x 3, Output: 56 x 56 x 64, Kernel: 11 x 11 x 3, Map: 1 x 1 x 64, Stride: 4 x 4 x 3, Sharing: (1), AutoPad: (1), LowerPad: 0, UpperPad: 0.

pool1: using GEMM convolution engine for geometry: Input: 56 x 56 x 64, Output: 27 x 27 x 64, Kernel: 3 x 3 x 1, Map: 1, Stride: 2 x 2 x 1, Sharing: (1), AutoPad: (0), LowerPad: 0, UpperPad: 0.

conv2.c: using GEMM convolution engine for geometry: Input: 27 x 27 x 64, Output: 27 x 27 x 192, Kernel: 5 x 5 x 64, Map: 1 x 1 x 192, Stride: 1 x 1 x 64, Sharing: (1), AutoPad: (1), LowerPad: 0, UpperPad: 0.

pool2: using GEMM convolution engine for geometry: Input: 27 x 27 x 192, Output: 13 x 13 x 192, Kernel: 3 x 3 x 1, Map: 1, Stride: 2 x 2 x 1, Sharing: (1), AutoPad: (0), LowerPad: 0, UpperPad: 0.

conv3.c: using GEMM convolution engine for geometry: Input: 13 x 13 x 192, Output: 13 x 13 x 384, Kernel: 3 x 3 x 192, Map: 1 x 1 x 384, Stride: 1 x 1 x 192, Sharing: (1), AutoPad: (1), LowerPad: 0, UpperPad: 0.

conv4.c: using GEMM convolution engine for geometry: Input: 13 x 13 x 384, Output: 13 x 13 x 256, Kernel: 3 x 3 x 384, Map: 1 x 1 x 256, Stride: 1 x 1 x 384, Sharing: (1), AutoPad: (1), LowerPad: 0, UpperPad: 0.

conv5.c: using GEMM convolution engine for geometry: Input: 13 x 13 x 256, Output: 13 x 13 x 256, Kernel: 3 x 3 x 256, Map: 1 x 1 x 256, Stride: 1 x 1 x 256, Sharing: (1), AutoPad: (1), LowerPad: 0, UpperPad: 0.

pool3: using GEMM convolution engine for geometry: Input: 13 x 13 x 256, Output: 6 x 6 x 256, Kernel: 3 x 3 x 1, Map: 1, Stride: 2 x 2 x 1, Sharing: (1), AutoPad: (0), LowerPad: 0, UpperPad: 0.


18 out of 48 nodes do not share the minibatch layout with the input data.

Post-processing network complete.


Post-processing network...

4 roots:
	OutputNodes.z = Plus()
	ce = CrossEntropyWithSoftmax()
	err = ErrorPrediction()
	errTop5 = ErrorPrediction()

Validating network. 50 nodes to process in pass 1.

Validating --> OutputNodes.W = LearnableParameter() :  -> [1000 x 4096]
Validating --> h2.W = LearnableParameter() :  -> [4096 x 4096]
Validating --> h1.W = LearnableParameter() :  -> [4096 x 6 x 6 x 256]
Validating --> conv5.W = LearnableParameter() :  -> [256 x 2304]
Validating --> conv4.W = LearnableParameter() :  -> [256 x 3456]
Validating --> conv3.W = LearnableParameter() :  -> [384 x 1728]
Validating --> conv2.W = LearnableParameter() :  -> [192 x 1600]
Validating --> conv1.W = LearnableParameter() :  -> [64 x 363]
Validating --> features = InputValue() :  -> [224 x 224 x 3 x *1]
Validating --> conv1.c = Convolution (conv1.W, features) : [64 x 363], [224 x 224 x 3 x *1] -> [56 x 56 x 64 x *1]
Validating --> conv1.b = LearnableParameter() :  -> [1 x 1 x 64]
Validating --> conv1.z = Plus (conv1.c, conv1.b) : [56 x 56 x 64 x *1], [1 x 1 x 64] -> [56 x 56 x 64 x *1]
Validating --> conv1.y = RectifiedLinear (conv1.z) : [56 x 56 x 64 x *1] -> [56 x 56 x 64 x *1]
Validating --> pool1 = MaxPooling (conv1.y) : [56 x 56 x 64 x *1] -> [27 x 27 x 64 x *1]
Validating --> conv2.c = Convolution (conv2.W, pool1) : [192 x 1600], [27 x 27 x 64 x *1] -> [27 x 27 x 192 x *1]
Validating --> conv2.b = LearnableParameter() :  -> [1 x 1 x 192]
Validating --> conv2.z = Plus (conv2.c, conv2.b) : [27 x 27 x 192 x *1], [1 x 1 x 192] -> [27 x 27 x 192 x *1]
Validating --> conv2.y = RectifiedLinear (conv2.z) : [27 x 27 x 192 x *1] -> [27 x 27 x 192 x *1]
Validating --> pool2 = MaxPooling (conv2.y) : [27 x 27 x 192 x *1] -> [13 x 13 x 192 x *1]
Validating --> conv3.c = Convolution (conv3.W, pool2) : [384 x 1728], [13 x 13 x 192 x *1] -> [13 x 13 x 384 x *1]
Validating --> conv3.b = LearnableParameter() :  -> [1 x 1 x 384]
Validating --> conv3.z = Plus (conv3.c, conv3.b) : [13 x 13 x 384 x *1], [1 x 1 x 384] -> [13 x 13 x 384 x *1]
Validating --> conv3.y = RectifiedLinear (conv3.z) : [13 x 13 x 384 x *1] -> [13 x 13 x 384 x *1]
Validating --> conv4.c = Convolution (conv4.W, conv3.y) : [256 x 3456], [13 x 13 x 384 x *1] -> [13 x 13 x 256 x *1]
Validating --> conv4.b = LearnableParameter() :  -> [1 x 1 x 256]
Validating --> conv4.z = Plus (conv4.c, conv4.b) : [13 x 13 x 256 x *1], [1 x 1 x 256] -> [13 x 13 x 256 x *1]
Validating --> conv4.y = RectifiedLinear (conv4.z) : [13 x 13 x 256 x *1] -> [13 x 13 x 256 x *1]
Validating --> conv5.c = Convolution (conv5.W, conv4.y) : [256 x 2304], [13 x 13 x 256 x *1] -> [13 x 13 x 256 x *1]
Validating --> conv5.b = LearnableParameter() :  -> [1 x 1 x 256]
Validating --> conv5.z = Plus (conv5.c, conv5.b) : [13 x 13 x 256 x *1], [1 x 1 x 256] -> [13 x 13 x 256 x *1]
Validating --> conv5.y = RectifiedLinear (conv5.z) : [13 x 13 x 256 x *1] -> [13 x 13 x 256 x *1]
Validating --> pool3 = MaxPooling (conv5.y) : [13 x 13 x 256 x *1] -> [6 x 6 x 256 x *1]
Validating --> h1.t = Times (h1.W, pool3) : [4096 x 6 x 6 x 256], [6 x 6 x 256 x *1] -> [4096 x *1]
Validating --> h1.b = LearnableParameter() :  -> [4096]
Validating --> h1.z = Plus (h1.t, h1.b) : [4096 x *1], [4096] -> [4096 x *1]
Validating --> h1.y = RectifiedLinear (h1.z) : [4096 x *1] -> [4096 x *1]
Validating --> h1_d = Dropout (h1.y) : [4096 x *1] -> [4096 x *1]
Validating --> h2.t = Times (h2.W, h1_d) : [4096 x 4096], [4096 x *1] -> [4096 x *1]
Validating --> h2.b = LearnableParameter() :  -> [4096]
Validating --> h2.z = Plus (h2.t, h2.b) : [4096 x *1], [4096] -> [4096 x *1]
Validating --> h2.y = RectifiedLinear (h2.z) : [4096 x *1] -> [4096 x *1]
Validating --> h2_d = Dropout (h2.y) : [4096 x *1] -> [4096 x *1]
Validating --> OutputNodes.t = Times (OutputNodes.W, h2_d) : [1000 x 4096], [4096 x *1] -> [1000 x *1]
Validating --> OutputNodes.b = LearnableParameter() :  -> [1000]
Validating --> OutputNodes.z = Plus (OutputNodes.t, OutputNodes.b) : [1000 x *1], [1000] -> [1000 x *1]
Validating --> labels = InputValue() :  -> [1000 x *1]
Validating --> ce = CrossEntropyWithSoftmax (labels, OutputNodes.z) : [1000 x *1], [1000 x *1] -> [1]
Validating --> err = ErrorPrediction (labels, OutputNodes.z) : [1000 x *1], [1000 x *1] -> [1]
Validating --> unnamed137 = LearnableParameter() :  -> [1 x 1]
Validating --> errTop5 = ErrorPrediction (labels, OutputNodes.z, unnamed137) : [1000 x *1], [1000 x *1], [1 x 1] -> [1]

Validating network. 31 nodes to process in pass 2.


Validating network, final pass.



20 out of 50 nodes do not share the minibatch layout with the input data.

Post-processing network complete.


07/14/2016 05:30:49: Action "edit" complete.


07/14/2016 05:30:49: ##############################################################################
07/14/2016 05:30:49: #                                                                            #
07/14/2016 05:30:49: # Action "test"                                                              #
07/14/2016 05:30:49: #                                                                            #
07/14/2016 05:30:49: ##############################################################################

NDLBuilder Using GPU 0

Post-processing network...

3 roots:
	OutputNodes.z = Plus()
	ce = CrossEntropyWithSoftmax()
	err = ErrorPrediction()

Validating network. 48 nodes to process in pass 1.

Validating --> OutputNodes.W = LearnableParameter() :  -> [1000 x 4096]
Validating --> h2.W = LearnableParameter() :  -> [4096 x 4096]
Validating --> h1.W = LearnableParameter() :  -> [4096 x 6 x 6 x 256]
Validating --> conv5.W = LearnableParameter() :  -> [256 x 2304]
Validating --> conv4.W = LearnableParameter() :  -> [256 x 3456]
Validating --> conv3.W = LearnableParameter() :  -> [384 x 1728]
Validating --> conv2.W = LearnableParameter() :  -> [192 x 1600]
Validating --> conv1.W = LearnableParameter() :  -> [64 x 363]
Validating --> features = InputValue() :  -> [224 x 224 x 3 x *2]
Validating --> conv1.c = Convolution (conv1.W, features) : [64 x 363], [224 x 224 x 3 x *2] -> [56 x 56 x 64 x *2]
Validating --> conv1.b = LearnableParameter() :  -> [1 x 1 x 64]
Validating --> conv1.z = Plus (conv1.c, conv1.b) : [56 x 56 x 64 x *2], [1 x 1 x 64] -> [56 x 56 x 64 x *2]
Validating --> conv1.y = RectifiedLinear (conv1.z) : [56 x 56 x 64 x *2] -> [56 x 56 x 64 x *2]
Validating --> pool1 = MaxPooling (conv1.y) : [56 x 56 x 64 x *2] -> [27 x 27 x 64 x *2]
Validating --> conv2.c = Convolution (conv2.W, pool1) : [192 x 1600], [27 x 27 x 64 x *2] -> [27 x 27 x 192 x *2]
Validating --> conv2.b = LearnableParameter() :  -> [1 x 1 x 192]
Validating --> conv2.z = Plus (conv2.c, conv2.b) : [27 x 27 x 192 x *2], [1 x 1 x 192] -> [27 x 27 x 192 x *2]
Validating --> conv2.y = RectifiedLinear (conv2.z) : [27 x 27 x 192 x *2] -> [27 x 27 x 192 x *2]
Validating --> pool2 = MaxPooling (conv2.y) : [27 x 27 x 192 x *2] -> [13 x 13 x 192 x *2]
Validating --> conv3.c = Convolution (conv3.W, pool2) : [384 x 1728], [13 x 13 x 192 x *2] -> [13 x 13 x 384 x *2]
Validating --> conv3.b = LearnableParameter() :  -> [1 x 1 x 384]
Validating --> conv3.z = Plus (conv3.c, conv3.b) : [13 x 13 x 384 x *2], [1 x 1 x 384] -> [13 x 13 x 384 x *2]
Validating --> conv3.y = RectifiedLinear (conv3.z) : [13 x 13 x 384 x *2] -> [13 x 13 x 384 x *2]
Validating --> conv4.c = Convolution (conv4.W, conv3.y) : [256 x 3456], [13 x 13 x 384 x *2] -> [13 x 13 x 256 x *2]
Validating --> conv4.b = LearnableParameter() :  -> [1 x 1 x 256]
Validating --> conv4.z = Plus (conv4.c, conv4.b) : [13 x 13 x 256 x *2], [1 x 1 x 256] -> [13 x 13 x 256 x *2]
Validating --> conv4.y = RectifiedLinear (conv4.z) : [13 x 13 x 256 x *2] -> [13 x 13 x 256 x *2]
Validating --> conv5.c = Convolution (conv5.W, conv4.y) : [256 x 2304], [13 x 13 x 256 x *2] -> [13 x 13 x 256 x *2]
Validating --> conv5.b = LearnableParameter() :  -> [1 x 1 x 256]
Validating --> conv5.z = Plus (conv5.c, conv5.b) : [13 x 13 x 256 x *2], [1 x 1 x 256] -> [13 x 13 x 256 x *2]
Validating --> conv5.y = RectifiedLinear (conv5.z) : [13 x 13 x 256 x *2] -> [13 x 13 x 256 x *2]
Validating --> pool3 = MaxPooling (conv5.y) : [13 x 13 x 256 x *2] -> [6 x 6 x 256 x *2]
Validating --> h1.t = Times (h1.W, pool3) : [4096 x 6 x 6 x 256], [6 x 6 x 256 x *2] -> [4096 x *2]
Validating --> h1.b = LearnableParameter() :  -> [4096]
Validating --> h1.z = Plus (h1.t, h1.b) : [4096 x *2], [4096] -> [4096 x *2]
Validating --> h1.y = RectifiedLinear (h1.z) : [4096 x *2] -> [4096 x *2]
Validating --> h1_d = Dropout (h1.y) : [4096 x *2] -> [4096 x *2]
Validating --> h2.t = Times (h2.W, h1_d) : [4096 x 4096], [4096 x *2] -> [4096 x *2]
Validating --> h2.b = LearnableParameter() :  -> [4096]
Validating --> h2.z = Plus (h2.t, h2.b) : [4096 x *2], [4096] -> [4096 x *2]
Validating --> h2.y = RectifiedLinear (h2.z) : [4096 x *2] -> [4096 x *2]
Validating --> h2_d = Dropout (h2.y) : [4096 x *2] -> [4096 x *2]
Validating --> OutputNodes.t = Times (OutputNodes.W, h2_d) : [1000 x 4096], [4096 x *2] -> [1000 x *2]
Validating --> OutputNodes.b = LearnableParameter() :  -> [1000]
Validating --> OutputNodes.z = Plus (OutputNodes.t, OutputNodes.b) : [1000 x *2], [1000] -> [1000 x *2]
Validating --> labels = InputValue() :  -> [1000 x *2]
Validating --> ce = CrossEntropyWithSoftmax (labels, OutputNodes.z) : [1000 x *2], [1000 x *2] -> [1]
Validating --> err = ErrorPrediction (labels, OutputNodes.z) : [1000 x *2], [1000 x *2] -> [1]

Validating network. 30 nodes to process in pass 2.


Validating network, final pass.


conv1.c: using cuDNN convolution engine for geometry: Input: 224 x 224 x 3, Output: 56 x 56 x 64, Kernel: 11 x 11 x 3, Map: 1 x 1 x 64, Stride: 4 x 4 x 3, Sharing: (1), AutoPad: (1), LowerPad: 0, UpperPad: 0.

pool1: using cuDNN convolution engine for geometry: Input: 56 x 56 x 64, Output: 27 x 27 x 64, Kernel: 3 x 3 x 1, Map: 1, Stride: 2 x 2 x 1, Sharing: (1), AutoPad: (0), LowerPad: 0, UpperPad: 0.

conv2.c: using cuDNN convolution engine for geometry: Input: 27 x 27 x 64, Output: 27 x 27 x 192, Kernel: 5 x 5 x 64, Map: 1 x 1 x 192, Stride: 1 x 1 x 64, Sharing: (1), AutoPad: (1), LowerPad: 0, UpperPad: 0.

pool2: using cuDNN convolution engine for geometry: Input: 27 x 27 x 192, Output: 13 x 13 x 192, Kernel: 3 x 3 x 1, Map: 1, Stride: 2 x 2 x 1, Sharing: (1), AutoPad: (0), LowerPad: 0, UpperPad: 0.

conv3.c: using cuDNN convolution engine for geometry: Input: 13 x 13 x 192, Output: 13 x 13 x 384, Kernel: 3 x 3 x 192, Map: 1 x 1 x 384, Stride: 1 x 1 x 192, Sharing: (1), AutoPad: (1), LowerPad: 0, UpperPad: 0.

conv4.c: using cuDNN convolution engine for geometry: Input: 13 x 13 x 384, Output: 13 x 13 x 256, Kernel: 3 x 3 x 384, Map: 1 x 1 x 256, Stride: 1 x 1 x 384, Sharing: (1), AutoPad: (1), LowerPad: 0, UpperPad: 0.

conv5.c: using cuDNN convolution engine for geometry: Input: 13 x 13 x 256, Output: 13 x 13 x 256, Kernel: 3 x 3 x 256, Map: 1 x 1 x 256, Stride: 1 x 1 x 256, Sharing: (1), AutoPad: (1), LowerPad: 0, UpperPad: 0.

pool3: using cuDNN convolution engine for geometry: Input: 13 x 13 x 256, Output: 6 x 6 x 256, Kernel: 3 x 3 x 1, Map: 1, Stride: 2 x 2 x 1, Sharing: (1), AutoPad: (0), LowerPad: 0, UpperPad: 0.


18 out of 48 nodes do not share the minibatch layout with the input data.

Post-processing network complete.

evalNodeNames are not specified, using all the default evalnodes and training criterion nodes.


Allocating matrices for forward and/or backward propagation.

Memory Sharing Structure:

0000000000000000: {[OutputNodes.W Gradient[1000 x 4096]] [OutputNodes.b Gradient[1000]] [OutputNodes.t Gradient[1000 x *2]] [OutputNodes.z Gradient[1000 x *2]] [ce Gradient[1]] [conv1.W Gradient[64 x 363]] [conv1.b Gradient[1 x 1 x 64]] [conv1.c Gradient[56 x 56 x 64 x *2]] [conv1.y Gradient[56 x 56 x 64 x *2]] [conv1.z Gradient[56 x 56 x 64 x *2]] [conv2.W Gradient[192 x 1600]] [conv2.b Gradient[1 x 1 x 192]] [conv2.c Gradient[27 x 27 x 192 x *2]] [conv2.y Gradient[27 x 27 x 192 x *2]] [conv2.z Gradient[27 x 27 x 192 x *2]] [conv3.W Gradient[384 x 1728]] [conv3.b Gradient[1 x 1 x 384]] [conv3.c Gradient[13 x 13 x 384 x *2]] [conv3.y Gradient[13 x 13 x 384 x *2]] [conv3.z Gradient[13 x 13 x 384 x *2]] [conv4.W Gradient[256 x 3456]] [conv4.b Gradient[1 x 1 x 256]] [conv4.c Gradient[13 x 13 x 256 x *2]] [conv4.y Gradient[13 x 13 x 256 x *2]] [conv4.z Gradient[13 x 13 x 256 x *2]] [conv5.W Gradient[256 x 2304]] [conv5.b Gradient[1 x 1 x 256]] [conv5.c Gradient[13 x 13 x 256 x *2]] [conv5.y Gradient[13 x 13 x 256 x *2]] [conv5.z Gradient[13 x 13 x 256 x *2]] [err Gradient[1]] [features Gradient[224 x 224 x 3 x *2]] [h1.W Gradient[4096 x 6 x 6 x 256]] [h1.b Gradient[4096]] [h1.t Gradient[4096 x *2]] [h1.y Gradient[4096 x *2]] [h1.z Gradient[4096 x *2]] [h1_d Gradient[4096 x *2]] [h2.W Gradient[4096 x 4096]] [h2.b Gradient[4096]] [h2.t Gradient[4096 x *2]] [h2.y Gradient[4096 x *2]] [h2.z Gradient[4096 x *2]] [h2_d Gradient[4096 x *2]] [labels Gradient[1000 x *2]] [pool1 Gradient[27 x 27 x 64 x *2]] [pool2 Gradient[13 x 13 x 192 x *2]] [pool3 Gradient[6 x 6 x 256 x *2]] }
00000075DBB72BB0: {[h1.b Value[4096]] }
00000075DBB72E30: {[h2.W Value[4096 x 4096]] }
00000075DBB73290: {[h1.W Value[4096 x 6 x 6 x 256]] }
00000075DBB73330: {[h2.b Value[4096]] }
00000075F0174F50: {[OutputNodes.z Value[1000 x *2]] }
00000075F0174FF0: {[conv4.c Value[13 x 13 x 256 x *2]] }
00000075F0175090: {[conv5.z Value[13 x 13 x 256 x *2]] }
00000075F0175130: {[conv2.z Value[27 x 27 x 192 x *2]] }
00000075F0175310: {[h2.t Value[4096 x *2]] }
00000075F0175450: {[err Value[1]] }
00000075F01754F0: {[conv1.z Value[56 x 56 x 64 x *2]] }
00000075F0175590: {[OutputNodes.W Value[1000 x 4096]] }
00000075F0175630: {[conv5.c Value[13 x 13 x 256 x *2]] }
00000075F01756D0: {[h1.z Value[4096 x *2]] }
00000075F0175770: {[h2.y Value[4096 x *2]] }
00000075F0175810: {[OutputNodes.t Value[1000 x *2]] }
00000075F0175950: {[conv1.c Value[56 x 56 x 64 x *2]] }
00000075F01759F0: {[pool1 Value[27 x 27 x 64 x *2]] }
00000075F0175A90: {[conv3.c Value[13 x 13 x 384 x *2]] }
00000075F0175B30: {[conv4.z Value[13 x 13 x 256 x *2]] }
00000075F0175BD0: {[h1.y Value[4096 x *2]] }
00000075F0175DB0: {[ce Value[1]] }
00000075F0175E50: {[conv5.y Value[13 x 13 x 256 x *2]] }
00000075F0175EF0: {[h2.z Value[4096 x *2]] }
00000075F0175F90: {[OutputNodes.b Value[1000]] }
00000075F0176030: {[h2_d Value[4096 x *2]] }
00000075F01760D0: {[conv4.y Value[13 x 13 x 256 x *2]] }
00000075F01762B0: {[pool2 Value[13 x 13 x 192 x *2]] }
00000075F0176350: {[conv2.c Value[27 x 27 x 192 x *2]] }
00000075F01765D0: {[pool3 Value[6 x 6 x 256 x *2]] }
00000075F01767B0: {[conv1.y Value[56 x 56 x 64 x *2]] }
00000075F0176850: {[h1.t Value[4096 x *2]] }
00000075F0176A30: {[h1_d Value[4096 x *2]] }
00000075F0176B70: {[conv3.z Value[13 x 13 x 384 x *2]] }
00000075F0176D50: {[conv2.y Value[27 x 27 x 192 x *2]] }
00000075F0176DF0: {[conv3.y Value[13 x 13 x 384 x *2]] }
00000075F9E74380: {[features Value[224 x 224 x 3 x *2]] }
00000075F9E746A0: {[conv3.W Value[384 x 1728]] }
00000075F9E74920: {[conv3.b Value[1 x 1 x 384]] }
00000075F9E74CE0: {[conv4.W Value[256 x 3456]] }
00000075F9E751E0: {[conv2.b Value[1 x 1 x 192]] }
00000075F9E753C0: {[conv1.W Value[64 x 363]] }
00000075F9E75DC0: {[conv1.b Value[1 x 1 x 64]] }
00000075F9E75FA0: {[conv2.W Value[192 x 1600]] }
00000075F9E765E0: {[labels Value[1000 x *2]] }
00000075F9E76EA0: {[conv5.b Value[1 x 1 x 256]] }
00000075F9E771C0: {[conv5.W Value[256 x 2304]] }
00000075F9E77F80: {[conv4.b Value[1 x 1 x 256]] }

07/14/2016 05:30:51: Minibatch[1-32]: err = 0.99800000 * 500; ce = 7.32805450 * 500
07/14/2016 05:30:51: Final Results: Minibatch[1-32]: err = 0.99800000 * 500; ce = 7.32805450 * 500; perplexity = 1522.41703333

07/14/2016 05:30:51: Action "test" complete.

07/14/2016 05:30:51: __COMPLETED__
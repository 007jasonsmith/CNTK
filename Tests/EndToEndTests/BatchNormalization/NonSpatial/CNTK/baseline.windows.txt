CPU info:
    CPU Model Name: Intel(R) Core(TM) i7-6820HQ CPU @ 2.70GHz
    Hardware threads: 8
    Total Memory: 33417320 kB
-------------------------------------------------------------------
=== Running /cygdrive/c/Users/mahilleb/Repos/CNTK/x64/release/cntk.exe configFile=C:\Users\mahilleb\Repos\CNTK\Tests\EndToEndTests\BatchNormalization\NonSpatial/01_OneHidden.cntk currentDirectory=C:\cygwin64\tmp\cntk-test-20160822174612.125245\BatchNormalization\NonSpatial_CuDNN@release_gpu\TestData RunDir=C:\cygwin64\tmp\cntk-test-20160822174612.125245\BatchNormalization\NonSpatial_CuDNN@release_gpu DataDir=C:\cygwin64\tmp\cntk-test-20160822174612.125245\BatchNormalization\NonSpatial_CuDNN@release_gpu\TestData ConfigDir=C:\Users\mahilleb\Repos\CNTK\Tests\EndToEndTests\BatchNormalization\NonSpatial OutputDir=C:\cygwin64\tmp\cntk-test-20160822174612.125245\BatchNormalization\NonSpatial_CuDNN@release_gpu DeviceId=0 timestamping=true batchNormalizationEngine=cudnn
-------------------------------------------------------------------
Build info: 

		Built time: Aug 22 2016 17:36:51
		Last modified date: Fri Aug 19 10:26:01 2016
		Build type: Release
		Build target: GPU
		With 1bit-SGD: yes
		Math lib: mkl
		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.5
		CUB_PATH: C:\R\cub-1.4.1
		CUDNN_PATH: C:\R\cudnn-7.5-windows10-x64-v5.0-ga\cuda
		Build Branch: mahilleb/CuDnn5Test
		Build SHA1: db500985aff6d7d67b90c1d0dedcbcd7f8ae7b96 (modified)
		Built by mahilleb on mahilleb42
		Build Path: C:\Users\mahilleb\Repos\CNTK\Source\CNTK\
-------------------------------------------------------------------
Changed current directory to C:\cygwin64\tmp\cntk-test-20160822174612.125245\BatchNormalization\NonSpatial_CuDNN@release_gpu\TestData
08/22/2016 16:46:32: -------------------------------------------------------------------
08/22/2016 16:46:32: Build info: 

08/22/2016 16:46:32: 		Built time: Aug 22 2016 17:36:51
08/22/2016 16:46:32: 		Last modified date: Fri Aug 19 10:26:01 2016
08/22/2016 16:46:32: 		Build type: Release
08/22/2016 16:46:32: 		Build target: GPU
08/22/2016 16:46:32: 		With 1bit-SGD: yes
08/22/2016 16:46:32: 		Math lib: mkl
08/22/2016 16:46:32: 		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.5
08/22/2016 16:46:32: 		CUB_PATH: C:\R\cub-1.4.1
08/22/2016 16:46:32: 		CUDNN_PATH: C:\R\cudnn-7.5-windows10-x64-v5.0-ga\cuda
08/22/2016 16:46:32: 		Build Branch: mahilleb/CuDnn5Test
08/22/2016 16:46:32: 		Build SHA1: db500985aff6d7d67b90c1d0dedcbcd7f8ae7b96 (modified)
08/22/2016 16:46:32: 		Built by mahilleb on mahilleb42
08/22/2016 16:46:32: 		Build Path: C:\Users\mahilleb\Repos\CNTK\Source\CNTK\
08/22/2016 16:46:32: -------------------------------------------------------------------
08/22/2016 16:46:32: -------------------------------------------------------------------
08/22/2016 16:46:32: GPU info:

08/22/2016 16:46:32: 		Device[0]: cores = 960; computeCapability = 5.0; type = "Quadro M2000M"; memory = 4096 MB
08/22/2016 16:46:32: -------------------------------------------------------------------

08/22/2016 16:46:32: Running on mahilleb42 at 2016/08/22 16:46:32
08/22/2016 16:46:32: Command line: 
C:\Users\mahilleb\Repos\CNTK\x64\release\cntk.exe  configFile=C:\Users\mahilleb\Repos\CNTK\Tests\EndToEndTests\BatchNormalization\NonSpatial/01_OneHidden.cntk  currentDirectory=C:\cygwin64\tmp\cntk-test-20160822174612.125245\BatchNormalization\NonSpatial_CuDNN@release_gpu\TestData  RunDir=C:\cygwin64\tmp\cntk-test-20160822174612.125245\BatchNormalization\NonSpatial_CuDNN@release_gpu  DataDir=C:\cygwin64\tmp\cntk-test-20160822174612.125245\BatchNormalization\NonSpatial_CuDNN@release_gpu\TestData  ConfigDir=C:\Users\mahilleb\Repos\CNTK\Tests\EndToEndTests\BatchNormalization\NonSpatial  OutputDir=C:\cygwin64\tmp\cntk-test-20160822174612.125245\BatchNormalization\NonSpatial_CuDNN@release_gpu  DeviceId=0  timestamping=true  batchNormalizationEngine=cudnn



08/22/2016 16:46:32: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
08/22/2016 16:46:32: rootDir = ".."
configDir = "$rootDir$/Config"
dataDir   = "$rootDir$/Data"
outputDir = "$rootDir$/Output"
modelDir  = "$outputDir$/Models"
deviceId = 0
command = train:test
precision = "float"
modelPath = "$modelDir$/01_OneHidden"
numMBsToShowResult = 500
traceLevel = 1
batchNormalizationEngine = "testMustOverrideBatchNormalizationEngine"
train = [
    action = "train"
    NDLNetworkBuilder = [
        initOnCPUOnly = true
        networkDescription = "$ConfigDir$/01_OneHidden.ndl"
    ]
    SGD = [
        epochSize = 60000
        minibatchSize = 32
        learningRatesPerSample = 0.003125
        momentumAsTimeConstant = 0
        maxEpochs = 3
    ]
    reader = [
        readerType = "CNTKTextFormatReader"
        file = "$DataDir$/Train-28x28_cntk_text.txt"
        input = [
            features = [
                dim = 784
                format = "dense"
            ]
            labels = [
                dim = 10
                format = "dense"
            ]
        ]
    ]   
]
test = [
    action = "test"
minibatchSize = 1024    
    evalNodeNames = ce:errs:top5Errs
    reader = [
        readerType = "CNTKTextFormatReader"
        file = "$DataDir$/Test-28x28_cntk_text.txt"
        input = [
            features = [
                dim = 784
                format = "dense"
            ]
            labels = [
                dim = 10
                format = "dense"
            ]
        ]
    ]
]
currentDirectory=C:\cygwin64\tmp\cntk-test-20160822174612.125245\BatchNormalization\NonSpatial_CuDNN@release_gpu\TestData
RunDir=C:\cygwin64\tmp\cntk-test-20160822174612.125245\BatchNormalization\NonSpatial_CuDNN@release_gpu
DataDir=C:\cygwin64\tmp\cntk-test-20160822174612.125245\BatchNormalization\NonSpatial_CuDNN@release_gpu\TestData
ConfigDir=C:\Users\mahilleb\Repos\CNTK\Tests\EndToEndTests\BatchNormalization\NonSpatial
OutputDir=C:\cygwin64\tmp\cntk-test-20160822174612.125245\BatchNormalization\NonSpatial_CuDNN@release_gpu
DeviceId=0
timestamping=true
batchNormalizationEngine=cudnn

08/22/2016 16:46:32: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<

08/22/2016 16:46:32: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
08/22/2016 16:46:32: rootDir = ".."
configDir = "../Config"
dataDir   = "../Data"
outputDir = "../Output"
modelDir  = "C:\cygwin64\tmp\cntk-test-20160822174612.125245\BatchNormalization\NonSpatial_CuDNN@release_gpu/Models"
deviceId = 0
command = train:test
precision = "float"
modelPath = "C:\cygwin64\tmp\cntk-test-20160822174612.125245\BatchNormalization\NonSpatial_CuDNN@release_gpu/Models/01_OneHidden"
numMBsToShowResult = 500
traceLevel = 1
batchNormalizationEngine = "testMustOverrideBatchNormalizationEngine"
train = [
    action = "train"
    NDLNetworkBuilder = [
        initOnCPUOnly = true
        networkDescription = "C:\Users\mahilleb\Repos\CNTK\Tests\EndToEndTests\BatchNormalization\NonSpatial/01_OneHidden.ndl"
    ]
    SGD = [
        epochSize = 60000
        minibatchSize = 32
        learningRatesPerSample = 0.003125
        momentumAsTimeConstant = 0
        maxEpochs = 3
    ]
    reader = [
        readerType = "CNTKTextFormatReader"
        file = "C:\cygwin64\tmp\cntk-test-20160822174612.125245\BatchNormalization\NonSpatial_CuDNN@release_gpu\TestData/Train-28x28_cntk_text.txt"
        input = [
            features = [
                dim = 784
                format = "dense"
            ]
            labels = [
                dim = 10
                format = "dense"
            ]
        ]
    ]   
]
test = [
    action = "test"
minibatchSize = 1024    
    evalNodeNames = ce:errs:top5Errs
    reader = [
        readerType = "CNTKTextFormatReader"
        file = "C:\cygwin64\tmp\cntk-test-20160822174612.125245\BatchNormalization\NonSpatial_CuDNN@release_gpu\TestData/Test-28x28_cntk_text.txt"
        input = [
            features = [
                dim = 784
                format = "dense"
            ]
            labels = [
                dim = 10
                format = "dense"
            ]
        ]
    ]
]
currentDirectory=C:\cygwin64\tmp\cntk-test-20160822174612.125245\BatchNormalization\NonSpatial_CuDNN@release_gpu\TestData
RunDir=C:\cygwin64\tmp\cntk-test-20160822174612.125245\BatchNormalization\NonSpatial_CuDNN@release_gpu
DataDir=C:\cygwin64\tmp\cntk-test-20160822174612.125245\BatchNormalization\NonSpatial_CuDNN@release_gpu\TestData
ConfigDir=C:\Users\mahilleb\Repos\CNTK\Tests\EndToEndTests\BatchNormalization\NonSpatial
OutputDir=C:\cygwin64\tmp\cntk-test-20160822174612.125245\BatchNormalization\NonSpatial_CuDNN@release_gpu
DeviceId=0
timestamping=true
batchNormalizationEngine=cudnn

08/22/2016 16:46:32: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<

08/22/2016 16:46:32: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
configparameters: 01_OneHidden.cntk:batchNormalizationEngine=cudnn
configparameters: 01_OneHidden.cntk:command=train:test
configparameters: 01_OneHidden.cntk:configDir=C:\Users\mahilleb\Repos\CNTK\Tests\EndToEndTests\BatchNormalization\NonSpatial
configparameters: 01_OneHidden.cntk:currentDirectory=C:\cygwin64\tmp\cntk-test-20160822174612.125245\BatchNormalization\NonSpatial_CuDNN@release_gpu\TestData
configparameters: 01_OneHidden.cntk:dataDir=C:\cygwin64\tmp\cntk-test-20160822174612.125245\BatchNormalization\NonSpatial_CuDNN@release_gpu\TestData
configparameters: 01_OneHidden.cntk:deviceId=0
configparameters: 01_OneHidden.cntk:modelDir=C:\cygwin64\tmp\cntk-test-20160822174612.125245\BatchNormalization\NonSpatial_CuDNN@release_gpu/Models
configparameters: 01_OneHidden.cntk:modelPath=C:\cygwin64\tmp\cntk-test-20160822174612.125245\BatchNormalization\NonSpatial_CuDNN@release_gpu/Models/01_OneHidden
configparameters: 01_OneHidden.cntk:numMBsToShowResult=500
configparameters: 01_OneHidden.cntk:outputDir=C:\cygwin64\tmp\cntk-test-20160822174612.125245\BatchNormalization\NonSpatial_CuDNN@release_gpu
configparameters: 01_OneHidden.cntk:precision=float
configparameters: 01_OneHidden.cntk:rootDir=..
configparameters: 01_OneHidden.cntk:RunDir=C:\cygwin64\tmp\cntk-test-20160822174612.125245\BatchNormalization\NonSpatial_CuDNN@release_gpu
configparameters: 01_OneHidden.cntk:test=[
    action = "test"
minibatchSize = 1024    
    evalNodeNames = ce:errs:top5Errs
    reader = [
        readerType = "CNTKTextFormatReader"
        file = "C:\cygwin64\tmp\cntk-test-20160822174612.125245\BatchNormalization\NonSpatial_CuDNN@release_gpu\TestData/Test-28x28_cntk_text.txt"
        input = [
            features = [
                dim = 784
                format = "dense"
            ]
            labels = [
                dim = 10
                format = "dense"
            ]
        ]
    ]
]

configparameters: 01_OneHidden.cntk:timestamping=true
configparameters: 01_OneHidden.cntk:traceLevel=1
configparameters: 01_OneHidden.cntk:train=[
    action = "train"
    NDLNetworkBuilder = [
        initOnCPUOnly = true
        networkDescription = "C:\Users\mahilleb\Repos\CNTK\Tests\EndToEndTests\BatchNormalization\NonSpatial/01_OneHidden.ndl"
    ]
    SGD = [
        epochSize = 60000
        minibatchSize = 32
        learningRatesPerSample = 0.003125
        momentumAsTimeConstant = 0
        maxEpochs = 3
    ]
    reader = [
        readerType = "CNTKTextFormatReader"
        file = "C:\cygwin64\tmp\cntk-test-20160822174612.125245\BatchNormalization\NonSpatial_CuDNN@release_gpu\TestData/Train-28x28_cntk_text.txt"
        input = [
            features = [
                dim = 784
                format = "dense"
            ]
            labels = [
                dim = 10
                format = "dense"
            ]
        ]
    ]   
]

08/22/2016 16:46:32: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
08/22/2016 16:46:32: Commands: train test
08/22/2016 16:46:32: Precision = "float"
08/22/2016 16:46:32: CNTKModelPath: C:\cygwin64\tmp\cntk-test-20160822174612.125245\BatchNormalization\NonSpatial_CuDNN@release_gpu/Models/01_OneHidden
08/22/2016 16:46:32: CNTKCommandTrainInfo: train : 3
08/22/2016 16:46:32: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 3

08/22/2016 16:46:32: ##############################################################################
08/22/2016 16:46:32: #                                                                            #
08/22/2016 16:46:32: # Action "train"                                                             #
08/22/2016 16:46:32: #                                                                            #
08/22/2016 16:46:32: ##############################################################################

08/22/2016 16:46:32: CNTKCommandTrainBegin: train
NDLBuilder Using GPU 0

08/22/2016 16:46:32: Creating virgin network.
Node 'featScale' (LearnableParameter operation): Initializing Parameter[1 x 1] <- 0.000000.
Node 'h1.W' (LearnableParameter operation): Initializing Parameter[200 x 784] <- 0.000000.
Node 'h1.b' (LearnableParameter operation): Initializing Parameter[200 x 1] <- 0.000000.
Node 'b' (LearnableParameter operation): Initializing Parameter[200 x 1] <- 0.000000.
Node 'sc' (LearnableParameter operation): Initializing Parameter[200 x 1] <- 0.000000.
Node 'm' (LearnableParameter operation): Initializing Parameter[200 x 1] <- 0.000000.
Node 'var' (LearnableParameter operation): Initializing Parameter[200 x 1] <- 0.000000.
Node 'ol.W' (LearnableParameter operation): Initializing Parameter[10 x 200] <- 0.000000.
Node 'ol.b' (LearnableParameter operation): Initializing Parameter[10 x 1] <- 0.000000.
Node 'unnamed32' (LearnableParameter operation): Initializing Parameter[1 x 1] <- 0.000000.
Node 'featScale' (LearnableParameter operation): Initializing Parameter[1 x 1] <- 0.003906.
Node 'featScale' (LearnableParameter operation): Initializing Parameter[1 x 1] <- 0.003906.
Node 'unnamed32' (LearnableParameter operation): Initializing Parameter[1 x 1] <- 5.000000.
Node 'featScale' (LearnableParameter operation): Initializing Parameter[1 x 1] <- 0.003906.
Node 'h1.W' (LearnableParameter operation): Initializing Parameter[200 x 784] <- uniform(seed=1, range=0.050000*1.000000, onCPU=true).
Node 'h1.b' (LearnableParameter operation): Initializing Parameter[200 x 1] <- uniform(seed=2, range=0.050000*1.000000, onCPU=true).
Node 'b' (LearnableParameter operation): Initializing Parameter[200 x 1] <- 0.000000.
Node 'sc' (LearnableParameter operation): Initializing Parameter[200 x 1] <- 1.000000.
Node 'm' (LearnableParameter operation): Initializing Parameter[200 x 1] <- 0.000000.
Node 'var' (LearnableParameter operation): Initializing Parameter[200 x 1] <- 0.000000.
Node 'ol.W' (LearnableParameter operation): Initializing Parameter[10 x 200] <- uniform(seed=3, range=0.050000*1.000000, onCPU=true).
Node 'ol.b' (LearnableParameter operation): Initializing Parameter[10 x 1] <- uniform(seed=4, range=0.050000*1.000000, onCPU=true).

Post-processing network...

4 roots:
	ce = CrossEntropyWithSoftmax()
	errs = ErrorPrediction()
	ol.z = Plus()
	top5Errs = ErrorPrediction()

Validating network. 21 nodes to process in pass 1.

Validating --> labels = InputValue() :  -> [10 x *]
Validating --> ol.W = LearnableParameter() :  -> [10 x 200]
Validating --> h1.W = LearnableParameter() :  -> [200 x 784]
Validating --> featScale = LearnableParameter() :  -> [1 x 1]
Validating --> features = InputValue() :  -> [784 x *]
Validating --> featScaled = ElementTimes (featScale, features) : [1 x 1], [784 x *] -> [784 x 1 x *]
Validating --> h1.t = Times (h1.W, featScaled) : [200 x 784], [784 x 1 x *] -> [200 x 1 x *]
Validating --> h1.b = LearnableParameter() :  -> [200 x 1]
Validating --> h1.z = Plus (h1.t, h1.b) : [200 x 1 x *], [200 x 1] -> [200 x 1 x *]
Validating --> sc = LearnableParameter() :  -> [200 x 1]
Validating --> b = LearnableParameter() :  -> [200 x 1]
Validating --> m = LearnableParameter() :  -> [200 x 1]
Validating --> var = LearnableParameter() :  -> [200 x 1]
Validating --> y = BatchNormalization (h1.z, sc, b, m, var) : [200 x 1 x *], [200 x 1], [200 x 1], [200 x 1], [200 x 1] -> [200 x 1 x *]
Validating --> ol.t = Times (ol.W, y) : [10 x 200], [200 x 1 x *] -> [10 x 1 x *]
Validating --> ol.b = LearnableParameter() :  -> [10 x 1]
Validating --> ol.z = Plus (ol.t, ol.b) : [10 x 1 x *], [10 x 1] -> [10 x 1 x *]
Validating --> ce = CrossEntropyWithSoftmax (labels, ol.z) : [10 x *], [10 x 1 x *] -> [1]
Validating --> errs = ErrorPrediction (labels, ol.z) : [10 x *], [10 x 1 x *] -> [1]
Validating --> unnamed32 = LearnableParameter() :  -> [1 x 1]
Validating --> top5Errs = ErrorPrediction (labels, ol.z, unnamed32) : [10 x *], [10 x 1 x *], [1 x 1] -> [1]

Validating network. 9 nodes to process in pass 2.


Validating network, final pass.


Using cuDNN batch normalization engine.


13 out of 21 nodes do not share the minibatch layout with the input data.

Post-processing network complete.

08/22/2016 16:46:33: Created model with 21 nodes on GPU 0.

08/22/2016 16:46:33: Training criterion node(s):
08/22/2016 16:46:33: 	ce = CrossEntropyWithSoftmax

08/22/2016 16:46:33: Evaluation criterion node(s):
08/22/2016 16:46:33: 	top5Errs = ErrorPrediction
08/22/2016 16:46:33: 	errs = ErrorPrediction


Allocating matrices for forward and/or backward propagation.

Memory Sharing: Out of 33 matrices, 8 are shared as 4, and 25 are not shared.

	{ h1.W : [200 x 784] (gradient)
	  h1.z : [200 x 1 x *] }
	{ ol.W : [10 x 200] (gradient)
	  ol.z : [10 x 1 x *] (gradient) }
	{ h1.z : [200 x 1 x *] (gradient)
	  ol.t : [10 x 1 x *] }
	{ ol.t : [10 x 1 x *] (gradient)
	  sc : [200 x 1] (gradient) }


08/22/2016 16:46:33: Training 159410 parameters in 6 out of 6 parameter tensors and 12 nodes with gradient:

08/22/2016 16:46:33: 	Node 'b' (LearnableParameter operation) : [200 x 1]
08/22/2016 16:46:33: 	Node 'h1.W' (LearnableParameter operation) : [200 x 784]
08/22/2016 16:46:33: 	Node 'h1.b' (LearnableParameter operation) : [200 x 1]
08/22/2016 16:46:33: 	Node 'ol.W' (LearnableParameter operation) : [10 x 200]
08/22/2016 16:46:33: 	Node 'ol.b' (LearnableParameter operation) : [10 x 1]
08/22/2016 16:46:33: 	Node 'sc' (LearnableParameter operation) : [200 x 1]

08/22/2016 16:46:33: No PreCompute nodes found, or all already computed. Skipping pre-computation step.

08/22/2016 16:46:33: Starting Epoch 1: learning rate per sample = 0.003125  effective momentum = 0.000000  momentum as time constant = 0.0 samples
BlockRandomizer::StartEpoch: epoch 0: frames [0..60000] (first sequence at sample 0), data subset 0 of 1

08/22/2016 16:46:33: Starting minibatch loop.
08/22/2016 16:46:35:  Epoch[ 1 of 3]-Minibatch[   1- 500, 26.67%]: ce = 0.46662509 * 16000; top5Errs = 1.306% * 16000; errs = 13.969% * 16000; time = 2.5768s; samplesPerSecond = 6209.3
08/22/2016 16:46:37:  Epoch[ 1 of 3]-Minibatch[ 501-1000, 53.33%]: ce = 0.39357101 * 16000; top5Errs = 0.794% * 16000; errs = 11.369% * 16000; time = 1.3959s; samplesPerSecond = 11461.8
08/22/2016 16:46:38:  Epoch[ 1 of 3]-Minibatch[1001-1500, 80.00%]: ce = 0.37906537 * 16000; top5Errs = 0.769% * 16000; errs = 11.100% * 16000; time = 1.3856s; samplesPerSecond = 11547.1
08/22/2016 16:46:39: Finished Epoch[ 1 of 3]: [Training] ce = 0.40404635 * 60000; top5Errs = 0.920% * 60000; errs = 11.822% * 60000; totalSamplesSeen = 60000; learningRatePerSample = 0.003125; epochTime=6.40517s
08/22/2016 16:46:39: SGD: Saving checkpoint model 'C:\cygwin64\tmp\cntk-test-20160822174612.125245\BatchNormalization\NonSpatial_CuDNN@release_gpu/Models/01_OneHidden.1'

08/22/2016 16:46:39: Starting Epoch 2: learning rate per sample = 0.003125  effective momentum = 0.000000  momentum as time constant = 0.0 samples
BlockRandomizer::StartEpoch: epoch 1: frames [60000..120000] (first sequence at sample 60000), data subset 0 of 1

08/22/2016 16:46:39: Starting minibatch loop.
08/22/2016 16:46:40:  Epoch[ 2 of 3]-Minibatch[   1- 500, 26.67%]: ce = 0.34492102 * 16000; top5Errs = 0.613% * 16000; errs = 10.225% * 16000; time = 1.3936s; samplesPerSecond = 11480.9
08/22/2016 16:46:42:  Epoch[ 2 of 3]-Minibatch[ 501-1000, 53.33%]: ce = 0.34236395 * 16000; top5Errs = 0.644% * 16000; errs = 10.144% * 16000; time = 1.3927s; samplesPerSecond = 11488.2
08/22/2016 16:46:43:  Epoch[ 2 of 3]-Minibatch[1001-1500, 80.00%]: ce = 0.36281952 * 16000; top5Errs = 0.800% * 16000; errs = 10.331% * 16000; time = 1.3694s; samplesPerSecond = 11684.2
08/22/2016 16:46:44: Finished Epoch[ 2 of 3]: [Training] ce = 0.34606566 * 60000; top5Errs = 0.663% * 60000; errs = 10.123% * 60000; totalSamplesSeen = 120000; learningRatePerSample = 0.003125; epochTime=5.20706s
08/22/2016 16:46:44: SGD: Saving checkpoint model 'C:\cygwin64\tmp\cntk-test-20160822174612.125245\BatchNormalization\NonSpatial_CuDNN@release_gpu/Models/01_OneHidden.2'

08/22/2016 16:46:44: Starting Epoch 3: learning rate per sample = 0.003125  effective momentum = 0.000000  momentum as time constant = 0.0 samples
BlockRandomizer::StartEpoch: epoch 2: frames [120000..180000] (first sequence at sample 120000), data subset 0 of 1

08/22/2016 16:46:44: Starting minibatch loop.
08/22/2016 16:46:46:  Epoch[ 3 of 3]-Minibatch[   1- 500, 26.67%]: ce = 0.33230911 * 16000; top5Errs = 0.581% * 16000; errs = 9.469% * 16000; time = 1.3521s; samplesPerSecond = 11833.7
08/22/2016 16:46:47:  Epoch[ 3 of 3]-Minibatch[ 501-1000, 53.33%]: ce = 0.32444919 * 16000; top5Errs = 0.531% * 16000; errs = 9.494% * 16000; time = 1.3505s; samplesPerSecond = 11847.9
08/22/2016 16:46:48:  Epoch[ 3 of 3]-Minibatch[1001-1500, 80.00%]: ce = 0.33893469 * 16000; top5Errs = 0.631% * 16000; errs = 9.588% * 16000; time = 1.3574s; samplesPerSecond = 11786.9
08/22/2016 16:46:49: Finished Epoch[ 3 of 3]: [Training] ce = 0.33093525 * 60000; top5Errs = 0.582% * 60000; errs = 9.548% * 60000; totalSamplesSeen = 180000; learningRatePerSample = 0.003125; epochTime=5.12492s
08/22/2016 16:46:49: SGD: Saving checkpoint model 'C:\cygwin64\tmp\cntk-test-20160822174612.125245\BatchNormalization\NonSpatial_CuDNN@release_gpu/Models/01_OneHidden'
08/22/2016 16:46:50: CNTKCommandTrainEnd: train

08/22/2016 16:46:50: Action "train" complete.


08/22/2016 16:46:50: ##############################################################################
08/22/2016 16:46:50: #                                                                            #
08/22/2016 16:46:50: # Action "test"                                                              #
08/22/2016 16:46:50: #                                                                            #
08/22/2016 16:46:50: ##############################################################################

INFO: y: initialized samplesSeen from mbCount when loading pre-CuDNNv5 model

Post-processing network...

3 roots:
	ce = CrossEntropyWithSoftmax()
	errs = ErrorPrediction()
	top5Errs = ErrorPrediction()

Validating network. 21 nodes to process in pass 1.

Validating --> labels = InputValue() :  -> [10 x *1]
Validating --> ol.W = LearnableParameter() :  -> [10 x 200]
Validating --> h1.W = LearnableParameter() :  -> [200 x 784]
Validating --> featScale = LearnableParameter() :  -> [1 x 1]
Validating --> features = InputValue() :  -> [784 x *1]
Validating --> featScaled = ElementTimes (featScale, features) : [1 x 1], [784 x *1] -> [784 x 1 x *1]
Validating --> h1.t = Times (h1.W, featScaled) : [200 x 784], [784 x 1 x *1] -> [200 x 1 x *1]
Validating --> h1.b = LearnableParameter() :  -> [200 x 1]
Validating --> h1.z = Plus (h1.t, h1.b) : [200 x 1 x *1], [200 x 1] -> [200 x 1 x *1]
Validating --> sc = LearnableParameter() :  -> [200 x 1]
Validating --> b = LearnableParameter() :  -> [200 x 1]
Validating --> m = LearnableParameter() :  -> [200 x 1]
Validating --> var = LearnableParameter() :  -> [200 x 1]
Validating --> y = BatchNormalization (h1.z, sc, b, m, var) : [200 x 1 x *1], [200 x 1], [200 x 1], [200 x 1], [200 x 1] -> [200 x 1 x *1]
Validating --> ol.t = Times (ol.W, y) : [10 x 200], [200 x 1 x *1] -> [10 x 1 x *1]
Validating --> ol.b = LearnableParameter() :  -> [10 x 1]
Validating --> ol.z = Plus (ol.t, ol.b) : [10 x 1 x *1], [10 x 1] -> [10 x 1 x *1]
Validating --> ce = CrossEntropyWithSoftmax (labels, ol.z) : [10 x *1], [10 x 1 x *1] -> [1]
Validating --> errs = ErrorPrediction (labels, ol.z) : [10 x *1], [10 x 1 x *1] -> [1]
Validating --> unnamed32 = LearnableParameter() :  -> [1 x 1]
Validating --> top5Errs = ErrorPrediction (labels, ol.z, unnamed32) : [10 x *1], [10 x 1 x *1], [1 x 1] -> [1]

Validating network. 9 nodes to process in pass 2.


Validating network, final pass.


Using cuDNN batch normalization engine.


13 out of 21 nodes do not share the minibatch layout with the input data.

Post-processing network complete.



Allocating matrices for forward and/or backward propagation.

Memory Sharing: Out of 21 matrices, 0 are shared as 0, and 21 are not shared.


BlockRandomizer::StartEpoch: epoch 0: frames [0..10000] (first sequence at sample 0), data subset 0 of 1
08/22/2016 16:46:50: Minibatch[1-10]: ce = 0.29474274 * 10000; errs = 7.990% * 10000; top5Errs = 0.540% * 10000
08/22/2016 16:46:50: Final Results: Minibatch[1-10]: ce = 0.29474274 * 10000; perplexity = 1.34278087; errs = 7.990% * 10000; top5Errs = 0.540% * 10000

08/22/2016 16:46:50: Action "test" complete.

08/22/2016 16:46:50: __COMPLETED__
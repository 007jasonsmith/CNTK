CPU info:
    CPU Model Name: Intel(R) Xeon(R) CPU E5-2630 v2 @ 2.60GHz
    Hardware threads: 24
    Total Memory: 264172964 kB
-------------------------------------------------------------------
=== Running mpiexec -n 2 /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/build/1bitsgd/release/bin/cntk configFile=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/ParallelBM/../ParallelBM/cntk.cntk currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data RunDir=/tmp/cntk-test-20160713165131.612468/Speech/DNN_ParallelBM@release_cpu DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/ParallelBM/.. OutputDir=/tmp/cntk-test-20160713165131.612468/Speech/DNN_ParallelBM@release_cpu DeviceId=-1 timestamping=true numCPUThreads=12 precision=double speechTrain=[SGD=[ParallelTrain=[parallelizationStartEpoch=2]]] stderr=/tmp/cntk-test-20160713165131.612468/Speech/DNN_ParallelBM@release_cpu/stderr
-------------------------------------------------------------------
Build info: 

		Built time: Jul 13 2016 15:58:36
		Last modified date: Wed Jul 13 15:14:47 2016
		Build type: release
		Build target: GPU
		With 1bit-SGD: yes
		Math lib: mkl
		CUDA_PATH: /usr/local/cuda-7.5
		CUB_PATH: /usr/local/cub-1.4.1
		CUDNN_PATH: /usr/local/cudnn-4.0
		Build Branch: HEAD
		Build SHA1: 539ab7467b022b4ffa087721bcf20d18485c8d0d
		Built by philly on adf92da755f9
		Build Path: /home/philly/jenkins/workspace/CNTK-Build-Linux
-------------------------------------------------------------------
-------------------------------------------------------------------
Build info: 

		Built time: Jul 13 2016 15:58:36
		Last modified date: Wed Jul 13 15:14:47 2016
		Build type: release
		Build target: GPU
		With 1bit-SGD: yes
		Math lib: mkl
		CUDA_PATH: /usr/local/cuda-7.5
		CUB_PATH: /usr/local/cub-1.4.1
		CUDNN_PATH: /usr/local/cudnn-4.0
		Build Branch: HEAD
		Build SHA1: 539ab7467b022b4ffa087721bcf20d18485c8d0d
		Built by philly on adf92da755f9
		Build Path: /home/philly/jenkins/workspace/CNTK-Build-Linux
-------------------------------------------------------------------
Changed current directory to /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
Changed current directory to /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
MPIWrapper: initializing MPI
MPIWrapper: initializing MPI
ping [requestnodes (before change)]: 2 nodes pinging each other
ping [requestnodes (before change)]: 2 nodes pinging each other
ping [requestnodes (before change)]: all 2 nodes responded
requestnodes [MPIWrapper]: using 2 out of 2 MPI nodes (2 requested); we (0) are in (participating)
ping [requestnodes (after change)]: 2 nodes pinging each other
ping [requestnodes (before change)]: all 2 nodes responded
requestnodes [MPIWrapper]: using 2 out of 2 MPI nodes (2 requested); we (1) are in (participating)
ping [requestnodes (after change)]: 2 nodes pinging each other
ping [requestnodes (after change)]: all 2 nodes responded
mpihelper: we are cog 0 in a gearbox of 2
ping [mpihelper]: 2 nodes pinging each other
ping [requestnodes (after change)]: all 2 nodes responded
mpihelper: we are cog 1 in a gearbox of 2
ping [mpihelper]: 2 nodes pinging each other
ping [mpihelper]: all 2 nodes responded
ping [mpihelper]: all 2 nodes responded
07/13/2016 16:51:51: Redirecting stderr to file /tmp/cntk-test-20160713165131.612468/Speech/DNN_ParallelBM@release_cpu/stderr_speechTrain.logrank0
07/13/2016 16:51:51: Redirecting stderr to file /tmp/cntk-test-20160713165131.612468/Speech/DNN_ParallelBM@release_cpu/stderr_speechTrain.logrank1
MPI Rank 0: 07/13/2016 16:51:51: -------------------------------------------------------------------
MPI Rank 0: 07/13/2016 16:51:51: Build info: 
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:51:51: 		Built time: Jul 13 2016 15:58:36
MPI Rank 0: 07/13/2016 16:51:51: 		Last modified date: Wed Jul 13 15:14:47 2016
MPI Rank 0: 07/13/2016 16:51:51: 		Build type: release
MPI Rank 0: 07/13/2016 16:51:51: 		Build target: GPU
MPI Rank 0: 07/13/2016 16:51:51: 		With 1bit-SGD: yes
MPI Rank 0: 07/13/2016 16:51:51: 		Math lib: mkl
MPI Rank 0: 07/13/2016 16:51:51: 		CUDA_PATH: /usr/local/cuda-7.5
MPI Rank 0: 07/13/2016 16:51:51: 		CUB_PATH: /usr/local/cub-1.4.1
MPI Rank 0: 07/13/2016 16:51:51: 		CUDNN_PATH: /usr/local/cudnn-4.0
MPI Rank 0: 07/13/2016 16:51:51: 		Build Branch: HEAD
MPI Rank 0: 07/13/2016 16:51:51: 		Build SHA1: 539ab7467b022b4ffa087721bcf20d18485c8d0d
MPI Rank 0: 07/13/2016 16:51:51: 		Built by philly on adf92da755f9
MPI Rank 0: 07/13/2016 16:51:51: 		Build Path: /home/philly/jenkins/workspace/CNTK-Build-Linux
MPI Rank 0: 07/13/2016 16:51:51: -------------------------------------------------------------------
MPI Rank 0: 07/13/2016 16:51:52: -------------------------------------------------------------------
MPI Rank 0: 07/13/2016 16:51:52: GPU info:
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:51:52: 		Device[0]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3071 MB
MPI Rank 0: 07/13/2016 16:51:52: 		Device[1]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3071 MB
MPI Rank 0: 07/13/2016 16:51:52: 		Device[2]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3071 MB
MPI Rank 0: 07/13/2016 16:51:52: 		Device[3]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3071 MB
MPI Rank 0: 07/13/2016 16:51:52: -------------------------------------------------------------------
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:51:52: Running on localhost at 2016/07/13 16:51:52
MPI Rank 0: 07/13/2016 16:51:52: Command line: 
MPI Rank 0: /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/build/1bitsgd/release/bin/cntk  configFile=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/ParallelBM/../ParallelBM/cntk.cntk  currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data  RunDir=/tmp/cntk-test-20160713165131.612468/Speech/DNN_ParallelBM@release_cpu  DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data  ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/ParallelBM/..  OutputDir=/tmp/cntk-test-20160713165131.612468/Speech/DNN_ParallelBM@release_cpu  DeviceId=-1  timestamping=true  numCPUThreads=12  precision=double  speechTrain=[SGD=[ParallelTrain=[parallelizationStartEpoch=2]]]  stderr=/tmp/cntk-test-20160713165131.612468/Speech/DNN_ParallelBM@release_cpu/stderr
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:51:52: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
MPI Rank 0: 07/13/2016 16:51:52: precision = "float"
MPI Rank 0: command = speechTrain
MPI Rank 0: deviceId = $DeviceId$
MPI Rank 0: parallelTrain = true
MPI Rank 0: speechTrain = [
MPI Rank 0:     action = "train"
MPI Rank 0:     modelPath = "$RunDir$/models/cntkSpeech.dnn"
MPI Rank 0:     deviceId = $DeviceId$
MPI Rank 0:     traceLevel = 1
MPI Rank 0:     SimpleNetworkBuilder = [
MPI Rank 0:         layerSizes = 363:512:512:132
MPI Rank 0:         trainingCriterion = "CrossEntropyWithSoftmax"
MPI Rank 0:         evalCriterion = "ErrorPrediction"
MPI Rank 0:         layerTypes = "Sigmoid"
MPI Rank 0:         initValueScale = 1.0
MPI Rank 0:         applyMeanVarNorm = true
MPI Rank 0:         uniformInit = true
MPI Rank 0:         needPrior = true
MPI Rank 0:     ]
MPI Rank 0:     ExperimentalNetworkBuilder = [    // the same as above but with BS. Not active; activate by commenting out the SimpleNetworkBuilder entry above
MPI Rank 0:         layerSizes = 363:512:512:132
MPI Rank 0:         trainingCriterion = 'CE'
MPI Rank 0:         evalCriterion = 'Err'
MPI Rank 0:         applyMeanVarNorm = true
MPI Rank 0:         L = Length(layerSizes)-1    // number of model layers
MPI Rank 0:         features = Input(layerSizes[0], 1, tag='feature') ; labels = Input(layerSizes[Length(layerSizes)-1], 1, tag='label')
MPI Rank 0:         featNorm = if applyMeanVarNorm
MPI Rank 0:                    then MeanVarNorm(features)
MPI Rank 0:                    else features
MPI Rank 0:         layers[layer:1..L-1] = if layer > 1
MPI Rank 0:                                then SBFF(layers[layer-1].Eh, layerSizes[layer], layerSizes[layer-1])
MPI Rank 0:                                else SBFF(featNorm, layerSizes[layer], layerSizes[layer-1])
MPI Rank 0:         outLayer = BFF(layers[L-1].Eh, layerSizes[L], layerSizes[L-1])
MPI Rank 0:         outZ = outLayer.z        // + PastValue(layerSizes[L], 1, outLayer.z)
MPI Rank 0:         CE = if trainingCriterion == 'CE'
MPI Rank 0:              then CrossEntropyWithSoftmax(labels, outZ, tag='criterion')
MPI Rank 0:              else Fail('unknown trainingCriterion ' + trainingCriterion)
MPI Rank 0:         Err = if evalCriterion == 'Err' then
MPI Rank 0:               ErrorPrediction(labels, outZ, tag='evaluation')
MPI Rank 0:               else Fail('unknown evalCriterion ' + evalCriterion)
MPI Rank 0:         logPrior = LogPrior(labels)
MPI Rank 0:         // TODO: how to add a tag to an infix operation?
MPI Rank 0:         ScaledLogLikelihood = Minus (outZ, logPrior, tag='output')
MPI Rank 0:     ]
MPI Rank 0:     SGD = [
MPI Rank 0:         epochSize = 20480
MPI Rank 0:         minibatchSize = 64:256:1024
MPI Rank 0:         learningRatesPerMB = 1.0:0.5:0.1
MPI Rank 0:         numMBsToShowResult = 3
MPI Rank 0:         momentumPerMB = 0.9:0.656119
MPI Rank 0:         dropoutRate = 0.0
MPI Rank 0:         maxEpochs = 5
MPI Rank 0:         keepCheckPointFiles = true
MPI Rank 0:         clippingThresholdPerSample = 1#INF
MPI Rank 0:         ParallelTrain = [
MPI Rank 0:             parallelizationMethod = "BlockMomentumSGD"
MPI Rank 0:             distributedMBReading = true
MPI Rank 0:             syncPerfStats=1
MPI Rank 0:             BlockMomentumSGD = [
MPI Rank 0:                 blockSizePerWorker=2048
MPI Rank 0:                 resetSGDMomentum=true
MPI Rank 0:                 useNesterovMomentum=true
MPI Rank 0:             ]
MPI Rank 0:         ]
MPI Rank 0:         AutoAdjust = [
MPI Rank 0:             reduceLearnRateIfImproveLessThan = 0
MPI Rank 0:             loadBestModel = true
MPI Rank 0:             increaseLearnRateIfImproveMoreThan = 1000000000
MPI Rank 0:             learnRateDecreaseFactor = 0.5
MPI Rank 0:             learnRateIncreaseFactor = 1.382
MPI Rank 0:             autoAdjustLR = "adjustAfterEpoch"
MPI Rank 0:         ]
MPI Rank 0:     ]
MPI Rank 0:     reader = [
MPI Rank 0:         readerType = "HTKMLFReader"
MPI Rank 0:         readMethod = "blockRandomize"
MPI Rank 0:         miniBatchMode = "partial"
MPI Rank 0:         randomize = "auto"
MPI Rank 0:         verbosity = 0
MPI Rank 0:         features = [
MPI Rank 0:             dim = 363
MPI Rank 0:             type = "real"
MPI Rank 0:             scpFile = "glob_0000.scp"
MPI Rank 0:         ]
MPI Rank 0:         labels = [
MPI Rank 0:             mlfFile = "$DataDir$/glob_0000.mlf"
MPI Rank 0:             labelMappingFile = "$DataDir$/state.list"
MPI Rank 0:             labelDim = 132
MPI Rank 0:             labelType = "category"
MPI Rank 0:         ]
MPI Rank 0:     ]
MPI Rank 0: ]
MPI Rank 0: currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
MPI Rank 0: RunDir=/tmp/cntk-test-20160713165131.612468/Speech/DNN_ParallelBM@release_cpu
MPI Rank 0: DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
MPI Rank 0: ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/ParallelBM/..
MPI Rank 0: OutputDir=/tmp/cntk-test-20160713165131.612468/Speech/DNN_ParallelBM@release_cpu
MPI Rank 0: DeviceId=-1
MPI Rank 0: timestamping=true
MPI Rank 0: numCPUThreads=12
MPI Rank 0: precision=double
MPI Rank 0: speechTrain=[SGD=[ParallelTrain=[parallelizationStartEpoch=2]]]
MPI Rank 0: stderr=/tmp/cntk-test-20160713165131.612468/Speech/DNN_ParallelBM@release_cpu/stderr
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:51:52: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:51:52: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 0: 07/13/2016 16:51:52: precision = "float"
MPI Rank 0: command = speechTrain
MPI Rank 0: deviceId = -1
MPI Rank 0: parallelTrain = true
MPI Rank 0: speechTrain = [
MPI Rank 0:     action = "train"
MPI Rank 0:     modelPath = "/tmp/cntk-test-20160713165131.612468/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn"
MPI Rank 0:     deviceId = -1
MPI Rank 0:     traceLevel = 1
MPI Rank 0:     SimpleNetworkBuilder = [
MPI Rank 0:         layerSizes = 363:512:512:132
MPI Rank 0:         trainingCriterion = "CrossEntropyWithSoftmax"
MPI Rank 0:         evalCriterion = "ErrorPrediction"
MPI Rank 0:         layerTypes = "Sigmoid"
MPI Rank 0:         initValueScale = 1.0
MPI Rank 0:         applyMeanVarNorm = true
MPI Rank 0:         uniformInit = true
MPI Rank 0:         needPrior = true
MPI Rank 0:     ]
MPI Rank 0:     ExperimentalNetworkBuilder = [    // the same as above but with BS. Not active; activate by commenting out the SimpleNetworkBuilder entry above
MPI Rank 0:         layerSizes = 363:512:512:132
MPI Rank 0:         trainingCriterion = 'CE'
MPI Rank 0:         evalCriterion = 'Err'
MPI Rank 0:         applyMeanVarNorm = true
MPI Rank 0:         L = Length(layerSizes)-1    // number of model layers
MPI Rank 0:         features = Input(layerSizes[0], 1, tag='feature') ; labels = Input(layerSizes[Length(layerSizes)-1], 1, tag='label')
MPI Rank 0:         featNorm = if applyMeanVarNorm
MPI Rank 0:                    then MeanVarNorm(features)
MPI Rank 0:                    else features
MPI Rank 0:         layers[layer:1..L-1] = if layer > 1
MPI Rank 0:                                then SBFF(layers[layer-1].Eh, layerSizes[layer], layerSizes[layer-1])
MPI Rank 0:                                else SBFF(featNorm, layerSizes[layer], layerSizes[layer-1])
MPI Rank 0:         outLayer = BFF(layers[L-1].Eh, layerSizes[L], layerSizes[L-1])
MPI Rank 0:         outZ = outLayer.z        // + PastValue(layerSizes[L], 1, outLayer.z)
MPI Rank 0:         CE = if trainingCriterion == 'CE'
MPI Rank 0:              then CrossEntropyWithSoftmax(labels, outZ, tag='criterion')
MPI Rank 0:              else Fail('unknown trainingCriterion ' + trainingCriterion)
MPI Rank 0:         Err = if evalCriterion == 'Err' then
MPI Rank 0:               ErrorPrediction(labels, outZ, tag='evaluation')
MPI Rank 0:               else Fail('unknown evalCriterion ' + evalCriterion)
MPI Rank 0:         logPrior = LogPrior(labels)
MPI Rank 0:         // TODO: how to add a tag to an infix operation?
MPI Rank 0:         ScaledLogLikelihood = Minus (outZ, logPrior, tag='output')
MPI Rank 0:     ]
MPI Rank 0:     SGD = [
MPI Rank 0:         epochSize = 20480
MPI Rank 0:         minibatchSize = 64:256:1024
MPI Rank 0:         learningRatesPerMB = 1.0:0.5:0.1
MPI Rank 0:         numMBsToShowResult = 3
MPI Rank 0:         momentumPerMB = 0.9:0.656119
MPI Rank 0:         dropoutRate = 0.0
MPI Rank 0:         maxEpochs = 5
MPI Rank 0:         keepCheckPointFiles = true
MPI Rank 0:         clippingThresholdPerSample = 1#INF
MPI Rank 0:         ParallelTrain = [
MPI Rank 0:             parallelizationMethod = "BlockMomentumSGD"
MPI Rank 0:             distributedMBReading = true
MPI Rank 0:             syncPerfStats=1
MPI Rank 0:             BlockMomentumSGD = [
MPI Rank 0:                 blockSizePerWorker=2048
MPI Rank 0:                 resetSGDMomentum=true
MPI Rank 0:                 useNesterovMomentum=true
MPI Rank 0:             ]
MPI Rank 0:         ]
MPI Rank 0:         AutoAdjust = [
MPI Rank 0:             reduceLearnRateIfImproveLessThan = 0
MPI Rank 0:             loadBestModel = true
MPI Rank 0:             increaseLearnRateIfImproveMoreThan = 1000000000
MPI Rank 0:             learnRateDecreaseFactor = 0.5
MPI Rank 0:             learnRateIncreaseFactor = 1.382
MPI Rank 0:             autoAdjustLR = "adjustAfterEpoch"
MPI Rank 0:         ]
MPI Rank 0:     ]
MPI Rank 0:     reader = [
MPI Rank 0:         readerType = "HTKMLFReader"
MPI Rank 0:         readMethod = "blockRandomize"
MPI Rank 0:         miniBatchMode = "partial"
MPI Rank 0:         randomize = "auto"
MPI Rank 0:         verbosity = 0
MPI Rank 0:         features = [
MPI Rank 0:             dim = 363
MPI Rank 0:             type = "real"
MPI Rank 0:             scpFile = "glob_0000.scp"
MPI Rank 0:         ]
MPI Rank 0:         labels = [
MPI Rank 0:             mlfFile = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/glob_0000.mlf"
MPI Rank 0:             labelMappingFile = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/state.list"
MPI Rank 0:             labelDim = 132
MPI Rank 0:             labelType = "category"
MPI Rank 0:         ]
MPI Rank 0:     ]
MPI Rank 0: ]
MPI Rank 0: currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
MPI Rank 0: RunDir=/tmp/cntk-test-20160713165131.612468/Speech/DNN_ParallelBM@release_cpu
MPI Rank 0: DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
MPI Rank 0: ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/ParallelBM/..
MPI Rank 0: OutputDir=/tmp/cntk-test-20160713165131.612468/Speech/DNN_ParallelBM@release_cpu
MPI Rank 0: DeviceId=-1
MPI Rank 0: timestamping=true
MPI Rank 0: numCPUThreads=12
MPI Rank 0: precision=double
MPI Rank 0: speechTrain=[SGD=[ParallelTrain=[parallelizationStartEpoch=2]]]
MPI Rank 0: stderr=/tmp/cntk-test-20160713165131.612468/Speech/DNN_ParallelBM@release_cpu/stderr
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:51:52: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:51:52: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 0: configparameters: cntk.cntk:command=speechTrain
MPI Rank 0: configparameters: cntk.cntk:ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/ParallelBM/..
MPI Rank 0: configparameters: cntk.cntk:currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
MPI Rank 0: configparameters: cntk.cntk:DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
MPI Rank 0: configparameters: cntk.cntk:deviceId=-1
MPI Rank 0: configparameters: cntk.cntk:numCPUThreads=12
MPI Rank 0: configparameters: cntk.cntk:OutputDir=/tmp/cntk-test-20160713165131.612468/Speech/DNN_ParallelBM@release_cpu
MPI Rank 0: configparameters: cntk.cntk:parallelTrain=true
MPI Rank 0: configparameters: cntk.cntk:precision=double
MPI Rank 0: configparameters: cntk.cntk:RunDir=/tmp/cntk-test-20160713165131.612468/Speech/DNN_ParallelBM@release_cpu
MPI Rank 0: configparameters: cntk.cntk:speechTrain=[
MPI Rank 0:     action = "train"
MPI Rank 0:     modelPath = "/tmp/cntk-test-20160713165131.612468/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn"
MPI Rank 0:     deviceId = -1
MPI Rank 0:     traceLevel = 1
MPI Rank 0:     SimpleNetworkBuilder = [
MPI Rank 0:         layerSizes = 363:512:512:132
MPI Rank 0:         trainingCriterion = "CrossEntropyWithSoftmax"
MPI Rank 0:         evalCriterion = "ErrorPrediction"
MPI Rank 0:         layerTypes = "Sigmoid"
MPI Rank 0:         initValueScale = 1.0
MPI Rank 0:         applyMeanVarNorm = true
MPI Rank 0:         uniformInit = true
MPI Rank 0:         needPrior = true
MPI Rank 0:     ]
MPI Rank 0:     ExperimentalNetworkBuilder = [    // the same as above but with BS. Not active; activate by commenting out the SimpleNetworkBuilder entry above
MPI Rank 0:         layerSizes = 363:512:512:132
MPI Rank 0:         trainingCriterion = 'CE'
MPI Rank 0:         evalCriterion = 'Err'
MPI Rank 0:         applyMeanVarNorm = true
MPI Rank 0:         L = Length(layerSizes)-1    // number of model layers
MPI Rank 0:         features = Input(layerSizes[0], 1, tag='feature') ; labels = Input(layerSizes[Length(layerSizes)-1], 1, tag='label')
MPI Rank 0:         featNorm = if applyMeanVarNorm
MPI Rank 0:                    then MeanVarNorm(features)
MPI Rank 0:                    else features
MPI Rank 0:         layers[layer:1..L-1] = if layer > 1
MPI Rank 0:                                then SBFF(layers[layer-1].Eh, layerSizes[layer], layerSizes[layer-1])
MPI Rank 0:                                else SBFF(featNorm, layerSizes[layer], layerSizes[layer-1])
MPI Rank 0:         outLayer = BFF(layers[L-1].Eh, layerSizes[L], layerSizes[L-1])
MPI Rank 0:         outZ = outLayer.z        // + PastValue(layerSizes[L], 1, outLayer.z)
MPI Rank 0:         CE = if trainingCriterion == 'CE'
MPI Rank 0:              then CrossEntropyWithSoftmax(labels, outZ, tag='criterion')
MPI Rank 0:              else Fail('unknown trainingCriterion ' + trainingCriterion)
MPI Rank 0:         Err = if evalCriterion == 'Err' then
MPI Rank 0:               ErrorPrediction(labels, outZ, tag='evaluation')
MPI Rank 0:               else Fail('unknown evalCriterion ' + evalCriterion)
MPI Rank 0:         logPrior = LogPrior(labels)
MPI Rank 0:         // TODO: how to add a tag to an infix operation?
MPI Rank 0:         ScaledLogLikelihood = Minus (outZ, logPrior, tag='output')
MPI Rank 0:     ]
MPI Rank 0:     SGD = [
MPI Rank 0:         epochSize = 20480
MPI Rank 0:         minibatchSize = 64:256:1024
MPI Rank 0:         learningRatesPerMB = 1.0:0.5:0.1
MPI Rank 0:         numMBsToShowResult = 3
MPI Rank 0:         momentumPerMB = 0.9:0.656119
MPI Rank 0:         dropoutRate = 0.0
MPI Rank 0:         maxEpochs = 5
MPI Rank 0:         keepCheckPointFiles = true
MPI Rank 0:         clippingThresholdPerSample = 1#INF
MPI Rank 0:         ParallelTrain = [
MPI Rank 0:             parallelizationMethod = "BlockMomentumSGD"
MPI Rank 0:             distributedMBReading = true
MPI Rank 0:             syncPerfStats=1
MPI Rank 0:             BlockMomentumSGD = [
MPI Rank 0:                 blockSizePerWorker=2048
MPI Rank 0:                 resetSGDMomentum=true
MPI Rank 0:                 useNesterovMomentum=true
MPI Rank 0:             ]
MPI Rank 0:         ]
MPI Rank 0:         AutoAdjust = [
MPI Rank 0:             reduceLearnRateIfImproveLessThan = 0
MPI Rank 0:             loadBestModel = true
MPI Rank 0:             increaseLearnRateIfImproveMoreThan = 1000000000
MPI Rank 0:             learnRateDecreaseFactor = 0.5
MPI Rank 0:             learnRateIncreaseFactor = 1.382
MPI Rank 0:             autoAdjustLR = "adjustAfterEpoch"
MPI Rank 0:         ]
MPI Rank 0:     ]
MPI Rank 0:     reader = [
MPI Rank 0:         readerType = "HTKMLFReader"
MPI Rank 0:         readMethod = "blockRandomize"
MPI Rank 0:         miniBatchMode = "partial"
MPI Rank 0:         randomize = "auto"
MPI Rank 0:         verbosity = 0
MPI Rank 0:         features = [
MPI Rank 0:             dim = 363
MPI Rank 0:             type = "real"
MPI Rank 0:             scpFile = "glob_0000.scp"
MPI Rank 0:         ]
MPI Rank 0:         labels = [
MPI Rank 0:             mlfFile = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/glob_0000.mlf"
MPI Rank 0:             labelMappingFile = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/state.list"
MPI Rank 0:             labelDim = 132
MPI Rank 0:             labelType = "category"
MPI Rank 0:         ]
MPI Rank 0:     ]
MPI Rank 0: ] [SGD=[ParallelTrain=[parallelizationStartEpoch=2]]]
MPI Rank 0: 
MPI Rank 0: configparameters: cntk.cntk:stderr=/tmp/cntk-test-20160713165131.612468/Speech/DNN_ParallelBM@release_cpu/stderr
MPI Rank 0: configparameters: cntk.cntk:timestamping=true
MPI Rank 0: 07/13/2016 16:51:52: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 0: 07/13/2016 16:51:52: Commands: speechTrain
MPI Rank 0: 07/13/2016 16:51:52: Precision = "double"
MPI Rank 0: 07/13/2016 16:51:52: Using 12 CPU threads.
MPI Rank 0: 07/13/2016 16:51:52: CNTKModelPath: /tmp/cntk-test-20160713165131.612468/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn
MPI Rank 0: 07/13/2016 16:51:52: CNTKCommandTrainInfo: speechTrain : 5
MPI Rank 0: 07/13/2016 16:51:52: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 5
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:51:52: ##############################################################################
MPI Rank 0: 07/13/2016 16:51:52: #                                                                            #
MPI Rank 0: 07/13/2016 16:51:52: # Action "train"                                                             #
MPI Rank 0: 07/13/2016 16:51:52: #                                                                            #
MPI Rank 0: 07/13/2016 16:51:52: ##############################################################################
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:51:52: CNTKCommandTrainBegin: speechTrain
MPI Rank 0: SimpleNetworkBuilder Using CPU
MPI Rank 0: reading script file glob_0000.scp ... 948 entries
MPI Rank 0: total 132 state names in state list /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/state.list
MPI Rank 0: htkmlfreader: reading MLF file /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/glob_0000.mlf ... total 948 entries
MPI Rank 0: ...............................................................................................feature set 0: 252734 frames in 948 out of 948 utterances
MPI Rank 0: label set 0: 129 classes
MPI Rank 0: minibatchutterancesource: 948 utterances grouped into 3 chunks, av. chunk size: 316.0 utterances, 84244.7 frames
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:51:52: Creating virgin network.
MPI Rank 0: 
MPI Rank 0: Post-processing network...
MPI Rank 0: 
MPI Rank 0: 7 roots:
MPI Rank 0: 	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
MPI Rank 0: 	EvalErrorPrediction = ErrorPrediction()
MPI Rank 0: 	InvStdOfFeatures = InvStdDev()
MPI Rank 0: 	MeanOfFeatures = Mean()
MPI Rank 0: 	PosteriorProb = Softmax()
MPI Rank 0: 	Prior = Mean()
MPI Rank 0: 	ScaledLogLikelihood = Minus()
MPI Rank 0: 
MPI Rank 0: Validating network. 25 nodes to process in pass 1.
MPI Rank 0: 
MPI Rank 0: Validating --> labels = InputValue() :  -> [132 x *]
MPI Rank 0: Validating --> W2 = LearnableParameter() :  -> [132 x 512]
MPI Rank 0: Validating --> W1 = LearnableParameter() :  -> [512 x 512]
MPI Rank 0: Validating --> W0 = LearnableParameter() :  -> [512 x 363]
MPI Rank 0: Validating --> features = InputValue() :  -> [363 x *]
MPI Rank 0: Validating --> MeanOfFeatures = Mean (features) : [363 x *] -> [363]
MPI Rank 0: Validating --> InvStdOfFeatures = InvStdDev (features) : [363 x *] -> [363]
MPI Rank 0: Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [363 x *], [363], [363] -> [363 x *]
MPI Rank 0: Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [512 x 363], [363 x *] -> [512 x *]
MPI Rank 0: Validating --> B0 = LearnableParameter() :  -> [512 x 1]
MPI Rank 0: Validating --> W0*features+B0 = Plus (W0*features, B0) : [512 x *], [512 x 1] -> [512 x 1 x *]
MPI Rank 0: Validating --> H1 = Sigmoid (W0*features+B0) : [512 x 1 x *] -> [512 x 1 x *]
MPI Rank 0: Validating --> W1*H1 = Times (W1, H1) : [512 x 512], [512 x 1 x *] -> [512 x 1 x *]
MPI Rank 0: Validating --> B1 = LearnableParameter() :  -> [512 x 1]
MPI Rank 0: Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [512 x 1 x *], [512 x 1] -> [512 x 1 x *]
MPI Rank 0: Validating --> H2 = Sigmoid (W1*H1+B1) : [512 x 1 x *] -> [512 x 1 x *]
MPI Rank 0: Validating --> W2*H1 = Times (W2, H2) : [132 x 512], [512 x 1 x *] -> [132 x 1 x *]
MPI Rank 0: Validating --> B2 = LearnableParameter() :  -> [132 x 1]
MPI Rank 0: Validating --> HLast = Plus (W2*H1, B2) : [132 x 1 x *], [132 x 1] -> [132 x 1 x *]
MPI Rank 0: Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [132 x *], [132 x 1 x *] -> [1]
MPI Rank 0: Validating --> EvalErrorPrediction = ErrorPrediction (labels, HLast) : [132 x *], [132 x 1 x *] -> [1]
MPI Rank 0: Validating --> PosteriorProb = Softmax (HLast) : [132 x 1 x *] -> [132 x 1 x *]
MPI Rank 0: Validating --> Prior = Mean (labels) : [132 x *] -> [132]
MPI Rank 0: Validating --> LogOfPrior = Log (Prior) : [132] -> [132]
MPI Rank 0: Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [132 x 1 x *], [132] -> [132 x 1 x *]
MPI Rank 0: 
MPI Rank 0: Validating network. 17 nodes to process in pass 2.
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: Validating network, final pass.
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: 12 out of 25 nodes do not share the minibatch layout with the input data.
MPI Rank 0: 
MPI Rank 0: Post-processing network complete.
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:51:52: Created model with 25 nodes on CPU.
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:51:52: Training criterion node(s):
MPI Rank 0: 07/13/2016 16:51:52: 	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:51:52: Evaluation criterion node(s):
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:51:52: 	EvalErrorPrediction = ErrorPrediction
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: Allocating matrices for forward and/or backward propagation.
MPI Rank 0: 
MPI Rank 0: Memory Sharing Structure:
MPI Rank 0: 
MPI Rank 0: (nil): {[EvalErrorPrediction Gradient[1]] [InvStdOfFeatures Gradient[363]] [LogOfPrior Gradient[132]] [MVNormalizedFeatures Gradient[363 x *]] [MeanOfFeatures Gradient[363]] [PosteriorProb Gradient[132 x 1 x *]] [PosteriorProb Value[132 x 1 x *]] [Prior Gradient[132]] [ScaledLogLikelihood Gradient[132 x 1 x *]] [features Gradient[363 x *]] [labels Gradient[132 x *]] }
MPI Rank 0: 0x2006eb8: {[LogOfPrior Value[132]] }
MPI Rank 0: 0x200b748: {[W0 Value[512 x 363]] }
MPI Rank 0: 0x202b6d8: {[labels Value[132 x *]] }
MPI Rank 0: 0x2046528: {[CrossEntropyWithSoftmax Gradient[1]] }
MPI Rank 0: 0x20466e8: {[B1 Gradient[512 x 1]] [H2 Gradient[512 x 1 x *]] [HLast Gradient[132 x 1 x *]] }
MPI Rank 0: 0x20468a8: {[W2*H1 Gradient[132 x 1 x *]] }
MPI Rank 0: 0x2046a68: {[B2 Gradient[132 x 1]] }
MPI Rank 0: 0x20aad88: {[EvalErrorPrediction Value[1]] }
MPI Rank 0: 0x20d08e8: {[ScaledLogLikelihood Value[132 x 1 x *]] }
MPI Rank 0: 0x20d0a48: {[CrossEntropyWithSoftmax Value[1]] }
MPI Rank 0: 0x20d0ed8: {[MVNormalizedFeatures Value[363 x *]] }
MPI Rank 0: 0x20fc558: {[W0*features+B0 Gradient[512 x 1 x *]] [W1*H1 Value[512 x 1 x *]] }
MPI Rank 0: 0x20fc718: {[W1 Gradient[512 x 512]] [W1*H1+B1 Value[512 x 1 x *]] }
MPI Rank 0: 0x20fc8d8: {[H2 Value[512 x 1 x *]] [W1*H1 Gradient[512 x 1 x *]] }
MPI Rank 0: 0x20fca98: {[B0 Gradient[512 x 1]] [H1 Gradient[512 x 1 x *]] [W1*H1+B1 Gradient[512 x 1 x *]] [W2*H1 Value[132 x 1 x *]] }
MPI Rank 0: 0x20fcc58: {[HLast Value[132 x 1 x *]] [W2 Gradient[132 x 512]] }
MPI Rank 0: 0x21059a8: {[B0 Value[512 x 1]] }
MPI Rank 0: 0x2107998: {[Prior Value[132]] }
MPI Rank 0: 0x210c8c8: {[W1 Value[512 x 512]] }
MPI Rank 0: 0x210e688: {[W0*features Value[512 x *]] }
MPI Rank 0: 0x210e898: {[W0 Gradient[512 x 363]] [W0*features+B0 Value[512 x 1 x *]] }
MPI Rank 0: 0x210ea58: {[H1 Value[512 x 1 x *]] [W0*features Gradient[512 x *]] }
MPI Rank 0: 0x2111478: {[B1 Value[512 x 1]] }
MPI Rank 0: 0x23016d8: {[MeanOfFeatures Value[363]] }
MPI Rank 0: 0x2301ca8: {[W2 Value[132 x 512]] }
MPI Rank 0: 0x2323458: {[B2 Value[132 x 1]] }
MPI Rank 0: 0x2835558: {[features Value[363 x *]] }
MPI Rank 0: 0x283a218: {[InvStdOfFeatures Value[363]] }
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:51:52: Precomputing --> 3 PreCompute nodes found.
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:51:52: 	MeanOfFeatures = Mean()
MPI Rank 0: 07/13/2016 16:51:52: 	InvStdOfFeatures = InvStdDev()
MPI Rank 0: 07/13/2016 16:51:52: 	Prior = Mean()
MPI Rank 0: minibatchiterator: epoch 0: frames [0..252734] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
MPI Rank 0: requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:51:54: Precomputing --> Completed.
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:51:54: Starting Epoch 1: learning rate per sample = 0.015625  effective momentum = 0.900000  momentum as time constant = 607.4 samples
MPI Rank 0: minibatchiterator: epoch 0: frames [0..20480] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:51:54: Starting minibatch loop.
MPI Rank 0: 07/13/2016 16:51:54:  Epoch[ 1 of 5]-Minibatch[   1-   3, 0.94%]: CrossEntropyWithSoftmax = 4.56947300 * 192; EvalErrorPrediction = 0.93750000 * 192; time = 0.1041s; samplesPerSecond = 1843.7
MPI Rank 0: 07/13/2016 16:51:54:  Epoch[ 1 of 5]-Minibatch[   4-   6, 1.88%]: CrossEntropyWithSoftmax = 4.43406315 * 192; EvalErrorPrediction = 0.93229167 * 192; time = 0.0912s; samplesPerSecond = 2104.7
MPI Rank 0: 07/13/2016 16:51:54:  Epoch[ 1 of 5]-Minibatch[   7-   9, 2.81%]: CrossEntropyWithSoftmax = 4.27880063 * 192; EvalErrorPrediction = 0.86458333 * 192; time = 0.0967s; samplesPerSecond = 1985.8
MPI Rank 0: 07/13/2016 16:51:54:  Epoch[ 1 of 5]-Minibatch[  10-  12, 3.75%]: CrossEntropyWithSoftmax = 4.08751953 * 192; EvalErrorPrediction = 0.86979167 * 192; time = 0.0923s; samplesPerSecond = 2081.1
MPI Rank 0: 07/13/2016 16:51:55:  Epoch[ 1 of 5]-Minibatch[  13-  15, 4.69%]: CrossEntropyWithSoftmax = 4.21737559 * 192; EvalErrorPrediction = 0.91145833 * 192; time = 0.0944s; samplesPerSecond = 2034.3
MPI Rank 0: 07/13/2016 16:51:55:  Epoch[ 1 of 5]-Minibatch[  16-  18, 5.62%]: CrossEntropyWithSoftmax = 4.14259750 * 192; EvalErrorPrediction = 0.92187500 * 192; time = 0.0959s; samplesPerSecond = 2002.7
MPI Rank 0: 07/13/2016 16:51:55:  Epoch[ 1 of 5]-Minibatch[  19-  21, 6.56%]: CrossEntropyWithSoftmax = 4.03221539 * 192; EvalErrorPrediction = 0.85416667 * 192; time = 0.0975s; samplesPerSecond = 1970.0
MPI Rank 0: 07/13/2016 16:51:55:  Epoch[ 1 of 5]-Minibatch[  22-  24, 7.50%]: CrossEntropyWithSoftmax = 4.09889450 * 192; EvalErrorPrediction = 0.89062500 * 192; time = 0.0967s; samplesPerSecond = 1986.3
MPI Rank 0: 07/13/2016 16:51:55:  Epoch[ 1 of 5]-Minibatch[  25-  27, 8.44%]: CrossEntropyWithSoftmax = 3.89612175 * 192; EvalErrorPrediction = 0.83854167 * 192; time = 0.0958s; samplesPerSecond = 2003.7
MPI Rank 0: 07/13/2016 16:51:55:  Epoch[ 1 of 5]-Minibatch[  28-  30, 9.38%]: CrossEntropyWithSoftmax = 3.98897999 * 192; EvalErrorPrediction = 0.88020833 * 192; time = 0.0954s; samplesPerSecond = 2013.6
MPI Rank 0: 07/13/2016 16:51:55:  Epoch[ 1 of 5]-Minibatch[  31-  33, 10.31%]: CrossEntropyWithSoftmax = 3.93572978 * 192; EvalErrorPrediction = 0.83333333 * 192; time = 0.0969s; samplesPerSecond = 1981.5
MPI Rank 0: 07/13/2016 16:51:55:  Epoch[ 1 of 5]-Minibatch[  34-  36, 11.25%]: CrossEntropyWithSoftmax = 3.76284095 * 192; EvalErrorPrediction = 0.89062500 * 192; time = 0.0949s; samplesPerSecond = 2022.7
MPI Rank 0: 07/13/2016 16:51:55:  Epoch[ 1 of 5]-Minibatch[  37-  39, 12.19%]: CrossEntropyWithSoftmax = 3.98522385 * 192; EvalErrorPrediction = 0.87500000 * 192; time = 0.0978s; samplesPerSecond = 1963.5
MPI Rank 0: 07/13/2016 16:51:55:  Epoch[ 1 of 5]-Minibatch[  40-  42, 13.12%]: CrossEntropyWithSoftmax = 3.66209590 * 192; EvalErrorPrediction = 0.84895833 * 192; time = 0.0975s; samplesPerSecond = 1969.4
MPI Rank 0: 07/13/2016 16:51:56:  Epoch[ 1 of 5]-Minibatch[  43-  45, 14.06%]: CrossEntropyWithSoftmax = 3.96368107 * 192; EvalErrorPrediction = 0.91666667 * 192; time = 0.0910s; samplesPerSecond = 2110.1
MPI Rank 0: 07/13/2016 16:51:56:  Epoch[ 1 of 5]-Minibatch[  46-  48, 15.00%]: CrossEntropyWithSoftmax = 3.76732554 * 192; EvalErrorPrediction = 0.85416667 * 192; time = 0.0920s; samplesPerSecond = 2088.0
MPI Rank 0: 07/13/2016 16:51:56:  Epoch[ 1 of 5]-Minibatch[  49-  51, 15.94%]: CrossEntropyWithSoftmax = 3.69456327 * 192; EvalErrorPrediction = 0.89062500 * 192; time = 0.1003s; samplesPerSecond = 1913.6
MPI Rank 0: 07/13/2016 16:51:56:  Epoch[ 1 of 5]-Minibatch[  52-  54, 16.88%]: CrossEntropyWithSoftmax = 3.82975145 * 192; EvalErrorPrediction = 0.89583333 * 192; time = 0.0953s; samplesPerSecond = 2014.4
MPI Rank 0: 07/13/2016 16:51:56:  Epoch[ 1 of 5]-Minibatch[  55-  57, 17.81%]: CrossEntropyWithSoftmax = 3.82370243 * 192; EvalErrorPrediction = 0.88020833 * 192; time = 0.0947s; samplesPerSecond = 2027.5
MPI Rank 0: 07/13/2016 16:51:56:  Epoch[ 1 of 5]-Minibatch[  58-  60, 18.75%]: CrossEntropyWithSoftmax = 3.57625565 * 192; EvalErrorPrediction = 0.84895833 * 192; time = 0.0903s; samplesPerSecond = 2127.0
MPI Rank 0: 07/13/2016 16:51:56:  Epoch[ 1 of 5]-Minibatch[  61-  63, 19.69%]: CrossEntropyWithSoftmax = 3.38811493 * 192; EvalErrorPrediction = 0.79166667 * 192; time = 0.0945s; samplesPerSecond = 2032.4
MPI Rank 0: 07/13/2016 16:51:56:  Epoch[ 1 of 5]-Minibatch[  64-  66, 20.62%]: CrossEntropyWithSoftmax = 3.52208661 * 192; EvalErrorPrediction = 0.77604167 * 192; time = 0.0976s; samplesPerSecond = 1966.3
MPI Rank 0: 07/13/2016 16:51:56:  Epoch[ 1 of 5]-Minibatch[  67-  69, 21.56%]: CrossEntropyWithSoftmax = 3.80866929 * 192; EvalErrorPrediction = 0.87500000 * 192; time = 0.0969s; samplesPerSecond = 1981.8
MPI Rank 0: 07/13/2016 16:51:56:  Epoch[ 1 of 5]-Minibatch[  70-  72, 22.50%]: CrossEntropyWithSoftmax = 3.54345746 * 192; EvalErrorPrediction = 0.86458333 * 192; time = 0.1050s; samplesPerSecond = 1828.3
MPI Rank 0: 07/13/2016 16:51:56:  Epoch[ 1 of 5]-Minibatch[  73-  75, 23.44%]: CrossEntropyWithSoftmax = 3.33936350 * 192; EvalErrorPrediction = 0.80208333 * 192; time = 0.0990s; samplesPerSecond = 1938.7
MPI Rank 0: 07/13/2016 16:51:57:  Epoch[ 1 of 5]-Minibatch[  76-  78, 24.38%]: CrossEntropyWithSoftmax = 3.43672338 * 192; EvalErrorPrediction = 0.78125000 * 192; time = 0.0953s; samplesPerSecond = 2014.6
MPI Rank 0: 07/13/2016 16:51:57:  Epoch[ 1 of 5]-Minibatch[  79-  81, 25.31%]: CrossEntropyWithSoftmax = 3.44585129 * 192; EvalErrorPrediction = 0.82812500 * 192; time = 0.0937s; samplesPerSecond = 2050.1
MPI Rank 0: 07/13/2016 16:51:57:  Epoch[ 1 of 5]-Minibatch[  82-  84, 26.25%]: CrossEntropyWithSoftmax = 3.43498669 * 192; EvalErrorPrediction = 0.76041667 * 192; time = 0.0949s; samplesPerSecond = 2022.7
MPI Rank 0: 07/13/2016 16:51:57:  Epoch[ 1 of 5]-Minibatch[  85-  87, 27.19%]: CrossEntropyWithSoftmax = 3.31632754 * 192; EvalErrorPrediction = 0.75000000 * 192; time = 0.0944s; samplesPerSecond = 2033.5
MPI Rank 0: 07/13/2016 16:51:57:  Epoch[ 1 of 5]-Minibatch[  88-  90, 28.12%]: CrossEntropyWithSoftmax = 3.33946924 * 192; EvalErrorPrediction = 0.80208333 * 192; time = 0.0958s; samplesPerSecond = 2003.8
MPI Rank 0: 07/13/2016 16:51:57:  Epoch[ 1 of 5]-Minibatch[  91-  93, 29.06%]: CrossEntropyWithSoftmax = 3.26118575 * 192; EvalErrorPrediction = 0.84375000 * 192; time = 0.0951s; samplesPerSecond = 2018.5
MPI Rank 0: 07/13/2016 16:51:57:  Epoch[ 1 of 5]-Minibatch[  94-  96, 30.00%]: CrossEntropyWithSoftmax = 3.56686839 * 192; EvalErrorPrediction = 0.85416667 * 192; time = 0.0928s; samplesPerSecond = 2068.4
MPI Rank 0: 07/13/2016 16:51:57:  Epoch[ 1 of 5]-Minibatch[  97-  99, 30.94%]: CrossEntropyWithSoftmax = 3.36674876 * 192; EvalErrorPrediction = 0.85416667 * 192; time = 0.0975s; samplesPerSecond = 1968.3
MPI Rank 0: 07/13/2016 16:51:57:  Epoch[ 1 of 5]-Minibatch[ 100- 102, 31.87%]: CrossEntropyWithSoftmax = 3.28977127 * 192; EvalErrorPrediction = 0.81250000 * 192; time = 0.1003s; samplesPerSecond = 1914.9
MPI Rank 0: 07/13/2016 16:51:57:  Epoch[ 1 of 5]-Minibatch[ 103- 105, 32.81%]: CrossEntropyWithSoftmax = 3.27969909 * 192; EvalErrorPrediction = 0.79166667 * 192; time = 0.0979s; samplesPerSecond = 1960.5
MPI Rank 0: 07/13/2016 16:51:58:  Epoch[ 1 of 5]-Minibatch[ 106- 108, 33.75%]: CrossEntropyWithSoftmax = 3.12259596 * 192; EvalErrorPrediction = 0.72916667 * 192; time = 0.0955s; samplesPerSecond = 2011.4
MPI Rank 0: 07/13/2016 16:51:58:  Epoch[ 1 of 5]-Minibatch[ 109- 111, 34.69%]: CrossEntropyWithSoftmax = 3.41981056 * 192; EvalErrorPrediction = 0.77604167 * 192; time = 0.0954s; samplesPerSecond = 2013.6
MPI Rank 0: 07/13/2016 16:51:58:  Epoch[ 1 of 5]-Minibatch[ 112- 114, 35.62%]: CrossEntropyWithSoftmax = 3.38297602 * 192; EvalErrorPrediction = 0.79166667 * 192; time = 0.0997s; samplesPerSecond = 1926.4
MPI Rank 0: 07/13/2016 16:51:58:  Epoch[ 1 of 5]-Minibatch[ 115- 117, 36.56%]: CrossEntropyWithSoftmax = 3.41994711 * 192; EvalErrorPrediction = 0.82812500 * 192; time = 0.0899s; samplesPerSecond = 2134.6
MPI Rank 0: 07/13/2016 16:51:58:  Epoch[ 1 of 5]-Minibatch[ 118- 120, 37.50%]: CrossEntropyWithSoftmax = 3.24732267 * 192; EvalErrorPrediction = 0.78125000 * 192; time = 0.0992s; samplesPerSecond = 1936.0
MPI Rank 0: 07/13/2016 16:51:58:  Epoch[ 1 of 5]-Minibatch[ 121- 123, 38.44%]: CrossEntropyWithSoftmax = 3.20269035 * 192; EvalErrorPrediction = 0.76041667 * 192; time = 0.0968s; samplesPerSecond = 1983.8
MPI Rank 0: 07/13/2016 16:51:58:  Epoch[ 1 of 5]-Minibatch[ 124- 126, 39.38%]: CrossEntropyWithSoftmax = 3.15326365 * 192; EvalErrorPrediction = 0.74479167 * 192; time = 0.0990s; samplesPerSecond = 1940.1
MPI Rank 0: 07/13/2016 16:51:58:  Epoch[ 1 of 5]-Minibatch[ 127- 129, 40.31%]: CrossEntropyWithSoftmax = 3.21802066 * 192; EvalErrorPrediction = 0.78125000 * 192; time = 0.1128s; samplesPerSecond = 1702.8
MPI Rank 0: 07/13/2016 16:51:58:  Epoch[ 1 of 5]-Minibatch[ 130- 132, 41.25%]: CrossEntropyWithSoftmax = 3.26091070 * 192; EvalErrorPrediction = 0.76041667 * 192; time = 0.0966s; samplesPerSecond = 1988.1
MPI Rank 0: 07/13/2016 16:51:58:  Epoch[ 1 of 5]-Minibatch[ 133- 135, 42.19%]: CrossEntropyWithSoftmax = 2.94987113 * 192; EvalErrorPrediction = 0.68229167 * 192; time = 0.0961s; samplesPerSecond = 1998.3
MPI Rank 0: 07/13/2016 16:51:59:  Epoch[ 1 of 5]-Minibatch[ 136- 138, 43.12%]: CrossEntropyWithSoftmax = 3.01829231 * 192; EvalErrorPrediction = 0.70312500 * 192; time = 0.0979s; samplesPerSecond = 1960.3
MPI Rank 0: 07/13/2016 16:51:59:  Epoch[ 1 of 5]-Minibatch[ 139- 141, 44.06%]: CrossEntropyWithSoftmax = 3.19981302 * 192; EvalErrorPrediction = 0.76562500 * 192; time = 0.0955s; samplesPerSecond = 2009.5
MPI Rank 0: 07/13/2016 16:51:59:  Epoch[ 1 of 5]-Minibatch[ 142- 144, 45.00%]: CrossEntropyWithSoftmax = 3.01620054 * 192; EvalErrorPrediction = 0.72916667 * 192; time = 0.0967s; samplesPerSecond = 1985.4
MPI Rank 0: 07/13/2016 16:51:59:  Epoch[ 1 of 5]-Minibatch[ 145- 147, 45.94%]: CrossEntropyWithSoftmax = 3.07482512 * 192; EvalErrorPrediction = 0.76562500 * 192; time = 0.0938s; samplesPerSecond = 2046.3
MPI Rank 0: 07/13/2016 16:51:59:  Epoch[ 1 of 5]-Minibatch[ 148- 150, 46.88%]: CrossEntropyWithSoftmax = 2.95940261 * 192; EvalErrorPrediction = 0.71875000 * 192; time = 0.0983s; samplesPerSecond = 1952.3
MPI Rank 0: 07/13/2016 16:51:59:  Epoch[ 1 of 5]-Minibatch[ 151- 153, 47.81%]: CrossEntropyWithSoftmax = 3.18955068 * 192; EvalErrorPrediction = 0.78125000 * 192; time = 0.0956s; samplesPerSecond = 2008.8
MPI Rank 0: 07/13/2016 16:51:59:  Epoch[ 1 of 5]-Minibatch[ 154- 156, 48.75%]: CrossEntropyWithSoftmax = 2.80225800 * 192; EvalErrorPrediction = 0.70312500 * 192; time = 0.1012s; samplesPerSecond = 1897.2
MPI Rank 0: 07/13/2016 16:51:59:  Epoch[ 1 of 5]-Minibatch[ 157- 159, 49.69%]: CrossEntropyWithSoftmax = 3.08865913 * 192; EvalErrorPrediction = 0.75520833 * 192; time = 0.0977s; samplesPerSecond = 1965.9
MPI Rank 0: 07/13/2016 16:51:59:  Epoch[ 1 of 5]-Minibatch[ 160- 162, 50.62%]: CrossEntropyWithSoftmax = 2.87171438 * 192; EvalErrorPrediction = 0.69791667 * 192; time = 0.0962s; samplesPerSecond = 1996.1
MPI Rank 0: 07/13/2016 16:51:59:  Epoch[ 1 of 5]-Minibatch[ 163- 165, 51.56%]: CrossEntropyWithSoftmax = 2.90723268 * 192; EvalErrorPrediction = 0.73958333 * 192; time = 0.0949s; samplesPerSecond = 2024.2
MPI Rank 0: 07/13/2016 16:51:59:  Epoch[ 1 of 5]-Minibatch[ 166- 168, 52.50%]: CrossEntropyWithSoftmax = 2.96438386 * 192; EvalErrorPrediction = 0.69270833 * 192; time = 0.0990s; samplesPerSecond = 1939.9
MPI Rank 0: 07/13/2016 16:52:00:  Epoch[ 1 of 5]-Minibatch[ 169- 171, 53.44%]: CrossEntropyWithSoftmax = 2.85407675 * 192; EvalErrorPrediction = 0.67708333 * 192; time = 0.0923s; samplesPerSecond = 2080.6
MPI Rank 0: 07/13/2016 16:52:00:  Epoch[ 1 of 5]-Minibatch[ 172- 174, 54.37%]: CrossEntropyWithSoftmax = 2.64516293 * 192; EvalErrorPrediction = 0.63020833 * 192; time = 0.0938s; samplesPerSecond = 2047.2
MPI Rank 0: 07/13/2016 16:52:00:  Epoch[ 1 of 5]-Minibatch[ 175- 177, 55.31%]: CrossEntropyWithSoftmax = 2.78779884 * 192; EvalErrorPrediction = 0.73437500 * 192; time = 0.0956s; samplesPerSecond = 2009.0
MPI Rank 0: 07/13/2016 16:52:00:  Epoch[ 1 of 5]-Minibatch[ 178- 180, 56.25%]: CrossEntropyWithSoftmax = 2.77691077 * 192; EvalErrorPrediction = 0.68229167 * 192; time = 0.0972s; samplesPerSecond = 1974.4
MPI Rank 0: 07/13/2016 16:52:00:  Epoch[ 1 of 5]-Minibatch[ 181- 183, 57.19%]: CrossEntropyWithSoftmax = 2.93466303 * 192; EvalErrorPrediction = 0.68229167 * 192; time = 0.0963s; samplesPerSecond = 1994.1
MPI Rank 0: 07/13/2016 16:52:00:  Epoch[ 1 of 5]-Minibatch[ 184- 186, 58.13%]: CrossEntropyWithSoftmax = 2.79665615 * 192; EvalErrorPrediction = 0.69791667 * 192; time = 0.0978s; samplesPerSecond = 1964.1
MPI Rank 0: 07/13/2016 16:52:00:  Epoch[ 1 of 5]-Minibatch[ 187- 189, 59.06%]: CrossEntropyWithSoftmax = 2.79141433 * 192; EvalErrorPrediction = 0.75520833 * 192; time = 0.0959s; samplesPerSecond = 2002.9
MPI Rank 0: 07/13/2016 16:52:00:  Epoch[ 1 of 5]-Minibatch[ 190- 192, 60.00%]: CrossEntropyWithSoftmax = 2.85677634 * 192; EvalErrorPrediction = 0.68750000 * 192; time = 0.0973s; samplesPerSecond = 1973.5
MPI Rank 0: 07/13/2016 16:52:00:  Epoch[ 1 of 5]-Minibatch[ 193- 195, 60.94%]: CrossEntropyWithSoftmax = 2.60438340 * 192; EvalErrorPrediction = 0.62500000 * 192; time = 0.0972s; samplesPerSecond = 1975.8
MPI Rank 0: 07/13/2016 16:52:00:  Epoch[ 1 of 5]-Minibatch[ 196- 198, 61.88%]: CrossEntropyWithSoftmax = 2.67867701 * 192; EvalErrorPrediction = 0.66666667 * 192; time = 0.0957s; samplesPerSecond = 2005.9
MPI Rank 0: 07/13/2016 16:52:01:  Epoch[ 1 of 5]-Minibatch[ 199- 201, 62.81%]: CrossEntropyWithSoftmax = 2.35420452 * 192; EvalErrorPrediction = 0.61458333 * 192; time = 0.0949s; samplesPerSecond = 2022.7
MPI Rank 0: 07/13/2016 16:52:01:  Epoch[ 1 of 5]-Minibatch[ 202- 204, 63.75%]: CrossEntropyWithSoftmax = 2.67860524 * 192; EvalErrorPrediction = 0.68750000 * 192; time = 0.0978s; samplesPerSecond = 1964.0
MPI Rank 0: 07/13/2016 16:52:01:  Epoch[ 1 of 5]-Minibatch[ 205- 207, 64.69%]: CrossEntropyWithSoftmax = 2.74438644 * 192; EvalErrorPrediction = 0.65625000 * 192; time = 0.0983s; samplesPerSecond = 1953.5
MPI Rank 0: 07/13/2016 16:52:01:  Epoch[ 1 of 5]-Minibatch[ 208- 210, 65.62%]: CrossEntropyWithSoftmax = 2.61472294 * 192; EvalErrorPrediction = 0.65625000 * 192; time = 0.0949s; samplesPerSecond = 2023.9
MPI Rank 0: 07/13/2016 16:52:01:  Epoch[ 1 of 5]-Minibatch[ 211- 213, 66.56%]: CrossEntropyWithSoftmax = 2.56292238 * 192; EvalErrorPrediction = 0.65104167 * 192; time = 0.0963s; samplesPerSecond = 1993.8
MPI Rank 0: 07/13/2016 16:52:01:  Epoch[ 1 of 5]-Minibatch[ 214- 216, 67.50%]: CrossEntropyWithSoftmax = 2.49905414 * 192; EvalErrorPrediction = 0.68229167 * 192; time = 0.0955s; samplesPerSecond = 2011.3
MPI Rank 0: 07/13/2016 16:52:01:  Epoch[ 1 of 5]-Minibatch[ 217- 219, 68.44%]: CrossEntropyWithSoftmax = 2.77977518 * 192; EvalErrorPrediction = 0.67708333 * 192; time = 0.0940s; samplesPerSecond = 2042.8
MPI Rank 0: 07/13/2016 16:52:01:  Epoch[ 1 of 5]-Minibatch[ 220- 222, 69.38%]: CrossEntropyWithSoftmax = 2.46098943 * 192; EvalErrorPrediction = 0.60416667 * 192; time = 0.0967s; samplesPerSecond = 1985.3
MPI Rank 0: 07/13/2016 16:52:01:  Epoch[ 1 of 5]-Minibatch[ 223- 225, 70.31%]: CrossEntropyWithSoftmax = 2.53972637 * 192; EvalErrorPrediction = 0.60416667 * 192; time = 0.0948s; samplesPerSecond = 2026.4
MPI Rank 0: 07/13/2016 16:52:01:  Epoch[ 1 of 5]-Minibatch[ 226- 228, 71.25%]: CrossEntropyWithSoftmax = 2.58069409 * 192; EvalErrorPrediction = 0.64583333 * 192; time = 0.0928s; samplesPerSecond = 2070.1
MPI Rank 0: 07/13/2016 16:52:01:  Epoch[ 1 of 5]-Minibatch[ 229- 231, 72.19%]: CrossEntropyWithSoftmax = 2.42808307 * 192; EvalErrorPrediction = 0.62500000 * 192; time = 0.0957s; samplesPerSecond = 2007.0
MPI Rank 0: 07/13/2016 16:52:02:  Epoch[ 1 of 5]-Minibatch[ 232- 234, 73.12%]: CrossEntropyWithSoftmax = 2.51795774 * 192; EvalErrorPrediction = 0.66666667 * 192; time = 0.0957s; samplesPerSecond = 2006.1
MPI Rank 0: 07/13/2016 16:52:02:  Epoch[ 1 of 5]-Minibatch[ 235- 237, 74.06%]: CrossEntropyWithSoftmax = 2.31017953 * 192; EvalErrorPrediction = 0.63541667 * 192; time = 0.1004s; samplesPerSecond = 1912.8
MPI Rank 0: 07/13/2016 16:52:02:  Epoch[ 1 of 5]-Minibatch[ 238- 240, 75.00%]: CrossEntropyWithSoftmax = 2.42763250 * 192; EvalErrorPrediction = 0.59375000 * 192; time = 0.0965s; samplesPerSecond = 1990.0
MPI Rank 0: 07/13/2016 16:52:02:  Epoch[ 1 of 5]-Minibatch[ 241- 243, 75.94%]: CrossEntropyWithSoftmax = 2.38337452 * 192; EvalErrorPrediction = 0.63020833 * 192; time = 0.0948s; samplesPerSecond = 2026.0
MPI Rank 0: 07/13/2016 16:52:02:  Epoch[ 1 of 5]-Minibatch[ 244- 246, 76.88%]: CrossEntropyWithSoftmax = 2.45688385 * 192; EvalErrorPrediction = 0.68229167 * 192; time = 0.0994s; samplesPerSecond = 1931.7
MPI Rank 0: 07/13/2016 16:52:02:  Epoch[ 1 of 5]-Minibatch[ 247- 249, 77.81%]: CrossEntropyWithSoftmax = 2.35065649 * 192; EvalErrorPrediction = 0.63020833 * 192; time = 0.0918s; samplesPerSecond = 2091.8
MPI Rank 0: 07/13/2016 16:52:02:  Epoch[ 1 of 5]-Minibatch[ 250- 252, 78.75%]: CrossEntropyWithSoftmax = 2.39950363 * 192; EvalErrorPrediction = 0.63541667 * 192; time = 0.0979s; samplesPerSecond = 1960.7
MPI Rank 0: 07/13/2016 16:52:02:  Epoch[ 1 of 5]-Minibatch[ 253- 255, 79.69%]: CrossEntropyWithSoftmax = 2.48031632 * 192; EvalErrorPrediction = 0.60937500 * 192; time = 0.0928s; samplesPerSecond = 2068.6
MPI Rank 0: 07/13/2016 16:52:02:  Epoch[ 1 of 5]-Minibatch[ 256- 258, 80.62%]: CrossEntropyWithSoftmax = 2.62124157 * 192; EvalErrorPrediction = 0.67708333 * 192; time = 0.0969s; samplesPerSecond = 1982.3
MPI Rank 0: 07/13/2016 16:52:02:  Epoch[ 1 of 5]-Minibatch[ 259- 261, 81.56%]: CrossEntropyWithSoftmax = 2.43263192 * 192; EvalErrorPrediction = 0.65625000 * 192; time = 0.0947s; samplesPerSecond = 2026.5
MPI Rank 0: 07/13/2016 16:52:03:  Epoch[ 1 of 5]-Minibatch[ 262- 264, 82.50%]: CrossEntropyWithSoftmax = 2.13490764 * 192; EvalErrorPrediction = 0.57291667 * 192; time = 0.0964s; samplesPerSecond = 1992.2
MPI Rank 0: 07/13/2016 16:52:03:  Epoch[ 1 of 5]-Minibatch[ 265- 267, 83.44%]: CrossEntropyWithSoftmax = 2.52272390 * 192; EvalErrorPrediction = 0.63541667 * 192; time = 0.0990s; samplesPerSecond = 1939.8
MPI Rank 0: 07/13/2016 16:52:03:  Epoch[ 1 of 5]-Minibatch[ 268- 270, 84.38%]: CrossEntropyWithSoftmax = 2.31215555 * 192; EvalErrorPrediction = 0.63020833 * 192; time = 0.0972s; samplesPerSecond = 1974.5
MPI Rank 0: 07/13/2016 16:52:03:  Epoch[ 1 of 5]-Minibatch[ 271- 273, 85.31%]: CrossEntropyWithSoftmax = 2.33888920 * 192; EvalErrorPrediction = 0.60416667 * 192; time = 0.0970s; samplesPerSecond = 1978.5
MPI Rank 0: 07/13/2016 16:52:03:  Epoch[ 1 of 5]-Minibatch[ 274- 276, 86.25%]: CrossEntropyWithSoftmax = 2.19318149 * 192; EvalErrorPrediction = 0.58854167 * 192; time = 0.0969s; samplesPerSecond = 1982.2
MPI Rank 0: 07/13/2016 16:52:03:  Epoch[ 1 of 5]-Minibatch[ 277- 279, 87.19%]: CrossEntropyWithSoftmax = 2.19368853 * 192; EvalErrorPrediction = 0.55208333 * 192; time = 0.0972s; samplesPerSecond = 1975.2
MPI Rank 0: 07/13/2016 16:52:03:  Epoch[ 1 of 5]-Minibatch[ 280- 282, 88.12%]: CrossEntropyWithSoftmax = 2.31322736 * 192; EvalErrorPrediction = 0.59895833 * 192; time = 0.1013s; samplesPerSecond = 1895.0
MPI Rank 0: 07/13/2016 16:52:03:  Epoch[ 1 of 5]-Minibatch[ 283- 285, 89.06%]: CrossEntropyWithSoftmax = 2.21496162 * 192; EvalErrorPrediction = 0.62500000 * 192; time = 0.0960s; samplesPerSecond = 2001.0
MPI Rank 0: 07/13/2016 16:52:03:  Epoch[ 1 of 5]-Minibatch[ 286- 288, 90.00%]: CrossEntropyWithSoftmax = 2.38257678 * 192; EvalErrorPrediction = 0.64062500 * 192; time = 0.0978s; samplesPerSecond = 1963.8
MPI Rank 0: 07/13/2016 16:52:03:  Epoch[ 1 of 5]-Minibatch[ 289- 291, 90.94%]: CrossEntropyWithSoftmax = 2.34785036 * 192; EvalErrorPrediction = 0.60416667 * 192; time = 0.0987s; samplesPerSecond = 1945.2
MPI Rank 0: 07/13/2016 16:52:04:  Epoch[ 1 of 5]-Minibatch[ 292- 294, 91.88%]: CrossEntropyWithSoftmax = 2.20545861 * 192; EvalErrorPrediction = 0.60416667 * 192; time = 0.0961s; samplesPerSecond = 1997.6
MPI Rank 0: 07/13/2016 16:52:04:  Epoch[ 1 of 5]-Minibatch[ 295- 297, 92.81%]: CrossEntropyWithSoftmax = 2.08751143 * 192; EvalErrorPrediction = 0.57291667 * 192; time = 0.0991s; samplesPerSecond = 1937.7
MPI Rank 0: 07/13/2016 16:52:04:  Epoch[ 1 of 5]-Minibatch[ 298- 300, 93.75%]: CrossEntropyWithSoftmax = 2.28302994 * 192; EvalErrorPrediction = 0.64583333 * 192; time = 0.0973s; samplesPerSecond = 1973.5
MPI Rank 0: 07/13/2016 16:52:04:  Epoch[ 1 of 5]-Minibatch[ 301- 303, 94.69%]: CrossEntropyWithSoftmax = 2.22267854 * 192; EvalErrorPrediction = 0.57291667 * 192; time = 0.0982s; samplesPerSecond = 1955.0
MPI Rank 0: 07/13/2016 16:52:04:  Epoch[ 1 of 5]-Minibatch[ 304- 306, 95.62%]: CrossEntropyWithSoftmax = 2.19855044 * 192; EvalErrorPrediction = 0.60416667 * 192; time = 0.0985s; samplesPerSecond = 1949.5
MPI Rank 0: 07/13/2016 16:52:04:  Epoch[ 1 of 5]-Minibatch[ 307- 309, 96.56%]: CrossEntropyWithSoftmax = 2.49612283 * 192; EvalErrorPrediction = 0.64583333 * 192; time = 0.0981s; samplesPerSecond = 1956.6
MPI Rank 0: 07/13/2016 16:52:04:  Epoch[ 1 of 5]-Minibatch[ 310- 312, 97.50%]: CrossEntropyWithSoftmax = 2.25409762 * 192; EvalErrorPrediction = 0.59375000 * 192; time = 0.0981s; samplesPerSecond = 1956.4
MPI Rank 0: 07/13/2016 16:52:04:  Epoch[ 1 of 5]-Minibatch[ 313- 315, 98.44%]: CrossEntropyWithSoftmax = 2.13085317 * 192; EvalErrorPrediction = 0.58333333 * 192; time = 0.0975s; samplesPerSecond = 1969.0
MPI Rank 0: 07/13/2016 16:52:04:  Epoch[ 1 of 5]-Minibatch[ 316- 318, 99.38%]: CrossEntropyWithSoftmax = 2.28902612 * 192; EvalErrorPrediction = 0.59375000 * 192; time = 0.0924s; samplesPerSecond = 2078.7
MPI Rank 0: 07/13/2016 16:52:04: Finished Epoch[ 1 of 5]: [Training] CrossEntropyWithSoftmax = 3.01292779 * 20480; EvalErrorPrediction = 0.72778320 * 20480; totalSamplesSeen = 20480; learningRatePerSample = 0.015625; epochTime=10.3096s
MPI Rank 0: 07/13/2016 16:52:04: SGD: Saving checkpoint model '/tmp/cntk-test-20160713165131.612468/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.1'
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:52:04: Starting Epoch 2: learning rate per sample = 0.001953  effective momentum = 0.656119  momentum as time constant = 607.5 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 1: frames [20480..40960] (first utterance at frame 20480), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:52:04: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 07/13/2016 16:52:05:  Epoch[ 2 of 5]-Minibatch[   1-   3, 3.75%]: CrossEntropyWithSoftmax = 2.25052560 * 519; EvalErrorPrediction = 0.62042389 * 519; time = 0.2485s; samplesPerSecond = 2088.3
MPI Rank 0: 07/13/2016 16:52:05:  Epoch[ 2 of 5]-Minibatch[   4-   6, 7.50%]: CrossEntropyWithSoftmax = 2.02824382 * 529; EvalErrorPrediction = 0.54442344 * 529; time = 0.2423s; samplesPerSecond = 2183.5
MPI Rank 0: 07/13/2016 16:52:05:  Epoch[ 2 of 5]-Minibatch[   7-   9, 11.25%]: CrossEntropyWithSoftmax = 2.04039147 * 494; EvalErrorPrediction = 0.55668016 * 494; time = 0.2249s; samplesPerSecond = 2196.8
MPI Rank 0: 07/13/2016 16:52:05:  Epoch[ 2 of 5]-Minibatch[  10-  12, 15.00%]: CrossEntropyWithSoftmax = 1.98880977 * 491; EvalErrorPrediction = 0.55193483 * 491; time = 0.2236s; samplesPerSecond = 2195.5
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.04-seconds latency this time; accumulated time on sync point = 0.04 seconds , average latency = 0.04 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     1.07 seconds since last report (0.00 seconds on comm.); 4331 samples processed by 2 workers (2190 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 4.06k samplesPerSecond , throughputPerWorker = 2.03k samplesPerSecond
MPI Rank 0: 07/13/2016 16:52:06:  Epoch[ 2 of 5]-Minibatch[  13-  15, 18.75%]: CrossEntropyWithSoftmax = 2.12620927 * 488; EvalErrorPrediction = 0.55327869 * 488; time = 0.2681s; samplesPerSecond = 1820.2
MPI Rank 0: 07/13/2016 16:52:06:  Epoch[ 2 of 5]-Minibatch[  16-  18, 22.50%]: CrossEntropyWithSoftmax = 2.00690071 * 485; EvalErrorPrediction = 0.56494845 * 485; time = 0.2182s; samplesPerSecond = 2222.4
MPI Rank 0: 07/13/2016 16:52:06:  Epoch[ 2 of 5]-Minibatch[  19-  21, 26.25%]: CrossEntropyWithSoftmax = 1.99194220 * 529; EvalErrorPrediction = 0.54442344 * 529; time = 0.2402s; samplesPerSecond = 2201.9
MPI Rank 0: 07/13/2016 16:52:06:  Epoch[ 2 of 5]-Minibatch[  22-  24, 30.00%]: CrossEntropyWithSoftmax = 1.96438270 * 468; EvalErrorPrediction = 0.56410256 * 468; time = 0.2116s; samplesPerSecond = 2211.5
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.05 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     0.99 seconds since last report (0.00 seconds on comm.); 4232 samples processed by 2 workers (2154 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 4.25k samplesPerSecond , throughputPerWorker = 2.13k samplesPerSecond
MPI Rank 0: 07/13/2016 16:52:07:  Epoch[ 2 of 5]-Minibatch[  25-  27, 33.75%]: CrossEntropyWithSoftmax = 2.00145662 * 499; EvalErrorPrediction = 0.53707415 * 499; time = 0.2520s; samplesPerSecond = 1980.5
MPI Rank 0: 07/13/2016 16:52:07:  Epoch[ 2 of 5]-Minibatch[  28-  30, 37.50%]: CrossEntropyWithSoftmax = 2.18677023 * 494; EvalErrorPrediction = 0.58502024 * 494; time = 0.2236s; samplesPerSecond = 2209.4
MPI Rank 0: 07/13/2016 16:52:07:  Epoch[ 2 of 5]-Minibatch[  31-  33, 41.25%]: CrossEntropyWithSoftmax = 1.97121551 * 479; EvalErrorPrediction = 0.55532359 * 479; time = 0.2193s; samplesPerSecond = 2184.4
MPI Rank 0: 07/13/2016 16:52:07:  Epoch[ 2 of 5]-Minibatch[  34-  36, 45.00%]: CrossEntropyWithSoftmax = 2.01765091 * 488; EvalErrorPrediction = 0.54303279 * 488; time = 0.2179s; samplesPerSecond = 2239.9
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.06 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     0.99 seconds since last report (0.00 seconds on comm.); 4185 samples processed by 2 workers (2125 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 4.23k samplesPerSecond , throughputPerWorker = 2.11k samplesPerSecond
MPI Rank 0: 07/13/2016 16:52:07:  Epoch[ 2 of 5]-Minibatch[  37-  39, 48.75%]: CrossEntropyWithSoftmax = 1.90503909 * 506; EvalErrorPrediction = 0.52173913 * 506; time = 0.2557s; samplesPerSecond = 1979.0
MPI Rank 0: 07/13/2016 16:52:08:  Epoch[ 2 of 5]-Minibatch[  40-  42, 52.50%]: CrossEntropyWithSoftmax = 1.87253137 * 512; EvalErrorPrediction = 0.53710938 * 512; time = 0.2314s; samplesPerSecond = 2212.7
MPI Rank 0: 07/13/2016 16:52:08:  Epoch[ 2 of 5]-Minibatch[  43-  45, 56.25%]: CrossEntropyWithSoftmax = 1.92699152 * 497; EvalErrorPrediction = 0.49899396 * 497; time = 0.2206s; samplesPerSecond = 2253.1
MPI Rank 0: 07/13/2016 16:52:08:  Epoch[ 2 of 5]-Minibatch[  46-  48, 60.00%]: CrossEntropyWithSoftmax = 1.86967957 * 502; EvalErrorPrediction = 0.54581673 * 502; time = 0.2303s; samplesPerSecond = 2179.5
MPI Rank 0: 07/13/2016 16:52:08:  Epoch[ 2 of 5]-Minibatch[  49-  51, 63.75%]: CrossEntropyWithSoftmax = 2.08077350 * 476; EvalErrorPrediction = 0.57142857 * 476; time = 0.2181s; samplesPerSecond = 2182.7
MPI Rank 0: 07/13/2016 16:52:09:  Epoch[ 2 of 5]-Minibatch[  52-  54, 67.50%]: CrossEntropyWithSoftmax = 2.00372686 * 487; EvalErrorPrediction = 0.53388090 * 487; time = 0.2143s; samplesPerSecond = 2272.1
MPI Rank 0: 07/13/2016 16:52:09:  Epoch[ 2 of 5]-Minibatch[  55-  57, 71.25%]: CrossEntropyWithSoftmax = 1.92223751 * 499; EvalErrorPrediction = 0.53306613 * 499; time = 0.2271s; samplesPerSecond = 2196.8
MPI Rank 0: 07/13/2016 16:52:09:  Epoch[ 2 of 5]-Minibatch[  58-  60, 75.00%]: CrossEntropyWithSoftmax = 1.96031873 * 475; EvalErrorPrediction = 0.54947368 * 475; time = 0.2102s; samplesPerSecond = 2259.5
MPI Rank 0: 07/13/2016 16:52:09:  Epoch[ 2 of 5]-Minibatch[  61-  63, 78.75%]: CrossEntropyWithSoftmax = 1.94324612 * 506; EvalErrorPrediction = 0.52964427 * 506; time = 0.2290s; samplesPerSecond = 2209.7
MPI Rank 0: 07/13/2016 16:52:09:  Epoch[ 2 of 5]-Minibatch[  64-  66, 82.50%]: CrossEntropyWithSoftmax = 1.94596052 * 472; EvalErrorPrediction = 0.53389831 * 472; time = 0.2133s; samplesPerSecond = 2212.5
MPI Rank 0: 07/13/2016 16:52:10:  Epoch[ 2 of 5]-Minibatch[  67-  69, 86.25%]: CrossEntropyWithSoftmax = 1.87864114 * 490; EvalErrorPrediction = 0.54693878 * 490; time = 0.2265s; samplesPerSecond = 2163.5
MPI Rank 0: 07/13/2016 16:52:10:  Epoch[ 2 of 5]-Minibatch[  70-  72, 90.00%]: CrossEntropyWithSoftmax = 1.94844616 * 477; EvalErrorPrediction = 0.51153040 * 477; time = 0.2136s; samplesPerSecond = 2232.9
MPI Rank 0: 07/13/2016 16:52:10:  Epoch[ 2 of 5]-Minibatch[  73-  75, 93.75%]: CrossEntropyWithSoftmax = 1.93817444 * 469; EvalErrorPrediction = 0.53091684 * 469; time = 0.2144s; samplesPerSecond = 2187.2
MPI Rank 0: 07/13/2016 16:52:10:  Epoch[ 2 of 5]-Minibatch[  76-  78, 97.50%]: CrossEntropyWithSoftmax = 1.94722731 * 495; EvalErrorPrediction = 0.53939394 * 495; time = 0.2194s; samplesPerSecond = 2256.3
MPI Rank 0: 07/13/2016 16:52:10:  Epoch[ 2 of 5]-Minibatch[  79-  81, 101.25%]: CrossEntropyWithSoftmax = 1.88543102 * 322; EvalErrorPrediction = 0.55279503 * 322; time = 0.1438s; samplesPerSecond = 2239.0
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.06 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     3.03 seconds since last report (0.00 seconds on comm.); 7732 samples processed by 2 workers (6679 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 2.55k samplesPerSecond , throughputPerWorker = 1.28k samplesPerSecond
MPI Rank 0: 07/13/2016 16:52:10: Finished Epoch[ 2 of 5]: [Training] CrossEntropyWithSoftmax = 2.00885273 * 20480; EvalErrorPrediction = 0.55078125 * 20480; totalSamplesSeen = 40960; learningRatePerSample = 0.001953125; epochTime=6.08086s
MPI Rank 0: 07/13/2016 16:52:11: SGD: Saving checkpoint model '/tmp/cntk-test-20160713165131.612468/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.2'
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:52:11: Starting Epoch 3: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 2: frames [40960..61440] (first utterance at frame 40960), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:52:11: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 07/13/2016 16:52:11:  Epoch[ 3 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.87780257 * 1939; EvalErrorPrediction = 0.50644662 * 1939; time = 0.8654s; samplesPerSecond = 2240.7
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     1.17 seconds since last report (0.00 seconds on comm.); 4844 samples processed by 2 workers (2583 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 4.15k samplesPerSecond , throughputPerWorker = 2.07k samplesPerSecond
MPI Rank 0: 07/13/2016 16:52:12:  Epoch[ 3 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.89404862 * 1944; EvalErrorPrediction = 0.52726337 * 1944; time = 0.8433s; samplesPerSecond = 2305.2
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     1.11 seconds since last report (0.00 seconds on comm.); 4849 samples processed by 2 workers (2580 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 4.37k samplesPerSecond , throughputPerWorker = 2.18k samplesPerSecond
MPI Rank 0: 07/13/2016 16:52:13:  Epoch[ 3 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.90812492 * 1918; EvalErrorPrediction = 0.53336809 * 1918; time = 0.8480s; samplesPerSecond = 2261.7
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     1.17 seconds since last report (0.00 seconds on comm.); 4868 samples processed by 2 workers (2595 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 4.17k samplesPerSecond , throughputPerWorker = 2.08k samplesPerSecond
MPI Rank 0: 07/13/2016 16:52:14:  Epoch[ 3 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.89877106 * 1957; EvalErrorPrediction = 0.53449157 * 1957; time = 0.8847s; samplesPerSecond = 2212.0
MPI Rank 0: 07/13/2016 16:52:15:  Epoch[ 3 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.88324196 * 1942; EvalErrorPrediction = 0.51956746 * 1942; time = 0.8136s; samplesPerSecond = 2386.8
MPI Rank 0: 07/13/2016 16:52:16:  Epoch[ 3 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.86867010 * 1929; EvalErrorPrediction = 0.52514256 * 1929; time = 0.8269s; samplesPerSecond = 2332.9
MPI Rank 0: 07/13/2016 16:52:16:  Epoch[ 3 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.90242165 * 1290; EvalErrorPrediction = 0.53023256 * 1290; time = 0.5652s; samplesPerSecond = 2282.3
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     2.22 seconds since last report (0.00 seconds on comm.); 5919 samples processed by 2 workers (5161 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 2.67k samplesPerSecond , throughputPerWorker = 1.33k samplesPerSecond
MPI Rank 0: 07/13/2016 16:52:16: Finished Epoch[ 3 of 5]: [Training] CrossEntropyWithSoftmax = 1.89787888 * 20480; EvalErrorPrediction = 0.52875977 * 20480; totalSamplesSeen = 61440; learningRatePerSample = 9.7656251e-05; epochTime=5.66531s
MPI Rank 0: 07/13/2016 16:52:16: SGD: Saving checkpoint model '/tmp/cntk-test-20160713165131.612468/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.3'
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:52:16: Starting Epoch 4: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:52:16: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 07/13/2016 16:52:17:  Epoch[ 4 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.91224926 * 1926; EvalErrorPrediction = 0.52803738 * 1926; time = 0.8447s; samplesPerSecond = 2280.1
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     1.15 seconds since last report (0.00 seconds on comm.); 4905 samples processed by 2 workers (2581 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 4.28k samplesPerSecond , throughputPerWorker = 2.14k samplesPerSecond
MPI Rank 0: 07/13/2016 16:52:18:  Epoch[ 4 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.80760312 * 1894; EvalErrorPrediction = 0.51108765 * 1894; time = 0.8366s; samplesPerSecond = 2264.0
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     1.11 seconds since last report (0.00 seconds on comm.); 4870 samples processed by 2 workers (2537 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 4.39k samplesPerSecond , throughputPerWorker = 2.19k samplesPerSecond
MPI Rank 0: 07/13/2016 16:52:19:  Epoch[ 4 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.86234536 * 1931; EvalErrorPrediction = 0.51424133 * 1931; time = 0.8354s; samplesPerSecond = 2311.5
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     1.08 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2513 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 4.54k samplesPerSecond , throughputPerWorker = 2.27k samplesPerSecond
MPI Rank 0: 07/13/2016 16:52:20:  Epoch[ 4 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.83816606 * 1880; EvalErrorPrediction = 0.50638298 * 1880; time = 0.8186s; samplesPerSecond = 2296.6
MPI Rank 0: 07/13/2016 16:52:20:  Epoch[ 4 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.80548301 * 1880; EvalErrorPrediction = 0.49680851 * 1880; time = 0.8039s; samplesPerSecond = 2338.5
MPI Rank 0: 07/13/2016 16:52:21:  Epoch[ 4 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.81476104 * 1861; EvalErrorPrediction = 0.50940355 * 1861; time = 0.8142s; samplesPerSecond = 2285.7
MPI Rank 0: 07/13/2016 16:52:22:  Epoch[ 4 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.82832821 * 1263; EvalErrorPrediction = 0.49802059 * 1263; time = 0.5601s; samplesPerSecond = 2255.1
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     2.19 seconds since last report (0.00 seconds on comm.); 5789 samples processed by 2 workers (5004 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 2.64k samplesPerSecond , throughputPerWorker = 1.32k samplesPerSecond
MPI Rank 0: 07/13/2016 16:52:22: Finished Epoch[ 4 of 5]: [Training] CrossEntropyWithSoftmax = 1.84940336 * 20480; EvalErrorPrediction = 0.51445312 * 20480; totalSamplesSeen = 81920; learningRatePerSample = 9.7656251e-05; epochTime=5.53189s
MPI Rank 0: 07/13/2016 16:52:22: SGD: Saving checkpoint model '/tmp/cntk-test-20160713165131.612468/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4'
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:52:22: Starting Epoch 5: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:52:22: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 07/13/2016 16:52:23:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80847097 * 1897; EvalErrorPrediction = 0.50237217 * 1897; time = 0.8155s; samplesPerSecond = 2326.2
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     1.10 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 4.48k samplesPerSecond , throughputPerWorker = 2.24k samplesPerSecond
MPI Rank 0: 07/13/2016 16:52:24:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86742287 * 1821; EvalErrorPrediction = 0.51784734 * 1821; time = 0.8117s; samplesPerSecond = 2243.5
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     1.07 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 4.55k samplesPerSecond , throughputPerWorker = 2.27k samplesPerSecond
MPI Rank 0: 07/13/2016 16:52:24:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.90215948 * 1871; EvalErrorPrediction = 0.51950828 * 1871; time = 0.8032s; samplesPerSecond = 2329.3
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     1.09 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 4.47k samplesPerSecond , throughputPerWorker = 2.23k samplesPerSecond
MPI Rank 0: 07/13/2016 16:52:25:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.83673317 * 1870; EvalErrorPrediction = 0.50320856 * 1870; time = 0.8225s; samplesPerSecond = 2273.5
MPI Rank 0: 07/13/2016 16:52:26:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.91249924 * 1899; EvalErrorPrediction = 0.52553976 * 1899; time = 0.7965s; samplesPerSecond = 2384.2
MPI Rank 0: 07/13/2016 16:52:27:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87327558 * 1878; EvalErrorPrediction = 0.52183174 * 1878; time = 0.8029s; samplesPerSecond = 2339.1
MPI Rank 0: 07/13/2016 16:52:27:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.87043426 * 1221; EvalErrorPrediction = 0.51678952 * 1221; time = 0.4946s; samplesPerSecond = 2468.7
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     2.11 seconds since last report (0.00 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 2.76k samplesPerSecond , throughputPerWorker = 1.38k samplesPerSecond
MPI Rank 0: 07/13/2016 16:52:27: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85300231 * 20480; EvalErrorPrediction = 0.51425781 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 9.7656251e-05; epochTime=5.36515s
MPI Rank 0: 07/13/2016 16:52:27: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160713165131.612468/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/13/2016 16:52:27: learnRatePerSample reduced to 4.8828126e-05
MPI Rank 0: 07/13/2016 16:52:27: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:52:27: Starting Epoch 5: learning rate per sample = 0.000049  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:52:27: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 07/13/2016 16:52:28:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80855659 * 1897; EvalErrorPrediction = 0.50184502 * 1897; time = 0.8217s; samplesPerSecond = 2308.7
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     1.09 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 4.49k samplesPerSecond , throughputPerWorker = 2.25k samplesPerSecond
MPI Rank 0: 07/13/2016 16:52:29:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86827725 * 1821; EvalErrorPrediction = 0.51729819 * 1821; time = 0.7753s; samplesPerSecond = 2348.8
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     1.05 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 4.65k samplesPerSecond , throughputPerWorker = 2.33k samplesPerSecond
MPI Rank 0: 07/13/2016 16:52:30:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.90376996 * 1871; EvalErrorPrediction = 0.51950828 * 1871; time = 0.8015s; samplesPerSecond = 2334.4
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     1.07 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 4.52k samplesPerSecond , throughputPerWorker = 2.26k samplesPerSecond
MPI Rank 0: 07/13/2016 16:52:31:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.83821663 * 1870; EvalErrorPrediction = 0.50641711 * 1870; time = 0.8147s; samplesPerSecond = 2295.2
MPI Rank 0: 07/13/2016 16:52:31:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.91393514 * 1899; EvalErrorPrediction = 0.52606635 * 1899; time = 0.8165s; samplesPerSecond = 2325.9
MPI Rank 0: 07/13/2016 16:52:32:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87537660 * 1878; EvalErrorPrediction = 0.52183174 * 1878; time = 0.7895s; samplesPerSecond = 2378.8
MPI Rank 0: 07/13/2016 16:52:33:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.87301608 * 1221; EvalErrorPrediction = 0.51842752 * 1221; time = 0.5234s; samplesPerSecond = 2332.8
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     2.14 seconds since last report (0.00 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 2.72k samplesPerSecond , throughputPerWorker = 1.36k samplesPerSecond
MPI Rank 0: 07/13/2016 16:52:33: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85426644 * 20480; EvalErrorPrediction = 0.51508789 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 4.8828126e-05; epochTime=5.36142s
MPI Rank 0: 07/13/2016 16:52:33: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160713165131.612468/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/13/2016 16:52:33: learnRatePerSample reduced to 2.4414063e-05
MPI Rank 0: 07/13/2016 16:52:33: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:52:33: Starting Epoch 5: learning rate per sample = 0.000024  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:52:33: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 07/13/2016 16:52:34:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80860170 * 1897; EvalErrorPrediction = 0.50184502 * 1897; time = 0.8295s; samplesPerSecond = 2286.8
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     1.10 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 4.46k samplesPerSecond , throughputPerWorker = 2.23k samplesPerSecond
MPI Rank 0: 07/13/2016 16:52:35:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86874821 * 1821; EvalErrorPrediction = 0.51784734 * 1821; time = 0.7789s; samplesPerSecond = 2337.9
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     1.07 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 4.58k samplesPerSecond , throughputPerWorker = 2.29k samplesPerSecond
MPI Rank 0: 07/13/2016 16:52:35:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.90471511 * 1871; EvalErrorPrediction = 0.52004276 * 1871; time = 0.8243s; samplesPerSecond = 2269.9
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     1.07 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 4.53k samplesPerSecond , throughputPerWorker = 2.27k samplesPerSecond
MPI Rank 0: 07/13/2016 16:52:36:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.83914326 * 1870; EvalErrorPrediction = 0.50802139 * 1870; time = 0.8027s; samplesPerSecond = 2329.6
MPI Rank 0: 07/13/2016 16:52:37:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.91489914 * 1899; EvalErrorPrediction = 0.52817272 * 1899; time = 0.8045s; samplesPerSecond = 2360.5
MPI Rank 0: 07/13/2016 16:52:38:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87668517 * 1878; EvalErrorPrediction = 0.52449414 * 1878; time = 0.7973s; samplesPerSecond = 2355.3
MPI Rank 0: 07/13/2016 16:52:38:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.87427101 * 1221; EvalErrorPrediction = 0.51678952 * 1221; time = 0.5256s; samplesPerSecond = 2323.1
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     2.14 seconds since last report (0.00 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 2.72k samplesPerSecond , throughputPerWorker = 1.36k samplesPerSecond
MPI Rank 0: 07/13/2016 16:52:38: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85499692 * 20480; EvalErrorPrediction = 0.51547852 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 2.4414063e-05; epochTime=5.38044s
MPI Rank 0: 07/13/2016 16:52:38: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160713165131.612468/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/13/2016 16:52:38: learnRatePerSample reduced to 1.2207031e-05
MPI Rank 0: 07/13/2016 16:52:38: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:52:39: Starting Epoch 5: learning rate per sample = 0.000012  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:52:39: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 07/13/2016 16:52:39:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80862485 * 1897; EvalErrorPrediction = 0.50184502 * 1897; time = 0.8215s; samplesPerSecond = 2309.2
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     1.08 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 4.55k samplesPerSecond , throughputPerWorker = 2.28k samplesPerSecond
MPI Rank 0: 07/13/2016 16:52:40:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86899591 * 1821; EvalErrorPrediction = 0.51784734 * 1821; time = 0.7933s; samplesPerSecond = 2295.6
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     1.09 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 4.48k samplesPerSecond , throughputPerWorker = 2.24k samplesPerSecond
MPI Rank 0: 07/13/2016 16:52:41:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.90523368 * 1871; EvalErrorPrediction = 0.52111170 * 1871; time = 0.8105s; samplesPerSecond = 2308.3
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     1.07 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 4.53k samplesPerSecond , throughputPerWorker = 2.27k samplesPerSecond
MPI Rank 0: 07/13/2016 16:52:42:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.83967949 * 1870; EvalErrorPrediction = 0.50695187 * 1870; time = 0.8106s; samplesPerSecond = 2306.8
MPI Rank 0: 07/13/2016 16:52:43:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.91551098 * 1899; EvalErrorPrediction = 0.52711954 * 1899; time = 0.8396s; samplesPerSecond = 2261.8
MPI Rank 0: 07/13/2016 16:52:43:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87747996 * 1878; EvalErrorPrediction = 0.52342918 * 1878; time = 0.7818s; samplesPerSecond = 2402.3
MPI Rank 0: 07/13/2016 16:52:44:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.87488056 * 1221; EvalErrorPrediction = 0.51842752 * 1221; time = 0.5194s; samplesPerSecond = 2350.8
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     2.15 seconds since last report (0.00 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 2.70k samplesPerSecond , throughputPerWorker = 1.35k samplesPerSecond
MPI Rank 0: 07/13/2016 16:52:44: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85540764 * 20480; EvalErrorPrediction = 0.51547852 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 1.2207031e-05; epochTime=5.39462s
MPI Rank 0: 07/13/2016 16:52:44: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160713165131.612468/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/13/2016 16:52:44: learnRatePerSample reduced to 6.1035157e-06
MPI Rank 0: 07/13/2016 16:52:44: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:52:44: Starting Epoch 5: learning rate per sample = 0.000006  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:52:44: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 07/13/2016 16:52:45:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80863657 * 1897; EvalErrorPrediction = 0.50184502 * 1897; time = 0.8108s; samplesPerSecond = 2339.6
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     1.09 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 4.53k samplesPerSecond , throughputPerWorker = 2.26k samplesPerSecond
MPI Rank 0: 07/13/2016 16:52:46:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86912298 * 1821; EvalErrorPrediction = 0.51784734 * 1821; time = 0.7805s; samplesPerSecond = 2333.1
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     1.07 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 4.56k samplesPerSecond , throughputPerWorker = 2.28k samplesPerSecond
MPI Rank 0: 07/13/2016 16:52:46:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.90550621 * 1871; EvalErrorPrediction = 0.52164618 * 1871; time = 0.8196s; samplesPerSecond = 2282.7
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     1.10 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 4.41k samplesPerSecond , throughputPerWorker = 2.21k samplesPerSecond
MPI Rank 0: 07/13/2016 16:52:47:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.83997065 * 1870; EvalErrorPrediction = 0.50802139 * 1870; time = 0.8419s; samplesPerSecond = 2221.1
MPI Rank 0: 07/13/2016 16:52:48:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.91586450 * 1899; EvalErrorPrediction = 0.52764613 * 1899; time = 0.8219s; samplesPerSecond = 2310.6
MPI Rank 0: 07/13/2016 16:52:49:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87793326 * 1878; EvalErrorPrediction = 0.52449414 * 1878; time = 0.8223s; samplesPerSecond = 2283.9
MPI Rank 0: 07/13/2016 16:52:49:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.87518958 * 1221; EvalErrorPrediction = 0.51924652 * 1221; time = 0.5124s; samplesPerSecond = 2382.8
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     2.17 seconds since last report (0.00 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 2.68k samplesPerSecond , throughputPerWorker = 1.34k samplesPerSecond
MPI Rank 0: 07/13/2016 16:52:49: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85562974 * 20480; EvalErrorPrediction = 0.51582031 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 6.1035157e-06; epochTime=5.42713s
MPI Rank 0: 07/13/2016 16:52:49: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160713165131.612468/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/13/2016 16:52:50: learnRatePerSample reduced to 3.0517579e-06
MPI Rank 0: 07/13/2016 16:52:50: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:52:50: Starting Epoch 5: learning rate per sample = 0.000003  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:52:50: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 07/13/2016 16:52:50:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80864247 * 1897; EvalErrorPrediction = 0.50184502 * 1897; time = 0.8250s; samplesPerSecond = 2299.5
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     1.09 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 4.49k samplesPerSecond , throughputPerWorker = 2.25k samplesPerSecond
MPI Rank 0: 07/13/2016 16:52:51:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86918735 * 1821; EvalErrorPrediction = 0.51784734 * 1821; time = 0.8017s; samplesPerSecond = 2271.5
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     1.10 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 4.44k samplesPerSecond , throughputPerWorker = 2.22k samplesPerSecond
MPI Rank 0: 07/13/2016 16:52:52:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.90564602 * 1871; EvalErrorPrediction = 0.52111170 * 1871; time = 0.8291s; samplesPerSecond = 2256.7
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     1.09 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 4.46k samplesPerSecond , throughputPerWorker = 2.23k samplesPerSecond
MPI Rank 0: 07/13/2016 16:52:53:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.84012271 * 1870; EvalErrorPrediction = 0.50855615 * 1870; time = 0.8213s; samplesPerSecond = 2276.8
MPI Rank 0: 07/13/2016 16:52:54:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.91605566 * 1899; EvalErrorPrediction = 0.52764613 * 1899; time = 0.8352s; samplesPerSecond = 2273.7
MPI Rank 0: 07/13/2016 16:52:55:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87817773 * 1878; EvalErrorPrediction = 0.52555911 * 1878; time = 0.7965s; samplesPerSecond = 2357.7
MPI Rank 0: 07/13/2016 16:52:55:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.87534772 * 1221; EvalErrorPrediction = 0.51924652 * 1221; time = 0.5141s; samplesPerSecond = 2375.2
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     2.16 seconds since last report (0.00 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 2.70k samplesPerSecond , throughputPerWorker = 1.35k samplesPerSecond
MPI Rank 0: 07/13/2016 16:52:55: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85574594 * 20480; EvalErrorPrediction = 0.51606445 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 3.0517579e-06; epochTime=5.4413s
MPI Rank 0: 07/13/2016 16:52:55: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160713165131.612468/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/13/2016 16:52:55: learnRatePerSample reduced to 1.5258789e-06
MPI Rank 0: 07/13/2016 16:52:55: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:52:55: Starting Epoch 5: learning rate per sample = 0.000002  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:52:55: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 07/13/2016 16:52:56:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80864542 * 1897; EvalErrorPrediction = 0.50184502 * 1897; time = 0.8188s; samplesPerSecond = 2316.7
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     1.10 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 4.49k samplesPerSecond , throughputPerWorker = 2.24k samplesPerSecond
MPI Rank 0: 07/13/2016 16:52:57:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86921975 * 1821; EvalErrorPrediction = 0.51784734 * 1821; time = 0.8113s; samplesPerSecond = 2244.4
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     1.09 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 4.50k samplesPerSecond , throughputPerWorker = 2.25k samplesPerSecond
MPI Rank 0: 07/13/2016 16:52:58:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.90571684 * 1871; EvalErrorPrediction = 0.52004276 * 1871; time = 0.8182s; samplesPerSecond = 2286.8
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     1.09 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 4.46k samplesPerSecond , throughputPerWorker = 2.23k samplesPerSecond
MPI Rank 0: 07/13/2016 16:52:58:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.84020046 * 1870; EvalErrorPrediction = 0.50855615 * 1870; time = 0.8165s; samplesPerSecond = 2290.4
MPI Rank 0: 07/13/2016 16:52:59:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.91615521 * 1899; EvalErrorPrediction = 0.52764613 * 1899; time = 0.8205s; samplesPerSecond = 2314.5
MPI Rank 0: 07/13/2016 16:53:00:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87830500 * 1878; EvalErrorPrediction = 0.52555911 * 1878; time = 0.7790s; samplesPerSecond = 2410.7
MPI Rank 0: 07/13/2016 16:53:01:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.87542816 * 1221; EvalErrorPrediction = 0.51924652 * 1221; time = 0.5041s; samplesPerSecond = 2422.2
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     2.12 seconds since last report (0.00 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 2.75k samplesPerSecond , throughputPerWorker = 1.38k samplesPerSecond
MPI Rank 0: 07/13/2016 16:53:01: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85580548 * 20480; EvalErrorPrediction = 0.51591797 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 1.5258789e-06; epochTime=5.38597s
MPI Rank 0: 07/13/2016 16:53:01: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160713165131.612468/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/13/2016 16:53:01: learnRatePerSample reduced to 7.6293946e-07
MPI Rank 0: 07/13/2016 16:53:01: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:53:01: Starting Epoch 5: learning rate per sample = 0.000001  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:53:01: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 07/13/2016 16:53:02:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80864691 * 1897; EvalErrorPrediction = 0.50184502 * 1897; time = 0.8286s; samplesPerSecond = 2289.5
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     1.11 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 4.43k samplesPerSecond , throughputPerWorker = 2.22k samplesPerSecond
MPI Rank 0: 07/13/2016 16:53:02:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86923600 * 1821; EvalErrorPrediction = 0.51784734 * 1821; time = 0.8031s; samplesPerSecond = 2267.4
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     1.09 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 4.46k samplesPerSecond , throughputPerWorker = 2.23k samplesPerSecond
MPI Rank 0: 07/13/2016 16:53:03:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.90575249 * 1871; EvalErrorPrediction = 0.52057723 * 1871; time = 0.8362s; samplesPerSecond = 2237.5
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     1.08 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 4.48k samplesPerSecond , throughputPerWorker = 2.24k samplesPerSecond
MPI Rank 0: 07/13/2016 16:53:04:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.84023978 * 1870; EvalErrorPrediction = 0.50855615 * 1870; time = 0.8154s; samplesPerSecond = 2293.5
MPI Rank 0: 07/13/2016 16:53:05:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.91620602 * 1899; EvalErrorPrediction = 0.52764613 * 1899; time = 0.8231s; samplesPerSecond = 2307.2
MPI Rank 0: 07/13/2016 16:53:06:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87836997 * 1878; EvalErrorPrediction = 0.52555911 * 1878; time = 0.8196s; samplesPerSecond = 2291.3
MPI Rank 0: 07/13/2016 16:53:06:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.87546879 * 1221; EvalErrorPrediction = 0.51924652 * 1221; time = 0.5249s; samplesPerSecond = 2326.0
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     2.18 seconds since last report (0.00 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 2.67k samplesPerSecond , throughputPerWorker = 1.34k samplesPerSecond
MPI Rank 0: 07/13/2016 16:53:06: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85583563 * 20480; EvalErrorPrediction = 0.51591797 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 7.6293946e-07; epochTime=5.46875s
MPI Rank 0: 07/13/2016 16:53:06: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160713165131.612468/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/13/2016 16:53:06: learnRatePerSample reduced to 3.8146973e-07
MPI Rank 0: 07/13/2016 16:53:06: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:53:06: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:53:06: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 07/13/2016 16:53:07:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80864765 * 1897; EvalErrorPrediction = 0.50184502 * 1897; time = 0.8174s; samplesPerSecond = 2320.8
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     1.07 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 4.57k samplesPerSecond , throughputPerWorker = 2.29k samplesPerSecond
MPI Rank 0: 07/13/2016 16:53:08:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86924414 * 1821; EvalErrorPrediction = 0.51784734 * 1821; time = 0.7852s; samplesPerSecond = 2319.1
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     1.10 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 4.46k samplesPerSecond , throughputPerWorker = 2.23k samplesPerSecond
MPI Rank 0: 07/13/2016 16:53:09:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.90577037 * 1871; EvalErrorPrediction = 0.52057723 * 1871; time = 0.8384s; samplesPerSecond = 2231.6
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     1.08 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 4.51k samplesPerSecond , throughputPerWorker = 2.26k samplesPerSecond
MPI Rank 0: 07/13/2016 16:53:10:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.84025955 * 1870; EvalErrorPrediction = 0.50855615 * 1870; time = 0.8012s; samplesPerSecond = 2334.1
MPI Rank 0: 07/13/2016 16:53:10:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.91623169 * 1899; EvalErrorPrediction = 0.52764613 * 1899; time = 0.8228s; samplesPerSecond = 2308.0
MPI Rank 0: 07/13/2016 16:53:11:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87840281 * 1878; EvalErrorPrediction = 0.52555911 * 1878; time = 0.8151s; samplesPerSecond = 2303.9
MPI Rank 0: 07/13/2016 16:53:12:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.87548922 * 1221; EvalErrorPrediction = 0.51924652 * 1221; time = 0.4912s; samplesPerSecond = 2485.9
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     2.14 seconds since last report (0.00 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 2.72k samplesPerSecond , throughputPerWorker = 1.36k samplesPerSecond
MPI Rank 0: 07/13/2016 16:53:12: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85585080 * 20480; EvalErrorPrediction = 0.51591797 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 3.8146973e-07; epochTime=5.38885s
MPI Rank 0: 07/13/2016 16:53:12: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160713165131.612468/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/13/2016 16:53:12: learnRatePerSample reduced to 1.9073487e-07
MPI Rank 0: 07/13/2016 16:53:12: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:53:12: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:53:12: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 07/13/2016 16:53:13:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80864802 * 1897; EvalErrorPrediction = 0.50184502 * 1897; time = 0.8334s; samplesPerSecond = 2276.2
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     1.11 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 4.43k samplesPerSecond , throughputPerWorker = 2.21k samplesPerSecond
MPI Rank 0: 07/13/2016 16:53:14:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86924821 * 1821; EvalErrorPrediction = 0.51784734 * 1821; time = 0.8119s; samplesPerSecond = 2242.9
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     1.08 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 4.51k samplesPerSecond , throughputPerWorker = 2.26k samplesPerSecond
MPI Rank 0: 07/13/2016 16:53:14:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.90577933 * 1871; EvalErrorPrediction = 0.51950828 * 1871; time = 0.8166s; samplesPerSecond = 2291.3
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     1.11 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 4.39k samplesPerSecond , throughputPerWorker = 2.19k samplesPerSecond
MPI Rank 0: 07/13/2016 16:53:15:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.84026946 * 1870; EvalErrorPrediction = 0.50855615 * 1870; time = 0.8327s; samplesPerSecond = 2245.7
MPI Rank 0: 07/13/2016 16:53:16:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.91624459 * 1899; EvalErrorPrediction = 0.52764613 * 1899; time = 0.8031s; samplesPerSecond = 2364.7
MPI Rank 0: 07/13/2016 16:53:17:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87841931 * 1878; EvalErrorPrediction = 0.52555911 * 1878; time = 0.8137s; samplesPerSecond = 2307.9
MPI Rank 0: 07/13/2016 16:53:17:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.87549946 * 1221; EvalErrorPrediction = 0.51924652 * 1221; time = 0.5069s; samplesPerSecond = 2408.9
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     2.14 seconds since last report (0.00 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 2.72k samplesPerSecond , throughputPerWorker = 1.36k samplesPerSecond
MPI Rank 0: 07/13/2016 16:53:17: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85585841 * 20480; EvalErrorPrediction = 0.51582031 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 1.9073487e-07; epochTime=5.43742s
MPI Rank 0: 07/13/2016 16:53:17: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160713165131.612468/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/13/2016 16:53:17: learnRatePerSample reduced to 9.5367433e-08
MPI Rank 0: 07/13/2016 16:53:17: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:53:17: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:53:17: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 07/13/2016 16:53:18:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80864820 * 1897; EvalErrorPrediction = 0.50184502 * 1897; time = 0.8218s; samplesPerSecond = 2308.4
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     1.09 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 4.49k samplesPerSecond , throughputPerWorker = 2.25k samplesPerSecond
MPI Rank 0: 07/13/2016 16:53:19:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86925024 * 1821; EvalErrorPrediction = 0.51784734 * 1821; time = 0.7891s; samplesPerSecond = 2307.7
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     1.07 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 4.55k samplesPerSecond , throughputPerWorker = 2.27k samplesPerSecond
MPI Rank 0: 07/13/2016 16:53:20:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.90578381 * 1871; EvalErrorPrediction = 0.51950828 * 1871; time = 0.8092s; samplesPerSecond = 2312.0
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     1.06 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 4.59k samplesPerSecond , throughputPerWorker = 2.29k samplesPerSecond
MPI Rank 0: 07/13/2016 16:53:21:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.84027442 * 1870; EvalErrorPrediction = 0.50855615 * 1870; time = 0.8004s; samplesPerSecond = 2336.2
MPI Rank 0: 07/13/2016 16:53:22:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.91625106 * 1899; EvalErrorPrediction = 0.52764613 * 1899; time = 0.8129s; samplesPerSecond = 2335.9
MPI Rank 0: 07/13/2016 16:53:22:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87842758 * 1878; EvalErrorPrediction = 0.52555911 * 1878; time = 0.8098s; samplesPerSecond = 2319.2
MPI Rank 0: 07/13/2016 16:53:23:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.87550459 * 1221; EvalErrorPrediction = 0.51924652 * 1221; time = 0.5159s; samplesPerSecond = 2366.8
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     2.15 seconds since last report (0.00 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 2.71k samplesPerSecond , throughputPerWorker = 1.35k samplesPerSecond
MPI Rank 0: 07/13/2016 16:53:23: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85586222 * 20480; EvalErrorPrediction = 0.51582031 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 9.5367433e-08; epochTime=5.37669s
MPI Rank 0: 07/13/2016 16:53:23: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160713165131.612468/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/13/2016 16:53:23: learnRatePerSample reduced to 4.7683717e-08
MPI Rank 0: 07/13/2016 16:53:23: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:53:23: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:53:23: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 07/13/2016 16:53:24:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80864830 * 1897; EvalErrorPrediction = 0.50184502 * 1897; time = 0.8152s; samplesPerSecond = 2327.1
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     1.08 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 4.54k samplesPerSecond , throughputPerWorker = 2.27k samplesPerSecond
MPI Rank 0: 07/13/2016 16:53:25:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86925126 * 1821; EvalErrorPrediction = 0.51784734 * 1821; time = 0.7922s; samplesPerSecond = 2298.5
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     1.10 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 4.44k samplesPerSecond , throughputPerWorker = 2.22k samplesPerSecond
MPI Rank 0: 07/13/2016 16:53:25:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.90578605 * 1871; EvalErrorPrediction = 0.51950828 * 1871; time = 0.8420s; samplesPerSecond = 2222.0
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     1.12 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 4.34k samplesPerSecond , throughputPerWorker = 2.17k samplesPerSecond
MPI Rank 0: 07/13/2016 16:53:26:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.84027691 * 1870; EvalErrorPrediction = 0.50855615 * 1870; time = 0.8458s; samplesPerSecond = 2211.0
MPI Rank 0: 07/13/2016 16:53:27:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.91625429 * 1899; EvalErrorPrediction = 0.52764613 * 1899; time = 0.8083s; samplesPerSecond = 2349.4
MPI Rank 0: 07/13/2016 16:53:28:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87843173 * 1878; EvalErrorPrediction = 0.52555911 * 1878; time = 0.8204s; samplesPerSecond = 2289.2
MPI Rank 0: 07/13/2016 16:53:28:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.87550715 * 1221; EvalErrorPrediction = 0.51924652 * 1221; time = 0.5243s; samplesPerSecond = 2328.6
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     2.17 seconds since last report (0.00 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 2.69k samplesPerSecond , throughputPerWorker = 1.34k samplesPerSecond
MPI Rank 0: 07/13/2016 16:53:28: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85586413 * 20480; EvalErrorPrediction = 0.51577148 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 4.7683717e-08; epochTime=5.46637s
MPI Rank 0: 07/13/2016 16:53:28: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160713165131.612468/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/13/2016 16:53:29: learnRatePerSample reduced to 2.3841858e-08
MPI Rank 0: 07/13/2016 16:53:29: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:53:29: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:53:29: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 07/13/2016 16:53:29:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80864834 * 1897; EvalErrorPrediction = 0.50184502 * 1897; time = 0.8116s; samplesPerSecond = 2337.5
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     1.09 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 4.52k samplesPerSecond , throughputPerWorker = 2.26k samplesPerSecond
MPI Rank 0: 07/13/2016 16:53:30:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86925177 * 1821; EvalErrorPrediction = 0.51784734 * 1821; time = 0.8048s; samplesPerSecond = 2262.6
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     1.06 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 4.60k samplesPerSecond , throughputPerWorker = 2.30k samplesPerSecond
MPI Rank 0: 07/13/2016 16:53:31:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.90578717 * 1871; EvalErrorPrediction = 0.51950828 * 1871; time = 0.7820s; samplesPerSecond = 2392.7
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     1.08 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 4.49k samplesPerSecond , throughputPerWorker = 2.25k samplesPerSecond
MPI Rank 0: 07/13/2016 16:53:32:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.84027815 * 1870; EvalErrorPrediction = 0.50855615 * 1870; time = 0.8278s; samplesPerSecond = 2258.9
MPI Rank 0: 07/13/2016 16:53:33:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.91625591 * 1899; EvalErrorPrediction = 0.52764613 * 1899; time = 0.8100s; samplesPerSecond = 2344.6
MPI Rank 0: 07/13/2016 16:53:33:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87843380 * 1878; EvalErrorPrediction = 0.52555911 * 1878; time = 0.8114s; samplesPerSecond = 2314.6
MPI Rank 0: 07/13/2016 16:53:34:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.87550844 * 1221; EvalErrorPrediction = 0.51924652 * 1221; time = 0.5341s; samplesPerSecond = 2286.1
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     2.17 seconds since last report (0.00 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 2.69k samplesPerSecond , throughputPerWorker = 1.34k samplesPerSecond
MPI Rank 0: 07/13/2016 16:53:34: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85586508 * 20480; EvalErrorPrediction = 0.51577148 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 2.3841858e-08; epochTime=5.39931s
MPI Rank 0: 07/13/2016 16:53:34: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160713165131.612468/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/13/2016 16:53:34: learnRatePerSample reduced to 1.1920929e-08
MPI Rank 0: 07/13/2016 16:53:34: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:53:34: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:53:34: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 07/13/2016 16:53:35:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80864837 * 1897; EvalErrorPrediction = 0.50184502 * 1897; time = 0.8343s; samplesPerSecond = 2273.8
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     1.11 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 4.43k samplesPerSecond , throughputPerWorker = 2.21k samplesPerSecond
MPI Rank 0: 07/13/2016 16:53:36:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86925203 * 1821; EvalErrorPrediction = 0.51784734 * 1821; time = 0.8085s; samplesPerSecond = 2252.2
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     1.10 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 4.45k samplesPerSecond , throughputPerWorker = 2.23k samplesPerSecond
MPI Rank 0: 07/13/2016 16:53:37:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.90578773 * 1871; EvalErrorPrediction = 0.51950828 * 1871; time = 0.8324s; samplesPerSecond = 2247.7
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     1.11 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 4.36k samplesPerSecond , throughputPerWorker = 2.18k samplesPerSecond
MPI Rank 0: 07/13/2016 16:53:37:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.84027877 * 1870; EvalErrorPrediction = 0.50855615 * 1870; time = 0.8405s; samplesPerSecond = 2224.9
MPI Rank 0: 07/13/2016 16:53:38:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.91625673 * 1899; EvalErrorPrediction = 0.52764613 * 1899; time = 0.8224s; samplesPerSecond = 2309.0
MPI Rank 0: 07/13/2016 16:53:39:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87843484 * 1878; EvalErrorPrediction = 0.52555911 * 1878; time = 0.8131s; samplesPerSecond = 2309.8
MPI Rank 0: 07/13/2016 16:53:40:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.87550908 * 1221; EvalErrorPrediction = 0.51924652 * 1221; time = 0.5295s; samplesPerSecond = 2305.8
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     2.18 seconds since last report (0.00 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 2.67k samplesPerSecond , throughputPerWorker = 1.34k samplesPerSecond
MPI Rank 0: 07/13/2016 16:53:40: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85586556 * 20480; EvalErrorPrediction = 0.51577148 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 1.1920929e-08; epochTime=5.49921s
MPI Rank 0: 07/13/2016 16:53:40: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160713165131.612468/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/13/2016 16:53:40: learnRatePerSample reduced to 5.9604646e-09
MPI Rank 0: 07/13/2016 16:53:40: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:53:40: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:53:40: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 07/13/2016 16:53:41:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80864838 * 1897; EvalErrorPrediction = 0.50184502 * 1897; time = 0.8282s; samplesPerSecond = 2290.5
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     1.10 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 4.45k samplesPerSecond , throughputPerWorker = 2.23k samplesPerSecond
MPI Rank 0: 07/13/2016 16:53:41:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86925216 * 1821; EvalErrorPrediction = 0.51784734 * 1821; time = 0.8081s; samplesPerSecond = 2253.5
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     1.10 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 4.45k samplesPerSecond , throughputPerWorker = 2.23k samplesPerSecond
MPI Rank 0: 07/13/2016 16:53:42:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.90578801 * 1871; EvalErrorPrediction = 0.51950828 * 1871; time = 0.8311s; samplesPerSecond = 2251.3
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     1.11 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 4.38k samplesPerSecond , throughputPerWorker = 2.19k samplesPerSecond
MPI Rank 0: 07/13/2016 16:53:43:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.84027908 * 1870; EvalErrorPrediction = 0.50855615 * 1870; time = 0.8379s; samplesPerSecond = 2231.8
MPI Rank 0: 07/13/2016 16:53:44:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.91625713 * 1899; EvalErrorPrediction = 0.52764613 * 1899; time = 0.8389s; samplesPerSecond = 2263.6
MPI Rank 0: 07/13/2016 16:53:45:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87843535 * 1878; EvalErrorPrediction = 0.52555911 * 1878; time = 0.8009s; samplesPerSecond = 2344.9
MPI Rank 0: 07/13/2016 16:53:45:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.87550940 * 1221; EvalErrorPrediction = 0.51924652 * 1221; time = 0.5314s; samplesPerSecond = 2297.7
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     2.18 seconds since last report (0.00 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 2.67k samplesPerSecond , throughputPerWorker = 1.33k samplesPerSecond
MPI Rank 0: 07/13/2016 16:53:45: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85586580 * 20480; EvalErrorPrediction = 0.51577148 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 5.9604646e-09; epochTime=5.4944s
MPI Rank 0: 07/13/2016 16:53:45: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160713165131.612468/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/13/2016 16:53:45: learnRatePerSample reduced to 2.9802323e-09
MPI Rank 0: 07/13/2016 16:53:45: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:53:45: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:53:45: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 07/13/2016 16:53:46:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80864838 * 1897; EvalErrorPrediction = 0.50184502 * 1897; time = 0.8270s; samplesPerSecond = 2293.8
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     1.10 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 4.45k samplesPerSecond , throughputPerWorker = 2.23k samplesPerSecond
MPI Rank 0: 07/13/2016 16:53:47:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86925222 * 1821; EvalErrorPrediction = 0.51784734 * 1821; time = 0.8231s; samplesPerSecond = 2212.2
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     1.12 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 4.37k samplesPerSecond , throughputPerWorker = 2.19k samplesPerSecond
MPI Rank 0: 07/13/2016 16:53:48:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.90578815 * 1871; EvalErrorPrediction = 0.51950828 * 1871; time = 0.8375s; samplesPerSecond = 2234.0
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     1.09 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 4.47k samplesPerSecond , throughputPerWorker = 2.24k samplesPerSecond
MPI Rank 0: 07/13/2016 16:53:49:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.84027924 * 1870; EvalErrorPrediction = 0.50855615 * 1870; time = 0.8142s; samplesPerSecond = 2296.8
MPI Rank 0: 07/13/2016 16:53:50:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.91625733 * 1899; EvalErrorPrediction = 0.52764613 * 1899; time = 0.8316s; samplesPerSecond = 2283.6
MPI Rank 0: 07/13/2016 16:53:50:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87843561 * 1878; EvalErrorPrediction = 0.52555911 * 1878; time = 0.8239s; samplesPerSecond = 2279.4
MPI Rank 0: 07/13/2016 16:53:51:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.87550956 * 1221; EvalErrorPrediction = 0.51924652 * 1221; time = 0.5368s; samplesPerSecond = 2274.7
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     2.21 seconds since last report (0.00 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 2.64k samplesPerSecond , throughputPerWorker = 1.32k samplesPerSecond
MPI Rank 0: 07/13/2016 16:53:51: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85586592 * 20480; EvalErrorPrediction = 0.51577148 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 2.9802323e-09; epochTime=5.51272s
MPI Rank 0: 07/13/2016 16:53:51: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160713165131.612468/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/13/2016 16:53:51: learnRatePerSample reduced to 1.4901161e-09
MPI Rank 0: 07/13/2016 16:53:51: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:53:51: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:53:51: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 07/13/2016 16:53:52:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80864839 * 1897; EvalErrorPrediction = 0.50184502 * 1897; time = 0.8508s; samplesPerSecond = 2229.6
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     1.13 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 4.34k samplesPerSecond , throughputPerWorker = 2.17k samplesPerSecond
MPI Rank 0: 07/13/2016 16:53:53:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86925225 * 1821; EvalErrorPrediction = 0.51784734 * 1821; time = 0.8139s; samplesPerSecond = 2237.3
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     1.09 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 4.47k samplesPerSecond , throughputPerWorker = 2.23k samplesPerSecond
MPI Rank 0: 07/13/2016 16:53:54:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.90578822 * 1871; EvalErrorPrediction = 0.51950828 * 1871; time = 0.8265s; samplesPerSecond = 2263.9
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     1.11 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 4.38k samplesPerSecond , throughputPerWorker = 2.19k samplesPerSecond
MPI Rank 0: 07/13/2016 16:53:54:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.84027932 * 1870; EvalErrorPrediction = 0.50855615 * 1870; time = 0.8398s; samplesPerSecond = 2226.6
MPI Rank 0: 07/13/2016 16:53:55:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.91625743 * 1899; EvalErrorPrediction = 0.52764613 * 1899; time = 0.8315s; samplesPerSecond = 2283.7
MPI Rank 0: 07/13/2016 16:53:56:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87843574 * 1878; EvalErrorPrediction = 0.52555911 * 1878; time = 0.7989s; samplesPerSecond = 2350.7
MPI Rank 0: 07/13/2016 16:53:57:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.87550964 * 1221; EvalErrorPrediction = 0.51924652 * 1221; time = 0.5300s; samplesPerSecond = 2303.7
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     2.17 seconds since last report (0.00 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 2.68k samplesPerSecond , throughputPerWorker = 1.34k samplesPerSecond
MPI Rank 0: 07/13/2016 16:53:57: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85586598 * 20480; EvalErrorPrediction = 0.51577148 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 1.4901161e-09; epochTime=5.50976s
MPI Rank 0: 07/13/2016 16:53:57: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160713165131.612468/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/13/2016 16:53:57: learnRatePerSample reduced to 7.4505807e-10
MPI Rank 0: 07/13/2016 16:53:57: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 07/13/2016 16:53:57: Learn Rate Per Sample for Epoch[5] = 7.4505807e-10 is less than minLearnRate 9.9999997e-10. Training complete.
MPI Rank 0: 07/13/2016 16:53:57: CNTKCommandTrainEnd: speechTrain
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:53:57: Action "train" complete.
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:53:57: __COMPLETED__
MPI Rank 0: ~MPIWrapper
MPI Rank 1: 07/13/2016 16:51:51: -------------------------------------------------------------------
MPI Rank 1: 07/13/2016 16:51:51: Build info: 
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:51:51: 		Built time: Jul 13 2016 15:58:36
MPI Rank 1: 07/13/2016 16:51:51: 		Last modified date: Wed Jul 13 15:14:47 2016
MPI Rank 1: 07/13/2016 16:51:51: 		Build type: release
MPI Rank 1: 07/13/2016 16:51:51: 		Build target: GPU
MPI Rank 1: 07/13/2016 16:51:51: 		With 1bit-SGD: yes
MPI Rank 1: 07/13/2016 16:51:51: 		Math lib: mkl
MPI Rank 1: 07/13/2016 16:51:51: 		CUDA_PATH: /usr/local/cuda-7.5
MPI Rank 1: 07/13/2016 16:51:51: 		CUB_PATH: /usr/local/cub-1.4.1
MPI Rank 1: 07/13/2016 16:51:51: 		CUDNN_PATH: /usr/local/cudnn-4.0
MPI Rank 1: 07/13/2016 16:51:51: 		Build Branch: HEAD
MPI Rank 1: 07/13/2016 16:51:51: 		Build SHA1: 539ab7467b022b4ffa087721bcf20d18485c8d0d
MPI Rank 1: 07/13/2016 16:51:51: 		Built by philly on adf92da755f9
MPI Rank 1: 07/13/2016 16:51:51: 		Build Path: /home/philly/jenkins/workspace/CNTK-Build-Linux
MPI Rank 1: 07/13/2016 16:51:51: -------------------------------------------------------------------
MPI Rank 1: 07/13/2016 16:51:52: -------------------------------------------------------------------
MPI Rank 1: 07/13/2016 16:51:52: GPU info:
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:51:52: 		Device[0]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3071 MB
MPI Rank 1: 07/13/2016 16:51:52: 		Device[1]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3071 MB
MPI Rank 1: 07/13/2016 16:51:52: 		Device[2]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3071 MB
MPI Rank 1: 07/13/2016 16:51:52: 		Device[3]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3071 MB
MPI Rank 1: 07/13/2016 16:51:52: -------------------------------------------------------------------
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:51:52: Running on localhost at 2016/07/13 16:51:52
MPI Rank 1: 07/13/2016 16:51:52: Command line: 
MPI Rank 1: /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/build/1bitsgd/release/bin/cntk  configFile=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/ParallelBM/../ParallelBM/cntk.cntk  currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data  RunDir=/tmp/cntk-test-20160713165131.612468/Speech/DNN_ParallelBM@release_cpu  DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data  ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/ParallelBM/..  OutputDir=/tmp/cntk-test-20160713165131.612468/Speech/DNN_ParallelBM@release_cpu  DeviceId=-1  timestamping=true  numCPUThreads=12  precision=double  speechTrain=[SGD=[ParallelTrain=[parallelizationStartEpoch=2]]]  stderr=/tmp/cntk-test-20160713165131.612468/Speech/DNN_ParallelBM@release_cpu/stderr
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:51:52: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
MPI Rank 1: 07/13/2016 16:51:52: precision = "float"
MPI Rank 1: command = speechTrain
MPI Rank 1: deviceId = $DeviceId$
MPI Rank 1: parallelTrain = true
MPI Rank 1: speechTrain = [
MPI Rank 1:     action = "train"
MPI Rank 1:     modelPath = "$RunDir$/models/cntkSpeech.dnn"
MPI Rank 1:     deviceId = $DeviceId$
MPI Rank 1:     traceLevel = 1
MPI Rank 1:     SimpleNetworkBuilder = [
MPI Rank 1:         layerSizes = 363:512:512:132
MPI Rank 1:         trainingCriterion = "CrossEntropyWithSoftmax"
MPI Rank 1:         evalCriterion = "ErrorPrediction"
MPI Rank 1:         layerTypes = "Sigmoid"
MPI Rank 1:         initValueScale = 1.0
MPI Rank 1:         applyMeanVarNorm = true
MPI Rank 1:         uniformInit = true
MPI Rank 1:         needPrior = true
MPI Rank 1:     ]
MPI Rank 1:     ExperimentalNetworkBuilder = [    // the same as above but with BS. Not active; activate by commenting out the SimpleNetworkBuilder entry above
MPI Rank 1:         layerSizes = 363:512:512:132
MPI Rank 1:         trainingCriterion = 'CE'
MPI Rank 1:         evalCriterion = 'Err'
MPI Rank 1:         applyMeanVarNorm = true
MPI Rank 1:         L = Length(layerSizes)-1    // number of model layers
MPI Rank 1:         features = Input(layerSizes[0], 1, tag='feature') ; labels = Input(layerSizes[Length(layerSizes)-1], 1, tag='label')
MPI Rank 1:         featNorm = if applyMeanVarNorm
MPI Rank 1:                    then MeanVarNorm(features)
MPI Rank 1:                    else features
MPI Rank 1:         layers[layer:1..L-1] = if layer > 1
MPI Rank 1:                                then SBFF(layers[layer-1].Eh, layerSizes[layer], layerSizes[layer-1])
MPI Rank 1:                                else SBFF(featNorm, layerSizes[layer], layerSizes[layer-1])
MPI Rank 1:         outLayer = BFF(layers[L-1].Eh, layerSizes[L], layerSizes[L-1])
MPI Rank 1:         outZ = outLayer.z        // + PastValue(layerSizes[L], 1, outLayer.z)
MPI Rank 1:         CE = if trainingCriterion == 'CE'
MPI Rank 1:              then CrossEntropyWithSoftmax(labels, outZ, tag='criterion')
MPI Rank 1:              else Fail('unknown trainingCriterion ' + trainingCriterion)
MPI Rank 1:         Err = if evalCriterion == 'Err' then
MPI Rank 1:               ErrorPrediction(labels, outZ, tag='evaluation')
MPI Rank 1:               else Fail('unknown evalCriterion ' + evalCriterion)
MPI Rank 1:         logPrior = LogPrior(labels)
MPI Rank 1:         // TODO: how to add a tag to an infix operation?
MPI Rank 1:         ScaledLogLikelihood = Minus (outZ, logPrior, tag='output')
MPI Rank 1:     ]
MPI Rank 1:     SGD = [
MPI Rank 1:         epochSize = 20480
MPI Rank 1:         minibatchSize = 64:256:1024
MPI Rank 1:         learningRatesPerMB = 1.0:0.5:0.1
MPI Rank 1:         numMBsToShowResult = 3
MPI Rank 1:         momentumPerMB = 0.9:0.656119
MPI Rank 1:         dropoutRate = 0.0
MPI Rank 1:         maxEpochs = 5
MPI Rank 1:         keepCheckPointFiles = true
MPI Rank 1:         clippingThresholdPerSample = 1#INF
MPI Rank 1:         ParallelTrain = [
MPI Rank 1:             parallelizationMethod = "BlockMomentumSGD"
MPI Rank 1:             distributedMBReading = true
MPI Rank 1:             syncPerfStats=1
MPI Rank 1:             BlockMomentumSGD = [
MPI Rank 1:                 blockSizePerWorker=2048
MPI Rank 1:                 resetSGDMomentum=true
MPI Rank 1:                 useNesterovMomentum=true
MPI Rank 1:             ]
MPI Rank 1:         ]
MPI Rank 1:         AutoAdjust = [
MPI Rank 1:             reduceLearnRateIfImproveLessThan = 0
MPI Rank 1:             loadBestModel = true
MPI Rank 1:             increaseLearnRateIfImproveMoreThan = 1000000000
MPI Rank 1:             learnRateDecreaseFactor = 0.5
MPI Rank 1:             learnRateIncreaseFactor = 1.382
MPI Rank 1:             autoAdjustLR = "adjustAfterEpoch"
MPI Rank 1:         ]
MPI Rank 1:     ]
MPI Rank 1:     reader = [
MPI Rank 1:         readerType = "HTKMLFReader"
MPI Rank 1:         readMethod = "blockRandomize"
MPI Rank 1:         miniBatchMode = "partial"
MPI Rank 1:         randomize = "auto"
MPI Rank 1:         verbosity = 0
MPI Rank 1:         features = [
MPI Rank 1:             dim = 363
MPI Rank 1:             type = "real"
MPI Rank 1:             scpFile = "glob_0000.scp"
MPI Rank 1:         ]
MPI Rank 1:         labels = [
MPI Rank 1:             mlfFile = "$DataDir$/glob_0000.mlf"
MPI Rank 1:             labelMappingFile = "$DataDir$/state.list"
MPI Rank 1:             labelDim = 132
MPI Rank 1:             labelType = "category"
MPI Rank 1:         ]
MPI Rank 1:     ]
MPI Rank 1: ]
MPI Rank 1: currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
MPI Rank 1: RunDir=/tmp/cntk-test-20160713165131.612468/Speech/DNN_ParallelBM@release_cpu
MPI Rank 1: DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
MPI Rank 1: ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/ParallelBM/..
MPI Rank 1: OutputDir=/tmp/cntk-test-20160713165131.612468/Speech/DNN_ParallelBM@release_cpu
MPI Rank 1: DeviceId=-1
MPI Rank 1: timestamping=true
MPI Rank 1: numCPUThreads=12
MPI Rank 1: precision=double
MPI Rank 1: speechTrain=[SGD=[ParallelTrain=[parallelizationStartEpoch=2]]]
MPI Rank 1: stderr=/tmp/cntk-test-20160713165131.612468/Speech/DNN_ParallelBM@release_cpu/stderr
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:51:52: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:51:52: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 1: 07/13/2016 16:51:52: precision = "float"
MPI Rank 1: command = speechTrain
MPI Rank 1: deviceId = -1
MPI Rank 1: parallelTrain = true
MPI Rank 1: speechTrain = [
MPI Rank 1:     action = "train"
MPI Rank 1:     modelPath = "/tmp/cntk-test-20160713165131.612468/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn"
MPI Rank 1:     deviceId = -1
MPI Rank 1:     traceLevel = 1
MPI Rank 1:     SimpleNetworkBuilder = [
MPI Rank 1:         layerSizes = 363:512:512:132
MPI Rank 1:         trainingCriterion = "CrossEntropyWithSoftmax"
MPI Rank 1:         evalCriterion = "ErrorPrediction"
MPI Rank 1:         layerTypes = "Sigmoid"
MPI Rank 1:         initValueScale = 1.0
MPI Rank 1:         applyMeanVarNorm = true
MPI Rank 1:         uniformInit = true
MPI Rank 1:         needPrior = true
MPI Rank 1:     ]
MPI Rank 1:     ExperimentalNetworkBuilder = [    // the same as above but with BS. Not active; activate by commenting out the SimpleNetworkBuilder entry above
MPI Rank 1:         layerSizes = 363:512:512:132
MPI Rank 1:         trainingCriterion = 'CE'
MPI Rank 1:         evalCriterion = 'Err'
MPI Rank 1:         applyMeanVarNorm = true
MPI Rank 1:         L = Length(layerSizes)-1    // number of model layers
MPI Rank 1:         features = Input(layerSizes[0], 1, tag='feature') ; labels = Input(layerSizes[Length(layerSizes)-1], 1, tag='label')
MPI Rank 1:         featNorm = if applyMeanVarNorm
MPI Rank 1:                    then MeanVarNorm(features)
MPI Rank 1:                    else features
MPI Rank 1:         layers[layer:1..L-1] = if layer > 1
MPI Rank 1:                                then SBFF(layers[layer-1].Eh, layerSizes[layer], layerSizes[layer-1])
MPI Rank 1:                                else SBFF(featNorm, layerSizes[layer], layerSizes[layer-1])
MPI Rank 1:         outLayer = BFF(layers[L-1].Eh, layerSizes[L], layerSizes[L-1])
MPI Rank 1:         outZ = outLayer.z        // + PastValue(layerSizes[L], 1, outLayer.z)
MPI Rank 1:         CE = if trainingCriterion == 'CE'
MPI Rank 1:              then CrossEntropyWithSoftmax(labels, outZ, tag='criterion')
MPI Rank 1:              else Fail('unknown trainingCriterion ' + trainingCriterion)
MPI Rank 1:         Err = if evalCriterion == 'Err' then
MPI Rank 1:               ErrorPrediction(labels, outZ, tag='evaluation')
MPI Rank 1:               else Fail('unknown evalCriterion ' + evalCriterion)
MPI Rank 1:         logPrior = LogPrior(labels)
MPI Rank 1:         // TODO: how to add a tag to an infix operation?
MPI Rank 1:         ScaledLogLikelihood = Minus (outZ, logPrior, tag='output')
MPI Rank 1:     ]
MPI Rank 1:     SGD = [
MPI Rank 1:         epochSize = 20480
MPI Rank 1:         minibatchSize = 64:256:1024
MPI Rank 1:         learningRatesPerMB = 1.0:0.5:0.1
MPI Rank 1:         numMBsToShowResult = 3
MPI Rank 1:         momentumPerMB = 0.9:0.656119
MPI Rank 1:         dropoutRate = 0.0
MPI Rank 1:         maxEpochs = 5
MPI Rank 1:         keepCheckPointFiles = true
MPI Rank 1:         clippingThresholdPerSample = 1#INF
MPI Rank 1:         ParallelTrain = [
MPI Rank 1:             parallelizationMethod = "BlockMomentumSGD"
MPI Rank 1:             distributedMBReading = true
MPI Rank 1:             syncPerfStats=1
MPI Rank 1:             BlockMomentumSGD = [
MPI Rank 1:                 blockSizePerWorker=2048
MPI Rank 1:                 resetSGDMomentum=true
MPI Rank 1:                 useNesterovMomentum=true
MPI Rank 1:             ]
MPI Rank 1:         ]
MPI Rank 1:         AutoAdjust = [
MPI Rank 1:             reduceLearnRateIfImproveLessThan = 0
MPI Rank 1:             loadBestModel = true
MPI Rank 1:             increaseLearnRateIfImproveMoreThan = 1000000000
MPI Rank 1:             learnRateDecreaseFactor = 0.5
MPI Rank 1:             learnRateIncreaseFactor = 1.382
MPI Rank 1:             autoAdjustLR = "adjustAfterEpoch"
MPI Rank 1:         ]
MPI Rank 1:     ]
MPI Rank 1:     reader = [
MPI Rank 1:         readerType = "HTKMLFReader"
MPI Rank 1:         readMethod = "blockRandomize"
MPI Rank 1:         miniBatchMode = "partial"
MPI Rank 1:         randomize = "auto"
MPI Rank 1:         verbosity = 0
MPI Rank 1:         features = [
MPI Rank 1:             dim = 363
MPI Rank 1:             type = "real"
MPI Rank 1:             scpFile = "glob_0000.scp"
MPI Rank 1:         ]
MPI Rank 1:         labels = [
MPI Rank 1:             mlfFile = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/glob_0000.mlf"
MPI Rank 1:             labelMappingFile = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/state.list"
MPI Rank 1:             labelDim = 132
MPI Rank 1:             labelType = "category"
MPI Rank 1:         ]
MPI Rank 1:     ]
MPI Rank 1: ]
MPI Rank 1: currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
MPI Rank 1: RunDir=/tmp/cntk-test-20160713165131.612468/Speech/DNN_ParallelBM@release_cpu
MPI Rank 1: DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
MPI Rank 1: ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/ParallelBM/..
MPI Rank 1: OutputDir=/tmp/cntk-test-20160713165131.612468/Speech/DNN_ParallelBM@release_cpu
MPI Rank 1: DeviceId=-1
MPI Rank 1: timestamping=true
MPI Rank 1: numCPUThreads=12
MPI Rank 1: precision=double
MPI Rank 1: speechTrain=[SGD=[ParallelTrain=[parallelizationStartEpoch=2]]]
MPI Rank 1: stderr=/tmp/cntk-test-20160713165131.612468/Speech/DNN_ParallelBM@release_cpu/stderr
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:51:52: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:51:52: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 1: configparameters: cntk.cntk:command=speechTrain
MPI Rank 1: configparameters: cntk.cntk:ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/ParallelBM/..
MPI Rank 1: configparameters: cntk.cntk:currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
MPI Rank 1: configparameters: cntk.cntk:DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
MPI Rank 1: configparameters: cntk.cntk:deviceId=-1
MPI Rank 1: configparameters: cntk.cntk:numCPUThreads=12
MPI Rank 1: configparameters: cntk.cntk:OutputDir=/tmp/cntk-test-20160713165131.612468/Speech/DNN_ParallelBM@release_cpu
MPI Rank 1: configparameters: cntk.cntk:parallelTrain=true
MPI Rank 1: configparameters: cntk.cntk:precision=double
MPI Rank 1: configparameters: cntk.cntk:RunDir=/tmp/cntk-test-20160713165131.612468/Speech/DNN_ParallelBM@release_cpu
MPI Rank 1: configparameters: cntk.cntk:speechTrain=[
MPI Rank 1:     action = "train"
MPI Rank 1:     modelPath = "/tmp/cntk-test-20160713165131.612468/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn"
MPI Rank 1:     deviceId = -1
MPI Rank 1:     traceLevel = 1
MPI Rank 1:     SimpleNetworkBuilder = [
MPI Rank 1:         layerSizes = 363:512:512:132
MPI Rank 1:         trainingCriterion = "CrossEntropyWithSoftmax"
MPI Rank 1:         evalCriterion = "ErrorPrediction"
MPI Rank 1:         layerTypes = "Sigmoid"
MPI Rank 1:         initValueScale = 1.0
MPI Rank 1:         applyMeanVarNorm = true
MPI Rank 1:         uniformInit = true
MPI Rank 1:         needPrior = true
MPI Rank 1:     ]
MPI Rank 1:     ExperimentalNetworkBuilder = [    // the same as above but with BS. Not active; activate by commenting out the SimpleNetworkBuilder entry above
MPI Rank 1:         layerSizes = 363:512:512:132
MPI Rank 1:         trainingCriterion = 'CE'
MPI Rank 1:         evalCriterion = 'Err'
MPI Rank 1:         applyMeanVarNorm = true
MPI Rank 1:         L = Length(layerSizes)-1    // number of model layers
MPI Rank 1:         features = Input(layerSizes[0], 1, tag='feature') ; labels = Input(layerSizes[Length(layerSizes)-1], 1, tag='label')
MPI Rank 1:         featNorm = if applyMeanVarNorm
MPI Rank 1:                    then MeanVarNorm(features)
MPI Rank 1:                    else features
MPI Rank 1:         layers[layer:1..L-1] = if layer > 1
MPI Rank 1:                                then SBFF(layers[layer-1].Eh, layerSizes[layer], layerSizes[layer-1])
MPI Rank 1:                                else SBFF(featNorm, layerSizes[layer], layerSizes[layer-1])
MPI Rank 1:         outLayer = BFF(layers[L-1].Eh, layerSizes[L], layerSizes[L-1])
MPI Rank 1:         outZ = outLayer.z        // + PastValue(layerSizes[L], 1, outLayer.z)
MPI Rank 1:         CE = if trainingCriterion == 'CE'
MPI Rank 1:              then CrossEntropyWithSoftmax(labels, outZ, tag='criterion')
MPI Rank 1:              else Fail('unknown trainingCriterion ' + trainingCriterion)
MPI Rank 1:         Err = if evalCriterion == 'Err' then
MPI Rank 1:               ErrorPrediction(labels, outZ, tag='evaluation')
MPI Rank 1:               else Fail('unknown evalCriterion ' + evalCriterion)
MPI Rank 1:         logPrior = LogPrior(labels)
MPI Rank 1:         // TODO: how to add a tag to an infix operation?
MPI Rank 1:         ScaledLogLikelihood = Minus (outZ, logPrior, tag='output')
MPI Rank 1:     ]
MPI Rank 1:     SGD = [
MPI Rank 1:         epochSize = 20480
MPI Rank 1:         minibatchSize = 64:256:1024
MPI Rank 1:         learningRatesPerMB = 1.0:0.5:0.1
MPI Rank 1:         numMBsToShowResult = 3
MPI Rank 1:         momentumPerMB = 0.9:0.656119
MPI Rank 1:         dropoutRate = 0.0
MPI Rank 1:         maxEpochs = 5
MPI Rank 1:         keepCheckPointFiles = true
MPI Rank 1:         clippingThresholdPerSample = 1#INF
MPI Rank 1:         ParallelTrain = [
MPI Rank 1:             parallelizationMethod = "BlockMomentumSGD"
MPI Rank 1:             distributedMBReading = true
MPI Rank 1:             syncPerfStats=1
MPI Rank 1:             BlockMomentumSGD = [
MPI Rank 1:                 blockSizePerWorker=2048
MPI Rank 1:                 resetSGDMomentum=true
MPI Rank 1:                 useNesterovMomentum=true
MPI Rank 1:             ]
MPI Rank 1:         ]
MPI Rank 1:         AutoAdjust = [
MPI Rank 1:             reduceLearnRateIfImproveLessThan = 0
MPI Rank 1:             loadBestModel = true
MPI Rank 1:             increaseLearnRateIfImproveMoreThan = 1000000000
MPI Rank 1:             learnRateDecreaseFactor = 0.5
MPI Rank 1:             learnRateIncreaseFactor = 1.382
MPI Rank 1:             autoAdjustLR = "adjustAfterEpoch"
MPI Rank 1:         ]
MPI Rank 1:     ]
MPI Rank 1:     reader = [
MPI Rank 1:         readerType = "HTKMLFReader"
MPI Rank 1:         readMethod = "blockRandomize"
MPI Rank 1:         miniBatchMode = "partial"
MPI Rank 1:         randomize = "auto"
MPI Rank 1:         verbosity = 0
MPI Rank 1:         features = [
MPI Rank 1:             dim = 363
MPI Rank 1:             type = "real"
MPI Rank 1:             scpFile = "glob_0000.scp"
MPI Rank 1:         ]
MPI Rank 1:         labels = [
MPI Rank 1:             mlfFile = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/glob_0000.mlf"
MPI Rank 1:             labelMappingFile = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/state.list"
MPI Rank 1:             labelDim = 132
MPI Rank 1:             labelType = "category"
MPI Rank 1:         ]
MPI Rank 1:     ]
MPI Rank 1: ] [SGD=[ParallelTrain=[parallelizationStartEpoch=2]]]
MPI Rank 1: 
MPI Rank 1: configparameters: cntk.cntk:stderr=/tmp/cntk-test-20160713165131.612468/Speech/DNN_ParallelBM@release_cpu/stderr
MPI Rank 1: configparameters: cntk.cntk:timestamping=true
MPI Rank 1: 07/13/2016 16:51:52: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 1: 07/13/2016 16:51:52: Commands: speechTrain
MPI Rank 1: 07/13/2016 16:51:52: Precision = "double"
MPI Rank 1: 07/13/2016 16:51:52: Using 12 CPU threads.
MPI Rank 1: 07/13/2016 16:51:52: CNTKModelPath: /tmp/cntk-test-20160713165131.612468/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn
MPI Rank 1: 07/13/2016 16:51:52: CNTKCommandTrainInfo: speechTrain : 5
MPI Rank 1: 07/13/2016 16:51:52: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 5
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:51:52: ##############################################################################
MPI Rank 1: 07/13/2016 16:51:52: #                                                                            #
MPI Rank 1: 07/13/2016 16:51:52: # Action "train"                                                             #
MPI Rank 1: 07/13/2016 16:51:52: #                                                                            #
MPI Rank 1: 07/13/2016 16:51:52: ##############################################################################
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:51:52: CNTKCommandTrainBegin: speechTrain
MPI Rank 1: SimpleNetworkBuilder Using CPU
MPI Rank 1: reading script file glob_0000.scp ... 948 entries
MPI Rank 1: total 132 state names in state list /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/state.list
MPI Rank 1: htkmlfreader: reading MLF file /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/glob_0000.mlf ... total 948 entries
MPI Rank 1: ...............................................................................................feature set 0: 252734 frames in 948 out of 948 utterances
MPI Rank 1: label set 0: 129 classes
MPI Rank 1: minibatchutterancesource: 948 utterances grouped into 3 chunks, av. chunk size: 316.0 utterances, 84244.7 frames
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:51:52: Creating virgin network.
MPI Rank 1: 
MPI Rank 1: Post-processing network...
MPI Rank 1: 
MPI Rank 1: 7 roots:
MPI Rank 1: 	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
MPI Rank 1: 	EvalErrorPrediction = ErrorPrediction()
MPI Rank 1: 	InvStdOfFeatures = InvStdDev()
MPI Rank 1: 	MeanOfFeatures = Mean()
MPI Rank 1: 	PosteriorProb = Softmax()
MPI Rank 1: 	Prior = Mean()
MPI Rank 1: 	ScaledLogLikelihood = Minus()
MPI Rank 1: 
MPI Rank 1: Validating network. 25 nodes to process in pass 1.
MPI Rank 1: 
MPI Rank 1: Validating --> labels = InputValue() :  -> [132 x *]
MPI Rank 1: Validating --> W2 = LearnableParameter() :  -> [132 x 512]
MPI Rank 1: Validating --> W1 = LearnableParameter() :  -> [512 x 512]
MPI Rank 1: Validating --> W0 = LearnableParameter() :  -> [512 x 363]
MPI Rank 1: Validating --> features = InputValue() :  -> [363 x *]
MPI Rank 1: Validating --> MeanOfFeatures = Mean (features) : [363 x *] -> [363]
MPI Rank 1: Validating --> InvStdOfFeatures = InvStdDev (features) : [363 x *] -> [363]
MPI Rank 1: Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [363 x *], [363], [363] -> [363 x *]
MPI Rank 1: Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [512 x 363], [363 x *] -> [512 x *]
MPI Rank 1: Validating --> B0 = LearnableParameter() :  -> [512 x 1]
MPI Rank 1: Validating --> W0*features+B0 = Plus (W0*features, B0) : [512 x *], [512 x 1] -> [512 x 1 x *]
MPI Rank 1: Validating --> H1 = Sigmoid (W0*features+B0) : [512 x 1 x *] -> [512 x 1 x *]
MPI Rank 1: Validating --> W1*H1 = Times (W1, H1) : [512 x 512], [512 x 1 x *] -> [512 x 1 x *]
MPI Rank 1: Validating --> B1 = LearnableParameter() :  -> [512 x 1]
MPI Rank 1: Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [512 x 1 x *], [512 x 1] -> [512 x 1 x *]
MPI Rank 1: Validating --> H2 = Sigmoid (W1*H1+B1) : [512 x 1 x *] -> [512 x 1 x *]
MPI Rank 1: Validating --> W2*H1 = Times (W2, H2) : [132 x 512], [512 x 1 x *] -> [132 x 1 x *]
MPI Rank 1: Validating --> B2 = LearnableParameter() :  -> [132 x 1]
MPI Rank 1: Validating --> HLast = Plus (W2*H1, B2) : [132 x 1 x *], [132 x 1] -> [132 x 1 x *]
MPI Rank 1: Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [132 x *], [132 x 1 x *] -> [1]
MPI Rank 1: Validating --> EvalErrorPrediction = ErrorPrediction (labels, HLast) : [132 x *], [132 x 1 x *] -> [1]
MPI Rank 1: Validating --> PosteriorProb = Softmax (HLast) : [132 x 1 x *] -> [132 x 1 x *]
MPI Rank 1: Validating --> Prior = Mean (labels) : [132 x *] -> [132]
MPI Rank 1: Validating --> LogOfPrior = Log (Prior) : [132] -> [132]
MPI Rank 1: Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [132 x 1 x *], [132] -> [132 x 1 x *]
MPI Rank 1: 
MPI Rank 1: Validating network. 17 nodes to process in pass 2.
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: Validating network, final pass.
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: 12 out of 25 nodes do not share the minibatch layout with the input data.
MPI Rank 1: 
MPI Rank 1: Post-processing network complete.
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:51:52: Created model with 25 nodes on CPU.
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:51:52: Training criterion node(s):
MPI Rank 1: 07/13/2016 16:51:52: 	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:51:52: Evaluation criterion node(s):
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:51:52: 	EvalErrorPrediction = ErrorPrediction
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: Allocating matrices for forward and/or backward propagation.
MPI Rank 1: 
MPI Rank 1: Memory Sharing Structure:
MPI Rank 1: 
MPI Rank 1: (nil): {[EvalErrorPrediction Gradient[1]] [InvStdOfFeatures Gradient[363]] [LogOfPrior Gradient[132]] [MVNormalizedFeatures Gradient[363 x *]] [MeanOfFeatures Gradient[363]] [PosteriorProb Gradient[132 x 1 x *]] [PosteriorProb Value[132 x 1 x *]] [Prior Gradient[132]] [ScaledLogLikelihood Gradient[132 x 1 x *]] [features Gradient[363 x *]] [labels Gradient[132 x *]] }
MPI Rank 1: 0x1512558: {[W2 Value[132 x 512]] }
MPI Rank 1: 0x1512d28: {[MeanOfFeatures Value[363]] }
MPI Rank 1: 0x1657f78: {[B1 Value[512 x 1]] }
MPI Rank 1: 0x165dcc8: {[B0 Value[512 x 1]] }
MPI Rank 1: 0x1869a48: {[InvStdOfFeatures Value[363]] }
MPI Rank 1: 0x18a7ba8: {[CrossEntropyWithSoftmax Gradient[1]] }
MPI Rank 1: 0x18a8648: {[W1 Value[512 x 512]] }
MPI Rank 1: 0x18afc28: {[MVNormalizedFeatures Value[363 x *]] }
MPI Rank 1: 0x18afde8: {[LogOfPrior Value[132]] }
MPI Rank 1: 0x18b3ae8: {[W0*features Value[512 x *]] }
MPI Rank 1: 0x18b3ca8: {[W0 Gradient[512 x 363]] [W0*features+B0 Value[512 x 1 x *]] }
MPI Rank 1: 0x18b3e68: {[H1 Value[512 x 1 x *]] [W0*features Gradient[512 x *]] }
MPI Rank 1: 0x18b4028: {[W0*features+B0 Gradient[512 x 1 x *]] [W1*H1 Value[512 x 1 x *]] }
MPI Rank 1: 0x18b41e8: {[W1 Gradient[512 x 512]] [W1*H1+B1 Value[512 x 1 x *]] }
MPI Rank 1: 0x18b9b18: {[EvalErrorPrediction Value[1]] }
MPI Rank 1: 0x18b9dd8: {[W0 Value[512 x 363]] }
MPI Rank 1: 0x1918208: {[ScaledLogLikelihood Value[132 x 1 x *]] }
MPI Rank 1: 0x19366a8: {[Prior Value[132]] }
MPI Rank 1: 0x19486b8: {[B1 Gradient[512 x 1]] [H2 Gradient[512 x 1 x *]] [HLast Gradient[132 x 1 x *]] }
MPI Rank 1: 0x1948818: {[W2*H1 Gradient[132 x 1 x *]] }
MPI Rank 1: 0x19489d8: {[B2 Gradient[132 x 1]] }
MPI Rank 1: 0x195bf28: {[labels Value[132 x *]] }
MPI Rank 1: 0x195c488: {[CrossEntropyWithSoftmax Value[1]] }
MPI Rank 1: 0x1965df8: {[H2 Value[512 x 1 x *]] [W1*H1 Gradient[512 x 1 x *]] }
MPI Rank 1: 0x1965fb8: {[B0 Gradient[512 x 1]] [H1 Gradient[512 x 1 x *]] [W1*H1+B1 Gradient[512 x 1 x *]] [W2*H1 Value[132 x 1 x *]] }
MPI Rank 1: 0x1966178: {[HLast Value[132 x 1 x *]] [W2 Gradient[132 x 512]] }
MPI Rank 1: 0x19cb578: {[B2 Value[132 x 1]] }
MPI Rank 1: 0x19ccc98: {[features Value[363 x *]] }
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:51:52: Precomputing --> 3 PreCompute nodes found.
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:51:52: 	MeanOfFeatures = Mean()
MPI Rank 1: 07/13/2016 16:51:52: 	InvStdOfFeatures = InvStdDev()
MPI Rank 1: 07/13/2016 16:51:52: 	Prior = Mean()
MPI Rank 1: minibatchiterator: epoch 0: frames [0..252734] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
MPI Rank 1: requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:51:54: Precomputing --> Completed.
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:51:54: Starting Epoch 1: learning rate per sample = 0.015625  effective momentum = 0.900000  momentum as time constant = 607.4 samples
MPI Rank 1: minibatchiterator: epoch 0: frames [0..20480] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:51:54: Starting minibatch loop.
MPI Rank 1: 07/13/2016 16:51:54:  Epoch[ 1 of 5]-Minibatch[   1-   3, 0.94%]: CrossEntropyWithSoftmax = 4.56947300 * 192; EvalErrorPrediction = 0.93750000 * 192; time = 0.1049s; samplesPerSecond = 1830.1
MPI Rank 1: 07/13/2016 16:51:54:  Epoch[ 1 of 5]-Minibatch[   4-   6, 1.88%]: CrossEntropyWithSoftmax = 4.43406315 * 192; EvalErrorPrediction = 0.93229167 * 192; time = 0.0953s; samplesPerSecond = 2013.9
MPI Rank 1: 07/13/2016 16:51:54:  Epoch[ 1 of 5]-Minibatch[   7-   9, 2.81%]: CrossEntropyWithSoftmax = 4.27880063 * 192; EvalErrorPrediction = 0.86458333 * 192; time = 0.0912s; samplesPerSecond = 2104.2
MPI Rank 1: 07/13/2016 16:51:54:  Epoch[ 1 of 5]-Minibatch[  10-  12, 3.75%]: CrossEntropyWithSoftmax = 4.08751953 * 192; EvalErrorPrediction = 0.86979167 * 192; time = 0.0924s; samplesPerSecond = 2078.8
MPI Rank 1: 07/13/2016 16:51:55:  Epoch[ 1 of 5]-Minibatch[  13-  15, 4.69%]: CrossEntropyWithSoftmax = 4.21737559 * 192; EvalErrorPrediction = 0.91145833 * 192; time = 0.0954s; samplesPerSecond = 2011.9
MPI Rank 1: 07/13/2016 16:51:55:  Epoch[ 1 of 5]-Minibatch[  16-  18, 5.62%]: CrossEntropyWithSoftmax = 4.14259750 * 192; EvalErrorPrediction = 0.92187500 * 192; time = 0.0963s; samplesPerSecond = 1993.9
MPI Rank 1: 07/13/2016 16:51:55:  Epoch[ 1 of 5]-Minibatch[  19-  21, 6.56%]: CrossEntropyWithSoftmax = 4.03221539 * 192; EvalErrorPrediction = 0.85416667 * 192; time = 0.0982s; samplesPerSecond = 1955.5
MPI Rank 1: 07/13/2016 16:51:55:  Epoch[ 1 of 5]-Minibatch[  22-  24, 7.50%]: CrossEntropyWithSoftmax = 4.09889450 * 192; EvalErrorPrediction = 0.89062500 * 192; time = 0.0945s; samplesPerSecond = 2031.2
MPI Rank 1: 07/13/2016 16:51:55:  Epoch[ 1 of 5]-Minibatch[  25-  27, 8.44%]: CrossEntropyWithSoftmax = 3.89612175 * 192; EvalErrorPrediction = 0.83854167 * 192; time = 0.0936s; samplesPerSecond = 2050.8
MPI Rank 1: 07/13/2016 16:51:55:  Epoch[ 1 of 5]-Minibatch[  28-  30, 9.38%]: CrossEntropyWithSoftmax = 3.98897999 * 192; EvalErrorPrediction = 0.88020833 * 192; time = 0.0942s; samplesPerSecond = 2038.1
MPI Rank 1: 07/13/2016 16:51:55:  Epoch[ 1 of 5]-Minibatch[  31-  33, 10.31%]: CrossEntropyWithSoftmax = 3.93572978 * 192; EvalErrorPrediction = 0.83333333 * 192; time = 0.0934s; samplesPerSecond = 2056.5
MPI Rank 1: 07/13/2016 16:51:55:  Epoch[ 1 of 5]-Minibatch[  34-  36, 11.25%]: CrossEntropyWithSoftmax = 3.76284095 * 192; EvalErrorPrediction = 0.89062500 * 192; time = 0.0952s; samplesPerSecond = 2017.4
MPI Rank 1: 07/13/2016 16:51:55:  Epoch[ 1 of 5]-Minibatch[  37-  39, 12.19%]: CrossEntropyWithSoftmax = 3.98522385 * 192; EvalErrorPrediction = 0.87500000 * 192; time = 0.1006s; samplesPerSecond = 1908.7
MPI Rank 1: 07/13/2016 16:51:55:  Epoch[ 1 of 5]-Minibatch[  40-  42, 13.12%]: CrossEntropyWithSoftmax = 3.66209590 * 192; EvalErrorPrediction = 0.84895833 * 192; time = 0.0948s; samplesPerSecond = 2024.7
MPI Rank 1: 07/13/2016 16:51:55:  Epoch[ 1 of 5]-Minibatch[  43-  45, 14.06%]: CrossEntropyWithSoftmax = 3.96368107 * 192; EvalErrorPrediction = 0.91666667 * 192; time = 0.0939s; samplesPerSecond = 2044.0
MPI Rank 1: 07/13/2016 16:51:56:  Epoch[ 1 of 5]-Minibatch[  46-  48, 15.00%]: CrossEntropyWithSoftmax = 3.76732554 * 192; EvalErrorPrediction = 0.85416667 * 192; time = 0.0983s; samplesPerSecond = 1954.0
MPI Rank 1: 07/13/2016 16:51:56:  Epoch[ 1 of 5]-Minibatch[  49-  51, 15.94%]: CrossEntropyWithSoftmax = 3.69456327 * 192; EvalErrorPrediction = 0.89062500 * 192; time = 0.0995s; samplesPerSecond = 1929.3
MPI Rank 1: 07/13/2016 16:51:56:  Epoch[ 1 of 5]-Minibatch[  52-  54, 16.88%]: CrossEntropyWithSoftmax = 3.82975145 * 192; EvalErrorPrediction = 0.89583333 * 192; time = 0.0964s; samplesPerSecond = 1991.3
MPI Rank 1: 07/13/2016 16:51:56:  Epoch[ 1 of 5]-Minibatch[  55-  57, 17.81%]: CrossEntropyWithSoftmax = 3.82370243 * 192; EvalErrorPrediction = 0.88020833 * 192; time = 0.0974s; samplesPerSecond = 1970.9
MPI Rank 1: 07/13/2016 16:51:56:  Epoch[ 1 of 5]-Minibatch[  58-  60, 18.75%]: CrossEntropyWithSoftmax = 3.57625565 * 192; EvalErrorPrediction = 0.84895833 * 192; time = 0.0940s; samplesPerSecond = 2042.9
MPI Rank 1: 07/13/2016 16:51:56:  Epoch[ 1 of 5]-Minibatch[  61-  63, 19.69%]: CrossEntropyWithSoftmax = 3.38811493 * 192; EvalErrorPrediction = 0.79166667 * 192; time = 0.0976s; samplesPerSecond = 1966.7
MPI Rank 1: 07/13/2016 16:51:56:  Epoch[ 1 of 5]-Minibatch[  64-  66, 20.62%]: CrossEntropyWithSoftmax = 3.52208661 * 192; EvalErrorPrediction = 0.77604167 * 192; time = 0.0955s; samplesPerSecond = 2010.6
MPI Rank 1: 07/13/2016 16:51:56:  Epoch[ 1 of 5]-Minibatch[  67-  69, 21.56%]: CrossEntropyWithSoftmax = 3.80866929 * 192; EvalErrorPrediction = 0.87500000 * 192; time = 0.0977s; samplesPerSecond = 1965.7
MPI Rank 1: 07/13/2016 16:51:56:  Epoch[ 1 of 5]-Minibatch[  70-  72, 22.50%]: CrossEntropyWithSoftmax = 3.54345746 * 192; EvalErrorPrediction = 0.86458333 * 192; time = 0.0938s; samplesPerSecond = 2047.6
MPI Rank 1: 07/13/2016 16:51:56:  Epoch[ 1 of 5]-Minibatch[  73-  75, 23.44%]: CrossEntropyWithSoftmax = 3.33936350 * 192; EvalErrorPrediction = 0.80208333 * 192; time = 0.0938s; samplesPerSecond = 2047.4
MPI Rank 1: 07/13/2016 16:51:57:  Epoch[ 1 of 5]-Minibatch[  76-  78, 24.38%]: CrossEntropyWithSoftmax = 3.43672338 * 192; EvalErrorPrediction = 0.78125000 * 192; time = 0.0940s; samplesPerSecond = 2043.6
MPI Rank 1: 07/13/2016 16:51:57:  Epoch[ 1 of 5]-Minibatch[  79-  81, 25.31%]: CrossEntropyWithSoftmax = 3.44585129 * 192; EvalErrorPrediction = 0.82812500 * 192; time = 0.0958s; samplesPerSecond = 2003.5
MPI Rank 1: 07/13/2016 16:51:57:  Epoch[ 1 of 5]-Minibatch[  82-  84, 26.25%]: CrossEntropyWithSoftmax = 3.43498669 * 192; EvalErrorPrediction = 0.76041667 * 192; time = 0.0928s; samplesPerSecond = 2069.1
MPI Rank 1: 07/13/2016 16:51:57:  Epoch[ 1 of 5]-Minibatch[  85-  87, 27.19%]: CrossEntropyWithSoftmax = 3.31632754 * 192; EvalErrorPrediction = 0.75000000 * 192; time = 0.0929s; samplesPerSecond = 2067.1
MPI Rank 1: 07/13/2016 16:51:57:  Epoch[ 1 of 5]-Minibatch[  88-  90, 28.12%]: CrossEntropyWithSoftmax = 3.33946924 * 192; EvalErrorPrediction = 0.80208333 * 192; time = 0.0914s; samplesPerSecond = 2101.7
MPI Rank 1: 07/13/2016 16:51:57:  Epoch[ 1 of 5]-Minibatch[  91-  93, 29.06%]: CrossEntropyWithSoftmax = 3.26118575 * 192; EvalErrorPrediction = 0.84375000 * 192; time = 0.0919s; samplesPerSecond = 2089.2
MPI Rank 1: 07/13/2016 16:51:57:  Epoch[ 1 of 5]-Minibatch[  94-  96, 30.00%]: CrossEntropyWithSoftmax = 3.56686839 * 192; EvalErrorPrediction = 0.85416667 * 192; time = 0.0899s; samplesPerSecond = 2134.6
MPI Rank 1: 07/13/2016 16:51:57:  Epoch[ 1 of 5]-Minibatch[  97-  99, 30.94%]: CrossEntropyWithSoftmax = 3.36674876 * 192; EvalErrorPrediction = 0.85416667 * 192; time = 0.0938s; samplesPerSecond = 2047.8
MPI Rank 1: 07/13/2016 16:51:57:  Epoch[ 1 of 5]-Minibatch[ 100- 102, 31.87%]: CrossEntropyWithSoftmax = 3.28977127 * 192; EvalErrorPrediction = 0.81250000 * 192; time = 0.0954s; samplesPerSecond = 2012.0
MPI Rank 1: 07/13/2016 16:51:57:  Epoch[ 1 of 5]-Minibatch[ 103- 105, 32.81%]: CrossEntropyWithSoftmax = 3.27969909 * 192; EvalErrorPrediction = 0.79166667 * 192; time = 0.0958s; samplesPerSecond = 2004.6
MPI Rank 1: 07/13/2016 16:51:57:  Epoch[ 1 of 5]-Minibatch[ 106- 108, 33.75%]: CrossEntropyWithSoftmax = 3.12259596 * 192; EvalErrorPrediction = 0.72916667 * 192; time = 0.0979s; samplesPerSecond = 1961.2
MPI Rank 1: 07/13/2016 16:51:58:  Epoch[ 1 of 5]-Minibatch[ 109- 111, 34.69%]: CrossEntropyWithSoftmax = 3.41981056 * 192; EvalErrorPrediction = 0.77604167 * 192; time = 0.0976s; samplesPerSecond = 1967.2
MPI Rank 1: 07/13/2016 16:51:58:  Epoch[ 1 of 5]-Minibatch[ 112- 114, 35.62%]: CrossEntropyWithSoftmax = 3.38297602 * 192; EvalErrorPrediction = 0.79166667 * 192; time = 0.1008s; samplesPerSecond = 1905.3
MPI Rank 1: 07/13/2016 16:51:58:  Epoch[ 1 of 5]-Minibatch[ 115- 117, 36.56%]: CrossEntropyWithSoftmax = 3.41994711 * 192; EvalErrorPrediction = 0.82812500 * 192; time = 0.0975s; samplesPerSecond = 1968.4
MPI Rank 1: 07/13/2016 16:51:58:  Epoch[ 1 of 5]-Minibatch[ 118- 120, 37.50%]: CrossEntropyWithSoftmax = 3.24732267 * 192; EvalErrorPrediction = 0.78125000 * 192; time = 0.0990s; samplesPerSecond = 1939.8
MPI Rank 1: 07/13/2016 16:51:58:  Epoch[ 1 of 5]-Minibatch[ 121- 123, 38.44%]: CrossEntropyWithSoftmax = 3.20269035 * 192; EvalErrorPrediction = 0.76041667 * 192; time = 0.0934s; samplesPerSecond = 2054.8
MPI Rank 1: 07/13/2016 16:51:58:  Epoch[ 1 of 5]-Minibatch[ 124- 126, 39.38%]: CrossEntropyWithSoftmax = 3.15326365 * 192; EvalErrorPrediction = 0.74479167 * 192; time = 0.0964s; samplesPerSecond = 1992.7
MPI Rank 1: 07/13/2016 16:51:58:  Epoch[ 1 of 5]-Minibatch[ 127- 129, 40.31%]: CrossEntropyWithSoftmax = 3.21802066 * 192; EvalErrorPrediction = 0.78125000 * 192; time = 0.1015s; samplesPerSecond = 1891.1
MPI Rank 1: 07/13/2016 16:51:58:  Epoch[ 1 of 5]-Minibatch[ 130- 132, 41.25%]: CrossEntropyWithSoftmax = 3.26091070 * 192; EvalErrorPrediction = 0.76041667 * 192; time = 0.0964s; samplesPerSecond = 1991.0
MPI Rank 1: 07/13/2016 16:51:58:  Epoch[ 1 of 5]-Minibatch[ 133- 135, 42.19%]: CrossEntropyWithSoftmax = 2.94987113 * 192; EvalErrorPrediction = 0.68229167 * 192; time = 0.0977s; samplesPerSecond = 1965.5
MPI Rank 1: 07/13/2016 16:51:58:  Epoch[ 1 of 5]-Minibatch[ 136- 138, 43.12%]: CrossEntropyWithSoftmax = 3.01829231 * 192; EvalErrorPrediction = 0.70312500 * 192; time = 0.0962s; samplesPerSecond = 1995.6
MPI Rank 1: 07/13/2016 16:51:59:  Epoch[ 1 of 5]-Minibatch[ 139- 141, 44.06%]: CrossEntropyWithSoftmax = 3.19981302 * 192; EvalErrorPrediction = 0.76562500 * 192; time = 0.0987s; samplesPerSecond = 1945.4
MPI Rank 1: 07/13/2016 16:51:59:  Epoch[ 1 of 5]-Minibatch[ 142- 144, 45.00%]: CrossEntropyWithSoftmax = 3.01620054 * 192; EvalErrorPrediction = 0.72916667 * 192; time = 0.0983s; samplesPerSecond = 1953.7
MPI Rank 1: 07/13/2016 16:51:59:  Epoch[ 1 of 5]-Minibatch[ 145- 147, 45.94%]: CrossEntropyWithSoftmax = 3.07482512 * 192; EvalErrorPrediction = 0.76562500 * 192; time = 0.0967s; samplesPerSecond = 1985.0
MPI Rank 1: 07/13/2016 16:51:59:  Epoch[ 1 of 5]-Minibatch[ 148- 150, 46.88%]: CrossEntropyWithSoftmax = 2.95940261 * 192; EvalErrorPrediction = 0.71875000 * 192; time = 0.0985s; samplesPerSecond = 1948.6
MPI Rank 1: 07/13/2016 16:51:59:  Epoch[ 1 of 5]-Minibatch[ 151- 153, 47.81%]: CrossEntropyWithSoftmax = 3.18955068 * 192; EvalErrorPrediction = 0.78125000 * 192; time = 0.0955s; samplesPerSecond = 2010.7
MPI Rank 1: 07/13/2016 16:51:59:  Epoch[ 1 of 5]-Minibatch[ 154- 156, 48.75%]: CrossEntropyWithSoftmax = 2.80225800 * 192; EvalErrorPrediction = 0.70312500 * 192; time = 0.0969s; samplesPerSecond = 1981.2
MPI Rank 1: 07/13/2016 16:51:59:  Epoch[ 1 of 5]-Minibatch[ 157- 159, 49.69%]: CrossEntropyWithSoftmax = 3.08865913 * 192; EvalErrorPrediction = 0.75520833 * 192; time = 0.0948s; samplesPerSecond = 2024.7
MPI Rank 1: 07/13/2016 16:51:59:  Epoch[ 1 of 5]-Minibatch[ 160- 162, 50.62%]: CrossEntropyWithSoftmax = 2.87171438 * 192; EvalErrorPrediction = 0.69791667 * 192; time = 0.0914s; samplesPerSecond = 2100.8
MPI Rank 1: 07/13/2016 16:51:59:  Epoch[ 1 of 5]-Minibatch[ 163- 165, 51.56%]: CrossEntropyWithSoftmax = 2.90723268 * 192; EvalErrorPrediction = 0.73958333 * 192; time = 0.0916s; samplesPerSecond = 2095.2
MPI Rank 1: 07/13/2016 16:51:59:  Epoch[ 1 of 5]-Minibatch[ 166- 168, 52.50%]: CrossEntropyWithSoftmax = 2.96438386 * 192; EvalErrorPrediction = 0.69270833 * 192; time = 0.0957s; samplesPerSecond = 2007.1
MPI Rank 1: 07/13/2016 16:52:00:  Epoch[ 1 of 5]-Minibatch[ 169- 171, 53.44%]: CrossEntropyWithSoftmax = 2.85407675 * 192; EvalErrorPrediction = 0.67708333 * 192; time = 0.0979s; samplesPerSecond = 1960.7
MPI Rank 1: 07/13/2016 16:52:00:  Epoch[ 1 of 5]-Minibatch[ 172- 174, 54.37%]: CrossEntropyWithSoftmax = 2.64516293 * 192; EvalErrorPrediction = 0.63020833 * 192; time = 0.0981s; samplesPerSecond = 1956.4
MPI Rank 1: 07/13/2016 16:52:00:  Epoch[ 1 of 5]-Minibatch[ 175- 177, 55.31%]: CrossEntropyWithSoftmax = 2.78779884 * 192; EvalErrorPrediction = 0.73437500 * 192; time = 0.0971s; samplesPerSecond = 1977.7
MPI Rank 1: 07/13/2016 16:52:00:  Epoch[ 1 of 5]-Minibatch[ 178- 180, 56.25%]: CrossEntropyWithSoftmax = 2.77691077 * 192; EvalErrorPrediction = 0.68229167 * 192; time = 0.0962s; samplesPerSecond = 1995.6
MPI Rank 1: 07/13/2016 16:52:00:  Epoch[ 1 of 5]-Minibatch[ 181- 183, 57.19%]: CrossEntropyWithSoftmax = 2.93466303 * 192; EvalErrorPrediction = 0.68229167 * 192; time = 0.0962s; samplesPerSecond = 1996.8
MPI Rank 1: 07/13/2016 16:52:00:  Epoch[ 1 of 5]-Minibatch[ 184- 186, 58.13%]: CrossEntropyWithSoftmax = 2.79665615 * 192; EvalErrorPrediction = 0.69791667 * 192; time = 0.0966s; samplesPerSecond = 1988.3
MPI Rank 1: 07/13/2016 16:52:00:  Epoch[ 1 of 5]-Minibatch[ 187- 189, 59.06%]: CrossEntropyWithSoftmax = 2.79141433 * 192; EvalErrorPrediction = 0.75520833 * 192; time = 0.0957s; samplesPerSecond = 2005.7
MPI Rank 1: 07/13/2016 16:52:00:  Epoch[ 1 of 5]-Minibatch[ 190- 192, 60.00%]: CrossEntropyWithSoftmax = 2.85677634 * 192; EvalErrorPrediction = 0.68750000 * 192; time = 0.0985s; samplesPerSecond = 1950.1
MPI Rank 1: 07/13/2016 16:52:00:  Epoch[ 1 of 5]-Minibatch[ 193- 195, 60.94%]: CrossEntropyWithSoftmax = 2.60438340 * 192; EvalErrorPrediction = 0.62500000 * 192; time = 0.0990s; samplesPerSecond = 1939.6
MPI Rank 1: 07/13/2016 16:52:00:  Epoch[ 1 of 5]-Minibatch[ 196- 198, 61.88%]: CrossEntropyWithSoftmax = 2.67867701 * 192; EvalErrorPrediction = 0.66666667 * 192; time = 0.0969s; samplesPerSecond = 1981.2
MPI Rank 1: 07/13/2016 16:52:00:  Epoch[ 1 of 5]-Minibatch[ 199- 201, 62.81%]: CrossEntropyWithSoftmax = 2.35420452 * 192; EvalErrorPrediction = 0.61458333 * 192; time = 0.0948s; samplesPerSecond = 2025.9
MPI Rank 1: 07/13/2016 16:52:01:  Epoch[ 1 of 5]-Minibatch[ 202- 204, 63.75%]: CrossEntropyWithSoftmax = 2.67860524 * 192; EvalErrorPrediction = 0.68750000 * 192; time = 0.0975s; samplesPerSecond = 1968.7
MPI Rank 1: 07/13/2016 16:52:01:  Epoch[ 1 of 5]-Minibatch[ 205- 207, 64.69%]: CrossEntropyWithSoftmax = 2.74438644 * 192; EvalErrorPrediction = 0.65625000 * 192; time = 0.0951s; samplesPerSecond = 2017.9
MPI Rank 1: 07/13/2016 16:52:01:  Epoch[ 1 of 5]-Minibatch[ 208- 210, 65.62%]: CrossEntropyWithSoftmax = 2.61472294 * 192; EvalErrorPrediction = 0.65625000 * 192; time = 0.0986s; samplesPerSecond = 1947.8
MPI Rank 1: 07/13/2016 16:52:01:  Epoch[ 1 of 5]-Minibatch[ 211- 213, 66.56%]: CrossEntropyWithSoftmax = 2.56292238 * 192; EvalErrorPrediction = 0.65104167 * 192; time = 0.0961s; samplesPerSecond = 1998.4
MPI Rank 1: 07/13/2016 16:52:01:  Epoch[ 1 of 5]-Minibatch[ 214- 216, 67.50%]: CrossEntropyWithSoftmax = 2.49905414 * 192; EvalErrorPrediction = 0.68229167 * 192; time = 0.0948s; samplesPerSecond = 2025.6
MPI Rank 1: 07/13/2016 16:52:01:  Epoch[ 1 of 5]-Minibatch[ 217- 219, 68.44%]: CrossEntropyWithSoftmax = 2.77977518 * 192; EvalErrorPrediction = 0.67708333 * 192; time = 0.0942s; samplesPerSecond = 2037.8
MPI Rank 1: 07/13/2016 16:52:01:  Epoch[ 1 of 5]-Minibatch[ 220- 222, 69.38%]: CrossEntropyWithSoftmax = 2.46098943 * 192; EvalErrorPrediction = 0.60416667 * 192; time = 0.0963s; samplesPerSecond = 1993.0
MPI Rank 1: 07/13/2016 16:52:01:  Epoch[ 1 of 5]-Minibatch[ 223- 225, 70.31%]: CrossEntropyWithSoftmax = 2.53972637 * 192; EvalErrorPrediction = 0.60416667 * 192; time = 0.0937s; samplesPerSecond = 2048.4
MPI Rank 1: 07/13/2016 16:52:01:  Epoch[ 1 of 5]-Minibatch[ 226- 228, 71.25%]: CrossEntropyWithSoftmax = 2.58069409 * 192; EvalErrorPrediction = 0.64583333 * 192; time = 0.0978s; samplesPerSecond = 1963.7
MPI Rank 1: 07/13/2016 16:52:01:  Epoch[ 1 of 5]-Minibatch[ 229- 231, 72.19%]: CrossEntropyWithSoftmax = 2.42808307 * 192; EvalErrorPrediction = 0.62500000 * 192; time = 0.0950s; samplesPerSecond = 2020.6
MPI Rank 1: 07/13/2016 16:52:02:  Epoch[ 1 of 5]-Minibatch[ 232- 234, 73.12%]: CrossEntropyWithSoftmax = 2.51795774 * 192; EvalErrorPrediction = 0.66666667 * 192; time = 0.0940s; samplesPerSecond = 2042.1
MPI Rank 1: 07/13/2016 16:52:02:  Epoch[ 1 of 5]-Minibatch[ 235- 237, 74.06%]: CrossEntropyWithSoftmax = 2.31017953 * 192; EvalErrorPrediction = 0.63541667 * 192; time = 0.0984s; samplesPerSecond = 1951.3
MPI Rank 1: 07/13/2016 16:52:02:  Epoch[ 1 of 5]-Minibatch[ 238- 240, 75.00%]: CrossEntropyWithSoftmax = 2.42763250 * 192; EvalErrorPrediction = 0.59375000 * 192; time = 0.0957s; samplesPerSecond = 2007.3
MPI Rank 1: 07/13/2016 16:52:02:  Epoch[ 1 of 5]-Minibatch[ 241- 243, 75.94%]: CrossEntropyWithSoftmax = 2.38337452 * 192; EvalErrorPrediction = 0.63020833 * 192; time = 0.0985s; samplesPerSecond = 1949.7
MPI Rank 1: 07/13/2016 16:52:02:  Epoch[ 1 of 5]-Minibatch[ 244- 246, 76.88%]: CrossEntropyWithSoftmax = 2.45688385 * 192; EvalErrorPrediction = 0.68229167 * 192; time = 0.0955s; samplesPerSecond = 2009.9
MPI Rank 1: 07/13/2016 16:52:02:  Epoch[ 1 of 5]-Minibatch[ 247- 249, 77.81%]: CrossEntropyWithSoftmax = 2.35065649 * 192; EvalErrorPrediction = 0.63020833 * 192; time = 0.0954s; samplesPerSecond = 2011.9
MPI Rank 1: 07/13/2016 16:52:02:  Epoch[ 1 of 5]-Minibatch[ 250- 252, 78.75%]: CrossEntropyWithSoftmax = 2.39950363 * 192; EvalErrorPrediction = 0.63541667 * 192; time = 0.0938s; samplesPerSecond = 2047.8
MPI Rank 1: 07/13/2016 16:52:02:  Epoch[ 1 of 5]-Minibatch[ 253- 255, 79.69%]: CrossEntropyWithSoftmax = 2.48031632 * 192; EvalErrorPrediction = 0.60937500 * 192; time = 0.0991s; samplesPerSecond = 1937.1
MPI Rank 1: 07/13/2016 16:52:02:  Epoch[ 1 of 5]-Minibatch[ 256- 258, 80.62%]: CrossEntropyWithSoftmax = 2.62124157 * 192; EvalErrorPrediction = 0.67708333 * 192; time = 0.0986s; samplesPerSecond = 1946.7
MPI Rank 1: 07/13/2016 16:52:02:  Epoch[ 1 of 5]-Minibatch[ 259- 261, 81.56%]: CrossEntropyWithSoftmax = 2.43263192 * 192; EvalErrorPrediction = 0.65625000 * 192; time = 0.0966s; samplesPerSecond = 1987.6
MPI Rank 1: 07/13/2016 16:52:03:  Epoch[ 1 of 5]-Minibatch[ 262- 264, 82.50%]: CrossEntropyWithSoftmax = 2.13490764 * 192; EvalErrorPrediction = 0.57291667 * 192; time = 0.0948s; samplesPerSecond = 2025.4
MPI Rank 1: 07/13/2016 16:52:03:  Epoch[ 1 of 5]-Minibatch[ 265- 267, 83.44%]: CrossEntropyWithSoftmax = 2.52272390 * 192; EvalErrorPrediction = 0.63541667 * 192; time = 0.0948s; samplesPerSecond = 2026.1
MPI Rank 1: 07/13/2016 16:52:03:  Epoch[ 1 of 5]-Minibatch[ 268- 270, 84.38%]: CrossEntropyWithSoftmax = 2.31215555 * 192; EvalErrorPrediction = 0.63020833 * 192; time = 0.0975s; samplesPerSecond = 1968.7
MPI Rank 1: 07/13/2016 16:52:03:  Epoch[ 1 of 5]-Minibatch[ 271- 273, 85.31%]: CrossEntropyWithSoftmax = 2.33888920 * 192; EvalErrorPrediction = 0.60416667 * 192; time = 0.0965s; samplesPerSecond = 1989.3
MPI Rank 1: 07/13/2016 16:52:03:  Epoch[ 1 of 5]-Minibatch[ 274- 276, 86.25%]: CrossEntropyWithSoftmax = 2.19318149 * 192; EvalErrorPrediction = 0.58854167 * 192; time = 0.0970s; samplesPerSecond = 1979.3
MPI Rank 1: 07/13/2016 16:52:03:  Epoch[ 1 of 5]-Minibatch[ 277- 279, 87.19%]: CrossEntropyWithSoftmax = 2.19368853 * 192; EvalErrorPrediction = 0.55208333 * 192; time = 0.0952s; samplesPerSecond = 2016.7
MPI Rank 1: 07/13/2016 16:52:03:  Epoch[ 1 of 5]-Minibatch[ 280- 282, 88.12%]: CrossEntropyWithSoftmax = 2.31322736 * 192; EvalErrorPrediction = 0.59895833 * 192; time = 0.0964s; samplesPerSecond = 1992.2
MPI Rank 1: 07/13/2016 16:52:03:  Epoch[ 1 of 5]-Minibatch[ 283- 285, 89.06%]: CrossEntropyWithSoftmax = 2.21496162 * 192; EvalErrorPrediction = 0.62500000 * 192; time = 0.0986s; samplesPerSecond = 1948.2
MPI Rank 1: 07/13/2016 16:52:03:  Epoch[ 1 of 5]-Minibatch[ 286- 288, 90.00%]: CrossEntropyWithSoftmax = 2.38257678 * 192; EvalErrorPrediction = 0.64062500 * 192; time = 0.1003s; samplesPerSecond = 1914.7
MPI Rank 1: 07/13/2016 16:52:03:  Epoch[ 1 of 5]-Minibatch[ 289- 291, 90.94%]: CrossEntropyWithSoftmax = 2.34785036 * 192; EvalErrorPrediction = 0.60416667 * 192; time = 0.0970s; samplesPerSecond = 1980.2
MPI Rank 1: 07/13/2016 16:52:03:  Epoch[ 1 of 5]-Minibatch[ 292- 294, 91.88%]: CrossEntropyWithSoftmax = 2.20545861 * 192; EvalErrorPrediction = 0.60416667 * 192; time = 0.0978s; samplesPerSecond = 1963.4
MPI Rank 1: 07/13/2016 16:52:04:  Epoch[ 1 of 5]-Minibatch[ 295- 297, 92.81%]: CrossEntropyWithSoftmax = 2.08751143 * 192; EvalErrorPrediction = 0.57291667 * 192; time = 0.0928s; samplesPerSecond = 2068.7
MPI Rank 1: 07/13/2016 16:52:04:  Epoch[ 1 of 5]-Minibatch[ 298- 300, 93.75%]: CrossEntropyWithSoftmax = 2.28302994 * 192; EvalErrorPrediction = 0.64583333 * 192; time = 0.0956s; samplesPerSecond = 2009.1
MPI Rank 1: 07/13/2016 16:52:04:  Epoch[ 1 of 5]-Minibatch[ 301- 303, 94.69%]: CrossEntropyWithSoftmax = 2.22267854 * 192; EvalErrorPrediction = 0.57291667 * 192; time = 0.0986s; samplesPerSecond = 1947.4
MPI Rank 1: 07/13/2016 16:52:04:  Epoch[ 1 of 5]-Minibatch[ 304- 306, 95.62%]: CrossEntropyWithSoftmax = 2.19855044 * 192; EvalErrorPrediction = 0.60416667 * 192; time = 0.0951s; samplesPerSecond = 2018.1
MPI Rank 1: 07/13/2016 16:52:04:  Epoch[ 1 of 5]-Minibatch[ 307- 309, 96.56%]: CrossEntropyWithSoftmax = 2.49612283 * 192; EvalErrorPrediction = 0.64583333 * 192; time = 0.0978s; samplesPerSecond = 1962.9
MPI Rank 1: 07/13/2016 16:52:04:  Epoch[ 1 of 5]-Minibatch[ 310- 312, 97.50%]: CrossEntropyWithSoftmax = 2.25409762 * 192; EvalErrorPrediction = 0.59375000 * 192; time = 0.0998s; samplesPerSecond = 1924.3
MPI Rank 1: 07/13/2016 16:52:04:  Epoch[ 1 of 5]-Minibatch[ 313- 315, 98.44%]: CrossEntropyWithSoftmax = 2.13085317 * 192; EvalErrorPrediction = 0.58333333 * 192; time = 0.0977s; samplesPerSecond = 1964.2
MPI Rank 1: 07/13/2016 16:52:04:  Epoch[ 1 of 5]-Minibatch[ 316- 318, 99.38%]: CrossEntropyWithSoftmax = 2.28902612 * 192; EvalErrorPrediction = 0.59375000 * 192; time = 0.0946s; samplesPerSecond = 2029.3
MPI Rank 1: 07/13/2016 16:52:04: Finished Epoch[ 1 of 5]: [Training] CrossEntropyWithSoftmax = 3.01292779 * 20480; EvalErrorPrediction = 0.72778320 * 20480; totalSamplesSeen = 20480; learningRatePerSample = 0.015625; epochTime=10.2702s
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:52:04: Starting Epoch 2: learning rate per sample = 0.001953  effective momentum = 0.656119  momentum as time constant = 607.5 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 1: frames [20480..40960] (first utterance at frame 20480), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:52:04: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 07/13/2016 16:52:05:  Epoch[ 2 of 5]-Minibatch[   1-   3, 3.75%]: CrossEntropyWithSoftmax = 2.08671820 * 249; EvalErrorPrediction = 0.55020080 * 249; time = 0.1244s; samplesPerSecond = 2000.8
MPI Rank 1: 07/13/2016 16:52:05:  Epoch[ 2 of 5]-Minibatch[   4-   6, 7.50%]: CrossEntropyWithSoftmax = 2.16912508 * 239; EvalErrorPrediction = 0.57740586 * 239; time = 0.1243s; samplesPerSecond = 1923.3
MPI Rank 1: 07/13/2016 16:52:05:  Epoch[ 2 of 5]-Minibatch[   7-   9, 11.25%]: CrossEntropyWithSoftmax = 2.09087687 * 274; EvalErrorPrediction = 0.55109489 * 274; time = 0.1316s; samplesPerSecond = 2082.4
MPI Rank 1: 07/13/2016 16:52:05:  Epoch[ 2 of 5]-Minibatch[  10-  12, 15.00%]: CrossEntropyWithSoftmax = 2.15400834 * 277; EvalErrorPrediction = 0.61371841 * 277; time = 0.1347s; samplesPerSecond = 2056.4
MPI Rank 1: 07/13/2016 16:52:05:  Epoch[ 2 of 5]-Minibatch[  13-  15, 18.75%]: CrossEntropyWithSoftmax = 2.03468379 * 280; EvalErrorPrediction = 0.54642857 * 280; time = 0.1332s; samplesPerSecond = 2102.6
MPI Rank 1: 07/13/2016 16:52:05:  Epoch[ 2 of 5]-Minibatch[  16-  18, 22.50%]: CrossEntropyWithSoftmax = 2.12707706 * 283; EvalErrorPrediction = 0.59363958 * 283; time = 0.1354s; samplesPerSecond = 2089.5
MPI Rank 1: 07/13/2016 16:52:05:  Epoch[ 2 of 5]-Minibatch[  19-  21, 26.25%]: CrossEntropyWithSoftmax = 2.05140796 * 239; EvalErrorPrediction = 0.56903766 * 239; time = 0.1154s; samplesPerSecond = 2071.4
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     1.07 seconds since last report (0.00 seconds on comm.); 4331 samples processed by 2 workers (2141 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 4.06k samplesPerSecond , throughputPerWorker = 2.03k samplesPerSecond
MPI Rank 1: 07/13/2016 16:52:05:  Epoch[ 2 of 5]-Minibatch[  22-  24, 30.00%]: CrossEntropyWithSoftmax = 2.01525982 * 300; EvalErrorPrediction = 0.54666667 * 300; time = 0.1633s; samplesPerSecond = 1837.1
MPI Rank 1: 07/13/2016 16:52:06:  Epoch[ 2 of 5]-Minibatch[  25-  27, 33.75%]: CrossEntropyWithSoftmax = 2.01429833 * 269; EvalErrorPrediction = 0.54646840 * 269; time = 0.1283s; samplesPerSecond = 2096.3
MPI Rank 1: 07/13/2016 16:52:06:  Epoch[ 2 of 5]-Minibatch[  28-  30, 37.50%]: CrossEntropyWithSoftmax = 2.17091946 * 274; EvalErrorPrediction = 0.56569343 * 274; time = 0.1275s; samplesPerSecond = 2148.7
MPI Rank 1: 07/13/2016 16:52:06:  Epoch[ 2 of 5]-Minibatch[  31-  33, 41.25%]: CrossEntropyWithSoftmax = 2.04765590 * 289; EvalErrorPrediction = 0.58823529 * 289; time = 0.1342s; samplesPerSecond = 2153.6
MPI Rank 1: 07/13/2016 16:52:06:  Epoch[ 2 of 5]-Minibatch[  34-  36, 45.00%]: CrossEntropyWithSoftmax = 2.08198284 * 280; EvalErrorPrediction = 0.62857143 * 280; time = 0.1317s; samplesPerSecond = 2125.3
MPI Rank 1: 07/13/2016 16:52:06:  Epoch[ 2 of 5]-Minibatch[  37-  39, 48.75%]: CrossEntropyWithSoftmax = 2.06262072 * 262; EvalErrorPrediction = 0.53435115 * 262; time = 0.1220s; samplesPerSecond = 2148.3
MPI Rank 1: 07/13/2016 16:52:06:  Epoch[ 2 of 5]-Minibatch[  40-  42, 52.50%]: CrossEntropyWithSoftmax = 2.08065983 * 256; EvalErrorPrediction = 0.56250000 * 256; time = 0.1205s; samplesPerSecond = 2124.4
MPI Rank 1: 07/13/2016 16:52:06:  Epoch[ 2 of 5]-Minibatch[  43-  45, 56.25%]: CrossEntropyWithSoftmax = 1.95307697 * 271; EvalErrorPrediction = 0.54243542 * 271; time = 0.1297s; samplesPerSecond = 2088.9
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     0.99 seconds since last report (0.00 seconds on comm.); 4232 samples processed by 2 workers (2078 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 4.25k samplesPerSecond , throughputPerWorker = 2.13k samplesPerSecond
MPI Rank 1: 07/13/2016 16:52:07:  Epoch[ 2 of 5]-Minibatch[  46-  48, 60.00%]: CrossEntropyWithSoftmax = 2.05133637 * 266; EvalErrorPrediction = 0.59022556 * 266; time = 0.1400s; samplesPerSecond = 1900.4
MPI Rank 1: 07/13/2016 16:52:07:  Epoch[ 2 of 5]-Minibatch[  49-  51, 63.75%]: CrossEntropyWithSoftmax = 2.16121433 * 292; EvalErrorPrediction = 0.61643836 * 292; time = 0.1459s; samplesPerSecond = 2000.8
MPI Rank 1: 07/13/2016 16:52:07:  Epoch[ 2 of 5]-Minibatch[  52-  54, 67.50%]: CrossEntropyWithSoftmax = 2.04937835 * 281; EvalErrorPrediction = 0.56939502 * 281; time = 0.1315s; samplesPerSecond = 2136.4
MPI Rank 1: 07/13/2016 16:52:07:  Epoch[ 2 of 5]-Minibatch[  55-  57, 71.25%]: CrossEntropyWithSoftmax = 1.96573797 * 269; EvalErrorPrediction = 0.50557621 * 269; time = 0.1279s; samplesPerSecond = 2103.6
MPI Rank 1: 07/13/2016 16:52:07:  Epoch[ 2 of 5]-Minibatch[  58-  60, 75.00%]: CrossEntropyWithSoftmax = 1.96927408 * 293; EvalErrorPrediction = 0.54607509 * 293; time = 0.1375s; samplesPerSecond = 2131.4
MPI Rank 1: 07/13/2016 16:52:07:  Epoch[ 2 of 5]-Minibatch[  61-  63, 78.75%]: CrossEntropyWithSoftmax = 1.96602409 * 262; EvalErrorPrediction = 0.51526718 * 262; time = 0.1218s; samplesPerSecond = 2150.3
MPI Rank 1: 07/13/2016 16:52:07:  Epoch[ 2 of 5]-Minibatch[  64-  66, 82.50%]: CrossEntropyWithSoftmax = 2.06123892 * 296; EvalErrorPrediction = 0.55067568 * 296; time = 0.1412s; samplesPerSecond = 2096.1
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     0.99 seconds since last report (0.00 seconds on comm.); 4185 samples processed by 2 workers (2060 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 4.23k samplesPerSecond , throughputPerWorker = 2.11k samplesPerSecond
MPI Rank 1: 07/13/2016 16:52:07:  Epoch[ 2 of 5]-Minibatch[  67-  69, 86.25%]: CrossEntropyWithSoftmax = 1.97564922 * 278; EvalErrorPrediction = 0.51079137 * 278; time = 0.1429s; samplesPerSecond = 1944.9
MPI Rank 1: 07/13/2016 16:52:08:  Epoch[ 2 of 5]-Minibatch[  70-  72, 90.00%]: CrossEntropyWithSoftmax = 2.03003870 * 291; EvalErrorPrediction = 0.53951890 * 291; time = 0.1353s; samplesPerSecond = 2150.1
MPI Rank 1: 07/13/2016 16:52:08:  Epoch[ 2 of 5]-Minibatch[  73-  75, 93.75%]: CrossEntropyWithSoftmax = 2.10265344 * 299; EvalErrorPrediction = 0.56187291 * 299; time = 0.1432s; samplesPerSecond = 2088.5
MPI Rank 1: 07/13/2016 16:52:08:  Epoch[ 2 of 5]-Minibatch[  76-  78, 97.50%]: CrossEntropyWithSoftmax = 1.87884845 * 273; EvalErrorPrediction = 0.51282051 * 273; time = 0.1286s; samplesPerSecond = 2123.0
MPI Rank 1: 07/13/2016 16:52:08:  Epoch[ 2 of 5]-Minibatch[  79-  81, 101.25%]: CrossEntropyWithSoftmax = 1.91420176 * 190; EvalErrorPrediction = 0.52631579 * 190; time = 0.0874s; samplesPerSecond = 2174.1
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.48-seconds latency this time; accumulated time on sync point = 0.48 seconds , average latency = 0.12 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     3.03 seconds since last report (2.04 seconds on comm.); 7732 samples processed by 2 workers (1053 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 2.55k samplesPerSecond , throughputPerWorker = 1.28k samplesPerSecond
MPI Rank 1: 07/13/2016 16:52:10: Finished Epoch[ 2 of 5]: [Training] CrossEntropyWithSoftmax = 2.00885273 * 20480; EvalErrorPrediction = 0.55078125 * 20480; totalSamplesSeen = 40960; learningRatePerSample = 0.001953125; epochTime=6.08087s
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:52:11: Starting Epoch 3: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 2: frames [40960..61440] (first utterance at frame 40960), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:52:11: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 07/13/2016 16:52:11:  Epoch[ 3 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.93776302 * 1133; EvalErrorPrediction = 0.55251545 * 1133; time = 0.5124s; samplesPerSecond = 2211.0
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.15-seconds latency this time; accumulated time on sync point = 0.15 seconds , average latency = 0.15 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     1.17 seconds since last report (0.00 seconds on comm.); 4844 samples processed by 2 workers (2261 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 4.15k samplesPerSecond , throughputPerWorker = 2.07k samplesPerSecond
MPI Rank 1: 07/13/2016 16:52:12:  Epoch[ 3 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.95554942 * 1128; EvalErrorPrediction = 0.53989362 * 1128; time = 0.6524s; samplesPerSecond = 1729.1
MPI Rank 1: 07/13/2016 16:52:12:  Epoch[ 3 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.86097969 * 1154; EvalErrorPrediction = 0.51039861 * 1154; time = 0.4832s; samplesPerSecond = 2388.2
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.15-seconds latency this time; accumulated time on sync point = 0.30 seconds , average latency = 0.15 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     1.11 seconds since last report (0.00 seconds on comm.); 4849 samples processed by 2 workers (2269 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 4.37k samplesPerSecond , throughputPerWorker = 2.18k samplesPerSecond
MPI Rank 1: 07/13/2016 16:52:13:  Epoch[ 3 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.88714011 * 1115; EvalErrorPrediction = 0.52376682 * 1115; time = 0.6268s; samplesPerSecond = 1778.7
MPI Rank 1: 07/13/2016 16:52:13:  Epoch[ 3 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.91141402 * 1130; EvalErrorPrediction = 0.54513274 * 1130; time = 0.4920s; samplesPerSecond = 2296.7
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.16-seconds latency this time; accumulated time on sync point = 0.45 seconds , average latency = 0.15 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     1.17 seconds since last report (0.00 seconds on comm.); 4868 samples processed by 2 workers (2273 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 4.17k samplesPerSecond , throughputPerWorker = 2.08k samplesPerSecond
MPI Rank 1: 07/13/2016 16:52:14:  Epoch[ 3 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.90296336 * 1143; EvalErrorPrediction = 0.53980752 * 1143; time = 0.6753s; samplesPerSecond = 1692.6
MPI Rank 1: 07/13/2016 16:52:14:  Epoch[ 3 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.93362099 * 758; EvalErrorPrediction = 0.53562005 * 758; time = 0.3406s; samplesPerSecond = 2225.2
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.73-seconds latency this time; accumulated time on sync point = 1.18 seconds , average latency = 0.30 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     2.22 seconds since last report (1.14 seconds on comm.); 5919 samples processed by 2 workers (758 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 2.67k samplesPerSecond , throughputPerWorker = 1.33k samplesPerSecond
MPI Rank 1: 07/13/2016 16:52:16: Finished Epoch[ 3 of 5]: [Training] CrossEntropyWithSoftmax = 1.89787888 * 20480; EvalErrorPrediction = 0.52875977 * 20480; totalSamplesSeen = 61440; learningRatePerSample = 9.7656251e-05; epochTime=5.66531s
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:52:16: Starting Epoch 4: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:52:16: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 07/13/2016 16:52:17:  Epoch[ 4 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.84821410 * 1146; EvalErrorPrediction = 0.50872600 * 1146; time = 0.4979s; samplesPerSecond = 2301.5
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.14-seconds latency this time; accumulated time on sync point = 0.14 seconds , average latency = 0.14 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     1.15 seconds since last report (0.00 seconds on comm.); 4905 samples processed by 2 workers (2324 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 4.28k samplesPerSecond , throughputPerWorker = 2.14k samplesPerSecond
MPI Rank 1: 07/13/2016 16:52:17:  Epoch[ 4 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.84074472 * 1178; EvalErrorPrediction = 0.50764007 * 1178; time = 0.6446s; samplesPerSecond = 1827.6
MPI Rank 1: 07/13/2016 16:52:18:  Epoch[ 4 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.89617847 * 1141; EvalErrorPrediction = 0.53198948 * 1141; time = 0.4920s; samplesPerSecond = 2319.2
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.10-seconds latency this time; accumulated time on sync point = 0.25 seconds , average latency = 0.12 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     1.11 seconds since last report (0.00 seconds on comm.); 4870 samples processed by 2 workers (2333 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 4.39k samplesPerSecond , throughputPerWorker = 2.19k samplesPerSecond
MPI Rank 1: 07/13/2016 16:52:19:  Epoch[ 4 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.90122104 * 1192; EvalErrorPrediction = 0.53859060 * 1192; time = 0.6179s; samplesPerSecond = 1929.0
MPI Rank 1: 07/13/2016 16:52:19:  Epoch[ 4 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.81959403 * 1192; EvalErrorPrediction = 0.51845638 * 1192; time = 0.5086s; samplesPerSecond = 2343.5
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.27 seconds , average latency = 0.09 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     1.08 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 4.54k samplesPerSecond , throughputPerWorker = 2.27k samplesPerSecond
MPI Rank 1: 07/13/2016 16:52:20:  Epoch[ 4 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.83237505 * 1211; EvalErrorPrediction = 0.50949628 * 1211; time = 0.5748s; samplesPerSecond = 2106.8
MPI Rank 1: 07/13/2016 16:52:20:  Epoch[ 4 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.95195212 * 785; EvalErrorPrediction = 0.54777070 * 785; time = 0.3421s; samplesPerSecond = 2294.5
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.73-seconds latency this time; accumulated time on sync point = 1.01 seconds , average latency = 0.25 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     2.19 seconds since last report (1.11 seconds on comm.); 5789 samples processed by 2 workers (785 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 2.64k samplesPerSecond , throughputPerWorker = 1.32k samplesPerSecond
MPI Rank 1: 07/13/2016 16:52:22: Finished Epoch[ 4 of 5]: [Training] CrossEntropyWithSoftmax = 1.84940336 * 20480; EvalErrorPrediction = 0.51445312 * 20480; totalSamplesSeen = 81920; learningRatePerSample = 9.7656251e-05; epochTime=5.5319s
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:52:22: Starting Epoch 5: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:52:22: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 07/13/2016 16:52:22:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.79235548 * 1175; EvalErrorPrediction = 0.49957447 * 1175; time = 0.5020s; samplesPerSecond = 2340.7
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.03 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     1.10 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 4.49k samplesPerSecond , throughputPerWorker = 2.24k samplesPerSecond
MPI Rank 1: 07/13/2016 16:52:23:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.84602168 * 1251; EvalErrorPrediction = 0.52358114 * 1251; time = 0.5908s; samplesPerSecond = 2117.4
MPI Rank 1: 07/13/2016 16:52:24:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.79460940 * 1201; EvalErrorPrediction = 0.50124896 * 1201; time = 0.4827s; samplesPerSecond = 2488.2
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.06-seconds latency this time; accumulated time on sync point = 0.09 seconds , average latency = 0.05 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     1.07 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 4.55k samplesPerSecond , throughputPerWorker = 2.27k samplesPerSecond
MPI Rank 1: 07/13/2016 16:52:24:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.86032081 * 1202; EvalErrorPrediction = 0.50915141 * 1202; time = 0.5915s; samplesPerSecond = 2032.2
MPI Rank 1: 07/13/2016 16:52:25:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.84149612 * 1173; EvalErrorPrediction = 0.51577153 * 1173; time = 0.4991s; samplesPerSecond = 2350.2
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.06-seconds latency this time; accumulated time on sync point = 0.16 seconds , average latency = 0.05 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     1.09 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 4.47k samplesPerSecond , throughputPerWorker = 2.23k samplesPerSecond
MPI Rank 1: 07/13/2016 16:52:25:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87763945 * 1194; EvalErrorPrediction = 0.52680067 * 1194; time = 0.5875s; samplesPerSecond = 2032.3
MPI Rank 1: 07/13/2016 16:52:26:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.79221618 * 827; EvalErrorPrediction = 0.51269649 * 827; time = 0.3512s; samplesPerSecond = 2354.5
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.70-seconds latency this time; accumulated time on sync point = 0.86 seconds , average latency = 0.22 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     2.11 seconds since last report (1.04 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 2.76k samplesPerSecond , throughputPerWorker = 1.38k samplesPerSecond
MPI Rank 1: 07/13/2016 16:52:27: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85300231 * 20480; EvalErrorPrediction = 0.51425781 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 9.7656251e-05; epochTime=5.36516s
MPI Rank 1: 07/13/2016 16:52:27: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160713165131.612468/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/13/2016 16:52:27: learnRatePerSample reduced to 4.8828126e-05
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:52:27: Starting Epoch 5: learning rate per sample = 0.000049  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:52:27: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 07/13/2016 16:52:28:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.79242721 * 1175; EvalErrorPrediction = 0.49957447 * 1175; time = 0.4932s; samplesPerSecond = 2382.5
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.07-seconds latency this time; accumulated time on sync point = 0.07 seconds , average latency = 0.07 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     1.09 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 4.49k samplesPerSecond , throughputPerWorker = 2.25k samplesPerSecond
MPI Rank 1: 07/13/2016 16:52:29:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.84627836 * 1251; EvalErrorPrediction = 0.52278177 * 1251; time = 0.5979s; samplesPerSecond = 2092.2
MPI Rank 1: 07/13/2016 16:52:29:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.79565103 * 1201; EvalErrorPrediction = 0.50707744 * 1201; time = 0.5187s; samplesPerSecond = 2315.6
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.07 seconds , average latency = 0.04 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     1.05 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 4.65k samplesPerSecond , throughputPerWorker = 2.33k samplesPerSecond
MPI Rank 1: 07/13/2016 16:52:30:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.86102857 * 1202; EvalErrorPrediction = 0.50998336 * 1202; time = 0.5313s; samplesPerSecond = 2262.5
MPI Rank 1: 07/13/2016 16:52:30:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.84398555 * 1173; EvalErrorPrediction = 0.51832907 * 1173; time = 0.4987s; samplesPerSecond = 2351.9
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.05-seconds latency this time; accumulated time on sync point = 0.12 seconds , average latency = 0.04 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     1.07 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 4.52k samplesPerSecond , throughputPerWorker = 2.26k samplesPerSecond
MPI Rank 1: 07/13/2016 16:52:31:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87898732 * 1194; EvalErrorPrediction = 0.52512563 * 1194; time = 0.5744s; samplesPerSecond = 2078.7
MPI Rank 1: 07/13/2016 16:52:31:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.79405711 * 827; EvalErrorPrediction = 0.51511487 * 827; time = 0.3511s; samplesPerSecond = 2355.4
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.74-seconds latency this time; accumulated time on sync point = 0.86 seconds , average latency = 0.21 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     2.14 seconds since last report (1.04 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 2.72k samplesPerSecond , throughputPerWorker = 1.36k samplesPerSecond
MPI Rank 1: 07/13/2016 16:52:33: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85426644 * 20480; EvalErrorPrediction = 0.51508789 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 4.8828126e-05; epochTime=5.36142s
MPI Rank 1: 07/13/2016 16:52:33: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160713165131.612468/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/13/2016 16:52:33: learnRatePerSample reduced to 2.4414063e-05
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:52:33: Starting Epoch 5: learning rate per sample = 0.000024  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:52:33: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 07/13/2016 16:52:33:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.79246348 * 1175; EvalErrorPrediction = 0.49957447 * 1175; time = 0.5052s; samplesPerSecond = 2325.8
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.04-seconds latency this time; accumulated time on sync point = 0.04 seconds , average latency = 0.04 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     1.10 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 4.46k samplesPerSecond , throughputPerWorker = 2.23k samplesPerSecond
MPI Rank 1: 07/13/2016 16:52:34:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.84641688 * 1251; EvalErrorPrediction = 0.52358114 * 1251; time = 0.5937s; samplesPerSecond = 2107.2
MPI Rank 1: 07/13/2016 16:52:35:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.79624499 * 1201; EvalErrorPrediction = 0.50707744 * 1201; time = 0.5037s; samplesPerSecond = 2384.4
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.07 seconds , average latency = 0.04 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     1.07 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 4.58k samplesPerSecond , throughputPerWorker = 2.29k samplesPerSecond
MPI Rank 1: 07/13/2016 16:52:35:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.86139356 * 1202; EvalErrorPrediction = 0.51247920 * 1202; time = 0.5620s; samplesPerSecond = 2138.9
MPI Rank 1: 07/13/2016 16:52:36:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.84547786 * 1173; EvalErrorPrediction = 0.51491901 * 1173; time = 0.4981s; samplesPerSecond = 2354.8
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.06-seconds latency this time; accumulated time on sync point = 0.13 seconds , average latency = 0.04 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     1.07 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 4.53k samplesPerSecond , throughputPerWorker = 2.27k samplesPerSecond
MPI Rank 1: 07/13/2016 16:52:36:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87969458 * 1194; EvalErrorPrediction = 0.52596315 * 1194; time = 0.5734s; samplesPerSecond = 2082.4
MPI Rank 1: 07/13/2016 16:52:37:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.79494286 * 827; EvalErrorPrediction = 0.50906892 * 827; time = 0.3503s; samplesPerSecond = 2360.7
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.72-seconds latency this time; accumulated time on sync point = 0.85 seconds , average latency = 0.21 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     2.14 seconds since last report (1.06 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 2.72k samplesPerSecond , throughputPerWorker = 1.36k samplesPerSecond
MPI Rank 1: 07/13/2016 16:52:38: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85499692 * 20480; EvalErrorPrediction = 0.51547852 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 2.4414063e-05; epochTime=5.38044s
MPI Rank 1: 07/13/2016 16:52:38: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160713165131.612468/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/13/2016 16:52:38: learnRatePerSample reduced to 1.2207031e-05
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:52:39: Starting Epoch 5: learning rate per sample = 0.000012  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:52:39: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 07/13/2016 16:52:39:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.79248172 * 1175; EvalErrorPrediction = 0.49957447 * 1175; time = 0.5082s; samplesPerSecond = 2312.3
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.02 seconds , average latency = 0.02 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     1.08 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 4.55k samplesPerSecond , throughputPerWorker = 2.28k samplesPerSecond
MPI Rank 1: 07/13/2016 16:52:40:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.84648880 * 1251; EvalErrorPrediction = 0.52278177 * 1251; time = 0.5681s; samplesPerSecond = 2201.9
MPI Rank 1: 07/13/2016 16:52:40:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.79656264 * 1201; EvalErrorPrediction = 0.50624480 * 1201; time = 0.5333s; samplesPerSecond = 2252.2
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.04 seconds , average latency = 0.02 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     1.09 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 4.48k samplesPerSecond , throughputPerWorker = 2.24k samplesPerSecond
MPI Rank 1: 07/13/2016 16:52:41:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.86158303 * 1202; EvalErrorPrediction = 0.51331115 * 1202; time = 0.5566s; samplesPerSecond = 2159.5
MPI Rank 1: 07/13/2016 16:52:41:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.84631070 * 1173; EvalErrorPrediction = 0.51406650 * 1173; time = 0.5128s; samplesPerSecond = 2287.3
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.05 seconds , average latency = 0.02 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     1.07 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 4.53k samplesPerSecond , throughputPerWorker = 2.27k samplesPerSecond
MPI Rank 1: 07/13/2016 16:52:42:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.88007633 * 1194; EvalErrorPrediction = 0.52931323 * 1194; time = 0.5579s; samplesPerSecond = 2140.4
MPI Rank 1: 07/13/2016 16:52:42:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.79541620 * 827; EvalErrorPrediction = 0.50906892 * 827; time = 0.3622s; samplesPerSecond = 2283.3
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.75-seconds latency this time; accumulated time on sync point = 0.79 seconds , average latency = 0.20 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     2.15 seconds since last report (1.03 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 2.70k samplesPerSecond , throughputPerWorker = 1.35k samplesPerSecond
MPI Rank 1: 07/13/2016 16:52:44: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85540764 * 20480; EvalErrorPrediction = 0.51547852 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 1.2207031e-05; epochTime=5.39462s
MPI Rank 1: 07/13/2016 16:52:44: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160713165131.612468/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/13/2016 16:52:44: learnRatePerSample reduced to 6.1035157e-06
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:52:44: Starting Epoch 5: learning rate per sample = 0.000006  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:52:44: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 07/13/2016 16:52:45:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.79249087 * 1175; EvalErrorPrediction = 0.49957447 * 1175; time = 0.5140s; samplesPerSecond = 2285.9
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.01 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     1.09 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 4.53k samplesPerSecond , throughputPerWorker = 2.26k samplesPerSecond
MPI Rank 1: 07/13/2016 16:52:45:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.84652543 * 1251; EvalErrorPrediction = 0.52278177 * 1251; time = 0.5690s; samplesPerSecond = 2198.5
MPI Rank 1: 07/13/2016 16:52:46:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.79672696 * 1201; EvalErrorPrediction = 0.50624480 * 1201; time = 0.5183s; samplesPerSecond = 2317.3
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.04 seconds , average latency = 0.02 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     1.07 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 4.56k samplesPerSecond , throughputPerWorker = 2.28k samplesPerSecond
MPI Rank 1: 07/13/2016 16:52:46:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.86168018 * 1202; EvalErrorPrediction = 0.51331115 * 1202; time = 0.5519s; samplesPerSecond = 2178.1
MPI Rank 1: 07/13/2016 16:52:47:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.84675286 * 1173; EvalErrorPrediction = 0.51406650 * 1173; time = 0.4733s; samplesPerSecond = 2478.5
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.10-seconds latency this time; accumulated time on sync point = 0.14 seconds , average latency = 0.05 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     1.10 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 4.41k samplesPerSecond , throughputPerWorker = 2.21k samplesPerSecond
MPI Rank 1: 07/13/2016 16:52:47:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.88027824 * 1194; EvalErrorPrediction = 0.52931323 * 1194; time = 0.6272s; samplesPerSecond = 1903.7
MPI Rank 1: 07/13/2016 16:52:48:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.79567029 * 827; EvalErrorPrediction = 0.50906892 * 827; time = 0.3554s; samplesPerSecond = 2326.9
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.74-seconds latency this time; accumulated time on sync point = 0.88 seconds , average latency = 0.22 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     2.17 seconds since last report (1.06 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 2.68k samplesPerSecond , throughputPerWorker = 1.34k samplesPerSecond
MPI Rank 1: 07/13/2016 16:52:49: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85562974 * 20480; EvalErrorPrediction = 0.51582031 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 6.1035157e-06; epochTime=5.42714s
MPI Rank 1: 07/13/2016 16:52:49: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160713165131.612468/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/13/2016 16:52:50: learnRatePerSample reduced to 3.0517579e-06
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:52:50: Starting Epoch 5: learning rate per sample = 0.000003  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:52:50: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 07/13/2016 16:52:50:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.79249545 * 1175; EvalErrorPrediction = 0.49957447 * 1175; time = 0.5116s; samplesPerSecond = 2296.9
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.05-seconds latency this time; accumulated time on sync point = 0.05 seconds , average latency = 0.05 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     1.09 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 4.49k samplesPerSecond , throughputPerWorker = 2.25k samplesPerSecond
MPI Rank 1: 07/13/2016 16:52:51:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.84654392 * 1251; EvalErrorPrediction = 0.52278177 * 1251; time = 0.5793s; samplesPerSecond = 2159.4
MPI Rank 1: 07/13/2016 16:52:51:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.79681054 * 1201; EvalErrorPrediction = 0.50624480 * 1201; time = 0.5034s; samplesPerSecond = 2385.7
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.07-seconds latency this time; accumulated time on sync point = 0.12 seconds , average latency = 0.06 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     1.10 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 4.44k samplesPerSecond , throughputPerWorker = 2.22k samplesPerSecond
MPI Rank 1: 07/13/2016 16:52:52:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.86172946 * 1202; EvalErrorPrediction = 0.51331115 * 1202; time = 0.5965s; samplesPerSecond = 2015.1
MPI Rank 1: 07/13/2016 16:52:52:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.84698096 * 1173; EvalErrorPrediction = 0.51491901 * 1173; time = 0.4778s; samplesPerSecond = 2455.1
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.08-seconds latency this time; accumulated time on sync point = 0.20 seconds , average latency = 0.07 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     1.09 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 4.46k samplesPerSecond , throughputPerWorker = 2.23k samplesPerSecond
MPI Rank 1: 07/13/2016 16:52:53:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.88038258 * 1194; EvalErrorPrediction = 0.52931323 * 1194; time = 0.6094s; samplesPerSecond = 1959.4
MPI Rank 1: 07/13/2016 16:52:53:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.79580336 * 827; EvalErrorPrediction = 0.51148730 * 827; time = 0.3419s; samplesPerSecond = 2418.7
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.76-seconds latency this time; accumulated time on sync point = 0.96 seconds , average latency = 0.24 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     2.16 seconds since last report (1.05 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 2.70k samplesPerSecond , throughputPerWorker = 1.35k samplesPerSecond
MPI Rank 1: 07/13/2016 16:52:55: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85574594 * 20480; EvalErrorPrediction = 0.51606445 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 3.0517579e-06; epochTime=5.4413s
MPI Rank 1: 07/13/2016 16:52:55: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160713165131.612468/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/13/2016 16:52:55: learnRatePerSample reduced to 1.5258789e-06
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:52:55: Starting Epoch 5: learning rate per sample = 0.000002  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:52:55: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 07/13/2016 16:52:56:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.79249774 * 1175; EvalErrorPrediction = 0.49957447 * 1175; time = 0.5018s; samplesPerSecond = 2341.6
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.03 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     1.10 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 4.49k samplesPerSecond , throughputPerWorker = 2.24k samplesPerSecond
MPI Rank 1: 07/13/2016 16:52:56:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.84655321 * 1251; EvalErrorPrediction = 0.52278177 * 1251; time = 0.5904s; samplesPerSecond = 2119.0
MPI Rank 1: 07/13/2016 16:52:57:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.79685269 * 1201; EvalErrorPrediction = 0.50624480 * 1201; time = 0.5162s; samplesPerSecond = 2326.8
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.05-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.04 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     1.09 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 4.50k samplesPerSecond , throughputPerWorker = 2.25k samplesPerSecond
MPI Rank 1: 07/13/2016 16:52:57:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.86175428 * 1202; EvalErrorPrediction = 0.51331115 * 1202; time = 0.5700s; samplesPerSecond = 2108.7
MPI Rank 1: 07/13/2016 16:52:58:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.84709684 * 1173; EvalErrorPrediction = 0.51491901 * 1173; time = 0.5061s; samplesPerSecond = 2317.5
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.05-seconds latency this time; accumulated time on sync point = 0.13 seconds , average latency = 0.04 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     1.09 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 4.46k samplesPerSecond , throughputPerWorker = 2.23k samplesPerSecond
MPI Rank 1: 07/13/2016 16:52:58:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.88043569 * 1194; EvalErrorPrediction = 0.52931323 * 1194; time = 0.5811s; samplesPerSecond = 2054.6
MPI Rank 1: 07/13/2016 16:52:59:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.79587164 * 827; EvalErrorPrediction = 0.51027811 * 827; time = 0.3448s; samplesPerSecond = 2398.4
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.74-seconds latency this time; accumulated time on sync point = 0.87 seconds , average latency = 0.22 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     2.12 seconds since last report (1.03 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 2.75k samplesPerSecond , throughputPerWorker = 1.38k samplesPerSecond
MPI Rank 1: 07/13/2016 16:53:01: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85580548 * 20480; EvalErrorPrediction = 0.51591797 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 1.5258789e-06; epochTime=5.38597s
MPI Rank 1: 07/13/2016 16:53:01: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160713165131.612468/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/13/2016 16:53:01: learnRatePerSample reduced to 7.6293946e-07
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:53:01: Starting Epoch 5: learning rate per sample = 0.000001  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:53:01: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 07/13/2016 16:53:01:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.79249889 * 1175; EvalErrorPrediction = 0.49957447 * 1175; time = 0.5071s; samplesPerSecond = 2317.1
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.06-seconds latency this time; accumulated time on sync point = 0.06 seconds , average latency = 0.06 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     1.11 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 4.43k samplesPerSecond , throughputPerWorker = 2.21k samplesPerSecond
MPI Rank 1: 07/13/2016 16:53:02:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.84655786 * 1251; EvalErrorPrediction = 0.52278177 * 1251; time = 0.5995s; samplesPerSecond = 2086.7
MPI Rank 1: 07/13/2016 16:53:02:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.79687385 * 1201; EvalErrorPrediction = 0.50624480 * 1201; time = 0.5126s; samplesPerSecond = 2343.1
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.05-seconds latency this time; accumulated time on sync point = 0.12 seconds , average latency = 0.06 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     1.09 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 4.46k samplesPerSecond , throughputPerWorker = 2.23k samplesPerSecond
MPI Rank 1: 07/13/2016 16:53:03:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.86176674 * 1202; EvalErrorPrediction = 0.51247920 * 1202; time = 0.5812s; samplesPerSecond = 2068.1
MPI Rank 1: 07/13/2016 16:53:03:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.84715525 * 1173; EvalErrorPrediction = 0.51491901 * 1173; time = 0.4917s; samplesPerSecond = 2385.6
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.09-seconds latency this time; accumulated time on sync point = 0.21 seconds , average latency = 0.07 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     1.08 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 4.48k samplesPerSecond , throughputPerWorker = 2.24k samplesPerSecond
MPI Rank 1: 07/13/2016 16:53:04:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.88046248 * 1194; EvalErrorPrediction = 0.52847571 * 1194; time = 0.5921s; samplesPerSecond = 2016.5
MPI Rank 1: 07/13/2016 16:53:04:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.79590625 * 827; EvalErrorPrediction = 0.51148730 * 827; time = 0.3577s; samplesPerSecond = 2312.3
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.73-seconds latency this time; accumulated time on sync point = 0.94 seconds , average latency = 0.23 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     2.18 seconds since last report (1.08 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 2.67k samplesPerSecond , throughputPerWorker = 1.34k samplesPerSecond
MPI Rank 1: 07/13/2016 16:53:06: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85583563 * 20480; EvalErrorPrediction = 0.51591797 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 7.6293946e-07; epochTime=5.46876s
MPI Rank 1: 07/13/2016 16:53:06: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160713165131.612468/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/13/2016 16:53:06: learnRatePerSample reduced to 3.8146973e-07
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:53:06: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:53:06: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 07/13/2016 16:53:07:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.79249946 * 1175; EvalErrorPrediction = 0.49957447 * 1175; time = 0.5163s; samplesPerSecond = 2275.8
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     1.07 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 4.57k samplesPerSecond , throughputPerWorker = 2.29k samplesPerSecond
MPI Rank 1: 07/13/2016 16:53:07:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.84656019 * 1251; EvalErrorPrediction = 0.52278177 * 1251; time = 0.5553s; samplesPerSecond = 2252.9
MPI Rank 1: 07/13/2016 16:53:08:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.79688446 * 1201; EvalErrorPrediction = 0.50624480 * 1201; time = 0.5168s; samplesPerSecond = 2323.7
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.05-seconds latency this time; accumulated time on sync point = 0.05 seconds , average latency = 0.02 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     1.10 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 4.46k samplesPerSecond , throughputPerWorker = 2.23k samplesPerSecond
MPI Rank 1: 07/13/2016 16:53:09:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.86177299 * 1202; EvalErrorPrediction = 0.51247920 * 1202; time = 0.5790s; samplesPerSecond = 2076.0
MPI Rank 1: 07/13/2016 16:53:09:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.84718457 * 1173; EvalErrorPrediction = 0.51491901 * 1173; time = 0.5130s; samplesPerSecond = 2286.4
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.06-seconds latency this time; accumulated time on sync point = 0.11 seconds , average latency = 0.04 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     1.08 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 4.51k samplesPerSecond , throughputPerWorker = 2.26k samplesPerSecond
MPI Rank 1: 07/13/2016 16:53:10:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.88047594 * 1194; EvalErrorPrediction = 0.52847571 * 1194; time = 0.5625s; samplesPerSecond = 2122.8
MPI Rank 1: 07/13/2016 16:53:10:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.79592368 * 827; EvalErrorPrediction = 0.51148730 * 827; time = 0.3377s; samplesPerSecond = 2448.8
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.75-seconds latency this time; accumulated time on sync point = 0.86 seconds , average latency = 0.21 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     2.14 seconds since last report (1.04 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 2.72k samplesPerSecond , throughputPerWorker = 1.36k samplesPerSecond
MPI Rank 1: 07/13/2016 16:53:12: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85585080 * 20480; EvalErrorPrediction = 0.51591797 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 3.8146973e-07; epochTime=5.38885s
MPI Rank 1: 07/13/2016 16:53:12: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160713165131.612468/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/13/2016 16:53:12: learnRatePerSample reduced to 1.9073487e-07
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:53:12: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:53:12: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 07/13/2016 16:53:12:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.79249975 * 1175; EvalErrorPrediction = 0.49957447 * 1175; time = 0.4883s; samplesPerSecond = 2406.3
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.06-seconds latency this time; accumulated time on sync point = 0.06 seconds , average latency = 0.06 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     1.11 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 4.43k samplesPerSecond , throughputPerWorker = 2.21k samplesPerSecond
MPI Rank 1: 07/13/2016 16:53:13:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.84656136 * 1251; EvalErrorPrediction = 0.52278177 * 1251; time = 0.6187s; samplesPerSecond = 2022.0
MPI Rank 1: 07/13/2016 16:53:14:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.79688976 * 1201; EvalErrorPrediction = 0.50624480 * 1201; time = 0.5314s; samplesPerSecond = 2259.9
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.07 seconds , average latency = 0.03 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     1.08 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 4.51k samplesPerSecond , throughputPerWorker = 2.26k samplesPerSecond
MPI Rank 1: 07/13/2016 16:53:14:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.86177611 * 1202; EvalErrorPrediction = 0.51247920 * 1202; time = 0.5502s; samplesPerSecond = 2184.7
MPI Rank 1: 07/13/2016 16:53:15:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.84719926 * 1173; EvalErrorPrediction = 0.51491901 * 1173; time = 0.5041s; samplesPerSecond = 2326.8
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.07-seconds latency this time; accumulated time on sync point = 0.13 seconds , average latency = 0.04 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     1.11 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 4.39k samplesPerSecond , throughputPerWorker = 2.19k samplesPerSecond
MPI Rank 1: 07/13/2016 16:53:15:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.88048269 * 1194; EvalErrorPrediction = 0.52847571 * 1194; time = 0.6026s; samplesPerSecond = 1981.3
MPI Rank 1: 07/13/2016 16:53:16:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.79593242 * 827; EvalErrorPrediction = 0.51148730 * 827; time = 0.3508s; samplesPerSecond = 2357.6
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.72-seconds latency this time; accumulated time on sync point = 0.85 seconds , average latency = 0.21 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     2.14 seconds since last report (1.05 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 2.72k samplesPerSecond , throughputPerWorker = 1.36k samplesPerSecond
MPI Rank 1: 07/13/2016 16:53:17: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85585841 * 20480; EvalErrorPrediction = 0.51582031 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 1.9073487e-07; epochTime=5.43742s
MPI Rank 1: 07/13/2016 16:53:17: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160713165131.612468/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/13/2016 16:53:17: learnRatePerSample reduced to 9.5367433e-08
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:53:17: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:53:17: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 07/13/2016 16:53:18:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.79249989 * 1175; EvalErrorPrediction = 0.49957447 * 1175; time = 0.5236s; samplesPerSecond = 2244.1
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.02 seconds , average latency = 0.02 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     1.09 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 4.49k samplesPerSecond , throughputPerWorker = 2.25k samplesPerSecond
MPI Rank 1: 07/13/2016 16:53:19:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.84656194 * 1251; EvalErrorPrediction = 0.52278177 * 1251; time = 0.5666s; samplesPerSecond = 2207.8
MPI Rank 1: 07/13/2016 16:53:19:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.79689242 * 1201; EvalErrorPrediction = 0.50624480 * 1201; time = 0.5181s; samplesPerSecond = 2317.9
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.05 seconds , average latency = 0.02 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     1.07 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 4.55k samplesPerSecond , throughputPerWorker = 2.27k samplesPerSecond
MPI Rank 1: 07/13/2016 16:53:20:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.86177767 * 1202; EvalErrorPrediction = 0.51247920 * 1202; time = 0.5554s; samplesPerSecond = 2164.3
MPI Rank 1: 07/13/2016 16:53:20:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.84720661 * 1173; EvalErrorPrediction = 0.51491901 * 1173; time = 0.5103s; samplesPerSecond = 2298.9
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.03 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     1.06 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 4.59k samplesPerSecond , throughputPerWorker = 2.30k samplesPerSecond
MPI Rank 1: 07/13/2016 16:53:21:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.88048607 * 1194; EvalErrorPrediction = 0.52847571 * 1194; time = 0.5473s; samplesPerSecond = 2181.7
MPI Rank 1: 07/13/2016 16:53:21:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.79593680 * 827; EvalErrorPrediction = 0.51148730 * 827; time = 0.3350s; samplesPerSecond = 2468.6
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.74-seconds latency this time; accumulated time on sync point = 0.82 seconds , average latency = 0.20 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     2.15 seconds since last report (1.06 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 2.71k samplesPerSecond , throughputPerWorker = 1.35k samplesPerSecond
MPI Rank 1: 07/13/2016 16:53:23: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85586222 * 20480; EvalErrorPrediction = 0.51582031 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 9.5367433e-08; epochTime=5.37669s
MPI Rank 1: 07/13/2016 16:53:23: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160713165131.612468/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/13/2016 16:53:23: learnRatePerSample reduced to 4.7683717e-08
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:53:23: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:53:23: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 07/13/2016 16:53:24:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.79249996 * 1175; EvalErrorPrediction = 0.49957447 * 1175; time = 0.5066s; samplesPerSecond = 2319.5
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.02 seconds , average latency = 0.02 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     1.08 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 4.54k samplesPerSecond , throughputPerWorker = 2.27k samplesPerSecond
MPI Rank 1: 07/13/2016 16:53:24:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.84656223 * 1251; EvalErrorPrediction = 0.52278177 * 1251; time = 0.5718s; samplesPerSecond = 2187.7
MPI Rank 1: 07/13/2016 16:53:25:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.79689375 * 1201; EvalErrorPrediction = 0.50624480 * 1201; time = 0.5123s; samplesPerSecond = 2344.4
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.05-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.04 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     1.10 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 4.44k samplesPerSecond , throughputPerWorker = 2.22k samplesPerSecond
MPI Rank 1: 07/13/2016 16:53:25:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.86177845 * 1202; EvalErrorPrediction = 0.51247920 * 1202; time = 0.5877s; samplesPerSecond = 2045.3
MPI Rank 1: 07/13/2016 16:53:26:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.84721029 * 1173; EvalErrorPrediction = 0.51491901 * 1173; time = 0.5152s; samplesPerSecond = 2276.8
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.08-seconds latency this time; accumulated time on sync point = 0.15 seconds , average latency = 0.05 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     1.12 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 4.34k samplesPerSecond , throughputPerWorker = 2.17k samplesPerSecond
MPI Rank 1: 07/13/2016 16:53:26:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.88048776 * 1194; EvalErrorPrediction = 0.52847571 * 1194; time = 0.6027s; samplesPerSecond = 1981.2
MPI Rank 1: 07/13/2016 16:53:27:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.79593899 * 827; EvalErrorPrediction = 0.51027811 * 827; time = 0.3665s; samplesPerSecond = 2256.5
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.71-seconds latency this time; accumulated time on sync point = 0.87 seconds , average latency = 0.22 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     2.17 seconds since last report (1.08 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 2.69k samplesPerSecond , throughputPerWorker = 1.34k samplesPerSecond
MPI Rank 1: 07/13/2016 16:53:28: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85586413 * 20480; EvalErrorPrediction = 0.51577148 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 4.7683717e-08; epochTime=5.46637s
MPI Rank 1: 07/13/2016 16:53:28: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160713165131.612468/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/13/2016 16:53:29: learnRatePerSample reduced to 2.3841858e-08
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:53:29: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:53:29: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 07/13/2016 16:53:29:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.79250000 * 1175; EvalErrorPrediction = 0.49957447 * 1175; time = 0.5172s; samplesPerSecond = 2271.7
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.03 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     1.09 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 4.52k samplesPerSecond , throughputPerWorker = 2.26k samplesPerSecond
MPI Rank 1: 07/13/2016 16:53:30:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.84656238 * 1251; EvalErrorPrediction = 0.52278177 * 1251; time = 0.5680s; samplesPerSecond = 2202.4
MPI Rank 1: 07/13/2016 16:53:30:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.79689441 * 1201; EvalErrorPrediction = 0.50624480 * 1201; time = 0.5126s; samplesPerSecond = 2343.1
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.05 seconds , average latency = 0.03 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     1.06 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 4.60k samplesPerSecond , throughputPerWorker = 2.30k samplesPerSecond
MPI Rank 1: 07/13/2016 16:53:31:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.86177885 * 1202; EvalErrorPrediction = 0.51247920 * 1202; time = 0.5486s; samplesPerSecond = 2190.9
MPI Rank 1: 07/13/2016 16:53:31:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.84721213 * 1173; EvalErrorPrediction = 0.51491901 * 1173; time = 0.5073s; samplesPerSecond = 2312.4
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.05-seconds latency this time; accumulated time on sync point = 0.10 seconds , average latency = 0.03 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     1.08 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 4.49k samplesPerSecond , throughputPerWorker = 2.25k samplesPerSecond
MPI Rank 1: 07/13/2016 16:53:32:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.88048860 * 1194; EvalErrorPrediction = 0.52847571 * 1194; time = 0.5731s; samplesPerSecond = 2083.4
MPI Rank 1: 07/13/2016 16:53:32:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.79594009 * 827; EvalErrorPrediction = 0.51027811 * 827; time = 0.3532s; samplesPerSecond = 2341.3
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.72-seconds latency this time; accumulated time on sync point = 0.83 seconds , average latency = 0.21 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     2.17 seconds since last report (1.08 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 2.69k samplesPerSecond , throughputPerWorker = 1.34k samplesPerSecond
MPI Rank 1: 07/13/2016 16:53:34: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85586508 * 20480; EvalErrorPrediction = 0.51577148 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 2.3841858e-08; epochTime=5.39931s
MPI Rank 1: 07/13/2016 16:53:34: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160713165131.612468/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/13/2016 16:53:34: learnRatePerSample reduced to 1.1920929e-08
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:53:34: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:53:34: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 07/13/2016 16:53:35:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.79250001 * 1175; EvalErrorPrediction = 0.49957447 * 1175; time = 0.5240s; samplesPerSecond = 2242.3
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.03 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     1.11 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 4.43k samplesPerSecond , throughputPerWorker = 2.21k samplesPerSecond
MPI Rank 1: 07/13/2016 16:53:35:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.84656245 * 1251; EvalErrorPrediction = 0.52278177 * 1251; time = 0.5831s; samplesPerSecond = 2145.3
MPI Rank 1: 07/13/2016 16:53:36:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.79689474 * 1201; EvalErrorPrediction = 0.50624480 * 1201; time = 0.5216s; samplesPerSecond = 2302.3
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.06-seconds latency this time; accumulated time on sync point = 0.10 seconds , average latency = 0.05 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     1.10 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 4.45k samplesPerSecond , throughputPerWorker = 2.23k samplesPerSecond
MPI Rank 1: 07/13/2016 16:53:36:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.86177904 * 1202; EvalErrorPrediction = 0.51247920 * 1202; time = 0.5747s; samplesPerSecond = 2091.7
MPI Rank 1: 07/13/2016 16:53:37:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.84721305 * 1173; EvalErrorPrediction = 0.51491901 * 1173; time = 0.5154s; samplesPerSecond = 2276.0
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.05-seconds latency this time; accumulated time on sync point = 0.15 seconds , average latency = 0.05 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     1.11 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 4.36k samplesPerSecond , throughputPerWorker = 2.18k samplesPerSecond
MPI Rank 1: 07/13/2016 16:53:37:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.88048902 * 1194; EvalErrorPrediction = 0.52847571 * 1194; time = 0.5978s; samplesPerSecond = 1997.3
MPI Rank 1: 07/13/2016 16:53:38:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.79594064 * 827; EvalErrorPrediction = 0.51027811 * 827; time = 0.3388s; samplesPerSecond = 2440.8
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.76-seconds latency this time; accumulated time on sync point = 0.91 seconds , average latency = 0.23 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     2.18 seconds since last report (1.07 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 2.67k samplesPerSecond , throughputPerWorker = 1.34k samplesPerSecond
MPI Rank 1: 07/13/2016 16:53:40: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85586556 * 20480; EvalErrorPrediction = 0.51577148 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 1.1920929e-08; epochTime=5.49921s
MPI Rank 1: 07/13/2016 16:53:40: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160713165131.612468/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/13/2016 16:53:40: learnRatePerSample reduced to 5.9604646e-09
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:53:40: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:53:40: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 07/13/2016 16:53:40:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.79250002 * 1175; EvalErrorPrediction = 0.49957447 * 1175; time = 0.4999s; samplesPerSecond = 2350.6
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.06-seconds latency this time; accumulated time on sync point = 0.06 seconds , average latency = 0.06 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     1.10 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 4.45k samplesPerSecond , throughputPerWorker = 2.23k samplesPerSecond
MPI Rank 1: 07/13/2016 16:53:41:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.84656249 * 1251; EvalErrorPrediction = 0.52278177 * 1251; time = 0.6009s; samplesPerSecond = 2081.8
MPI Rank 1: 07/13/2016 16:53:41:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.79689491 * 1201; EvalErrorPrediction = 0.50624480 * 1201; time = 0.5196s; samplesPerSecond = 2311.6
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.05-seconds latency this time; accumulated time on sync point = 0.11 seconds , average latency = 0.06 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     1.10 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 4.45k samplesPerSecond , throughputPerWorker = 2.23k samplesPerSecond
MPI Rank 1: 07/13/2016 16:53:42:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.86177914 * 1202; EvalErrorPrediction = 0.51247920 * 1202; time = 0.5771s; samplesPerSecond = 2082.8
MPI Rank 1: 07/13/2016 16:53:43:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.84721351 * 1173; EvalErrorPrediction = 0.51491901 * 1173; time = 0.5134s; samplesPerSecond = 2284.8
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.08-seconds latency this time; accumulated time on sync point = 0.19 seconds , average latency = 0.06 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     1.11 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 4.38k samplesPerSecond , throughputPerWorker = 2.19k samplesPerSecond
MPI Rank 1: 07/13/2016 16:53:43:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.88048924 * 1194; EvalErrorPrediction = 0.52847571 * 1194; time = 0.5951s; samplesPerSecond = 2006.4
MPI Rank 1: 07/13/2016 16:53:43:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.79594091 * 827; EvalErrorPrediction = 0.51027811 * 827; time = 0.3640s; samplesPerSecond = 2272.0
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.73-seconds latency this time; accumulated time on sync point = 0.92 seconds , average latency = 0.23 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     2.18 seconds since last report (1.08 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 2.67k samplesPerSecond , throughputPerWorker = 1.33k samplesPerSecond
MPI Rank 1: 07/13/2016 16:53:45: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85586580 * 20480; EvalErrorPrediction = 0.51577148 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 5.9604646e-09; epochTime=5.49441s
MPI Rank 1: 07/13/2016 16:53:45: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160713165131.612468/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/13/2016 16:53:45: learnRatePerSample reduced to 2.9802323e-09
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:53:45: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:53:45: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 07/13/2016 16:53:46:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.79250003 * 1175; EvalErrorPrediction = 0.49957447 * 1175; time = 0.5086s; samplesPerSecond = 2310.1
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.04-seconds latency this time; accumulated time on sync point = 0.04 seconds , average latency = 0.04 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     1.10 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 4.45k samplesPerSecond , throughputPerWorker = 2.23k samplesPerSecond
MPI Rank 1: 07/13/2016 16:53:47:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.84656251 * 1251; EvalErrorPrediction = 0.52278177 * 1251; time = 0.5923s; samplesPerSecond = 2112.1
MPI Rank 1: 07/13/2016 16:53:47:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.79689499 * 1201; EvalErrorPrediction = 0.50624480 * 1201; time = 0.5259s; samplesPerSecond = 2283.9
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.05-seconds latency this time; accumulated time on sync point = 0.09 seconds , average latency = 0.05 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     1.12 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 4.37k samplesPerSecond , throughputPerWorker = 2.19k samplesPerSecond
MPI Rank 1: 07/13/2016 16:53:48:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.86177919 * 1202; EvalErrorPrediction = 0.51247920 * 1202; time = 0.5909s; samplesPerSecond = 2034.2
MPI Rank 1: 07/13/2016 16:53:48:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.84721374 * 1173; EvalErrorPrediction = 0.51491901 * 1173; time = 0.5041s; samplesPerSecond = 2327.0
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.04-seconds latency this time; accumulated time on sync point = 0.13 seconds , average latency = 0.04 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     1.09 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 4.47k samplesPerSecond , throughputPerWorker = 2.24k samplesPerSecond
MPI Rank 1: 07/13/2016 16:53:49:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.88048934 * 1194; EvalErrorPrediction = 0.52847571 * 1194; time = 0.5809s; samplesPerSecond = 2055.5
MPI Rank 1: 07/13/2016 16:53:49:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.79594105 * 827; EvalErrorPrediction = 0.51027811 * 827; time = 0.3400s; samplesPerSecond = 2432.5
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.76-seconds latency this time; accumulated time on sync point = 0.89 seconds , average latency = 0.22 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     2.21 seconds since last report (1.10 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 2.64k samplesPerSecond , throughputPerWorker = 1.32k samplesPerSecond
MPI Rank 1: 07/13/2016 16:53:51: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85586592 * 20480; EvalErrorPrediction = 0.51577148 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 2.9802323e-09; epochTime=5.51273s
MPI Rank 1: 07/13/2016 16:53:51: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160713165131.612468/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/13/2016 16:53:51: learnRatePerSample reduced to 1.4901161e-09
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:53:51: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:53:51: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 07/13/2016 16:53:52:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.79250003 * 1175; EvalErrorPrediction = 0.49957447 * 1175; time = 0.5046s; samplesPerSecond = 2328.5
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.06-seconds latency this time; accumulated time on sync point = 0.06 seconds , average latency = 0.06 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     1.13 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 4.34k samplesPerSecond , throughputPerWorker = 2.17k samplesPerSecond
MPI Rank 1: 07/13/2016 16:53:52:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.84656251 * 1251; EvalErrorPrediction = 0.52278177 * 1251; time = 0.6255s; samplesPerSecond = 2000.2
MPI Rank 1: 07/13/2016 16:53:53:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.79689503 * 1201; EvalErrorPrediction = 0.50624480 * 1201; time = 0.5283s; samplesPerSecond = 2273.5
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.10 seconds , average latency = 0.05 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     1.09 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 4.47k samplesPerSecond , throughputPerWorker = 2.23k samplesPerSecond
MPI Rank 1: 07/13/2016 16:53:53:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.86177921 * 1202; EvalErrorPrediction = 0.51247920 * 1202; time = 0.5651s; samplesPerSecond = 2127.1
MPI Rank 1: 07/13/2016 16:53:54:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.84721386 * 1173; EvalErrorPrediction = 0.51491901 * 1173; time = 0.4975s; samplesPerSecond = 2357.6
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.08-seconds latency this time; accumulated time on sync point = 0.18 seconds , average latency = 0.06 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     1.11 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 4.38k samplesPerSecond , throughputPerWorker = 2.19k samplesPerSecond
MPI Rank 1: 07/13/2016 16:53:54:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.88048939 * 1194; EvalErrorPrediction = 0.52847571 * 1194; time = 0.6112s; samplesPerSecond = 1953.6
MPI Rank 1: 07/13/2016 16:53:55:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.79594112 * 827; EvalErrorPrediction = 0.51027811 * 827; time = 0.3539s; samplesPerSecond = 2337.0
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.75-seconds latency this time; accumulated time on sync point = 0.93 seconds , average latency = 0.23 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     2.17 seconds since last report (1.06 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 2.68k samplesPerSecond , throughputPerWorker = 1.34k samplesPerSecond
MPI Rank 1: 07/13/2016 16:53:57: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85586598 * 20480; EvalErrorPrediction = 0.51577148 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 1.4901161e-09; epochTime=5.50977s
MPI Rank 1: 07/13/2016 16:53:57: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160713165131.612468/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/13/2016 16:53:57: learnRatePerSample reduced to 7.4505807e-10
MPI Rank 1: 07/13/2016 16:53:57: Learn Rate Per Sample for Epoch[5] = 7.4505807e-10 is less than minLearnRate 9.9999997e-10. Training complete.
MPI Rank 1: 07/13/2016 16:53:57: CNTKCommandTrainEnd: speechTrain
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:53:57: Action "train" complete.
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:53:57: __COMPLETED__
MPI Rank 1: ~MPIWrapper
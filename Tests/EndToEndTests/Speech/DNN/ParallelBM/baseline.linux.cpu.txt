CPU info:
    CPU Model Name: Intel(R) Xeon(R) CPU E5-2630 v2 @ 2.60GHz
    Hardware threads: 24
    Total Memory: 264172964 kB
-------------------------------------------------------------------
=== Running mpiexec -n 2 /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/build/1bitsgd/release/bin/cntk configFile=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/ParallelBM/../ParallelBM/cntk.cntk currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data RunDir=/tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_cpu DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/ParallelBM/.. OutputDir=/tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_cpu DeviceId=-1 timestamping=true numCPUThreads=12 precision=double speechTrain=[SGD=[ParallelTrain=[parallelizationStartEpoch=2]]] stderr=/tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_cpu/stderr
-------------------------------------------------------------------
Build info: 

		Built time: Jul 14 2016 12:05:02
		Last modified date: Thu Jul 14 10:47:21 2016
		Build type: release
		Build target: GPU
		With 1bit-SGD: yes
		Math lib: mkl
		CUDA_PATH: /usr/local/cuda-7.5
		CUB_PATH: /usr/local/cub-1.4.1
		CUDNN_PATH: /usr/local/cudnn-4.0
		Build Branch: HEAD
		Build SHA1: 72bee394bf461e8f6f0feb593a8416c05f481957
		Built by philly on a77bf6d98305
		Build Path: /home/philly/jenkins/workspace/CNTK-Build-Linux
-------------------------------------------------------------------
-------------------------------------------------------------------
Build info: 

		Built time: Jul 14 2016 12:05:02
		Last modified date: Thu Jul 14 10:47:21 2016
		Build type: release
		Build target: GPU
		With 1bit-SGD: yes
		Math lib: mkl
		CUDA_PATH: /usr/local/cuda-7.5
		CUB_PATH: /usr/local/cub-1.4.1
		CUDNN_PATH: /usr/local/cudnn-4.0
		Build Branch: HEAD
		Build SHA1: 72bee394bf461e8f6f0feb593a8416c05f481957
		Built by philly on a77bf6d98305
		Build Path: /home/philly/jenkins/workspace/CNTK-Build-Linux
-------------------------------------------------------------------
Changed current directory to /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
Changed current directory to /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
MPIWrapper: initializing MPI
MPIWrapper: initializing MPI
ping [requestnodes (before change)]: 2 nodes pinging each other
ping [requestnodes (before change)]: 2 nodes pinging each other
ping [requestnodes (before change)]: all 2 nodes responded
requestnodes [MPIWrapper]: using 2 out of 2 MPI nodes (2 requested); we (0) are in (participating)
ping [requestnodes (after change)]: 2 nodes pinging each other
ping [requestnodes (before change)]: all 2 nodes responded
requestnodes [MPIWrapper]: using 2 out of 2 MPI nodes (2 requested); we (1) are in (participating)
ping [requestnodes (after change)]: 2 nodes pinging each other
ping [requestnodes (after change)]: all 2 nodes responded
mpihelper: we are cog 0 in a gearbox of 2
ping [mpihelper]: 2 nodes pinging each other
ping [requestnodes (after change)]: all 2 nodes responded
mpihelper: we are cog 1 in a gearbox of 2
ping [mpihelper]: 2 nodes pinging each other
ping [mpihelper]: all 2 nodes responded
ping [mpihelper]: all 2 nodes responded
07/14/2016 12:41:20: Redirecting stderr to file /tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_cpu/stderr_speechTrain.logrank0
07/14/2016 12:41:21: Redirecting stderr to file /tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_cpu/stderr_speechTrain.logrank1
MPI Rank 0: 07/14/2016 12:41:20: -------------------------------------------------------------------
MPI Rank 0: 07/14/2016 12:41:20: Build info: 
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:41:20: 		Built time: Jul 14 2016 12:05:02
MPI Rank 0: 07/14/2016 12:41:20: 		Last modified date: Thu Jul 14 10:47:21 2016
MPI Rank 0: 07/14/2016 12:41:20: 		Build type: release
MPI Rank 0: 07/14/2016 12:41:20: 		Build target: GPU
MPI Rank 0: 07/14/2016 12:41:20: 		With 1bit-SGD: yes
MPI Rank 0: 07/14/2016 12:41:20: 		Math lib: mkl
MPI Rank 0: 07/14/2016 12:41:20: 		CUDA_PATH: /usr/local/cuda-7.5
MPI Rank 0: 07/14/2016 12:41:20: 		CUB_PATH: /usr/local/cub-1.4.1
MPI Rank 0: 07/14/2016 12:41:20: 		CUDNN_PATH: /usr/local/cudnn-4.0
MPI Rank 0: 07/14/2016 12:41:20: 		Build Branch: HEAD
MPI Rank 0: 07/14/2016 12:41:20: 		Build SHA1: 72bee394bf461e8f6f0feb593a8416c05f481957
MPI Rank 0: 07/14/2016 12:41:20: 		Built by philly on a77bf6d98305
MPI Rank 0: 07/14/2016 12:41:20: 		Build Path: /home/philly/jenkins/workspace/CNTK-Build-Linux
MPI Rank 0: 07/14/2016 12:41:20: -------------------------------------------------------------------
MPI Rank 0: 07/14/2016 12:41:22: -------------------------------------------------------------------
MPI Rank 0: 07/14/2016 12:41:22: GPU info:
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:41:22: 		Device[0]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3071 MB
MPI Rank 0: 07/14/2016 12:41:22: 		Device[1]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3071 MB
MPI Rank 0: 07/14/2016 12:41:22: 		Device[2]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3071 MB
MPI Rank 0: 07/14/2016 12:41:22: 		Device[3]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3071 MB
MPI Rank 0: 07/14/2016 12:41:22: -------------------------------------------------------------------
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:41:22: Running on localhost at 2016/07/14 12:41:22
MPI Rank 0: 07/14/2016 12:41:22: Command line: 
MPI Rank 0: /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/build/1bitsgd/release/bin/cntk  configFile=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/ParallelBM/../ParallelBM/cntk.cntk  currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data  RunDir=/tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_cpu  DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data  ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/ParallelBM/..  OutputDir=/tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_cpu  DeviceId=-1  timestamping=true  numCPUThreads=12  precision=double  speechTrain=[SGD=[ParallelTrain=[parallelizationStartEpoch=2]]]  stderr=/tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_cpu/stderr
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:41:22: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
MPI Rank 0: 07/14/2016 12:41:22: precision = "float"
MPI Rank 0: command = speechTrain
MPI Rank 0: deviceId = $DeviceId$
MPI Rank 0: parallelTrain = true
MPI Rank 0: speechTrain = [
MPI Rank 0:     action = "train"
MPI Rank 0:     modelPath = "$RunDir$/models/cntkSpeech.dnn"
MPI Rank 0:     deviceId = $DeviceId$
MPI Rank 0:     traceLevel = 1
MPI Rank 0:     SimpleNetworkBuilder = [
MPI Rank 0:         layerSizes = 363:512:512:132
MPI Rank 0:         trainingCriterion = "CrossEntropyWithSoftmax"
MPI Rank 0:         evalCriterion = "ErrorPrediction"
MPI Rank 0:         layerTypes = "Sigmoid"
MPI Rank 0:         initValueScale = 1.0
MPI Rank 0:         applyMeanVarNorm = true
MPI Rank 0:         uniformInit = true
MPI Rank 0:         needPrior = true
MPI Rank 0:     ]
MPI Rank 0:     ExperimentalNetworkBuilder = [    // the same as above but with BS. Not active; activate by commenting out the SimpleNetworkBuilder entry above
MPI Rank 0:         layerSizes = 363:512:512:132
MPI Rank 0:         trainingCriterion = 'CE'
MPI Rank 0:         evalCriterion = 'Err'
MPI Rank 0:         applyMeanVarNorm = true
MPI Rank 0:         L = Length(layerSizes)-1    // number of model layers
MPI Rank 0:         features = Input(layerSizes[0], 1, tag='feature') ; labels = Input(layerSizes[Length(layerSizes)-1], 1, tag='label')
MPI Rank 0:         featNorm = if applyMeanVarNorm
MPI Rank 0:                    then MeanVarNorm(features)
MPI Rank 0:                    else features
MPI Rank 0:         layers[layer:1..L-1] = if layer > 1
MPI Rank 0:                                then SBFF(layers[layer-1].Eh, layerSizes[layer], layerSizes[layer-1])
MPI Rank 0:                                else SBFF(featNorm, layerSizes[layer], layerSizes[layer-1])
MPI Rank 0:         outLayer = BFF(layers[L-1].Eh, layerSizes[L], layerSizes[L-1])
MPI Rank 0:         outZ = outLayer.z        // + PastValue(layerSizes[L], 1, outLayer.z)
MPI Rank 0:         CE = if trainingCriterion == 'CE'
MPI Rank 0:              then CrossEntropyWithSoftmax(labels, outZ, tag='criterion')
MPI Rank 0:              else Fail('unknown trainingCriterion ' + trainingCriterion)
MPI Rank 0:         Err = if evalCriterion == 'Err' then
MPI Rank 0:               ErrorPrediction(labels, outZ, tag='evaluation')
MPI Rank 0:               else Fail('unknown evalCriterion ' + evalCriterion)
MPI Rank 0:         logPrior = LogPrior(labels)
MPI Rank 0:         // TODO: how to add a tag to an infix operation?
MPI Rank 0:         ScaledLogLikelihood = Minus (outZ, logPrior, tag='output')
MPI Rank 0:     ]
MPI Rank 0:     SGD = [
MPI Rank 0:         epochSize = 20480
MPI Rank 0:         minibatchSize = 64:256:1024
MPI Rank 0:         learningRatesPerMB = 1.0:0.5:0.1
MPI Rank 0:         numMBsToShowResult = 3
MPI Rank 0:         momentumPerMB = 0.9:0.656119
MPI Rank 0:         dropoutRate = 0.0
MPI Rank 0:         maxEpochs = 5
MPI Rank 0:         keepCheckPointFiles = true
MPI Rank 0:         clippingThresholdPerSample = 1#INF
MPI Rank 0:         ParallelTrain = [
MPI Rank 0:             parallelizationMethod = "BlockMomentumSGD"
MPI Rank 0:             distributedMBReading = true
MPI Rank 0:             syncPerfStats=1
MPI Rank 0:             BlockMomentumSGD = [
MPI Rank 0:                 blockSizePerWorker=2048
MPI Rank 0:                 resetSGDMomentum=true
MPI Rank 0:                 useNesterovMomentum=true
MPI Rank 0:             ]
MPI Rank 0:         ]
MPI Rank 0:         AutoAdjust = [
MPI Rank 0:             reduceLearnRateIfImproveLessThan = 0
MPI Rank 0:             loadBestModel = true
MPI Rank 0:             increaseLearnRateIfImproveMoreThan = 1000000000
MPI Rank 0:             learnRateDecreaseFactor = 0.5
MPI Rank 0:             learnRateIncreaseFactor = 1.382
MPI Rank 0:             autoAdjustLR = "adjustAfterEpoch"
MPI Rank 0:         ]
MPI Rank 0:     ]
MPI Rank 0:     reader = [
MPI Rank 0:         readerType = "HTKMLFReader"
MPI Rank 0:         readMethod = "blockRandomize"
MPI Rank 0:         miniBatchMode = "partial"
MPI Rank 0:         randomize = "auto"
MPI Rank 0:         verbosity = 0
MPI Rank 0:         features = [
MPI Rank 0:             dim = 363
MPI Rank 0:             type = "real"
MPI Rank 0:             scpFile = "glob_0000.scp"
MPI Rank 0:         ]
MPI Rank 0:         labels = [
MPI Rank 0:             mlfFile = "$DataDir$/glob_0000.mlf"
MPI Rank 0:             labelMappingFile = "$DataDir$/state.list"
MPI Rank 0:             labelDim = 132
MPI Rank 0:             labelType = "category"
MPI Rank 0:         ]
MPI Rank 0:     ]
MPI Rank 0: ]
MPI Rank 0: currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
MPI Rank 0: RunDir=/tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_cpu
MPI Rank 0: DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
MPI Rank 0: ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/ParallelBM/..
MPI Rank 0: OutputDir=/tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_cpu
MPI Rank 0: DeviceId=-1
MPI Rank 0: timestamping=true
MPI Rank 0: numCPUThreads=12
MPI Rank 0: precision=double
MPI Rank 0: speechTrain=[SGD=[ParallelTrain=[parallelizationStartEpoch=2]]]
MPI Rank 0: stderr=/tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_cpu/stderr
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:41:22: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:41:22: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 0: 07/14/2016 12:41:22: precision = "float"
MPI Rank 0: command = speechTrain
MPI Rank 0: deviceId = -1
MPI Rank 0: parallelTrain = true
MPI Rank 0: speechTrain = [
MPI Rank 0:     action = "train"
MPI Rank 0:     modelPath = "/tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn"
MPI Rank 0:     deviceId = -1
MPI Rank 0:     traceLevel = 1
MPI Rank 0:     SimpleNetworkBuilder = [
MPI Rank 0:         layerSizes = 363:512:512:132
MPI Rank 0:         trainingCriterion = "CrossEntropyWithSoftmax"
MPI Rank 0:         evalCriterion = "ErrorPrediction"
MPI Rank 0:         layerTypes = "Sigmoid"
MPI Rank 0:         initValueScale = 1.0
MPI Rank 0:         applyMeanVarNorm = true
MPI Rank 0:         uniformInit = true
MPI Rank 0:         needPrior = true
MPI Rank 0:     ]
MPI Rank 0:     ExperimentalNetworkBuilder = [    // the same as above but with BS. Not active; activate by commenting out the SimpleNetworkBuilder entry above
MPI Rank 0:         layerSizes = 363:512:512:132
MPI Rank 0:         trainingCriterion = 'CE'
MPI Rank 0:         evalCriterion = 'Err'
MPI Rank 0:         applyMeanVarNorm = true
MPI Rank 0:         L = Length(layerSizes)-1    // number of model layers
MPI Rank 0:         features = Input(layerSizes[0], 1, tag='feature') ; labels = Input(layerSizes[Length(layerSizes)-1], 1, tag='label')
MPI Rank 0:         featNorm = if applyMeanVarNorm
MPI Rank 0:                    then MeanVarNorm(features)
MPI Rank 0:                    else features
MPI Rank 0:         layers[layer:1..L-1] = if layer > 1
MPI Rank 0:                                then SBFF(layers[layer-1].Eh, layerSizes[layer], layerSizes[layer-1])
MPI Rank 0:                                else SBFF(featNorm, layerSizes[layer], layerSizes[layer-1])
MPI Rank 0:         outLayer = BFF(layers[L-1].Eh, layerSizes[L], layerSizes[L-1])
MPI Rank 0:         outZ = outLayer.z        // + PastValue(layerSizes[L], 1, outLayer.z)
MPI Rank 0:         CE = if trainingCriterion == 'CE'
MPI Rank 0:              then CrossEntropyWithSoftmax(labels, outZ, tag='criterion')
MPI Rank 0:              else Fail('unknown trainingCriterion ' + trainingCriterion)
MPI Rank 0:         Err = if evalCriterion == 'Err' then
MPI Rank 0:               ErrorPrediction(labels, outZ, tag='evaluation')
MPI Rank 0:               else Fail('unknown evalCriterion ' + evalCriterion)
MPI Rank 0:         logPrior = LogPrior(labels)
MPI Rank 0:         // TODO: how to add a tag to an infix operation?
MPI Rank 0:         ScaledLogLikelihood = Minus (outZ, logPrior, tag='output')
MPI Rank 0:     ]
MPI Rank 0:     SGD = [
MPI Rank 0:         epochSize = 20480
MPI Rank 0:         minibatchSize = 64:256:1024
MPI Rank 0:         learningRatesPerMB = 1.0:0.5:0.1
MPI Rank 0:         numMBsToShowResult = 3
MPI Rank 0:         momentumPerMB = 0.9:0.656119
MPI Rank 0:         dropoutRate = 0.0
MPI Rank 0:         maxEpochs = 5
MPI Rank 0:         keepCheckPointFiles = true
MPI Rank 0:         clippingThresholdPerSample = 1#INF
MPI Rank 0:         ParallelTrain = [
MPI Rank 0:             parallelizationMethod = "BlockMomentumSGD"
MPI Rank 0:             distributedMBReading = true
MPI Rank 0:             syncPerfStats=1
MPI Rank 0:             BlockMomentumSGD = [
MPI Rank 0:                 blockSizePerWorker=2048
MPI Rank 0:                 resetSGDMomentum=true
MPI Rank 0:                 useNesterovMomentum=true
MPI Rank 0:             ]
MPI Rank 0:         ]
MPI Rank 0:         AutoAdjust = [
MPI Rank 0:             reduceLearnRateIfImproveLessThan = 0
MPI Rank 0:             loadBestModel = true
MPI Rank 0:             increaseLearnRateIfImproveMoreThan = 1000000000
MPI Rank 0:             learnRateDecreaseFactor = 0.5
MPI Rank 0:             learnRateIncreaseFactor = 1.382
MPI Rank 0:             autoAdjustLR = "adjustAfterEpoch"
MPI Rank 0:         ]
MPI Rank 0:     ]
MPI Rank 0:     reader = [
MPI Rank 0:         readerType = "HTKMLFReader"
MPI Rank 0:         readMethod = "blockRandomize"
MPI Rank 0:         miniBatchMode = "partial"
MPI Rank 0:         randomize = "auto"
MPI Rank 0:         verbosity = 0
MPI Rank 0:         features = [
MPI Rank 0:             dim = 363
MPI Rank 0:             type = "real"
MPI Rank 0:             scpFile = "glob_0000.scp"
MPI Rank 0:         ]
MPI Rank 0:         labels = [
MPI Rank 0:             mlfFile = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/glob_0000.mlf"
MPI Rank 0:             labelMappingFile = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/state.list"
MPI Rank 0:             labelDim = 132
MPI Rank 0:             labelType = "category"
MPI Rank 0:         ]
MPI Rank 0:     ]
MPI Rank 0: ]
MPI Rank 0: currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
MPI Rank 0: RunDir=/tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_cpu
MPI Rank 0: DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
MPI Rank 0: ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/ParallelBM/..
MPI Rank 0: OutputDir=/tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_cpu
MPI Rank 0: DeviceId=-1
MPI Rank 0: timestamping=true
MPI Rank 0: numCPUThreads=12
MPI Rank 0: precision=double
MPI Rank 0: speechTrain=[SGD=[ParallelTrain=[parallelizationStartEpoch=2]]]
MPI Rank 0: stderr=/tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_cpu/stderr
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:41:22: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:41:22: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 0: configparameters: cntk.cntk:command=speechTrain
MPI Rank 0: configparameters: cntk.cntk:ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/ParallelBM/..
MPI Rank 0: configparameters: cntk.cntk:currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
MPI Rank 0: configparameters: cntk.cntk:DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
MPI Rank 0: configparameters: cntk.cntk:deviceId=-1
MPI Rank 0: configparameters: cntk.cntk:numCPUThreads=12
MPI Rank 0: configparameters: cntk.cntk:OutputDir=/tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_cpu
MPI Rank 0: configparameters: cntk.cntk:parallelTrain=true
MPI Rank 0: configparameters: cntk.cntk:precision=double
MPI Rank 0: configparameters: cntk.cntk:RunDir=/tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_cpu
MPI Rank 0: configparameters: cntk.cntk:speechTrain=[
MPI Rank 0:     action = "train"
MPI Rank 0:     modelPath = "/tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn"
MPI Rank 0:     deviceId = -1
MPI Rank 0:     traceLevel = 1
MPI Rank 0:     SimpleNetworkBuilder = [
MPI Rank 0:         layerSizes = 363:512:512:132
MPI Rank 0:         trainingCriterion = "CrossEntropyWithSoftmax"
MPI Rank 0:         evalCriterion = "ErrorPrediction"
MPI Rank 0:         layerTypes = "Sigmoid"
MPI Rank 0:         initValueScale = 1.0
MPI Rank 0:         applyMeanVarNorm = true
MPI Rank 0:         uniformInit = true
MPI Rank 0:         needPrior = true
MPI Rank 0:     ]
MPI Rank 0:     ExperimentalNetworkBuilder = [    // the same as above but with BS. Not active; activate by commenting out the SimpleNetworkBuilder entry above
MPI Rank 0:         layerSizes = 363:512:512:132
MPI Rank 0:         trainingCriterion = 'CE'
MPI Rank 0:         evalCriterion = 'Err'
MPI Rank 0:         applyMeanVarNorm = true
MPI Rank 0:         L = Length(layerSizes)-1    // number of model layers
MPI Rank 0:         features = Input(layerSizes[0], 1, tag='feature') ; labels = Input(layerSizes[Length(layerSizes)-1], 1, tag='label')
MPI Rank 0:         featNorm = if applyMeanVarNorm
MPI Rank 0:                    then MeanVarNorm(features)
MPI Rank 0:                    else features
MPI Rank 0:         layers[layer:1..L-1] = if layer > 1
MPI Rank 0:                                then SBFF(layers[layer-1].Eh, layerSizes[layer], layerSizes[layer-1])
MPI Rank 0:                                else SBFF(featNorm, layerSizes[layer], layerSizes[layer-1])
MPI Rank 0:         outLayer = BFF(layers[L-1].Eh, layerSizes[L], layerSizes[L-1])
MPI Rank 0:         outZ = outLayer.z        // + PastValue(layerSizes[L], 1, outLayer.z)
MPI Rank 0:         CE = if trainingCriterion == 'CE'
MPI Rank 0:              then CrossEntropyWithSoftmax(labels, outZ, tag='criterion')
MPI Rank 0:              else Fail('unknown trainingCriterion ' + trainingCriterion)
MPI Rank 0:         Err = if evalCriterion == 'Err' then
MPI Rank 0:               ErrorPrediction(labels, outZ, tag='evaluation')
MPI Rank 0:               else Fail('unknown evalCriterion ' + evalCriterion)
MPI Rank 0:         logPrior = LogPrior(labels)
MPI Rank 0:         // TODO: how to add a tag to an infix operation?
MPI Rank 0:         ScaledLogLikelihood = Minus (outZ, logPrior, tag='output')
MPI Rank 0:     ]
MPI Rank 0:     SGD = [
MPI Rank 0:         epochSize = 20480
MPI Rank 0:         minibatchSize = 64:256:1024
MPI Rank 0:         learningRatesPerMB = 1.0:0.5:0.1
MPI Rank 0:         numMBsToShowResult = 3
MPI Rank 0:         momentumPerMB = 0.9:0.656119
MPI Rank 0:         dropoutRate = 0.0
MPI Rank 0:         maxEpochs = 5
MPI Rank 0:         keepCheckPointFiles = true
MPI Rank 0:         clippingThresholdPerSample = 1#INF
MPI Rank 0:         ParallelTrain = [
MPI Rank 0:             parallelizationMethod = "BlockMomentumSGD"
MPI Rank 0:             distributedMBReading = true
MPI Rank 0:             syncPerfStats=1
MPI Rank 0:             BlockMomentumSGD = [
MPI Rank 0:                 blockSizePerWorker=2048
MPI Rank 0:                 resetSGDMomentum=true
MPI Rank 0:                 useNesterovMomentum=true
MPI Rank 0:             ]
MPI Rank 0:         ]
MPI Rank 0:         AutoAdjust = [
MPI Rank 0:             reduceLearnRateIfImproveLessThan = 0
MPI Rank 0:             loadBestModel = true
MPI Rank 0:             increaseLearnRateIfImproveMoreThan = 1000000000
MPI Rank 0:             learnRateDecreaseFactor = 0.5
MPI Rank 0:             learnRateIncreaseFactor = 1.382
MPI Rank 0:             autoAdjustLR = "adjustAfterEpoch"
MPI Rank 0:         ]
MPI Rank 0:     ]
MPI Rank 0:     reader = [
MPI Rank 0:         readerType = "HTKMLFReader"
MPI Rank 0:         readMethod = "blockRandomize"
MPI Rank 0:         miniBatchMode = "partial"
MPI Rank 0:         randomize = "auto"
MPI Rank 0:         verbosity = 0
MPI Rank 0:         features = [
MPI Rank 0:             dim = 363
MPI Rank 0:             type = "real"
MPI Rank 0:             scpFile = "glob_0000.scp"
MPI Rank 0:         ]
MPI Rank 0:         labels = [
MPI Rank 0:             mlfFile = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/glob_0000.mlf"
MPI Rank 0:             labelMappingFile = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/state.list"
MPI Rank 0:             labelDim = 132
MPI Rank 0:             labelType = "category"
MPI Rank 0:         ]
MPI Rank 0:     ]
MPI Rank 0: ] [SGD=[ParallelTrain=[parallelizationStartEpoch=2]]]
MPI Rank 0: 
MPI Rank 0: configparameters: cntk.cntk:stderr=/tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_cpu/stderr
MPI Rank 0: configparameters: cntk.cntk:timestamping=true
MPI Rank 0: 07/14/2016 12:41:22: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 0: 07/14/2016 12:41:22: Commands: speechTrain
MPI Rank 0: 07/14/2016 12:41:22: Precision = "double"
MPI Rank 0: 07/14/2016 12:41:22: Using 12 CPU threads.
MPI Rank 0: 07/14/2016 12:41:22: CNTKModelPath: /tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn
MPI Rank 0: 07/14/2016 12:41:22: CNTKCommandTrainInfo: speechTrain : 5
MPI Rank 0: 07/14/2016 12:41:22: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 5
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:41:22: ##############################################################################
MPI Rank 0: 07/14/2016 12:41:22: #                                                                            #
MPI Rank 0: 07/14/2016 12:41:22: # Action "train"                                                             #
MPI Rank 0: 07/14/2016 12:41:22: #                                                                            #
MPI Rank 0: 07/14/2016 12:41:22: ##############################################################################
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:41:22: CNTKCommandTrainBegin: speechTrain
MPI Rank 0: SimpleNetworkBuilder Using CPU
MPI Rank 0: reading script file glob_0000.scp ... 948 entries
MPI Rank 0: total 132 state names in state list /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/state.list
MPI Rank 0: htkmlfreader: reading MLF file /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/glob_0000.mlf ... total 948 entries
MPI Rank 0: ...............................................................................................feature set 0: 252734 frames in 948 out of 948 utterances
MPI Rank 0: label set 0: 129 classes
MPI Rank 0: minibatchutterancesource: 948 utterances grouped into 3 chunks, av. chunk size: 316.0 utterances, 84244.7 frames
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:41:22: Creating virgin network.
MPI Rank 0: 
MPI Rank 0: Post-processing network...
MPI Rank 0: 
MPI Rank 0: 7 roots:
MPI Rank 0: 	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
MPI Rank 0: 	EvalErrorPrediction = ErrorPrediction()
MPI Rank 0: 	InvStdOfFeatures = InvStdDev()
MPI Rank 0: 	MeanOfFeatures = Mean()
MPI Rank 0: 	PosteriorProb = Softmax()
MPI Rank 0: 	Prior = Mean()
MPI Rank 0: 	ScaledLogLikelihood = Minus()
MPI Rank 0: 
MPI Rank 0: Validating network. 25 nodes to process in pass 1.
MPI Rank 0: 
MPI Rank 0: Validating --> labels = InputValue() :  -> [132 x *]
MPI Rank 0: Validating --> W2 = LearnableParameter() :  -> [132 x 512]
MPI Rank 0: Validating --> W1 = LearnableParameter() :  -> [512 x 512]
MPI Rank 0: Validating --> W0 = LearnableParameter() :  -> [512 x 363]
MPI Rank 0: Validating --> features = InputValue() :  -> [363 x *]
MPI Rank 0: Validating --> MeanOfFeatures = Mean (features) : [363 x *] -> [363]
MPI Rank 0: Validating --> InvStdOfFeatures = InvStdDev (features) : [363 x *] -> [363]
MPI Rank 0: Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [363 x *], [363], [363] -> [363 x *]
MPI Rank 0: Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [512 x 363], [363 x *] -> [512 x *]
MPI Rank 0: Validating --> B0 = LearnableParameter() :  -> [512 x 1]
MPI Rank 0: Validating --> W0*features+B0 = Plus (W0*features, B0) : [512 x *], [512 x 1] -> [512 x 1 x *]
MPI Rank 0: Validating --> H1 = Sigmoid (W0*features+B0) : [512 x 1 x *] -> [512 x 1 x *]
MPI Rank 0: Validating --> W1*H1 = Times (W1, H1) : [512 x 512], [512 x 1 x *] -> [512 x 1 x *]
MPI Rank 0: Validating --> B1 = LearnableParameter() :  -> [512 x 1]
MPI Rank 0: Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [512 x 1 x *], [512 x 1] -> [512 x 1 x *]
MPI Rank 0: Validating --> H2 = Sigmoid (W1*H1+B1) : [512 x 1 x *] -> [512 x 1 x *]
MPI Rank 0: Validating --> W2*H1 = Times (W2, H2) : [132 x 512], [512 x 1 x *] -> [132 x 1 x *]
MPI Rank 0: Validating --> B2 = LearnableParameter() :  -> [132 x 1]
MPI Rank 0: Validating --> HLast = Plus (W2*H1, B2) : [132 x 1 x *], [132 x 1] -> [132 x 1 x *]
MPI Rank 0: Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [132 x *], [132 x 1 x *] -> [1]
MPI Rank 0: Validating --> EvalErrorPrediction = ErrorPrediction (labels, HLast) : [132 x *], [132 x 1 x *] -> [1]
MPI Rank 0: Validating --> PosteriorProb = Softmax (HLast) : [132 x 1 x *] -> [132 x 1 x *]
MPI Rank 0: Validating --> Prior = Mean (labels) : [132 x *] -> [132]
MPI Rank 0: Validating --> LogOfPrior = Log (Prior) : [132] -> [132]
MPI Rank 0: Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [132 x 1 x *], [132] -> [132 x 1 x *]
MPI Rank 0: 
MPI Rank 0: Validating network. 17 nodes to process in pass 2.
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: Validating network, final pass.
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: 12 out of 25 nodes do not share the minibatch layout with the input data.
MPI Rank 0: 
MPI Rank 0: Post-processing network complete.
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:41:22: Created model with 25 nodes on CPU.
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:41:22: Training criterion node(s):
MPI Rank 0: 07/14/2016 12:41:22: 	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:41:22: Evaluation criterion node(s):
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:41:22: 	EvalErrorPrediction = ErrorPrediction
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: Allocating matrices for forward and/or backward propagation.
MPI Rank 0: 
MPI Rank 0: Memory Sharing Structure:
MPI Rank 0: 
MPI Rank 0: (nil): {[EvalErrorPrediction Gradient[1]] [InvStdOfFeatures Gradient[363]] [LogOfPrior Gradient[132]] [MVNormalizedFeatures Gradient[363 x *]] [MeanOfFeatures Gradient[363]] [PosteriorProb Gradient[132 x 1 x *]] [PosteriorProb Value[132 x 1 x *]] [Prior Gradient[132]] [ScaledLogLikelihood Gradient[132 x 1 x *]] [features Gradient[363 x *]] [labels Gradient[132 x *]] }
MPI Rank 0: 0x2fc4fb8: {[MeanOfFeatures Value[363]] }
MPI Rank 0: 0x2ff88c8: {[W0 Gradient[512 x 363]] [W0*features+B0 Value[512 x 1 x *]] }
MPI Rank 0: 0x2ff8a88: {[H1 Value[512 x 1 x *]] [W0*features Gradient[512 x *]] }
MPI Rank 0: 0x2ff8c48: {[W0*features+B0 Gradient[512 x 1 x *]] [W1*H1 Value[512 x 1 x *]] }
MPI Rank 0: 0x2ff8e08: {[W1 Gradient[512 x 512]] [W1*H1+B1 Value[512 x 1 x *]] }
MPI Rank 0: 0x2ff8fc8: {[H2 Value[512 x 1 x *]] [W1*H1 Gradient[512 x 1 x *]] }
MPI Rank 0: 0x30188c8: {[InvStdOfFeatures Value[363]] }
MPI Rank 0: 0x3018f68: {[EvalErrorPrediction Value[1]] }
MPI Rank 0: 0x301b828: {[MVNormalizedFeatures Value[363 x *]] }
MPI Rank 0: 0x301bad8: {[B0 Value[512 x 1]] }
MPI Rank 0: 0x30cc9e8: {[B2 Value[132 x 1]] }
MPI Rank 0: 0x30ccae8: {[labels Value[132 x *]] }
MPI Rank 0: 0x30f40b8: {[CrossEntropyWithSoftmax Gradient[1]] }
MPI Rank 0: 0x30f4598: {[CrossEntropyWithSoftmax Value[1]] }
MPI Rank 0: 0x3124368: {[W0 Value[512 x 363]] }
MPI Rank 0: 0x312f7e8: {[W1 Value[512 x 512]] }
MPI Rank 0: 0x3136058: {[W2 Value[132 x 512]] }
MPI Rank 0: 0x3136bc8: {[ScaledLogLikelihood Value[132 x 1 x *]] }
MPI Rank 0: 0x3138be8: {[W0*features Value[512 x *]] }
MPI Rank 0: 0x3138c98: {[LogOfPrior Value[132]] }
MPI Rank 0: 0x313b078: {[B1 Gradient[512 x 1]] [H2 Gradient[512 x 1 x *]] [HLast Gradient[132 x 1 x *]] }
MPI Rank 0: 0x313b238: {[W2*H1 Gradient[132 x 1 x *]] }
MPI Rank 0: 0x313b3f8: {[B2 Gradient[132 x 1]] }
MPI Rank 0: 0x31412c8: {[B0 Gradient[512 x 1]] [H1 Gradient[512 x 1 x *]] [W1*H1+B1 Gradient[512 x 1 x *]] [W2*H1 Value[132 x 1 x *]] }
MPI Rank 0: 0x3141488: {[HLast Value[132 x 1 x *]] [W2 Gradient[132 x 512]] }
MPI Rank 0: 0x3146f88: {[B1 Value[512 x 1]] }
MPI Rank 0: 0x3334508: {[Prior Value[132]] }
MPI Rank 0: 0x333c248: {[features Value[363 x *]] }
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:41:22: Precomputing --> 3 PreCompute nodes found.
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:41:22: 	MeanOfFeatures = Mean()
MPI Rank 0: 07/14/2016 12:41:22: 	InvStdOfFeatures = InvStdDev()
MPI Rank 0: 07/14/2016 12:41:22: 	Prior = Mean()
MPI Rank 0: minibatchiterator: epoch 0: frames [0..252734] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
MPI Rank 0: requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:41:24: Precomputing --> Completed.
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:41:24: Starting Epoch 1: learning rate per sample = 0.015625  effective momentum = 0.900000  momentum as time constant = 607.4 samples
MPI Rank 0: minibatchiterator: epoch 0: frames [0..20480] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:41:24: Starting minibatch loop.
MPI Rank 0: 07/14/2016 12:41:24:  Epoch[ 1 of 5]-Minibatch[   1-   3, 0.94%]: CrossEntropyWithSoftmax = 4.56947300 * 192; EvalErrorPrediction = 0.93750000 * 192; time = 0.1048s; samplesPerSecond = 1832.4
MPI Rank 0: 07/14/2016 12:41:24:  Epoch[ 1 of 5]-Minibatch[   4-   6, 1.88%]: CrossEntropyWithSoftmax = 4.43406315 * 192; EvalErrorPrediction = 0.93229167 * 192; time = 0.0952s; samplesPerSecond = 2015.9
MPI Rank 0: 07/14/2016 12:41:24:  Epoch[ 1 of 5]-Minibatch[   7-   9, 2.81%]: CrossEntropyWithSoftmax = 4.27880063 * 192; EvalErrorPrediction = 0.86458333 * 192; time = 0.0945s; samplesPerSecond = 2032.1
MPI Rank 0: 07/14/2016 12:41:24:  Epoch[ 1 of 5]-Minibatch[  10-  12, 3.75%]: CrossEntropyWithSoftmax = 4.08751953 * 192; EvalErrorPrediction = 0.86979167 * 192; time = 0.0959s; samplesPerSecond = 2002.7
MPI Rank 0: 07/14/2016 12:41:24:  Epoch[ 1 of 5]-Minibatch[  13-  15, 4.69%]: CrossEntropyWithSoftmax = 4.21737559 * 192; EvalErrorPrediction = 0.91145833 * 192; time = 0.0955s; samplesPerSecond = 2010.7
MPI Rank 0: 07/14/2016 12:41:24:  Epoch[ 1 of 5]-Minibatch[  16-  18, 5.62%]: CrossEntropyWithSoftmax = 4.14259750 * 192; EvalErrorPrediction = 0.92187500 * 192; time = 0.0979s; samplesPerSecond = 1961.2
MPI Rank 0: 07/14/2016 12:41:25:  Epoch[ 1 of 5]-Minibatch[  19-  21, 6.56%]: CrossEntropyWithSoftmax = 4.03221539 * 192; EvalErrorPrediction = 0.85416667 * 192; time = 0.1009s; samplesPerSecond = 1902.9
MPI Rank 0: 07/14/2016 12:41:25:  Epoch[ 1 of 5]-Minibatch[  22-  24, 7.50%]: CrossEntropyWithSoftmax = 4.09889450 * 192; EvalErrorPrediction = 0.89062500 * 192; time = 0.0939s; samplesPerSecond = 2044.7
MPI Rank 0: 07/14/2016 12:41:25:  Epoch[ 1 of 5]-Minibatch[  25-  27, 8.44%]: CrossEntropyWithSoftmax = 3.89612175 * 192; EvalErrorPrediction = 0.83854167 * 192; time = 0.0944s; samplesPerSecond = 2034.3
MPI Rank 0: 07/14/2016 12:41:25:  Epoch[ 1 of 5]-Minibatch[  28-  30, 9.38%]: CrossEntropyWithSoftmax = 3.98897999 * 192; EvalErrorPrediction = 0.88020833 * 192; time = 0.0948s; samplesPerSecond = 2024.5
MPI Rank 0: 07/14/2016 12:41:25:  Epoch[ 1 of 5]-Minibatch[  31-  33, 10.31%]: CrossEntropyWithSoftmax = 3.93572978 * 192; EvalErrorPrediction = 0.83333333 * 192; time = 0.0933s; samplesPerSecond = 2057.0
MPI Rank 0: 07/14/2016 12:41:25:  Epoch[ 1 of 5]-Minibatch[  34-  36, 11.25%]: CrossEntropyWithSoftmax = 3.76284095 * 192; EvalErrorPrediction = 0.89062500 * 192; time = 0.0955s; samplesPerSecond = 2009.4
MPI Rank 0: 07/14/2016 12:41:25:  Epoch[ 1 of 5]-Minibatch[  37-  39, 12.19%]: CrossEntropyWithSoftmax = 3.98522385 * 192; EvalErrorPrediction = 0.87500000 * 192; time = 0.0968s; samplesPerSecond = 1984.3
MPI Rank 0: 07/14/2016 12:41:25:  Epoch[ 1 of 5]-Minibatch[  40-  42, 13.12%]: CrossEntropyWithSoftmax = 3.66209590 * 192; EvalErrorPrediction = 0.84895833 * 192; time = 0.0966s; samplesPerSecond = 1987.4
MPI Rank 0: 07/14/2016 12:41:25:  Epoch[ 1 of 5]-Minibatch[  43-  45, 14.06%]: CrossEntropyWithSoftmax = 3.96368107 * 192; EvalErrorPrediction = 0.91666667 * 192; time = 0.0950s; samplesPerSecond = 2020.8
MPI Rank 0: 07/14/2016 12:41:25:  Epoch[ 1 of 5]-Minibatch[  46-  48, 15.00%]: CrossEntropyWithSoftmax = 3.76732554 * 192; EvalErrorPrediction = 0.85416667 * 192; time = 0.0947s; samplesPerSecond = 2027.4
MPI Rank 0: 07/14/2016 12:41:25:  Epoch[ 1 of 5]-Minibatch[  49-  51, 15.94%]: CrossEntropyWithSoftmax = 3.69456327 * 192; EvalErrorPrediction = 0.89062500 * 192; time = 0.0956s; samplesPerSecond = 2009.4
MPI Rank 0: 07/14/2016 12:41:26:  Epoch[ 1 of 5]-Minibatch[  52-  54, 16.88%]: CrossEntropyWithSoftmax = 3.82975145 * 192; EvalErrorPrediction = 0.89583333 * 192; time = 0.0995s; samplesPerSecond = 1929.2
MPI Rank 0: 07/14/2016 12:41:26:  Epoch[ 1 of 5]-Minibatch[  55-  57, 17.81%]: CrossEntropyWithSoftmax = 3.82370243 * 192; EvalErrorPrediction = 0.88020833 * 192; time = 0.0948s; samplesPerSecond = 2024.3
MPI Rank 0: 07/14/2016 12:41:26:  Epoch[ 1 of 5]-Minibatch[  58-  60, 18.75%]: CrossEntropyWithSoftmax = 3.57625565 * 192; EvalErrorPrediction = 0.84895833 * 192; time = 0.0947s; samplesPerSecond = 2028.5
MPI Rank 0: 07/14/2016 12:41:26:  Epoch[ 1 of 5]-Minibatch[  61-  63, 19.69%]: CrossEntropyWithSoftmax = 3.38811493 * 192; EvalErrorPrediction = 0.79166667 * 192; time = 0.0968s; samplesPerSecond = 1983.3
MPI Rank 0: 07/14/2016 12:41:26:  Epoch[ 1 of 5]-Minibatch[  64-  66, 20.62%]: CrossEntropyWithSoftmax = 3.52208661 * 192; EvalErrorPrediction = 0.77604167 * 192; time = 0.0954s; samplesPerSecond = 2012.1
MPI Rank 0: 07/14/2016 12:41:26:  Epoch[ 1 of 5]-Minibatch[  67-  69, 21.56%]: CrossEntropyWithSoftmax = 3.80866929 * 192; EvalErrorPrediction = 0.87500000 * 192; time = 0.0958s; samplesPerSecond = 2004.7
MPI Rank 0: 07/14/2016 12:41:26:  Epoch[ 1 of 5]-Minibatch[  70-  72, 22.50%]: CrossEntropyWithSoftmax = 3.54345746 * 192; EvalErrorPrediction = 0.86458333 * 192; time = 0.1042s; samplesPerSecond = 1842.6
MPI Rank 0: 07/14/2016 12:41:26:  Epoch[ 1 of 5]-Minibatch[  73-  75, 23.44%]: CrossEntropyWithSoftmax = 3.33936350 * 192; EvalErrorPrediction = 0.80208333 * 192; time = 0.0953s; samplesPerSecond = 2014.4
MPI Rank 0: 07/14/2016 12:41:26:  Epoch[ 1 of 5]-Minibatch[  76-  78, 24.38%]: CrossEntropyWithSoftmax = 3.43672338 * 192; EvalErrorPrediction = 0.78125000 * 192; time = 0.0966s; samplesPerSecond = 1987.2
MPI Rank 0: 07/14/2016 12:41:26:  Epoch[ 1 of 5]-Minibatch[  79-  81, 25.31%]: CrossEntropyWithSoftmax = 3.44585129 * 192; EvalErrorPrediction = 0.82812500 * 192; time = 0.0940s; samplesPerSecond = 2041.6
MPI Rank 0: 07/14/2016 12:41:27:  Epoch[ 1 of 5]-Minibatch[  82-  84, 26.25%]: CrossEntropyWithSoftmax = 3.43498669 * 192; EvalErrorPrediction = 0.76041667 * 192; time = 0.0963s; samplesPerSecond = 1993.1
MPI Rank 0: 07/14/2016 12:41:27:  Epoch[ 1 of 5]-Minibatch[  85-  87, 27.19%]: CrossEntropyWithSoftmax = 3.31632754 * 192; EvalErrorPrediction = 0.75000000 * 192; time = 0.1032s; samplesPerSecond = 1861.3
MPI Rank 0: 07/14/2016 12:41:27:  Epoch[ 1 of 5]-Minibatch[  88-  90, 28.12%]: CrossEntropyWithSoftmax = 3.33946924 * 192; EvalErrorPrediction = 0.80208333 * 192; time = 0.0993s; samplesPerSecond = 1933.0
MPI Rank 0: 07/14/2016 12:41:27:  Epoch[ 1 of 5]-Minibatch[  91-  93, 29.06%]: CrossEntropyWithSoftmax = 3.26118575 * 192; EvalErrorPrediction = 0.84375000 * 192; time = 0.0923s; samplesPerSecond = 2079.7
MPI Rank 0: 07/14/2016 12:41:27:  Epoch[ 1 of 5]-Minibatch[  94-  96, 30.00%]: CrossEntropyWithSoftmax = 3.56686839 * 192; EvalErrorPrediction = 0.85416667 * 192; time = 0.0974s; samplesPerSecond = 1970.4
MPI Rank 0: 07/14/2016 12:41:27:  Epoch[ 1 of 5]-Minibatch[  97-  99, 30.94%]: CrossEntropyWithSoftmax = 3.36674876 * 192; EvalErrorPrediction = 0.85416667 * 192; time = 0.0963s; samplesPerSecond = 1994.3
MPI Rank 0: 07/14/2016 12:41:27:  Epoch[ 1 of 5]-Minibatch[ 100- 102, 31.87%]: CrossEntropyWithSoftmax = 3.28977127 * 192; EvalErrorPrediction = 0.81250000 * 192; time = 0.0956s; samplesPerSecond = 2007.4
MPI Rank 0: 07/14/2016 12:41:27:  Epoch[ 1 of 5]-Minibatch[ 103- 105, 32.81%]: CrossEntropyWithSoftmax = 3.27969909 * 192; EvalErrorPrediction = 0.79166667 * 192; time = 0.0957s; samplesPerSecond = 2007.2
MPI Rank 0: 07/14/2016 12:41:27:  Epoch[ 1 of 5]-Minibatch[ 106- 108, 33.75%]: CrossEntropyWithSoftmax = 3.12259596 * 192; EvalErrorPrediction = 0.72916667 * 192; time = 0.0955s; samplesPerSecond = 2010.3
MPI Rank 0: 07/14/2016 12:41:27:  Epoch[ 1 of 5]-Minibatch[ 109- 111, 34.69%]: CrossEntropyWithSoftmax = 3.41981056 * 192; EvalErrorPrediction = 0.77604167 * 192; time = 0.0953s; samplesPerSecond = 2014.8
MPI Rank 0: 07/14/2016 12:41:27:  Epoch[ 1 of 5]-Minibatch[ 112- 114, 35.62%]: CrossEntropyWithSoftmax = 3.38297602 * 192; EvalErrorPrediction = 0.79166667 * 192; time = 0.0971s; samplesPerSecond = 1977.5
MPI Rank 0: 07/14/2016 12:41:28:  Epoch[ 1 of 5]-Minibatch[ 115- 117, 36.56%]: CrossEntropyWithSoftmax = 3.41994711 * 192; EvalErrorPrediction = 0.82812500 * 192; time = 0.0964s; samplesPerSecond = 1991.6
MPI Rank 0: 07/14/2016 12:41:28:  Epoch[ 1 of 5]-Minibatch[ 118- 120, 37.50%]: CrossEntropyWithSoftmax = 3.24732267 * 192; EvalErrorPrediction = 0.78125000 * 192; time = 0.0972s; samplesPerSecond = 1975.3
MPI Rank 0: 07/14/2016 12:41:28:  Epoch[ 1 of 5]-Minibatch[ 121- 123, 38.44%]: CrossEntropyWithSoftmax = 3.20269035 * 192; EvalErrorPrediction = 0.76041667 * 192; time = 0.0960s; samplesPerSecond = 2000.4
MPI Rank 0: 07/14/2016 12:41:28:  Epoch[ 1 of 5]-Minibatch[ 124- 126, 39.38%]: CrossEntropyWithSoftmax = 3.15326365 * 192; EvalErrorPrediction = 0.74479167 * 192; time = 0.0958s; samplesPerSecond = 2004.8
MPI Rank 0: 07/14/2016 12:41:28:  Epoch[ 1 of 5]-Minibatch[ 127- 129, 40.31%]: CrossEntropyWithSoftmax = 3.21802066 * 192; EvalErrorPrediction = 0.78125000 * 192; time = 0.0944s; samplesPerSecond = 2034.9
MPI Rank 0: 07/14/2016 12:41:28:  Epoch[ 1 of 5]-Minibatch[ 130- 132, 41.25%]: CrossEntropyWithSoftmax = 3.26091070 * 192; EvalErrorPrediction = 0.76041667 * 192; time = 0.0939s; samplesPerSecond = 2044.6
MPI Rank 0: 07/14/2016 12:41:28:  Epoch[ 1 of 5]-Minibatch[ 133- 135, 42.19%]: CrossEntropyWithSoftmax = 2.94987113 * 192; EvalErrorPrediction = 0.68229167 * 192; time = 0.0956s; samplesPerSecond = 2008.6
MPI Rank 0: 07/14/2016 12:41:28:  Epoch[ 1 of 5]-Minibatch[ 136- 138, 43.12%]: CrossEntropyWithSoftmax = 3.01829231 * 192; EvalErrorPrediction = 0.70312500 * 192; time = 0.0976s; samplesPerSecond = 1967.0
MPI Rank 0: 07/14/2016 12:41:28:  Epoch[ 1 of 5]-Minibatch[ 139- 141, 44.06%]: CrossEntropyWithSoftmax = 3.19981302 * 192; EvalErrorPrediction = 0.76562500 * 192; time = 0.0972s; samplesPerSecond = 1974.9
MPI Rank 0: 07/14/2016 12:41:28:  Epoch[ 1 of 5]-Minibatch[ 142- 144, 45.00%]: CrossEntropyWithSoftmax = 3.01620054 * 192; EvalErrorPrediction = 0.72916667 * 192; time = 0.0987s; samplesPerSecond = 1945.6
MPI Rank 0: 07/14/2016 12:41:29:  Epoch[ 1 of 5]-Minibatch[ 145- 147, 45.94%]: CrossEntropyWithSoftmax = 3.07482512 * 192; EvalErrorPrediction = 0.76562500 * 192; time = 0.0956s; samplesPerSecond = 2007.8
MPI Rank 0: 07/14/2016 12:41:29:  Epoch[ 1 of 5]-Minibatch[ 148- 150, 46.88%]: CrossEntropyWithSoftmax = 2.95940261 * 192; EvalErrorPrediction = 0.71875000 * 192; time = 0.0954s; samplesPerSecond = 2012.8
MPI Rank 0: 07/14/2016 12:41:29:  Epoch[ 1 of 5]-Minibatch[ 151- 153, 47.81%]: CrossEntropyWithSoftmax = 3.18955068 * 192; EvalErrorPrediction = 0.78125000 * 192; time = 0.0943s; samplesPerSecond = 2035.3
MPI Rank 0: 07/14/2016 12:41:29:  Epoch[ 1 of 5]-Minibatch[ 154- 156, 48.75%]: CrossEntropyWithSoftmax = 2.80225800 * 192; EvalErrorPrediction = 0.70312500 * 192; time = 0.0984s; samplesPerSecond = 1951.0
MPI Rank 0: 07/14/2016 12:41:29:  Epoch[ 1 of 5]-Minibatch[ 157- 159, 49.69%]: CrossEntropyWithSoftmax = 3.08865913 * 192; EvalErrorPrediction = 0.75520833 * 192; time = 0.0965s; samplesPerSecond = 1989.9
MPI Rank 0: 07/14/2016 12:41:29:  Epoch[ 1 of 5]-Minibatch[ 160- 162, 50.62%]: CrossEntropyWithSoftmax = 2.87171438 * 192; EvalErrorPrediction = 0.69791667 * 192; time = 0.0960s; samplesPerSecond = 1999.2
MPI Rank 0: 07/14/2016 12:41:29:  Epoch[ 1 of 5]-Minibatch[ 163- 165, 51.56%]: CrossEntropyWithSoftmax = 2.90723268 * 192; EvalErrorPrediction = 0.73958333 * 192; time = 0.0955s; samplesPerSecond = 2009.4
MPI Rank 0: 07/14/2016 12:41:29:  Epoch[ 1 of 5]-Minibatch[ 166- 168, 52.50%]: CrossEntropyWithSoftmax = 2.96438386 * 192; EvalErrorPrediction = 0.69270833 * 192; time = 0.0949s; samplesPerSecond = 2022.8
MPI Rank 0: 07/14/2016 12:41:29:  Epoch[ 1 of 5]-Minibatch[ 169- 171, 53.44%]: CrossEntropyWithSoftmax = 2.85407675 * 192; EvalErrorPrediction = 0.67708333 * 192; time = 0.0965s; samplesPerSecond = 1989.2
MPI Rank 0: 07/14/2016 12:41:29:  Epoch[ 1 of 5]-Minibatch[ 172- 174, 54.37%]: CrossEntropyWithSoftmax = 2.64516293 * 192; EvalErrorPrediction = 0.63020833 * 192; time = 0.0961s; samplesPerSecond = 1997.0
MPI Rank 0: 07/14/2016 12:41:30:  Epoch[ 1 of 5]-Minibatch[ 175- 177, 55.31%]: CrossEntropyWithSoftmax = 2.78779884 * 192; EvalErrorPrediction = 0.73437500 * 192; time = 0.1004s; samplesPerSecond = 1912.7
MPI Rank 0: 07/14/2016 12:41:30:  Epoch[ 1 of 5]-Minibatch[ 178- 180, 56.25%]: CrossEntropyWithSoftmax = 2.77691077 * 192; EvalErrorPrediction = 0.68229167 * 192; time = 0.0985s; samplesPerSecond = 1949.4
MPI Rank 0: 07/14/2016 12:41:30:  Epoch[ 1 of 5]-Minibatch[ 181- 183, 57.19%]: CrossEntropyWithSoftmax = 2.93466303 * 192; EvalErrorPrediction = 0.68229167 * 192; time = 0.0991s; samplesPerSecond = 1936.6
MPI Rank 0: 07/14/2016 12:41:30:  Epoch[ 1 of 5]-Minibatch[ 184- 186, 58.13%]: CrossEntropyWithSoftmax = 2.79665615 * 192; EvalErrorPrediction = 0.69791667 * 192; time = 0.0943s; samplesPerSecond = 2035.1
MPI Rank 0: 07/14/2016 12:41:30:  Epoch[ 1 of 5]-Minibatch[ 187- 189, 59.06%]: CrossEntropyWithSoftmax = 2.79141433 * 192; EvalErrorPrediction = 0.75520833 * 192; time = 0.0972s; samplesPerSecond = 1975.2
MPI Rank 0: 07/14/2016 12:41:30:  Epoch[ 1 of 5]-Minibatch[ 190- 192, 60.00%]: CrossEntropyWithSoftmax = 2.85677634 * 192; EvalErrorPrediction = 0.68750000 * 192; time = 0.0962s; samplesPerSecond = 1996.4
MPI Rank 0: 07/14/2016 12:41:30:  Epoch[ 1 of 5]-Minibatch[ 193- 195, 60.94%]: CrossEntropyWithSoftmax = 2.60438340 * 192; EvalErrorPrediction = 0.62500000 * 192; time = 0.0965s; samplesPerSecond = 1989.0
MPI Rank 0: 07/14/2016 12:41:30:  Epoch[ 1 of 5]-Minibatch[ 196- 198, 61.88%]: CrossEntropyWithSoftmax = 2.67867701 * 192; EvalErrorPrediction = 0.66666667 * 192; time = 0.0964s; samplesPerSecond = 1991.1
MPI Rank 0: 07/14/2016 12:41:30:  Epoch[ 1 of 5]-Minibatch[ 199- 201, 62.81%]: CrossEntropyWithSoftmax = 2.35420452 * 192; EvalErrorPrediction = 0.61458333 * 192; time = 0.0953s; samplesPerSecond = 2015.2
MPI Rank 0: 07/14/2016 12:41:30:  Epoch[ 1 of 5]-Minibatch[ 202- 204, 63.75%]: CrossEntropyWithSoftmax = 2.67860524 * 192; EvalErrorPrediction = 0.68750000 * 192; time = 0.0950s; samplesPerSecond = 2020.2
MPI Rank 0: 07/14/2016 12:41:30:  Epoch[ 1 of 5]-Minibatch[ 205- 207, 64.69%]: CrossEntropyWithSoftmax = 2.74438644 * 192; EvalErrorPrediction = 0.65625000 * 192; time = 0.0949s; samplesPerSecond = 2022.9
MPI Rank 0: 07/14/2016 12:41:31:  Epoch[ 1 of 5]-Minibatch[ 208- 210, 65.62%]: CrossEntropyWithSoftmax = 2.61472294 * 192; EvalErrorPrediction = 0.65625000 * 192; time = 0.0977s; samplesPerSecond = 1965.6
MPI Rank 0: 07/14/2016 12:41:31:  Epoch[ 1 of 5]-Minibatch[ 211- 213, 66.56%]: CrossEntropyWithSoftmax = 2.56292238 * 192; EvalErrorPrediction = 0.65104167 * 192; time = 0.0992s; samplesPerSecond = 1936.3
MPI Rank 0: 07/14/2016 12:41:31:  Epoch[ 1 of 5]-Minibatch[ 214- 216, 67.50%]: CrossEntropyWithSoftmax = 2.49905414 * 192; EvalErrorPrediction = 0.68229167 * 192; time = 0.0943s; samplesPerSecond = 2036.1
MPI Rank 0: 07/14/2016 12:41:31:  Epoch[ 1 of 5]-Minibatch[ 217- 219, 68.44%]: CrossEntropyWithSoftmax = 2.77977518 * 192; EvalErrorPrediction = 0.67708333 * 192; time = 0.0951s; samplesPerSecond = 2019.1
MPI Rank 0: 07/14/2016 12:41:31:  Epoch[ 1 of 5]-Minibatch[ 220- 222, 69.38%]: CrossEntropyWithSoftmax = 2.46098943 * 192; EvalErrorPrediction = 0.60416667 * 192; time = 0.0994s; samplesPerSecond = 1931.5
MPI Rank 0: 07/14/2016 12:41:31:  Epoch[ 1 of 5]-Minibatch[ 223- 225, 70.31%]: CrossEntropyWithSoftmax = 2.53972637 * 192; EvalErrorPrediction = 0.60416667 * 192; time = 0.0972s; samplesPerSecond = 1975.3
MPI Rank 0: 07/14/2016 12:41:31:  Epoch[ 1 of 5]-Minibatch[ 226- 228, 71.25%]: CrossEntropyWithSoftmax = 2.58069409 * 192; EvalErrorPrediction = 0.64583333 * 192; time = 0.0944s; samplesPerSecond = 2034.4
MPI Rank 0: 07/14/2016 12:41:31:  Epoch[ 1 of 5]-Minibatch[ 229- 231, 72.19%]: CrossEntropyWithSoftmax = 2.42808307 * 192; EvalErrorPrediction = 0.62500000 * 192; time = 0.0959s; samplesPerSecond = 2003.1
MPI Rank 0: 07/14/2016 12:41:31:  Epoch[ 1 of 5]-Minibatch[ 232- 234, 73.12%]: CrossEntropyWithSoftmax = 2.51795774 * 192; EvalErrorPrediction = 0.66666667 * 192; time = 0.0980s; samplesPerSecond = 1959.2
MPI Rank 0: 07/14/2016 12:41:31:  Epoch[ 1 of 5]-Minibatch[ 235- 237, 74.06%]: CrossEntropyWithSoftmax = 2.31017953 * 192; EvalErrorPrediction = 0.63541667 * 192; time = 0.0979s; samplesPerSecond = 1960.5
MPI Rank 0: 07/14/2016 12:41:32:  Epoch[ 1 of 5]-Minibatch[ 238- 240, 75.00%]: CrossEntropyWithSoftmax = 2.42763250 * 192; EvalErrorPrediction = 0.59375000 * 192; time = 0.0953s; samplesPerSecond = 2014.9
MPI Rank 0: 07/14/2016 12:41:32:  Epoch[ 1 of 5]-Minibatch[ 241- 243, 75.94%]: CrossEntropyWithSoftmax = 2.38337452 * 192; EvalErrorPrediction = 0.63020833 * 192; time = 0.1046s; samplesPerSecond = 1835.6
MPI Rank 0: 07/14/2016 12:41:32:  Epoch[ 1 of 5]-Minibatch[ 244- 246, 76.88%]: CrossEntropyWithSoftmax = 2.45688385 * 192; EvalErrorPrediction = 0.68229167 * 192; time = 0.0971s; samplesPerSecond = 1978.3
MPI Rank 0: 07/14/2016 12:41:32:  Epoch[ 1 of 5]-Minibatch[ 247- 249, 77.81%]: CrossEntropyWithSoftmax = 2.35065649 * 192; EvalErrorPrediction = 0.63020833 * 192; time = 0.0929s; samplesPerSecond = 2067.8
MPI Rank 0: 07/14/2016 12:41:32:  Epoch[ 1 of 5]-Minibatch[ 250- 252, 78.75%]: CrossEntropyWithSoftmax = 2.39950363 * 192; EvalErrorPrediction = 0.63541667 * 192; time = 0.0953s; samplesPerSecond = 2015.5
MPI Rank 0: 07/14/2016 12:41:32:  Epoch[ 1 of 5]-Minibatch[ 253- 255, 79.69%]: CrossEntropyWithSoftmax = 2.48031632 * 192; EvalErrorPrediction = 0.60937500 * 192; time = 0.0966s; samplesPerSecond = 1986.8
MPI Rank 0: 07/14/2016 12:41:32:  Epoch[ 1 of 5]-Minibatch[ 256- 258, 80.62%]: CrossEntropyWithSoftmax = 2.62124157 * 192; EvalErrorPrediction = 0.67708333 * 192; time = 0.0978s; samplesPerSecond = 1963.6
MPI Rank 0: 07/14/2016 12:41:32:  Epoch[ 1 of 5]-Minibatch[ 259- 261, 81.56%]: CrossEntropyWithSoftmax = 2.43263192 * 192; EvalErrorPrediction = 0.65625000 * 192; time = 0.0973s; samplesPerSecond = 1974.1
MPI Rank 0: 07/14/2016 12:41:32:  Epoch[ 1 of 5]-Minibatch[ 262- 264, 82.50%]: CrossEntropyWithSoftmax = 2.13490764 * 192; EvalErrorPrediction = 0.57291667 * 192; time = 0.0941s; samplesPerSecond = 2040.3
MPI Rank 0: 07/14/2016 12:41:32:  Epoch[ 1 of 5]-Minibatch[ 265- 267, 83.44%]: CrossEntropyWithSoftmax = 2.52272390 * 192; EvalErrorPrediction = 0.63541667 * 192; time = 0.0974s; samplesPerSecond = 1971.4
MPI Rank 0: 07/14/2016 12:41:33:  Epoch[ 1 of 5]-Minibatch[ 268- 270, 84.38%]: CrossEntropyWithSoftmax = 2.31215555 * 192; EvalErrorPrediction = 0.63020833 * 192; time = 0.0955s; samplesPerSecond = 2010.7
MPI Rank 0: 07/14/2016 12:41:33:  Epoch[ 1 of 5]-Minibatch[ 271- 273, 85.31%]: CrossEntropyWithSoftmax = 2.33888920 * 192; EvalErrorPrediction = 0.60416667 * 192; time = 0.0980s; samplesPerSecond = 1958.5
MPI Rank 0: 07/14/2016 12:41:33:  Epoch[ 1 of 5]-Minibatch[ 274- 276, 86.25%]: CrossEntropyWithSoftmax = 2.19318149 * 192; EvalErrorPrediction = 0.58854167 * 192; time = 0.0995s; samplesPerSecond = 1930.2
MPI Rank 0: 07/14/2016 12:41:33:  Epoch[ 1 of 5]-Minibatch[ 277- 279, 87.19%]: CrossEntropyWithSoftmax = 2.19368853 * 192; EvalErrorPrediction = 0.55208333 * 192; time = 0.0997s; samplesPerSecond = 1925.7
MPI Rank 0: 07/14/2016 12:41:33:  Epoch[ 1 of 5]-Minibatch[ 280- 282, 88.12%]: CrossEntropyWithSoftmax = 2.31322736 * 192; EvalErrorPrediction = 0.59895833 * 192; time = 0.0954s; samplesPerSecond = 2013.6
MPI Rank 0: 07/14/2016 12:41:33:  Epoch[ 1 of 5]-Minibatch[ 283- 285, 89.06%]: CrossEntropyWithSoftmax = 2.21496162 * 192; EvalErrorPrediction = 0.62500000 * 192; time = 0.0971s; samplesPerSecond = 1977.4
MPI Rank 0: 07/14/2016 12:41:33:  Epoch[ 1 of 5]-Minibatch[ 286- 288, 90.00%]: CrossEntropyWithSoftmax = 2.38257678 * 192; EvalErrorPrediction = 0.64062500 * 192; time = 0.0974s; samplesPerSecond = 1970.3
MPI Rank 0: 07/14/2016 12:41:33:  Epoch[ 1 of 5]-Minibatch[ 289- 291, 90.94%]: CrossEntropyWithSoftmax = 2.34785036 * 192; EvalErrorPrediction = 0.60416667 * 192; time = 0.0987s; samplesPerSecond = 1945.8
MPI Rank 0: 07/14/2016 12:41:33:  Epoch[ 1 of 5]-Minibatch[ 292- 294, 91.88%]: CrossEntropyWithSoftmax = 2.20545861 * 192; EvalErrorPrediction = 0.60416667 * 192; time = 0.0968s; samplesPerSecond = 1984.4
MPI Rank 0: 07/14/2016 12:41:33:  Epoch[ 1 of 5]-Minibatch[ 295- 297, 92.81%]: CrossEntropyWithSoftmax = 2.08751143 * 192; EvalErrorPrediction = 0.57291667 * 192; time = 0.0970s; samplesPerSecond = 1979.4
MPI Rank 0: 07/14/2016 12:41:33:  Epoch[ 1 of 5]-Minibatch[ 298- 300, 93.75%]: CrossEntropyWithSoftmax = 2.28302994 * 192; EvalErrorPrediction = 0.64583333 * 192; time = 0.0955s; samplesPerSecond = 2009.7
MPI Rank 0: 07/14/2016 12:41:34:  Epoch[ 1 of 5]-Minibatch[ 301- 303, 94.69%]: CrossEntropyWithSoftmax = 2.22267854 * 192; EvalErrorPrediction = 0.57291667 * 192; time = 0.0959s; samplesPerSecond = 2002.7
MPI Rank 0: 07/14/2016 12:41:34:  Epoch[ 1 of 5]-Minibatch[ 304- 306, 95.62%]: CrossEntropyWithSoftmax = 2.19855044 * 192; EvalErrorPrediction = 0.60416667 * 192; time = 0.0974s; samplesPerSecond = 1970.7
MPI Rank 0: 07/14/2016 12:41:34:  Epoch[ 1 of 5]-Minibatch[ 307- 309, 96.56%]: CrossEntropyWithSoftmax = 2.49612283 * 192; EvalErrorPrediction = 0.64583333 * 192; time = 0.0978s; samplesPerSecond = 1964.1
MPI Rank 0: 07/14/2016 12:41:34:  Epoch[ 1 of 5]-Minibatch[ 310- 312, 97.50%]: CrossEntropyWithSoftmax = 2.25409762 * 192; EvalErrorPrediction = 0.59375000 * 192; time = 0.0937s; samplesPerSecond = 2050.2
MPI Rank 0: 07/14/2016 12:41:34:  Epoch[ 1 of 5]-Minibatch[ 313- 315, 98.44%]: CrossEntropyWithSoftmax = 2.13085317 * 192; EvalErrorPrediction = 0.58333333 * 192; time = 0.0951s; samplesPerSecond = 2018.2
MPI Rank 0: 07/14/2016 12:41:34:  Epoch[ 1 of 5]-Minibatch[ 316- 318, 99.38%]: CrossEntropyWithSoftmax = 2.28902612 * 192; EvalErrorPrediction = 0.59375000 * 192; time = 0.0988s; samplesPerSecond = 1943.4
MPI Rank 0: 07/14/2016 12:41:34: Finished Epoch[ 1 of 5]: [Training] CrossEntropyWithSoftmax = 3.01292779 * 20480; EvalErrorPrediction = 0.72778320 * 20480; totalSamplesSeen = 20480; learningRatePerSample = 0.015625; epochTime=10.3179s
MPI Rank 0: 07/14/2016 12:41:34: SGD: Saving checkpoint model '/tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.1'
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:41:34: Starting Epoch 2: learning rate per sample = 0.001953  effective momentum = 0.656119  momentum as time constant = 607.5 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 1: frames [20480..40960] (first utterance at frame 20480), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:41:34: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 07/14/2016 12:41:34:  Epoch[ 2 of 5]-Minibatch[   1-   3, 3.75%]: CrossEntropyWithSoftmax = 2.25052560 * 519; EvalErrorPrediction = 0.62042389 * 519; time = 0.2506s; samplesPerSecond = 2070.7
MPI Rank 0: 07/14/2016 12:41:35:  Epoch[ 2 of 5]-Minibatch[   4-   6, 7.50%]: CrossEntropyWithSoftmax = 2.02824382 * 529; EvalErrorPrediction = 0.54442344 * 529; time = 0.2423s; samplesPerSecond = 2182.9
MPI Rank 0: 07/14/2016 12:41:35:  Epoch[ 2 of 5]-Minibatch[   7-   9, 11.25%]: CrossEntropyWithSoftmax = 2.04039147 * 494; EvalErrorPrediction = 0.55668016 * 494; time = 0.2212s; samplesPerSecond = 2233.7
MPI Rank 0: 07/14/2016 12:41:35:  Epoch[ 2 of 5]-Minibatch[  10-  12, 15.00%]: CrossEntropyWithSoftmax = 1.98880977 * 491; EvalErrorPrediction = 0.55193483 * 491; time = 0.2102s; samplesPerSecond = 2335.7
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.06-seconds latency this time; accumulated time on sync point = 0.06 seconds , average latency = 0.06 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     1.07 seconds since last report (0.00 seconds on comm.); 4331 samples processed by 2 workers (2190 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 4.04k samplesPerSecond , throughputPerWorker = 2.02k samplesPerSecond
MPI Rank 0: 07/14/2016 12:41:35:  Epoch[ 2 of 5]-Minibatch[  13-  15, 18.75%]: CrossEntropyWithSoftmax = 2.12620927 * 488; EvalErrorPrediction = 0.55327869 * 488; time = 0.2923s; samplesPerSecond = 1669.3
MPI Rank 0: 07/14/2016 12:41:36:  Epoch[ 2 of 5]-Minibatch[  16-  18, 22.50%]: CrossEntropyWithSoftmax = 2.00690071 * 485; EvalErrorPrediction = 0.56494845 * 485; time = 0.2221s; samplesPerSecond = 2183.5
MPI Rank 0: 07/14/2016 12:41:36:  Epoch[ 2 of 5]-Minibatch[  19-  21, 26.25%]: CrossEntropyWithSoftmax = 1.99194220 * 529; EvalErrorPrediction = 0.54442344 * 529; time = 0.2332s; samplesPerSecond = 2268.0
MPI Rank 0: 07/14/2016 12:41:36:  Epoch[ 2 of 5]-Minibatch[  22-  24, 30.00%]: CrossEntropyWithSoftmax = 1.96438270 * 468; EvalErrorPrediction = 0.56410256 * 468; time = 0.2149s; samplesPerSecond = 2177.7
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.07 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     1.00 seconds since last report (0.00 seconds on comm.); 4232 samples processed by 2 workers (2154 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 4.23k samplesPerSecond , throughputPerWorker = 2.11k samplesPerSecond
MPI Rank 0: 07/14/2016 12:41:36:  Epoch[ 2 of 5]-Minibatch[  25-  27, 33.75%]: CrossEntropyWithSoftmax = 2.00145662 * 499; EvalErrorPrediction = 0.53707415 * 499; time = 0.2486s; samplesPerSecond = 2007.2
MPI Rank 0: 07/14/2016 12:41:37:  Epoch[ 2 of 5]-Minibatch[  28-  30, 37.50%]: CrossEntropyWithSoftmax = 2.18677023 * 494; EvalErrorPrediction = 0.58502024 * 494; time = 0.2212s; samplesPerSecond = 2233.5
MPI Rank 0: 07/14/2016 12:41:37:  Epoch[ 2 of 5]-Minibatch[  31-  33, 41.25%]: CrossEntropyWithSoftmax = 1.97121551 * 479; EvalErrorPrediction = 0.55532359 * 479; time = 0.2270s; samplesPerSecond = 2110.6
MPI Rank 0: 07/14/2016 12:41:37:  Epoch[ 2 of 5]-Minibatch[  34-  36, 45.00%]: CrossEntropyWithSoftmax = 2.01765091 * 488; EvalErrorPrediction = 0.54303279 * 488; time = 0.2206s; samplesPerSecond = 2211.7
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.04-seconds latency this time; accumulated time on sync point = 0.11 seconds , average latency = 0.04 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     1.01 seconds since last report (0.00 seconds on comm.); 4185 samples processed by 2 workers (2125 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 4.14k samplesPerSecond , throughputPerWorker = 2.07k samplesPerSecond
MPI Rank 0: 07/14/2016 12:41:37:  Epoch[ 2 of 5]-Minibatch[  37-  39, 48.75%]: CrossEntropyWithSoftmax = 1.90503909 * 506; EvalErrorPrediction = 0.52173913 * 506; time = 0.2730s; samplesPerSecond = 1853.3
MPI Rank 0: 07/14/2016 12:41:38:  Epoch[ 2 of 5]-Minibatch[  40-  42, 52.50%]: CrossEntropyWithSoftmax = 1.87253137 * 512; EvalErrorPrediction = 0.53710938 * 512; time = 0.2313s; samplesPerSecond = 2213.3
MPI Rank 0: 07/14/2016 12:41:38:  Epoch[ 2 of 5]-Minibatch[  43-  45, 56.25%]: CrossEntropyWithSoftmax = 1.92699152 * 497; EvalErrorPrediction = 0.49899396 * 497; time = 0.2286s; samplesPerSecond = 2174.4
MPI Rank 0: 07/14/2016 12:41:38:  Epoch[ 2 of 5]-Minibatch[  46-  48, 60.00%]: CrossEntropyWithSoftmax = 1.86967957 * 502; EvalErrorPrediction = 0.54581673 * 502; time = 0.2311s; samplesPerSecond = 2172.4
MPI Rank 0: 07/14/2016 12:41:38:  Epoch[ 2 of 5]-Minibatch[  49-  51, 63.75%]: CrossEntropyWithSoftmax = 2.08077350 * 476; EvalErrorPrediction = 0.57142857 * 476; time = 0.2260s; samplesPerSecond = 2105.8
MPI Rank 0: 07/14/2016 12:41:38:  Epoch[ 2 of 5]-Minibatch[  52-  54, 67.50%]: CrossEntropyWithSoftmax = 2.00372686 * 487; EvalErrorPrediction = 0.53388090 * 487; time = 0.2247s; samplesPerSecond = 2167.0
MPI Rank 0: 07/14/2016 12:41:39:  Epoch[ 2 of 5]-Minibatch[  55-  57, 71.25%]: CrossEntropyWithSoftmax = 1.92223751 * 499; EvalErrorPrediction = 0.53306613 * 499; time = 0.2232s; samplesPerSecond = 2235.9
MPI Rank 0: 07/14/2016 12:41:39:  Epoch[ 2 of 5]-Minibatch[  58-  60, 75.00%]: CrossEntropyWithSoftmax = 1.96031873 * 475; EvalErrorPrediction = 0.54947368 * 475; time = 0.2072s; samplesPerSecond = 2292.9
MPI Rank 0: 07/14/2016 12:41:39:  Epoch[ 2 of 5]-Minibatch[  61-  63, 78.75%]: CrossEntropyWithSoftmax = 1.94324612 * 506; EvalErrorPrediction = 0.52964427 * 506; time = 0.2274s; samplesPerSecond = 2224.7
MPI Rank 0: 07/14/2016 12:41:39:  Epoch[ 2 of 5]-Minibatch[  64-  66, 82.50%]: CrossEntropyWithSoftmax = 1.94596052 * 472; EvalErrorPrediction = 0.53389831 * 472; time = 0.2133s; samplesPerSecond = 2212.9
MPI Rank 0: 07/14/2016 12:41:40:  Epoch[ 2 of 5]-Minibatch[  67-  69, 86.25%]: CrossEntropyWithSoftmax = 1.87864114 * 490; EvalErrorPrediction = 0.54693878 * 490; time = 0.2231s; samplesPerSecond = 2196.7
MPI Rank 0: 07/14/2016 12:41:40:  Epoch[ 2 of 5]-Minibatch[  70-  72, 90.00%]: CrossEntropyWithSoftmax = 1.94844616 * 477; EvalErrorPrediction = 0.51153040 * 477; time = 0.2195s; samplesPerSecond = 2173.0
MPI Rank 0: 07/14/2016 12:41:40:  Epoch[ 2 of 5]-Minibatch[  73-  75, 93.75%]: CrossEntropyWithSoftmax = 1.93817444 * 469; EvalErrorPrediction = 0.53091684 * 469; time = 0.2178s; samplesPerSecond = 2153.7
MPI Rank 0: 07/14/2016 12:41:40:  Epoch[ 2 of 5]-Minibatch[  76-  78, 97.50%]: CrossEntropyWithSoftmax = 1.94722731 * 495; EvalErrorPrediction = 0.53939394 * 495; time = 0.2266s; samplesPerSecond = 2184.3
MPI Rank 0: 07/14/2016 12:41:40:  Epoch[ 2 of 5]-Minibatch[  79-  81, 101.25%]: CrossEntropyWithSoftmax = 1.88543102 * 322; EvalErrorPrediction = 0.55279503 * 322; time = 0.1498s; samplesPerSecond = 2150.0
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.11 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     3.07 seconds since last report (0.00 seconds on comm.); 7732 samples processed by 2 workers (6679 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 2.52k samplesPerSecond , throughputPerWorker = 1.26k samplesPerSecond
MPI Rank 0: 07/14/2016 12:41:40: Finished Epoch[ 2 of 5]: [Training] CrossEntropyWithSoftmax = 2.00885273 * 20480; EvalErrorPrediction = 0.55078125 * 20480; totalSamplesSeen = 40960; learningRatePerSample = 0.001953125; epochTime=6.15099s
MPI Rank 0: 07/14/2016 12:41:40: SGD: Saving checkpoint model '/tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.2'
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:41:40: Starting Epoch 3: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 2: frames [40960..61440] (first utterance at frame 40960), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:41:40: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 07/14/2016 12:41:41:  Epoch[ 3 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.87780257 * 1939; EvalErrorPrediction = 0.50644662 * 1939; time = 0.8764s; samplesPerSecond = 2212.4
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     1.17 seconds since last report (0.00 seconds on comm.); 4844 samples processed by 2 workers (2583 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 4.13k samplesPerSecond , throughputPerWorker = 2.06k samplesPerSecond
MPI Rank 0: 07/14/2016 12:41:42:  Epoch[ 3 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.89404862 * 1944; EvalErrorPrediction = 0.52726337 * 1944; time = 0.8434s; samplesPerSecond = 2305.0
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     1.12 seconds since last report (0.00 seconds on comm.); 4849 samples processed by 2 workers (2580 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 4.33k samplesPerSecond , throughputPerWorker = 2.17k samplesPerSecond
MPI Rank 0: 07/14/2016 12:41:43:  Epoch[ 3 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.90812492 * 1918; EvalErrorPrediction = 0.53336809 * 1918; time = 0.8482s; samplesPerSecond = 2261.2
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     1.16 seconds since last report (0.00 seconds on comm.); 4868 samples processed by 2 workers (2595 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 4.21k samplesPerSecond , throughputPerWorker = 2.11k samplesPerSecond
MPI Rank 0: 07/14/2016 12:41:44:  Epoch[ 3 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.89877106 * 1957; EvalErrorPrediction = 0.53449157 * 1957; time = 0.8755s; samplesPerSecond = 2235.4
MPI Rank 0: 07/14/2016 12:41:45:  Epoch[ 3 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.88324196 * 1942; EvalErrorPrediction = 0.51956746 * 1942; time = 0.8276s; samplesPerSecond = 2346.5
MPI Rank 0: 07/14/2016 12:41:46:  Epoch[ 3 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.86867010 * 1929; EvalErrorPrediction = 0.52514256 * 1929; time = 0.8128s; samplesPerSecond = 2373.3
MPI Rank 0: 07/14/2016 12:41:46:  Epoch[ 3 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.90242165 * 1290; EvalErrorPrediction = 0.53023256 * 1290; time = 0.5565s; samplesPerSecond = 2318.2
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     2.21 seconds since last report (0.00 seconds on comm.); 5919 samples processed by 2 workers (5161 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 2.68k samplesPerSecond , throughputPerWorker = 1.34k samplesPerSecond
MPI Rank 0: 07/14/2016 12:41:46: Finished Epoch[ 3 of 5]: [Training] CrossEntropyWithSoftmax = 1.89787888 * 20480; EvalErrorPrediction = 0.52875977 * 20480; totalSamplesSeen = 61440; learningRatePerSample = 9.7656251e-05; epochTime=5.65997s
MPI Rank 0: 07/14/2016 12:41:46: SGD: Saving checkpoint model '/tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.3'
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:41:46: Starting Epoch 4: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:41:46: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 07/14/2016 12:41:47:  Epoch[ 4 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.91224926 * 1926; EvalErrorPrediction = 0.52803738 * 1926; time = 0.8222s; samplesPerSecond = 2342.6
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     1.12 seconds since last report (0.00 seconds on comm.); 4905 samples processed by 2 workers (2581 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 4.38k samplesPerSecond , throughputPerWorker = 2.19k samplesPerSecond
MPI Rank 0: 07/14/2016 12:41:48:  Epoch[ 4 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.80760312 * 1894; EvalErrorPrediction = 0.51108765 * 1894; time = 0.8345s; samplesPerSecond = 2269.5
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     1.11 seconds since last report (0.00 seconds on comm.); 4870 samples processed by 2 workers (2537 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 4.38k samplesPerSecond , throughputPerWorker = 2.19k samplesPerSecond
MPI Rank 0: 07/14/2016 12:41:49:  Epoch[ 4 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.86234536 * 1931; EvalErrorPrediction = 0.51424133 * 1931; time = 0.8488s; samplesPerSecond = 2275.0
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     1.09 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2513 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 4.49k samplesPerSecond , throughputPerWorker = 2.25k samplesPerSecond
MPI Rank 0: 07/14/2016 12:41:50:  Epoch[ 4 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.83816606 * 1880; EvalErrorPrediction = 0.50638298 * 1880; time = 0.8167s; samplesPerSecond = 2301.9
MPI Rank 0: 07/14/2016 12:41:50:  Epoch[ 4 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.80548301 * 1880; EvalErrorPrediction = 0.49680851 * 1880; time = 0.7586s; samplesPerSecond = 2478.2
MPI Rank 0: 07/14/2016 12:41:51:  Epoch[ 4 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.81476104 * 1861; EvalErrorPrediction = 0.50940355 * 1861; time = 0.7603s; samplesPerSecond = 2447.7
MPI Rank 0: 07/14/2016 12:41:52:  Epoch[ 4 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.82832821 * 1263; EvalErrorPrediction = 0.49802059 * 1263; time = 0.5406s; samplesPerSecond = 2336.2
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     2.07 seconds since last report (0.00 seconds on comm.); 5789 samples processed by 2 workers (5004 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 2.79k samplesPerSecond , throughputPerWorker = 1.40k samplesPerSecond
MPI Rank 0: 07/14/2016 12:41:52: Finished Epoch[ 4 of 5]: [Training] CrossEntropyWithSoftmax = 1.84940336 * 20480; EvalErrorPrediction = 0.51445312 * 20480; totalSamplesSeen = 81920; learningRatePerSample = 9.7656251e-05; epochTime=5.40139s
MPI Rank 0: 07/14/2016 12:41:52: SGD: Saving checkpoint model '/tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4'
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:41:52: Starting Epoch 5: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:41:52: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 07/14/2016 12:41:53:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80847097 * 1897; EvalErrorPrediction = 0.50237217 * 1897; time = 0.8137s; samplesPerSecond = 2331.4
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.02 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     1.10 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 4.46k samplesPerSecond , throughputPerWorker = 2.23k samplesPerSecond
MPI Rank 0: 07/14/2016 12:41:53:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86742287 * 1821; EvalErrorPrediction = 0.51784734 * 1821; time = 0.7982s; samplesPerSecond = 2281.5
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.02 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     1.07 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 4.58k samplesPerSecond , throughputPerWorker = 2.29k samplesPerSecond
MPI Rank 0: 07/14/2016 12:41:54:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.90215948 * 1871; EvalErrorPrediction = 0.51950828 * 1871; time = 0.8157s; samplesPerSecond = 2293.9
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.02 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     1.08 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 4.50k samplesPerSecond , throughputPerWorker = 2.25k samplesPerSecond
MPI Rank 0: 07/14/2016 12:41:55:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.83673317 * 1870; EvalErrorPrediction = 0.50320856 * 1870; time = 0.8162s; samplesPerSecond = 2291.1
MPI Rank 0: 07/14/2016 12:41:56:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.91249924 * 1899; EvalErrorPrediction = 0.52553976 * 1899; time = 0.7912s; samplesPerSecond = 2400.3
MPI Rank 0: 07/14/2016 12:41:57:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87327558 * 1878; EvalErrorPrediction = 0.52183174 * 1878; time = 0.7794s; samplesPerSecond = 2409.7
MPI Rank 0: 07/14/2016 12:41:57:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.87043426 * 1221; EvalErrorPrediction = 0.51678952 * 1221; time = 0.5242s; samplesPerSecond = 2329.1
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.02 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     2.11 seconds since last report (0.00 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 2.76k samplesPerSecond , throughputPerWorker = 1.38k samplesPerSecond
MPI Rank 0: 07/14/2016 12:41:57: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85300231 * 20480; EvalErrorPrediction = 0.51425781 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 9.7656251e-05; epochTime=5.35607s
MPI Rank 0: 07/14/2016 12:41:57: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 12:41:57: learnRatePerSample reduced to 4.8828126e-05
MPI Rank 0: 07/14/2016 12:41:57: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:41:57: Starting Epoch 5: learning rate per sample = 0.000049  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:41:57: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 07/14/2016 12:41:58:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80855659 * 1897; EvalErrorPrediction = 0.50184502 * 1897; time = 0.7816s; samplesPerSecond = 2427.2
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     1.05 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 4.68k samplesPerSecond , throughputPerWorker = 2.34k samplesPerSecond
MPI Rank 0: 07/14/2016 12:41:59:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86827725 * 1821; EvalErrorPrediction = 0.51729819 * 1821; time = 0.7960s; samplesPerSecond = 2287.6
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     1.08 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 4.53k samplesPerSecond , throughputPerWorker = 2.27k samplesPerSecond
MPI Rank 0: 07/14/2016 12:42:00:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.90376996 * 1871; EvalErrorPrediction = 0.51950828 * 1871; time = 0.7960s; samplesPerSecond = 2350.5
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     1.04 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 4.65k samplesPerSecond , throughputPerWorker = 2.32k samplesPerSecond
MPI Rank 0: 07/14/2016 12:42:00:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.83821663 * 1870; EvalErrorPrediction = 0.50641711 * 1870; time = 0.7948s; samplesPerSecond = 2352.9
MPI Rank 0: 07/14/2016 12:42:01:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.91393514 * 1899; EvalErrorPrediction = 0.52606635 * 1899; time = 0.8022s; samplesPerSecond = 2367.4
MPI Rank 0: 07/14/2016 12:42:02:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87537660 * 1878; EvalErrorPrediction = 0.52183174 * 1878; time = 0.7957s; samplesPerSecond = 2360.1
MPI Rank 0: 07/14/2016 12:42:02:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.87301608 * 1221; EvalErrorPrediction = 0.51842752 * 1221; time = 0.5106s; samplesPerSecond = 2391.4
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     2.12 seconds since last report (0.00 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 2.75k samplesPerSecond , throughputPerWorker = 1.37k samplesPerSecond
MPI Rank 0: 07/14/2016 12:42:03: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85426644 * 20480; EvalErrorPrediction = 0.51508789 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 4.8828126e-05; epochTime=5.29455s
MPI Rank 0: 07/14/2016 12:42:03: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 12:42:03: learnRatePerSample reduced to 2.4414063e-05
MPI Rank 0: 07/14/2016 12:42:03: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:42:03: Starting Epoch 5: learning rate per sample = 0.000024  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:42:03: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 07/14/2016 12:42:03:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80860170 * 1897; EvalErrorPrediction = 0.50184502 * 1897; time = 0.8117s; samplesPerSecond = 2337.1
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     1.08 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 4.55k samplesPerSecond , throughputPerWorker = 2.27k samplesPerSecond
MPI Rank 0: 07/14/2016 12:42:04:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86874821 * 1821; EvalErrorPrediction = 0.51784734 * 1821; time = 0.7728s; samplesPerSecond = 2356.3
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     1.06 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 4.60k samplesPerSecond , throughputPerWorker = 2.30k samplesPerSecond
MPI Rank 0: 07/14/2016 12:42:05:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.90471511 * 1871; EvalErrorPrediction = 0.52004276 * 1871; time = 0.8096s; samplesPerSecond = 2310.9
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     1.05 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 4.60k samplesPerSecond , throughputPerWorker = 2.30k samplesPerSecond
MPI Rank 0: 07/14/2016 12:42:06:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.83914326 * 1870; EvalErrorPrediction = 0.50802139 * 1870; time = 0.7983s; samplesPerSecond = 2342.4
MPI Rank 0: 07/14/2016 12:42:07:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.91489914 * 1899; EvalErrorPrediction = 0.52817272 * 1899; time = 0.8128s; samplesPerSecond = 2336.4
MPI Rank 0: 07/14/2016 12:42:07:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87668517 * 1878; EvalErrorPrediction = 0.52449414 * 1878; time = 0.7985s; samplesPerSecond = 2351.9
MPI Rank 0: 07/14/2016 12:42:08:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.87427101 * 1221; EvalErrorPrediction = 0.51678952 * 1221; time = 0.5042s; samplesPerSecond = 2421.7
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     2.13 seconds since last report (0.00 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 2.74k samplesPerSecond , throughputPerWorker = 1.37k samplesPerSecond
MPI Rank 0: 07/14/2016 12:42:08: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85499692 * 20480; EvalErrorPrediction = 0.51547852 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 2.4414063e-05; epochTime=5.32699s
MPI Rank 0: 07/14/2016 12:42:08: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 12:42:08: learnRatePerSample reduced to 1.2207031e-05
MPI Rank 0: 07/14/2016 12:42:08: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:42:08: Starting Epoch 5: learning rate per sample = 0.000012  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:42:08: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 07/14/2016 12:42:09:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80862485 * 1897; EvalErrorPrediction = 0.50184502 * 1897; time = 0.7959s; samplesPerSecond = 2383.6
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     1.07 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 4.61k samplesPerSecond , throughputPerWorker = 2.31k samplesPerSecond
MPI Rank 0: 07/14/2016 12:42:10:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86899591 * 1821; EvalErrorPrediction = 0.51784734 * 1821; time = 0.7701s; samplesPerSecond = 2364.6
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     1.05 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 4.65k samplesPerSecond , throughputPerWorker = 2.32k samplesPerSecond
MPI Rank 0: 07/14/2016 12:42:11:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.90523368 * 1871; EvalErrorPrediction = 0.52111170 * 1871; time = 0.8067s; samplesPerSecond = 2319.4
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     1.06 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 4.57k samplesPerSecond , throughputPerWorker = 2.29k samplesPerSecond
MPI Rank 0: 07/14/2016 12:42:11:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.83967949 * 1870; EvalErrorPrediction = 0.50695187 * 1870; time = 0.8018s; samplesPerSecond = 2332.2
MPI Rank 0: 07/14/2016 12:42:12:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.91551098 * 1899; EvalErrorPrediction = 0.52711954 * 1899; time = 0.8300s; samplesPerSecond = 2287.9
MPI Rank 0: 07/14/2016 12:42:13:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87747996 * 1878; EvalErrorPrediction = 0.52342918 * 1878; time = 0.7817s; samplesPerSecond = 2402.4
MPI Rank 0: 07/14/2016 12:42:13:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.87488056 * 1221; EvalErrorPrediction = 0.51842752 * 1221; time = 0.5198s; samplesPerSecond = 2349.1
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     2.15 seconds since last report (0.00 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 2.72k samplesPerSecond , throughputPerWorker = 1.36k samplesPerSecond
MPI Rank 0: 07/14/2016 12:42:13: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85540764 * 20480; EvalErrorPrediction = 0.51547852 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 1.2207031e-05; epochTime=5.32423s
MPI Rank 0: 07/14/2016 12:42:13: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 12:42:14: learnRatePerSample reduced to 6.1035157e-06
MPI Rank 0: 07/14/2016 12:42:14: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:42:14: Starting Epoch 5: learning rate per sample = 0.000006  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:42:14: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 07/14/2016 12:42:14:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80863657 * 1897; EvalErrorPrediction = 0.50184502 * 1897; time = 0.7723s; samplesPerSecond = 2456.3
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.05-seconds latency this time; accumulated time on sync point = 0.05 seconds , average latency = 0.05 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     1.08 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 4.54k samplesPerSecond , throughputPerWorker = 2.27k samplesPerSecond
MPI Rank 0: 07/14/2016 12:42:15:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86912298 * 1821; EvalErrorPrediction = 0.51784734 * 1821; time = 0.8306s; samplesPerSecond = 2192.3
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.05 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     1.07 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 4.57k samplesPerSecond , throughputPerWorker = 2.29k samplesPerSecond
MPI Rank 0: 07/14/2016 12:42:16:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.90550621 * 1871; EvalErrorPrediction = 0.52164618 * 1871; time = 0.8071s; samplesPerSecond = 2318.1
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.05 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     1.06 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 4.56k samplesPerSecond , throughputPerWorker = 2.28k samplesPerSecond
MPI Rank 0: 07/14/2016 12:42:17:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.83997065 * 1870; EvalErrorPrediction = 0.50802139 * 1870; time = 0.8015s; samplesPerSecond = 2333.2
MPI Rank 0: 07/14/2016 12:42:18:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.91586450 * 1899; EvalErrorPrediction = 0.52764613 * 1899; time = 0.8322s; samplesPerSecond = 2282.0
MPI Rank 0: 07/14/2016 12:42:18:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87793326 * 1878; EvalErrorPrediction = 0.52449414 * 1878; time = 0.7867s; samplesPerSecond = 2387.1
MPI Rank 0: 07/14/2016 12:42:19:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.87518958 * 1221; EvalErrorPrediction = 0.51924652 * 1221; time = 0.4969s; samplesPerSecond = 2457.3
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.05 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     2.13 seconds since last report (0.00 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 2.74k samplesPerSecond , throughputPerWorker = 1.37k samplesPerSecond
MPI Rank 0: 07/14/2016 12:42:19: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85562974 * 20480; EvalErrorPrediction = 0.51582031 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 6.1035157e-06; epochTime=5.34486s
MPI Rank 0: 07/14/2016 12:42:19: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 12:42:19: learnRatePerSample reduced to 3.0517579e-06
MPI Rank 0: 07/14/2016 12:42:19: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:42:19: Starting Epoch 5: learning rate per sample = 0.000003  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:42:19: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 07/14/2016 12:42:20:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80864247 * 1897; EvalErrorPrediction = 0.50184502 * 1897; time = 0.7970s; samplesPerSecond = 2380.1
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     1.07 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 4.60k samplesPerSecond , throughputPerWorker = 2.30k samplesPerSecond
MPI Rank 0: 07/14/2016 12:42:21:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86918735 * 1821; EvalErrorPrediction = 0.51784734 * 1821; time = 0.7718s; samplesPerSecond = 2359.3
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.02 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     1.05 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 4.66k samplesPerSecond , throughputPerWorker = 2.33k samplesPerSecond
MPI Rank 0: 07/14/2016 12:42:21:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.90564602 * 1871; EvalErrorPrediction = 0.52111170 * 1871; time = 0.7947s; samplesPerSecond = 2354.5
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.02 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     1.06 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 4.57k samplesPerSecond , throughputPerWorker = 2.28k samplesPerSecond
MPI Rank 0: 07/14/2016 12:42:22:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.84012271 * 1870; EvalErrorPrediction = 0.50855615 * 1870; time = 0.8108s; samplesPerSecond = 2306.4
MPI Rank 0: 07/14/2016 12:42:23:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.91605566 * 1899; EvalErrorPrediction = 0.52764613 * 1899; time = 0.7913s; samplesPerSecond = 2399.9
MPI Rank 0: 07/14/2016 12:42:24:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87817773 * 1878; EvalErrorPrediction = 0.52555911 * 1878; time = 0.7740s; samplesPerSecond = 2426.4
MPI Rank 0: 07/14/2016 12:42:24:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.87534772 * 1221; EvalErrorPrediction = 0.51924652 * 1221; time = 0.5223s; samplesPerSecond = 2337.5
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.02 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     2.10 seconds since last report (0.00 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 2.77k samplesPerSecond , throughputPerWorker = 1.39k samplesPerSecond
MPI Rank 0: 07/14/2016 12:42:24: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85574594 * 20480; EvalErrorPrediction = 0.51606445 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 3.0517579e-06; epochTime=5.27975s
MPI Rank 0: 07/14/2016 12:42:24: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 12:42:24: learnRatePerSample reduced to 1.5258789e-06
MPI Rank 0: 07/14/2016 12:42:24: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:42:25: Starting Epoch 5: learning rate per sample = 0.000002  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:42:25: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 07/14/2016 12:42:25:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80864542 * 1897; EvalErrorPrediction = 0.50184502 * 1897; time = 0.8046s; samplesPerSecond = 2357.7
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     1.06 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 4.64k samplesPerSecond , throughputPerWorker = 2.32k samplesPerSecond
MPI Rank 0: 07/14/2016 12:42:26:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86921975 * 1821; EvalErrorPrediction = 0.51784734 * 1821; time = 0.7847s; samplesPerSecond = 2320.6
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     1.11 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 4.39k samplesPerSecond , throughputPerWorker = 2.19k samplesPerSecond
MPI Rank 0: 07/14/2016 12:42:27:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.90571684 * 1871; EvalErrorPrediction = 0.52004276 * 1871; time = 0.8448s; samplesPerSecond = 2214.6
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     1.06 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 4.56k samplesPerSecond , throughputPerWorker = 2.28k samplesPerSecond
MPI Rank 0: 07/14/2016 12:42:28:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.84020046 * 1870; EvalErrorPrediction = 0.50855615 * 1870; time = 0.7990s; samplesPerSecond = 2340.5
MPI Rank 0: 07/14/2016 12:42:29:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.91615521 * 1899; EvalErrorPrediction = 0.52764613 * 1899; time = 0.7898s; samplesPerSecond = 2404.4
MPI Rank 0: 07/14/2016 12:42:29:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87830500 * 1878; EvalErrorPrediction = 0.52555911 * 1878; time = 0.7782s; samplesPerSecond = 2413.1
MPI Rank 0: 07/14/2016 12:42:30:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.87542816 * 1221; EvalErrorPrediction = 0.51924652 * 1221; time = 0.4966s; samplesPerSecond = 2458.6
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     2.08 seconds since last report (0.00 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 2.80k samplesPerSecond , throughputPerWorker = 1.40k samplesPerSecond
MPI Rank 0: 07/14/2016 12:42:30: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85580548 * 20480; EvalErrorPrediction = 0.51591797 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 1.5258789e-06; epochTime=5.31556s
MPI Rank 0: 07/14/2016 12:42:30: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 12:42:30: learnRatePerSample reduced to 7.6293946e-07
MPI Rank 0: 07/14/2016 12:42:30: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:42:30: Starting Epoch 5: learning rate per sample = 0.000001  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:42:30: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 07/14/2016 12:42:31:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80864691 * 1897; EvalErrorPrediction = 0.50184502 * 1897; time = 0.8100s; samplesPerSecond = 2342.1
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     1.07 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 4.57k samplesPerSecond , throughputPerWorker = 2.29k samplesPerSecond
MPI Rank 0: 07/14/2016 12:42:32:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86923600 * 1821; EvalErrorPrediction = 0.51784734 * 1821; time = 0.7654s; samplesPerSecond = 2379.3
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     1.06 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 4.60k samplesPerSecond , throughputPerWorker = 2.30k samplesPerSecond
MPI Rank 0: 07/14/2016 12:42:32:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.90575249 * 1871; EvalErrorPrediction = 0.52057723 * 1871; time = 0.8272s; samplesPerSecond = 2261.9
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     1.07 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 4.55k samplesPerSecond , throughputPerWorker = 2.27k samplesPerSecond
MPI Rank 0: 07/14/2016 12:42:33:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.84023978 * 1870; EvalErrorPrediction = 0.50855615 * 1870; time = 0.7983s; samplesPerSecond = 2342.6
MPI Rank 0: 07/14/2016 12:42:34:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.91620602 * 1899; EvalErrorPrediction = 0.52764613 * 1899; time = 0.7785s; samplesPerSecond = 2439.4
MPI Rank 0: 07/14/2016 12:42:35:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87836997 * 1878; EvalErrorPrediction = 0.52555911 * 1878; time = 0.7855s; samplesPerSecond = 2390.8
MPI Rank 0: 07/14/2016 12:42:35:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.87546879 * 1221; EvalErrorPrediction = 0.51924652 * 1221; time = 0.5039s; samplesPerSecond = 2422.9
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     2.08 seconds since last report (0.00 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 2.80k samplesPerSecond , throughputPerWorker = 1.40k samplesPerSecond
MPI Rank 0: 07/14/2016 12:42:35: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85583563 * 20480; EvalErrorPrediction = 0.51591797 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 7.6293946e-07; epochTime=5.28659s
MPI Rank 0: 07/14/2016 12:42:35: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 12:42:35: learnRatePerSample reduced to 3.8146973e-07
MPI Rank 0: 07/14/2016 12:42:35: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:42:35: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:42:35: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 07/14/2016 12:42:36:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80864765 * 1897; EvalErrorPrediction = 0.50184502 * 1897; time = 0.7922s; samplesPerSecond = 2394.7
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     1.06 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 4.64k samplesPerSecond , throughputPerWorker = 2.32k samplesPerSecond
MPI Rank 0: 07/14/2016 12:42:37:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86924414 * 1821; EvalErrorPrediction = 0.51784734 * 1821; time = 0.7831s; samplesPerSecond = 2325.4
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     1.07 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 4.58k samplesPerSecond , throughputPerWorker = 2.29k samplesPerSecond
MPI Rank 0: 07/14/2016 12:42:38:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.90577037 * 1871; EvalErrorPrediction = 0.52057723 * 1871; time = 0.8064s; samplesPerSecond = 2320.3
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     1.08 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 4.52k samplesPerSecond , throughputPerWorker = 2.26k samplesPerSecond
MPI Rank 0: 07/14/2016 12:42:39:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.84025955 * 1870; EvalErrorPrediction = 0.50855615 * 1870; time = 0.8149s; samplesPerSecond = 2294.8
MPI Rank 0: 07/14/2016 12:42:39:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.91623169 * 1899; EvalErrorPrediction = 0.52764613 * 1899; time = 0.8020s; samplesPerSecond = 2367.8
MPI Rank 0: 07/14/2016 12:42:40:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87840281 * 1878; EvalErrorPrediction = 0.52555911 * 1878; time = 0.7796s; samplesPerSecond = 2409.0
MPI Rank 0: 07/14/2016 12:42:41:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.87548922 * 1221; EvalErrorPrediction = 0.51924652 * 1221; time = 0.5127s; samplesPerSecond = 2381.5
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     2.11 seconds since last report (0.00 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 2.76k samplesPerSecond , throughputPerWorker = 1.38k samplesPerSecond
MPI Rank 0: 07/14/2016 12:42:41: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85585080 * 20480; EvalErrorPrediction = 0.51591797 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 3.8146973e-07; epochTime=5.30988s
MPI Rank 0: 07/14/2016 12:42:41: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 12:42:41: learnRatePerSample reduced to 1.9073487e-07
MPI Rank 0: 07/14/2016 12:42:41: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:42:41: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:42:41: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 07/14/2016 12:42:42:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80864802 * 1897; EvalErrorPrediction = 0.50184502 * 1897; time = 0.8317s; samplesPerSecond = 2280.9
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     1.10 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 4.48k samplesPerSecond , throughputPerWorker = 2.24k samplesPerSecond
MPI Rank 0: 07/14/2016 12:42:43:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86924821 * 1821; EvalErrorPrediction = 0.51784734 * 1821; time = 0.8024s; samplesPerSecond = 2269.4
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     1.08 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 4.52k samplesPerSecond , throughputPerWorker = 2.26k samplesPerSecond
MPI Rank 0: 07/14/2016 12:42:43:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.90577933 * 1871; EvalErrorPrediction = 0.51950828 * 1871; time = 0.7952s; samplesPerSecond = 2353.0
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     1.04 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 4.68k samplesPerSecond , throughputPerWorker = 2.34k samplesPerSecond
MPI Rank 0: 07/14/2016 12:42:44:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.84026946 * 1870; EvalErrorPrediction = 0.50855615 * 1870; time = 0.7826s; samplesPerSecond = 2389.4
MPI Rank 0: 07/14/2016 12:42:45:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.91624459 * 1899; EvalErrorPrediction = 0.52764613 * 1899; time = 0.8118s; samplesPerSecond = 2339.1
MPI Rank 0: 07/14/2016 12:42:46:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87841931 * 1878; EvalErrorPrediction = 0.52555911 * 1878; time = 0.7793s; samplesPerSecond = 2409.7
MPI Rank 0: 07/14/2016 12:42:46:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.87549946 * 1221; EvalErrorPrediction = 0.51924652 * 1221; time = 0.5121s; samplesPerSecond = 2384.4
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     2.12 seconds since last report (0.00 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 2.75k samplesPerSecond , throughputPerWorker = 1.38k samplesPerSecond
MPI Rank 0: 07/14/2016 12:42:46: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85585841 * 20480; EvalErrorPrediction = 0.51582031 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 1.9073487e-07; epochTime=5.33339s
MPI Rank 0: 07/14/2016 12:42:46: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 12:42:46: learnRatePerSample reduced to 9.5367433e-08
MPI Rank 0: 07/14/2016 12:42:46: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:42:46: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:42:46: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 07/14/2016 12:42:47:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80864820 * 1897; EvalErrorPrediction = 0.50184502 * 1897; time = 0.7981s; samplesPerSecond = 2376.8
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.01 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     1.08 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 4.55k samplesPerSecond , throughputPerWorker = 2.28k samplesPerSecond
MPI Rank 0: 07/14/2016 12:42:48:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86925024 * 1821; EvalErrorPrediction = 0.51784734 * 1821; time = 0.8029s; samplesPerSecond = 2268.1
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.01 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     1.07 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 4.58k samplesPerSecond , throughputPerWorker = 2.29k samplesPerSecond
MPI Rank 0: 07/14/2016 12:42:49:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.90578381 * 1871; EvalErrorPrediction = 0.51950828 * 1871; time = 0.8091s; samplesPerSecond = 2312.5
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.01 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     1.08 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 4.48k samplesPerSecond , throughputPerWorker = 2.24k samplesPerSecond
MPI Rank 0: 07/14/2016 12:42:50:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.84027442 * 1870; EvalErrorPrediction = 0.50855615 * 1870; time = 0.8155s; samplesPerSecond = 2293.1
MPI Rank 0: 07/14/2016 12:42:50:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.91625106 * 1899; EvalErrorPrediction = 0.52764613 * 1899; time = 0.7887s; samplesPerSecond = 2407.7
MPI Rank 0: 07/14/2016 12:42:51:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87842758 * 1878; EvalErrorPrediction = 0.52555911 * 1878; time = 0.7855s; samplesPerSecond = 2390.7
MPI Rank 0: 07/14/2016 12:42:52:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.87550459 * 1221; EvalErrorPrediction = 0.51924652 * 1221; time = 0.5242s; samplesPerSecond = 2329.3
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.01 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     2.11 seconds since last report (0.00 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 2.76k samplesPerSecond , throughputPerWorker = 1.38k samplesPerSecond
MPI Rank 0: 07/14/2016 12:42:52: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85586222 * 20480; EvalErrorPrediction = 0.51582031 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 9.5367433e-08; epochTime=5.34269s
MPI Rank 0: 07/14/2016 12:42:52: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 12:42:52: learnRatePerSample reduced to 4.7683717e-08
MPI Rank 0: 07/14/2016 12:42:52: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:42:52: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:42:52: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 07/14/2016 12:42:53:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80864830 * 1897; EvalErrorPrediction = 0.50184502 * 1897; time = 0.8069s; samplesPerSecond = 2351.0
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     1.09 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 4.52k samplesPerSecond , throughputPerWorker = 2.26k samplesPerSecond
MPI Rank 0: 07/14/2016 12:42:53:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86925126 * 1821; EvalErrorPrediction = 0.51784734 * 1821; time = 0.8098s; samplesPerSecond = 2248.7
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     1.09 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 4.47k samplesPerSecond , throughputPerWorker = 2.23k samplesPerSecond
MPI Rank 0: 07/14/2016 12:42:54:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.90578605 * 1871; EvalErrorPrediction = 0.51950828 * 1871; time = 0.8271s; samplesPerSecond = 2262.3
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     1.08 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 4.49k samplesPerSecond , throughputPerWorker = 2.25k samplesPerSecond
MPI Rank 0: 07/14/2016 12:42:55:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.84027691 * 1870; EvalErrorPrediction = 0.50855615 * 1870; time = 0.8145s; samplesPerSecond = 2295.8
MPI Rank 0: 07/14/2016 12:42:56:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.91625429 * 1899; EvalErrorPrediction = 0.52764613 * 1899; time = 0.7872s; samplesPerSecond = 2412.4
MPI Rank 0: 07/14/2016 12:42:57:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87843173 * 1878; EvalErrorPrediction = 0.52555911 * 1878; time = 0.8162s; samplesPerSecond = 2300.9
MPI Rank 0: 07/14/2016 12:42:57:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.87550715 * 1221; EvalErrorPrediction = 0.51924652 * 1221; time = 0.5086s; samplesPerSecond = 2400.7
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     2.13 seconds since last report (0.00 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 2.74k samplesPerSecond , throughputPerWorker = 1.37k samplesPerSecond
MPI Rank 0: 07/14/2016 12:42:57: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85586413 * 20480; EvalErrorPrediction = 0.51577148 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 4.7683717e-08; epochTime=5.38836s
MPI Rank 0: 07/14/2016 12:42:57: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 12:42:57: learnRatePerSample reduced to 2.3841858e-08
MPI Rank 0: 07/14/2016 12:42:57: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:42:57: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:42:57: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 07/14/2016 12:42:58:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80864834 * 1897; EvalErrorPrediction = 0.50184502 * 1897; time = 0.8314s; samplesPerSecond = 2281.7
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     1.11 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 4.43k samplesPerSecond , throughputPerWorker = 2.22k samplesPerSecond
MPI Rank 0: 07/14/2016 12:42:59:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86925177 * 1821; EvalErrorPrediction = 0.51784734 * 1821; time = 0.8011s; samplesPerSecond = 2273.2
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     1.07 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 4.55k samplesPerSecond , throughputPerWorker = 2.28k samplesPerSecond
MPI Rank 0: 07/14/2016 12:43:00:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.90578717 * 1871; EvalErrorPrediction = 0.51950828 * 1871; time = 0.7954s; samplesPerSecond = 2352.2
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     1.04 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 4.66k samplesPerSecond , throughputPerWorker = 2.33k samplesPerSecond
MPI Rank 0: 07/14/2016 12:43:01:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.84027815 * 1870; EvalErrorPrediction = 0.50855615 * 1870; time = 0.7917s; samplesPerSecond = 2362.0
MPI Rank 0: 07/14/2016 12:43:01:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.91625591 * 1899; EvalErrorPrediction = 0.52764613 * 1899; time = 0.8189s; samplesPerSecond = 2318.8
MPI Rank 0: 07/14/2016 12:43:02:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87843380 * 1878; EvalErrorPrediction = 0.52555911 * 1878; time = 0.8016s; samplesPerSecond = 2342.9
MPI Rank 0: 07/14/2016 12:43:03:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.87550844 * 1221; EvalErrorPrediction = 0.51924652 * 1221; time = 0.5075s; samplesPerSecond = 2405.7
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     2.14 seconds since last report (0.00 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 2.72k samplesPerSecond , throughputPerWorker = 1.36k samplesPerSecond
MPI Rank 0: 07/14/2016 12:43:03: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85586508 * 20480; EvalErrorPrediction = 0.51577148 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 2.3841858e-08; epochTime=5.36565s
MPI Rank 0: 07/14/2016 12:43:03: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 12:43:03: learnRatePerSample reduced to 1.1920929e-08
MPI Rank 0: 07/14/2016 12:43:03: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:43:03: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:43:03: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 07/14/2016 12:43:04:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80864837 * 1897; EvalErrorPrediction = 0.50184502 * 1897; time = 0.8105s; samplesPerSecond = 2340.4
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     1.08 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 4.55k samplesPerSecond , throughputPerWorker = 2.27k samplesPerSecond
MPI Rank 0: 07/14/2016 12:43:05:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86925203 * 1821; EvalErrorPrediction = 0.51784734 * 1821; time = 0.7976s; samplesPerSecond = 2283.1
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     1.06 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 4.61k samplesPerSecond , throughputPerWorker = 2.30k samplesPerSecond
MPI Rank 0: 07/14/2016 12:43:05:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.90578773 * 1871; EvalErrorPrediction = 0.51950828 * 1871; time = 0.7948s; samplesPerSecond = 2353.9
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     1.11 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 4.36k samplesPerSecond , throughputPerWorker = 2.18k samplesPerSecond
MPI Rank 0: 07/14/2016 12:43:06:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.84027877 * 1870; EvalErrorPrediction = 0.50855615 * 1870; time = 0.8471s; samplesPerSecond = 2207.4
MPI Rank 0: 07/14/2016 12:43:07:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.91625673 * 1899; EvalErrorPrediction = 0.52764613 * 1899; time = 0.8080s; samplesPerSecond = 2350.3
MPI Rank 0: 07/14/2016 12:43:08:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87843484 * 1878; EvalErrorPrediction = 0.52555911 * 1878; time = 0.7756s; samplesPerSecond = 2421.3
MPI Rank 0: 07/14/2016 12:43:08:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.87550908 * 1221; EvalErrorPrediction = 0.51924652 * 1221; time = 0.4986s; samplesPerSecond = 2448.8
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     2.10 seconds since last report (0.00 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 2.78k samplesPerSecond , throughputPerWorker = 1.39k samplesPerSecond
MPI Rank 0: 07/14/2016 12:43:08: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85586556 * 20480; EvalErrorPrediction = 0.51577148 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 1.1920929e-08; epochTime=5.35014s
MPI Rank 0: 07/14/2016 12:43:08: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 12:43:08: learnRatePerSample reduced to 5.9604646e-09
MPI Rank 0: 07/14/2016 12:43:08: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:43:08: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:43:08: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 07/14/2016 12:43:09:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80864838 * 1897; EvalErrorPrediction = 0.50184502 * 1897; time = 0.8325s; samplesPerSecond = 2278.8
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     1.11 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 4.42k samplesPerSecond , throughputPerWorker = 2.21k samplesPerSecond
MPI Rank 0: 07/14/2016 12:43:10:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86925216 * 1821; EvalErrorPrediction = 0.51784734 * 1821; time = 0.8129s; samplesPerSecond = 2240.2
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     1.09 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 4.46k samplesPerSecond , throughputPerWorker = 2.23k samplesPerSecond
MPI Rank 0: 07/14/2016 12:43:11:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.90578801 * 1871; EvalErrorPrediction = 0.51950828 * 1871; time = 0.8225s; samplesPerSecond = 2274.7
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     1.10 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 4.42k samplesPerSecond , throughputPerWorker = 2.21k samplesPerSecond
MPI Rank 0: 07/14/2016 12:43:12:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.84027908 * 1870; EvalErrorPrediction = 0.50855615 * 1870; time = 0.8339s; samplesPerSecond = 2242.5
MPI Rank 0: 07/14/2016 12:43:13:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.91625713 * 1899; EvalErrorPrediction = 0.52764613 * 1899; time = 0.8049s; samplesPerSecond = 2359.2
MPI Rank 0: 07/14/2016 12:43:13:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87843535 * 1878; EvalErrorPrediction = 0.52555911 * 1878; time = 0.8067s; samplesPerSecond = 2328.1
MPI Rank 0: 07/14/2016 12:43:14:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.87550940 * 1221; EvalErrorPrediction = 0.51924652 * 1221; time = 0.5252s; samplesPerSecond = 2324.6
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     2.15 seconds since last report (0.00 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 2.71k samplesPerSecond , throughputPerWorker = 1.35k samplesPerSecond
MPI Rank 0: 07/14/2016 12:43:14: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85586580 * 20480; EvalErrorPrediction = 0.51577148 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 5.9604646e-09; epochTime=5.45667s
MPI Rank 0: 07/14/2016 12:43:14: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 12:43:14: learnRatePerSample reduced to 2.9802323e-09
MPI Rank 0: 07/14/2016 12:43:14: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:43:14: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:43:14: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 07/14/2016 12:43:15:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80864838 * 1897; EvalErrorPrediction = 0.50184502 * 1897; time = 0.8197s; samplesPerSecond = 2314.4
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     1.09 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 4.50k samplesPerSecond , throughputPerWorker = 2.25k samplesPerSecond
MPI Rank 0: 07/14/2016 12:43:16:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86925222 * 1821; EvalErrorPrediction = 0.51784734 * 1821; time = 0.8007s; samplesPerSecond = 2274.2
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     1.08 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 4.52k samplesPerSecond , throughputPerWorker = 2.26k samplesPerSecond
MPI Rank 0: 07/14/2016 12:43:16:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.90578815 * 1871; EvalErrorPrediction = 0.51950828 * 1871; time = 0.8150s; samplesPerSecond = 2295.7
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     1.08 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 4.48k samplesPerSecond , throughputPerWorker = 2.24k samplesPerSecond
MPI Rank 0: 07/14/2016 12:43:17:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.84027924 * 1870; EvalErrorPrediction = 0.50855615 * 1870; time = 0.8174s; samplesPerSecond = 2287.8
MPI Rank 0: 07/14/2016 12:43:18:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.91625733 * 1899; EvalErrorPrediction = 0.52764613 * 1899; time = 0.8357s; samplesPerSecond = 2272.4
MPI Rank 0: 07/14/2016 12:43:19:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87843561 * 1878; EvalErrorPrediction = 0.52555911 * 1878; time = 0.8078s; samplesPerSecond = 2324.8
MPI Rank 0: 07/14/2016 12:43:19:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.87550956 * 1221; EvalErrorPrediction = 0.51924652 * 1221; time = 0.5281s; samplesPerSecond = 2312.0
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     2.19 seconds since last report (0.00 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 2.67k samplesPerSecond , throughputPerWorker = 1.33k samplesPerSecond
MPI Rank 0: 07/14/2016 12:43:19: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85586592 * 20480; EvalErrorPrediction = 0.51577148 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 2.9802323e-09; epochTime=5.44268s
MPI Rank 0: 07/14/2016 12:43:19: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 12:43:20: learnRatePerSample reduced to 1.4901161e-09
MPI Rank 0: 07/14/2016 12:43:20: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:43:20: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:43:20: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 07/14/2016 12:43:20:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80864839 * 1897; EvalErrorPrediction = 0.50184502 * 1897; time = 0.7828s; samplesPerSecond = 2423.2
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.02 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     1.08 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 4.57k samplesPerSecond , throughputPerWorker = 2.28k samplesPerSecond
MPI Rank 0: 07/14/2016 12:43:21:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86925225 * 1821; EvalErrorPrediction = 0.51784734 * 1821; time = 0.8102s; samplesPerSecond = 2247.7
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.02 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     1.07 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 4.59k samplesPerSecond , throughputPerWorker = 2.29k samplesPerSecond
MPI Rank 0: 07/14/2016 12:43:22:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.90578822 * 1871; EvalErrorPrediction = 0.51950828 * 1871; time = 0.8167s; samplesPerSecond = 2290.9
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.02 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     1.10 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 4.40k samplesPerSecond , throughputPerWorker = 2.20k samplesPerSecond
MPI Rank 0: 07/14/2016 12:43:23:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.84027932 * 1870; EvalErrorPrediction = 0.50855615 * 1870; time = 0.8303s; samplesPerSecond = 2252.2
MPI Rank 0: 07/14/2016 12:43:24:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.91625743 * 1899; EvalErrorPrediction = 0.52764613 * 1899; time = 0.8078s; samplesPerSecond = 2350.8
MPI Rank 0: 07/14/2016 12:43:24:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87843574 * 1878; EvalErrorPrediction = 0.52555911 * 1878; time = 0.7891s; samplesPerSecond = 2379.9
MPI Rank 0: 07/14/2016 12:43:25:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.87550964 * 1221; EvalErrorPrediction = 0.51924652 * 1221; time = 0.5209s; samplesPerSecond = 2343.9
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.02 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     2.13 seconds since last report (0.00 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 2.73k samplesPerSecond , throughputPerWorker = 1.37k samplesPerSecond
MPI Rank 0: 07/14/2016 12:43:25: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85586598 * 20480; EvalErrorPrediction = 0.51577148 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 1.4901161e-09; epochTime=5.37679s
MPI Rank 0: 07/14/2016 12:43:25: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 12:43:25: learnRatePerSample reduced to 7.4505807e-10
MPI Rank 0: 07/14/2016 12:43:25: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 07/14/2016 12:43:25: Learn Rate Per Sample for Epoch[5] = 7.4505807e-10 is less than minLearnRate 9.9999997e-10. Training complete.
MPI Rank 0: 07/14/2016 12:43:25: CNTKCommandTrainEnd: speechTrain
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:43:25: Action "train" complete.
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:43:25: __COMPLETED__
MPI Rank 0: ~MPIWrapper
MPI Rank 1: 07/14/2016 12:41:21: -------------------------------------------------------------------
MPI Rank 1: 07/14/2016 12:41:21: Build info: 
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:41:21: 		Built time: Jul 14 2016 12:05:02
MPI Rank 1: 07/14/2016 12:41:21: 		Last modified date: Thu Jul 14 10:47:21 2016
MPI Rank 1: 07/14/2016 12:41:21: 		Build type: release
MPI Rank 1: 07/14/2016 12:41:21: 		Build target: GPU
MPI Rank 1: 07/14/2016 12:41:21: 		With 1bit-SGD: yes
MPI Rank 1: 07/14/2016 12:41:21: 		Math lib: mkl
MPI Rank 1: 07/14/2016 12:41:21: 		CUDA_PATH: /usr/local/cuda-7.5
MPI Rank 1: 07/14/2016 12:41:21: 		CUB_PATH: /usr/local/cub-1.4.1
MPI Rank 1: 07/14/2016 12:41:21: 		CUDNN_PATH: /usr/local/cudnn-4.0
MPI Rank 1: 07/14/2016 12:41:21: 		Build Branch: HEAD
MPI Rank 1: 07/14/2016 12:41:21: 		Build SHA1: 72bee394bf461e8f6f0feb593a8416c05f481957
MPI Rank 1: 07/14/2016 12:41:21: 		Built by philly on a77bf6d98305
MPI Rank 1: 07/14/2016 12:41:21: 		Build Path: /home/philly/jenkins/workspace/CNTK-Build-Linux
MPI Rank 1: 07/14/2016 12:41:21: -------------------------------------------------------------------
MPI Rank 1: 07/14/2016 12:41:22: -------------------------------------------------------------------
MPI Rank 1: 07/14/2016 12:41:22: GPU info:
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:41:22: 		Device[0]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3071 MB
MPI Rank 1: 07/14/2016 12:41:22: 		Device[1]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3071 MB
MPI Rank 1: 07/14/2016 12:41:22: 		Device[2]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3071 MB
MPI Rank 1: 07/14/2016 12:41:22: 		Device[3]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3071 MB
MPI Rank 1: 07/14/2016 12:41:22: -------------------------------------------------------------------
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:41:22: Running on localhost at 2016/07/14 12:41:22
MPI Rank 1: 07/14/2016 12:41:22: Command line: 
MPI Rank 1: /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/build/1bitsgd/release/bin/cntk  configFile=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/ParallelBM/../ParallelBM/cntk.cntk  currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data  RunDir=/tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_cpu  DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data  ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/ParallelBM/..  OutputDir=/tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_cpu  DeviceId=-1  timestamping=true  numCPUThreads=12  precision=double  speechTrain=[SGD=[ParallelTrain=[parallelizationStartEpoch=2]]]  stderr=/tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_cpu/stderr
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:41:22: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
MPI Rank 1: 07/14/2016 12:41:22: precision = "float"
MPI Rank 1: command = speechTrain
MPI Rank 1: deviceId = $DeviceId$
MPI Rank 1: parallelTrain = true
MPI Rank 1: speechTrain = [
MPI Rank 1:     action = "train"
MPI Rank 1:     modelPath = "$RunDir$/models/cntkSpeech.dnn"
MPI Rank 1:     deviceId = $DeviceId$
MPI Rank 1:     traceLevel = 1
MPI Rank 1:     SimpleNetworkBuilder = [
MPI Rank 1:         layerSizes = 363:512:512:132
MPI Rank 1:         trainingCriterion = "CrossEntropyWithSoftmax"
MPI Rank 1:         evalCriterion = "ErrorPrediction"
MPI Rank 1:         layerTypes = "Sigmoid"
MPI Rank 1:         initValueScale = 1.0
MPI Rank 1:         applyMeanVarNorm = true
MPI Rank 1:         uniformInit = true
MPI Rank 1:         needPrior = true
MPI Rank 1:     ]
MPI Rank 1:     ExperimentalNetworkBuilder = [    // the same as above but with BS. Not active; activate by commenting out the SimpleNetworkBuilder entry above
MPI Rank 1:         layerSizes = 363:512:512:132
MPI Rank 1:         trainingCriterion = 'CE'
MPI Rank 1:         evalCriterion = 'Err'
MPI Rank 1:         applyMeanVarNorm = true
MPI Rank 1:         L = Length(layerSizes)-1    // number of model layers
MPI Rank 1:         features = Input(layerSizes[0], 1, tag='feature') ; labels = Input(layerSizes[Length(layerSizes)-1], 1, tag='label')
MPI Rank 1:         featNorm = if applyMeanVarNorm
MPI Rank 1:                    then MeanVarNorm(features)
MPI Rank 1:                    else features
MPI Rank 1:         layers[layer:1..L-1] = if layer > 1
MPI Rank 1:                                then SBFF(layers[layer-1].Eh, layerSizes[layer], layerSizes[layer-1])
MPI Rank 1:                                else SBFF(featNorm, layerSizes[layer], layerSizes[layer-1])
MPI Rank 1:         outLayer = BFF(layers[L-1].Eh, layerSizes[L], layerSizes[L-1])
MPI Rank 1:         outZ = outLayer.z        // + PastValue(layerSizes[L], 1, outLayer.z)
MPI Rank 1:         CE = if trainingCriterion == 'CE'
MPI Rank 1:              then CrossEntropyWithSoftmax(labels, outZ, tag='criterion')
MPI Rank 1:              else Fail('unknown trainingCriterion ' + trainingCriterion)
MPI Rank 1:         Err = if evalCriterion == 'Err' then
MPI Rank 1:               ErrorPrediction(labels, outZ, tag='evaluation')
MPI Rank 1:               else Fail('unknown evalCriterion ' + evalCriterion)
MPI Rank 1:         logPrior = LogPrior(labels)
MPI Rank 1:         // TODO: how to add a tag to an infix operation?
MPI Rank 1:         ScaledLogLikelihood = Minus (outZ, logPrior, tag='output')
MPI Rank 1:     ]
MPI Rank 1:     SGD = [
MPI Rank 1:         epochSize = 20480
MPI Rank 1:         minibatchSize = 64:256:1024
MPI Rank 1:         learningRatesPerMB = 1.0:0.5:0.1
MPI Rank 1:         numMBsToShowResult = 3
MPI Rank 1:         momentumPerMB = 0.9:0.656119
MPI Rank 1:         dropoutRate = 0.0
MPI Rank 1:         maxEpochs = 5
MPI Rank 1:         keepCheckPointFiles = true
MPI Rank 1:         clippingThresholdPerSample = 1#INF
MPI Rank 1:         ParallelTrain = [
MPI Rank 1:             parallelizationMethod = "BlockMomentumSGD"
MPI Rank 1:             distributedMBReading = true
MPI Rank 1:             syncPerfStats=1
MPI Rank 1:             BlockMomentumSGD = [
MPI Rank 1:                 blockSizePerWorker=2048
MPI Rank 1:                 resetSGDMomentum=true
MPI Rank 1:                 useNesterovMomentum=true
MPI Rank 1:             ]
MPI Rank 1:         ]
MPI Rank 1:         AutoAdjust = [
MPI Rank 1:             reduceLearnRateIfImproveLessThan = 0
MPI Rank 1:             loadBestModel = true
MPI Rank 1:             increaseLearnRateIfImproveMoreThan = 1000000000
MPI Rank 1:             learnRateDecreaseFactor = 0.5
MPI Rank 1:             learnRateIncreaseFactor = 1.382
MPI Rank 1:             autoAdjustLR = "adjustAfterEpoch"
MPI Rank 1:         ]
MPI Rank 1:     ]
MPI Rank 1:     reader = [
MPI Rank 1:         readerType = "HTKMLFReader"
MPI Rank 1:         readMethod = "blockRandomize"
MPI Rank 1:         miniBatchMode = "partial"
MPI Rank 1:         randomize = "auto"
MPI Rank 1:         verbosity = 0
MPI Rank 1:         features = [
MPI Rank 1:             dim = 363
MPI Rank 1:             type = "real"
MPI Rank 1:             scpFile = "glob_0000.scp"
MPI Rank 1:         ]
MPI Rank 1:         labels = [
MPI Rank 1:             mlfFile = "$DataDir$/glob_0000.mlf"
MPI Rank 1:             labelMappingFile = "$DataDir$/state.list"
MPI Rank 1:             labelDim = 132
MPI Rank 1:             labelType = "category"
MPI Rank 1:         ]
MPI Rank 1:     ]
MPI Rank 1: ]
MPI Rank 1: currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
MPI Rank 1: RunDir=/tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_cpu
MPI Rank 1: DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
MPI Rank 1: ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/ParallelBM/..
MPI Rank 1: OutputDir=/tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_cpu
MPI Rank 1: DeviceId=-1
MPI Rank 1: timestamping=true
MPI Rank 1: numCPUThreads=12
MPI Rank 1: precision=double
MPI Rank 1: speechTrain=[SGD=[ParallelTrain=[parallelizationStartEpoch=2]]]
MPI Rank 1: stderr=/tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_cpu/stderr
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:41:22: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:41:22: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 1: 07/14/2016 12:41:22: precision = "float"
MPI Rank 1: command = speechTrain
MPI Rank 1: deviceId = -1
MPI Rank 1: parallelTrain = true
MPI Rank 1: speechTrain = [
MPI Rank 1:     action = "train"
MPI Rank 1:     modelPath = "/tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn"
MPI Rank 1:     deviceId = -1
MPI Rank 1:     traceLevel = 1
MPI Rank 1:     SimpleNetworkBuilder = [
MPI Rank 1:         layerSizes = 363:512:512:132
MPI Rank 1:         trainingCriterion = "CrossEntropyWithSoftmax"
MPI Rank 1:         evalCriterion = "ErrorPrediction"
MPI Rank 1:         layerTypes = "Sigmoid"
MPI Rank 1:         initValueScale = 1.0
MPI Rank 1:         applyMeanVarNorm = true
MPI Rank 1:         uniformInit = true
MPI Rank 1:         needPrior = true
MPI Rank 1:     ]
MPI Rank 1:     ExperimentalNetworkBuilder = [    // the same as above but with BS. Not active; activate by commenting out the SimpleNetworkBuilder entry above
MPI Rank 1:         layerSizes = 363:512:512:132
MPI Rank 1:         trainingCriterion = 'CE'
MPI Rank 1:         evalCriterion = 'Err'
MPI Rank 1:         applyMeanVarNorm = true
MPI Rank 1:         L = Length(layerSizes)-1    // number of model layers
MPI Rank 1:         features = Input(layerSizes[0], 1, tag='feature') ; labels = Input(layerSizes[Length(layerSizes)-1], 1, tag='label')
MPI Rank 1:         featNorm = if applyMeanVarNorm
MPI Rank 1:                    then MeanVarNorm(features)
MPI Rank 1:                    else features
MPI Rank 1:         layers[layer:1..L-1] = if layer > 1
MPI Rank 1:                                then SBFF(layers[layer-1].Eh, layerSizes[layer], layerSizes[layer-1])
MPI Rank 1:                                else SBFF(featNorm, layerSizes[layer], layerSizes[layer-1])
MPI Rank 1:         outLayer = BFF(layers[L-1].Eh, layerSizes[L], layerSizes[L-1])
MPI Rank 1:         outZ = outLayer.z        // + PastValue(layerSizes[L], 1, outLayer.z)
MPI Rank 1:         CE = if trainingCriterion == 'CE'
MPI Rank 1:              then CrossEntropyWithSoftmax(labels, outZ, tag='criterion')
MPI Rank 1:              else Fail('unknown trainingCriterion ' + trainingCriterion)
MPI Rank 1:         Err = if evalCriterion == 'Err' then
MPI Rank 1:               ErrorPrediction(labels, outZ, tag='evaluation')
MPI Rank 1:               else Fail('unknown evalCriterion ' + evalCriterion)
MPI Rank 1:         logPrior = LogPrior(labels)
MPI Rank 1:         // TODO: how to add a tag to an infix operation?
MPI Rank 1:         ScaledLogLikelihood = Minus (outZ, logPrior, tag='output')
MPI Rank 1:     ]
MPI Rank 1:     SGD = [
MPI Rank 1:         epochSize = 20480
MPI Rank 1:         minibatchSize = 64:256:1024
MPI Rank 1:         learningRatesPerMB = 1.0:0.5:0.1
MPI Rank 1:         numMBsToShowResult = 3
MPI Rank 1:         momentumPerMB = 0.9:0.656119
MPI Rank 1:         dropoutRate = 0.0
MPI Rank 1:         maxEpochs = 5
MPI Rank 1:         keepCheckPointFiles = true
MPI Rank 1:         clippingThresholdPerSample = 1#INF
MPI Rank 1:         ParallelTrain = [
MPI Rank 1:             parallelizationMethod = "BlockMomentumSGD"
MPI Rank 1:             distributedMBReading = true
MPI Rank 1:             syncPerfStats=1
MPI Rank 1:             BlockMomentumSGD = [
MPI Rank 1:                 blockSizePerWorker=2048
MPI Rank 1:                 resetSGDMomentum=true
MPI Rank 1:                 useNesterovMomentum=true
MPI Rank 1:             ]
MPI Rank 1:         ]
MPI Rank 1:         AutoAdjust = [
MPI Rank 1:             reduceLearnRateIfImproveLessThan = 0
MPI Rank 1:             loadBestModel = true
MPI Rank 1:             increaseLearnRateIfImproveMoreThan = 1000000000
MPI Rank 1:             learnRateDecreaseFactor = 0.5
MPI Rank 1:             learnRateIncreaseFactor = 1.382
MPI Rank 1:             autoAdjustLR = "adjustAfterEpoch"
MPI Rank 1:         ]
MPI Rank 1:     ]
MPI Rank 1:     reader = [
MPI Rank 1:         readerType = "HTKMLFReader"
MPI Rank 1:         readMethod = "blockRandomize"
MPI Rank 1:         miniBatchMode = "partial"
MPI Rank 1:         randomize = "auto"
MPI Rank 1:         verbosity = 0
MPI Rank 1:         features = [
MPI Rank 1:             dim = 363
MPI Rank 1:             type = "real"
MPI Rank 1:             scpFile = "glob_0000.scp"
MPI Rank 1:         ]
MPI Rank 1:         labels = [
MPI Rank 1:             mlfFile = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/glob_0000.mlf"
MPI Rank 1:             labelMappingFile = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/state.list"
MPI Rank 1:             labelDim = 132
MPI Rank 1:             labelType = "category"
MPI Rank 1:         ]
MPI Rank 1:     ]
MPI Rank 1: ]
MPI Rank 1: currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
MPI Rank 1: RunDir=/tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_cpu
MPI Rank 1: DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
MPI Rank 1: ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/ParallelBM/..
MPI Rank 1: OutputDir=/tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_cpu
MPI Rank 1: DeviceId=-1
MPI Rank 1: timestamping=true
MPI Rank 1: numCPUThreads=12
MPI Rank 1: precision=double
MPI Rank 1: speechTrain=[SGD=[ParallelTrain=[parallelizationStartEpoch=2]]]
MPI Rank 1: stderr=/tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_cpu/stderr
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:41:22: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:41:22: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 1: configparameters: cntk.cntk:command=speechTrain
MPI Rank 1: configparameters: cntk.cntk:ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/ParallelBM/..
MPI Rank 1: configparameters: cntk.cntk:currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
MPI Rank 1: configparameters: cntk.cntk:DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
MPI Rank 1: configparameters: cntk.cntk:deviceId=-1
MPI Rank 1: configparameters: cntk.cntk:numCPUThreads=12
MPI Rank 1: configparameters: cntk.cntk:OutputDir=/tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_cpu
MPI Rank 1: configparameters: cntk.cntk:parallelTrain=true
MPI Rank 1: configparameters: cntk.cntk:precision=double
MPI Rank 1: configparameters: cntk.cntk:RunDir=/tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_cpu
MPI Rank 1: configparameters: cntk.cntk:speechTrain=[
MPI Rank 1:     action = "train"
MPI Rank 1:     modelPath = "/tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn"
MPI Rank 1:     deviceId = -1
MPI Rank 1:     traceLevel = 1
MPI Rank 1:     SimpleNetworkBuilder = [
MPI Rank 1:         layerSizes = 363:512:512:132
MPI Rank 1:         trainingCriterion = "CrossEntropyWithSoftmax"
MPI Rank 1:         evalCriterion = "ErrorPrediction"
MPI Rank 1:         layerTypes = "Sigmoid"
MPI Rank 1:         initValueScale = 1.0
MPI Rank 1:         applyMeanVarNorm = true
MPI Rank 1:         uniformInit = true
MPI Rank 1:         needPrior = true
MPI Rank 1:     ]
MPI Rank 1:     ExperimentalNetworkBuilder = [    // the same as above but with BS. Not active; activate by commenting out the SimpleNetworkBuilder entry above
MPI Rank 1:         layerSizes = 363:512:512:132
MPI Rank 1:         trainingCriterion = 'CE'
MPI Rank 1:         evalCriterion = 'Err'
MPI Rank 1:         applyMeanVarNorm = true
MPI Rank 1:         L = Length(layerSizes)-1    // number of model layers
MPI Rank 1:         features = Input(layerSizes[0], 1, tag='feature') ; labels = Input(layerSizes[Length(layerSizes)-1], 1, tag='label')
MPI Rank 1:         featNorm = if applyMeanVarNorm
MPI Rank 1:                    then MeanVarNorm(features)
MPI Rank 1:                    else features
MPI Rank 1:         layers[layer:1..L-1] = if layer > 1
MPI Rank 1:                                then SBFF(layers[layer-1].Eh, layerSizes[layer], layerSizes[layer-1])
MPI Rank 1:                                else SBFF(featNorm, layerSizes[layer], layerSizes[layer-1])
MPI Rank 1:         outLayer = BFF(layers[L-1].Eh, layerSizes[L], layerSizes[L-1])
MPI Rank 1:         outZ = outLayer.z        // + PastValue(layerSizes[L], 1, outLayer.z)
MPI Rank 1:         CE = if trainingCriterion == 'CE'
MPI Rank 1:              then CrossEntropyWithSoftmax(labels, outZ, tag='criterion')
MPI Rank 1:              else Fail('unknown trainingCriterion ' + trainingCriterion)
MPI Rank 1:         Err = if evalCriterion == 'Err' then
MPI Rank 1:               ErrorPrediction(labels, outZ, tag='evaluation')
MPI Rank 1:               else Fail('unknown evalCriterion ' + evalCriterion)
MPI Rank 1:         logPrior = LogPrior(labels)
MPI Rank 1:         // TODO: how to add a tag to an infix operation?
MPI Rank 1:         ScaledLogLikelihood = Minus (outZ, logPrior, tag='output')
MPI Rank 1:     ]
MPI Rank 1:     SGD = [
MPI Rank 1:         epochSize = 20480
MPI Rank 1:         minibatchSize = 64:256:1024
MPI Rank 1:         learningRatesPerMB = 1.0:0.5:0.1
MPI Rank 1:         numMBsToShowResult = 3
MPI Rank 1:         momentumPerMB = 0.9:0.656119
MPI Rank 1:         dropoutRate = 0.0
MPI Rank 1:         maxEpochs = 5
MPI Rank 1:         keepCheckPointFiles = true
MPI Rank 1:         clippingThresholdPerSample = 1#INF
MPI Rank 1:         ParallelTrain = [
MPI Rank 1:             parallelizationMethod = "BlockMomentumSGD"
MPI Rank 1:             distributedMBReading = true
MPI Rank 1:             syncPerfStats=1
MPI Rank 1:             BlockMomentumSGD = [
MPI Rank 1:                 blockSizePerWorker=2048
MPI Rank 1:                 resetSGDMomentum=true
MPI Rank 1:                 useNesterovMomentum=true
MPI Rank 1:             ]
MPI Rank 1:         ]
MPI Rank 1:         AutoAdjust = [
MPI Rank 1:             reduceLearnRateIfImproveLessThan = 0
MPI Rank 1:             loadBestModel = true
MPI Rank 1:             increaseLearnRateIfImproveMoreThan = 1000000000
MPI Rank 1:             learnRateDecreaseFactor = 0.5
MPI Rank 1:             learnRateIncreaseFactor = 1.382
MPI Rank 1:             autoAdjustLR = "adjustAfterEpoch"
MPI Rank 1:         ]
MPI Rank 1:     ]
MPI Rank 1:     reader = [
MPI Rank 1:         readerType = "HTKMLFReader"
MPI Rank 1:         readMethod = "blockRandomize"
MPI Rank 1:         miniBatchMode = "partial"
MPI Rank 1:         randomize = "auto"
MPI Rank 1:         verbosity = 0
MPI Rank 1:         features = [
MPI Rank 1:             dim = 363
MPI Rank 1:             type = "real"
MPI Rank 1:             scpFile = "glob_0000.scp"
MPI Rank 1:         ]
MPI Rank 1:         labels = [
MPI Rank 1:             mlfFile = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/glob_0000.mlf"
MPI Rank 1:             labelMappingFile = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/state.list"
MPI Rank 1:             labelDim = 132
MPI Rank 1:             labelType = "category"
MPI Rank 1:         ]
MPI Rank 1:     ]
MPI Rank 1: ] [SGD=[ParallelTrain=[parallelizationStartEpoch=2]]]
MPI Rank 1: 
MPI Rank 1: configparameters: cntk.cntk:stderr=/tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_cpu/stderr
MPI Rank 1: configparameters: cntk.cntk:timestamping=true
MPI Rank 1: 07/14/2016 12:41:22: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 1: 07/14/2016 12:41:22: Commands: speechTrain
MPI Rank 1: 07/14/2016 12:41:22: Precision = "double"
MPI Rank 1: 07/14/2016 12:41:22: Using 12 CPU threads.
MPI Rank 1: 07/14/2016 12:41:22: CNTKModelPath: /tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn
MPI Rank 1: 07/14/2016 12:41:22: CNTKCommandTrainInfo: speechTrain : 5
MPI Rank 1: 07/14/2016 12:41:22: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 5
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:41:22: ##############################################################################
MPI Rank 1: 07/14/2016 12:41:22: #                                                                            #
MPI Rank 1: 07/14/2016 12:41:22: # Action "train"                                                             #
MPI Rank 1: 07/14/2016 12:41:22: #                                                                            #
MPI Rank 1: 07/14/2016 12:41:22: ##############################################################################
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:41:22: CNTKCommandTrainBegin: speechTrain
MPI Rank 1: SimpleNetworkBuilder Using CPU
MPI Rank 1: reading script file glob_0000.scp ... 948 entries
MPI Rank 1: total 132 state names in state list /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/state.list
MPI Rank 1: htkmlfreader: reading MLF file /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/glob_0000.mlf ... total 948 entries
MPI Rank 1: ...............................................................................................feature set 0: 252734 frames in 948 out of 948 utterances
MPI Rank 1: label set 0: 129 classes
MPI Rank 1: minibatchutterancesource: 948 utterances grouped into 3 chunks, av. chunk size: 316.0 utterances, 84244.7 frames
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:41:22: Creating virgin network.
MPI Rank 1: 
MPI Rank 1: Post-processing network...
MPI Rank 1: 
MPI Rank 1: 7 roots:
MPI Rank 1: 	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
MPI Rank 1: 	EvalErrorPrediction = ErrorPrediction()
MPI Rank 1: 	InvStdOfFeatures = InvStdDev()
MPI Rank 1: 	MeanOfFeatures = Mean()
MPI Rank 1: 	PosteriorProb = Softmax()
MPI Rank 1: 	Prior = Mean()
MPI Rank 1: 	ScaledLogLikelihood = Minus()
MPI Rank 1: 
MPI Rank 1: Validating network. 25 nodes to process in pass 1.
MPI Rank 1: 
MPI Rank 1: Validating --> labels = InputValue() :  -> [132 x *]
MPI Rank 1: Validating --> W2 = LearnableParameter() :  -> [132 x 512]
MPI Rank 1: Validating --> W1 = LearnableParameter() :  -> [512 x 512]
MPI Rank 1: Validating --> W0 = LearnableParameter() :  -> [512 x 363]
MPI Rank 1: Validating --> features = InputValue() :  -> [363 x *]
MPI Rank 1: Validating --> MeanOfFeatures = Mean (features) : [363 x *] -> [363]
MPI Rank 1: Validating --> InvStdOfFeatures = InvStdDev (features) : [363 x *] -> [363]
MPI Rank 1: Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [363 x *], [363], [363] -> [363 x *]
MPI Rank 1: Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [512 x 363], [363 x *] -> [512 x *]
MPI Rank 1: Validating --> B0 = LearnableParameter() :  -> [512 x 1]
MPI Rank 1: Validating --> W0*features+B0 = Plus (W0*features, B0) : [512 x *], [512 x 1] -> [512 x 1 x *]
MPI Rank 1: Validating --> H1 = Sigmoid (W0*features+B0) : [512 x 1 x *] -> [512 x 1 x *]
MPI Rank 1: Validating --> W1*H1 = Times (W1, H1) : [512 x 512], [512 x 1 x *] -> [512 x 1 x *]
MPI Rank 1: Validating --> B1 = LearnableParameter() :  -> [512 x 1]
MPI Rank 1: Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [512 x 1 x *], [512 x 1] -> [512 x 1 x *]
MPI Rank 1: Validating --> H2 = Sigmoid (W1*H1+B1) : [512 x 1 x *] -> [512 x 1 x *]
MPI Rank 1: Validating --> W2*H1 = Times (W2, H2) : [132 x 512], [512 x 1 x *] -> [132 x 1 x *]
MPI Rank 1: Validating --> B2 = LearnableParameter() :  -> [132 x 1]
MPI Rank 1: Validating --> HLast = Plus (W2*H1, B2) : [132 x 1 x *], [132 x 1] -> [132 x 1 x *]
MPI Rank 1: Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [132 x *], [132 x 1 x *] -> [1]
MPI Rank 1: Validating --> EvalErrorPrediction = ErrorPrediction (labels, HLast) : [132 x *], [132 x 1 x *] -> [1]
MPI Rank 1: Validating --> PosteriorProb = Softmax (HLast) : [132 x 1 x *] -> [132 x 1 x *]
MPI Rank 1: Validating --> Prior = Mean (labels) : [132 x *] -> [132]
MPI Rank 1: Validating --> LogOfPrior = Log (Prior) : [132] -> [132]
MPI Rank 1: Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [132 x 1 x *], [132] -> [132 x 1 x *]
MPI Rank 1: 
MPI Rank 1: Validating network. 17 nodes to process in pass 2.
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: Validating network, final pass.
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: 12 out of 25 nodes do not share the minibatch layout with the input data.
MPI Rank 1: 
MPI Rank 1: Post-processing network complete.
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:41:22: Created model with 25 nodes on CPU.
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:41:22: Training criterion node(s):
MPI Rank 1: 07/14/2016 12:41:22: 	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:41:22: Evaluation criterion node(s):
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:41:22: 	EvalErrorPrediction = ErrorPrediction
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: Allocating matrices for forward and/or backward propagation.
MPI Rank 1: 
MPI Rank 1: Memory Sharing Structure:
MPI Rank 1: 
MPI Rank 1: (nil): {[EvalErrorPrediction Gradient[1]] [InvStdOfFeatures Gradient[363]] [LogOfPrior Gradient[132]] [MVNormalizedFeatures Gradient[363 x *]] [MeanOfFeatures Gradient[363]] [PosteriorProb Gradient[132 x 1 x *]] [PosteriorProb Value[132 x 1 x *]] [Prior Gradient[132]] [ScaledLogLikelihood Gradient[132 x 1 x *]] [features Gradient[363 x *]] [labels Gradient[132 x *]] }
MPI Rank 1: 0x2788948: {[features Value[363 x *]] }
MPI Rank 1: 0x278f848: {[B0 Value[512 x 1]] }
MPI Rank 1: 0x2793398: {[W0*features Value[512 x *]] }
MPI Rank 1: 0x2795e88: {[W1 Value[512 x 512]] }
MPI Rank 1: 0x2796018: {[W0 Gradient[512 x 363]] [W0*features+B0 Value[512 x 1 x *]] }
MPI Rank 1: 0x27961d8: {[H1 Value[512 x 1 x *]] [W0*features Gradient[512 x *]] }
MPI Rank 1: 0x2796398: {[W0*features+B0 Gradient[512 x 1 x *]] [W1*H1 Value[512 x 1 x *]] }
MPI Rank 1: 0x2796558: {[W1 Gradient[512 x 512]] [W1*H1+B1 Value[512 x 1 x *]] }
MPI Rank 1: 0x2796718: {[H2 Value[512 x 1 x *]] [W1*H1 Gradient[512 x 1 x *]] }
MPI Rank 1: 0x27a5668: {[W0 Value[512 x 363]] }
MPI Rank 1: 0x27a58a8: {[InvStdOfFeatures Value[363]] }
MPI Rank 1: 0x27afe38: {[CrossEntropyWithSoftmax Gradient[1]] }
MPI Rank 1: 0x27afff8: {[B1 Gradient[512 x 1]] [H2 Gradient[512 x 1 x *]] [HLast Gradient[132 x 1 x *]] }
MPI Rank 1: 0x27b01b8: {[W2*H1 Gradient[132 x 1 x *]] }
MPI Rank 1: 0x27c6408: {[B1 Value[512 x 1]] }
MPI Rank 1: 0x27d18c8: {[B2 Gradient[132 x 1]] }
MPI Rank 1: 0x27e4458: {[EvalErrorPrediction Value[1]] }
MPI Rank 1: 0x27e45b8: {[ScaledLogLikelihood Value[132 x 1 x *]] }
MPI Rank 1: 0x27e5528: {[B2 Value[132 x 1]] }
MPI Rank 1: 0x2a66348: {[Prior Value[132]] }
MPI Rank 1: 0x2a9ee68: {[labels Value[132 x *]] }
MPI Rank 1: 0x2aa2068: {[CrossEntropyWithSoftmax Value[1]] }
MPI Rank 1: 0x2aa2488: {[MVNormalizedFeatures Value[363 x *]] }
MPI Rank 1: 0x2aa2538: {[LogOfPrior Value[132]] }
MPI Rank 1: 0x2ab21a8: {[MeanOfFeatures Value[363]] }
MPI Rank 1: 0x2ab5c88: {[W2 Value[132 x 512]] }
MPI Rank 1: 0x2ab7bd8: {[B0 Gradient[512 x 1]] [H1 Gradient[512 x 1 x *]] [W1*H1+B1 Gradient[512 x 1 x *]] [W2*H1 Value[132 x 1 x *]] }
MPI Rank 1: 0x2ab7d98: {[HLast Value[132 x 1 x *]] [W2 Gradient[132 x 512]] }
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:41:22: Precomputing --> 3 PreCompute nodes found.
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:41:22: 	MeanOfFeatures = Mean()
MPI Rank 1: 07/14/2016 12:41:22: 	InvStdOfFeatures = InvStdDev()
MPI Rank 1: 07/14/2016 12:41:22: 	Prior = Mean()
MPI Rank 1: minibatchiterator: epoch 0: frames [0..252734] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
MPI Rank 1: requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:41:24: Precomputing --> Completed.
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:41:24: Starting Epoch 1: learning rate per sample = 0.015625  effective momentum = 0.900000  momentum as time constant = 607.4 samples
MPI Rank 1: minibatchiterator: epoch 0: frames [0..20480] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:41:24: Starting minibatch loop.
MPI Rank 1: 07/14/2016 12:41:24:  Epoch[ 1 of 5]-Minibatch[   1-   3, 0.94%]: CrossEntropyWithSoftmax = 4.56947300 * 192; EvalErrorPrediction = 0.93750000 * 192; time = 0.1012s; samplesPerSecond = 1897.5
MPI Rank 1: 07/14/2016 12:41:24:  Epoch[ 1 of 5]-Minibatch[   4-   6, 1.88%]: CrossEntropyWithSoftmax = 4.43406315 * 192; EvalErrorPrediction = 0.93229167 * 192; time = 0.0955s; samplesPerSecond = 2009.7
MPI Rank 1: 07/14/2016 12:41:24:  Epoch[ 1 of 5]-Minibatch[   7-   9, 2.81%]: CrossEntropyWithSoftmax = 4.27880063 * 192; EvalErrorPrediction = 0.86458333 * 192; time = 0.0965s; samplesPerSecond = 1990.6
MPI Rank 1: 07/14/2016 12:41:24:  Epoch[ 1 of 5]-Minibatch[  10-  12, 3.75%]: CrossEntropyWithSoftmax = 4.08751953 * 192; EvalErrorPrediction = 0.86979167 * 192; time = 0.0963s; samplesPerSecond = 1993.0
MPI Rank 1: 07/14/2016 12:41:24:  Epoch[ 1 of 5]-Minibatch[  13-  15, 4.69%]: CrossEntropyWithSoftmax = 4.21737559 * 192; EvalErrorPrediction = 0.91145833 * 192; time = 0.0916s; samplesPerSecond = 2095.1
MPI Rank 1: 07/14/2016 12:41:24:  Epoch[ 1 of 5]-Minibatch[  16-  18, 5.62%]: CrossEntropyWithSoftmax = 4.14259750 * 192; EvalErrorPrediction = 0.92187500 * 192; time = 0.0945s; samplesPerSecond = 2031.0
MPI Rank 1: 07/14/2016 12:41:24:  Epoch[ 1 of 5]-Minibatch[  19-  21, 6.56%]: CrossEntropyWithSoftmax = 4.03221539 * 192; EvalErrorPrediction = 0.85416667 * 192; time = 0.1026s; samplesPerSecond = 1871.5
MPI Rank 1: 07/14/2016 12:41:25:  Epoch[ 1 of 5]-Minibatch[  22-  24, 7.50%]: CrossEntropyWithSoftmax = 4.09889450 * 192; EvalErrorPrediction = 0.89062500 * 192; time = 0.0961s; samplesPerSecond = 1997.4
MPI Rank 1: 07/14/2016 12:41:25:  Epoch[ 1 of 5]-Minibatch[  25-  27, 8.44%]: CrossEntropyWithSoftmax = 3.89612175 * 192; EvalErrorPrediction = 0.83854167 * 192; time = 0.0931s; samplesPerSecond = 2062.2
MPI Rank 1: 07/14/2016 12:41:25:  Epoch[ 1 of 5]-Minibatch[  28-  30, 9.38%]: CrossEntropyWithSoftmax = 3.98897999 * 192; EvalErrorPrediction = 0.88020833 * 192; time = 0.0933s; samplesPerSecond = 2057.0
MPI Rank 1: 07/14/2016 12:41:25:  Epoch[ 1 of 5]-Minibatch[  31-  33, 10.31%]: CrossEntropyWithSoftmax = 3.93572978 * 192; EvalErrorPrediction = 0.83333333 * 192; time = 0.0983s; samplesPerSecond = 1953.7
MPI Rank 1: 07/14/2016 12:41:25:  Epoch[ 1 of 5]-Minibatch[  34-  36, 11.25%]: CrossEntropyWithSoftmax = 3.76284095 * 192; EvalErrorPrediction = 0.89062500 * 192; time = 0.0985s; samplesPerSecond = 1948.8
MPI Rank 1: 07/14/2016 12:41:25:  Epoch[ 1 of 5]-Minibatch[  37-  39, 12.19%]: CrossEntropyWithSoftmax = 3.98522385 * 192; EvalErrorPrediction = 0.87500000 * 192; time = 0.0949s; samplesPerSecond = 2022.4
MPI Rank 1: 07/14/2016 12:41:25:  Epoch[ 1 of 5]-Minibatch[  40-  42, 13.12%]: CrossEntropyWithSoftmax = 3.66209590 * 192; EvalErrorPrediction = 0.84895833 * 192; time = 0.0989s; samplesPerSecond = 1942.0
MPI Rank 1: 07/14/2016 12:41:25:  Epoch[ 1 of 5]-Minibatch[  43-  45, 14.06%]: CrossEntropyWithSoftmax = 3.96368107 * 192; EvalErrorPrediction = 0.91666667 * 192; time = 0.0945s; samplesPerSecond = 2031.3
MPI Rank 1: 07/14/2016 12:41:25:  Epoch[ 1 of 5]-Minibatch[  46-  48, 15.00%]: CrossEntropyWithSoftmax = 3.76732554 * 192; EvalErrorPrediction = 0.85416667 * 192; time = 0.0938s; samplesPerSecond = 2045.8
MPI Rank 1: 07/14/2016 12:41:25:  Epoch[ 1 of 5]-Minibatch[  49-  51, 15.94%]: CrossEntropyWithSoftmax = 3.69456327 * 192; EvalErrorPrediction = 0.89062500 * 192; time = 0.0972s; samplesPerSecond = 1975.7
MPI Rank 1: 07/14/2016 12:41:26:  Epoch[ 1 of 5]-Minibatch[  52-  54, 16.88%]: CrossEntropyWithSoftmax = 3.82975145 * 192; EvalErrorPrediction = 0.89583333 * 192; time = 0.0959s; samplesPerSecond = 2001.8
MPI Rank 1: 07/14/2016 12:41:26:  Epoch[ 1 of 5]-Minibatch[  55-  57, 17.81%]: CrossEntropyWithSoftmax = 3.82370243 * 192; EvalErrorPrediction = 0.88020833 * 192; time = 0.0962s; samplesPerSecond = 1996.4
MPI Rank 1: 07/14/2016 12:41:26:  Epoch[ 1 of 5]-Minibatch[  58-  60, 18.75%]: CrossEntropyWithSoftmax = 3.57625565 * 192; EvalErrorPrediction = 0.84895833 * 192; time = 0.0966s; samplesPerSecond = 1986.7
MPI Rank 1: 07/14/2016 12:41:26:  Epoch[ 1 of 5]-Minibatch[  61-  63, 19.69%]: CrossEntropyWithSoftmax = 3.38811493 * 192; EvalErrorPrediction = 0.79166667 * 192; time = 0.0956s; samplesPerSecond = 2008.4
MPI Rank 1: 07/14/2016 12:41:26:  Epoch[ 1 of 5]-Minibatch[  64-  66, 20.62%]: CrossEntropyWithSoftmax = 3.52208661 * 192; EvalErrorPrediction = 0.77604167 * 192; time = 0.0969s; samplesPerSecond = 1980.9
MPI Rank 1: 07/14/2016 12:41:26:  Epoch[ 1 of 5]-Minibatch[  67-  69, 21.56%]: CrossEntropyWithSoftmax = 3.80866929 * 192; EvalErrorPrediction = 0.87500000 * 192; time = 0.0953s; samplesPerSecond = 2014.2
MPI Rank 1: 07/14/2016 12:41:26:  Epoch[ 1 of 5]-Minibatch[  70-  72, 22.50%]: CrossEntropyWithSoftmax = 3.54345746 * 192; EvalErrorPrediction = 0.86458333 * 192; time = 0.1021s; samplesPerSecond = 1881.3
MPI Rank 1: 07/14/2016 12:41:26:  Epoch[ 1 of 5]-Minibatch[  73-  75, 23.44%]: CrossEntropyWithSoftmax = 3.33936350 * 192; EvalErrorPrediction = 0.80208333 * 192; time = 0.0919s; samplesPerSecond = 2089.0
MPI Rank 1: 07/14/2016 12:41:26:  Epoch[ 1 of 5]-Minibatch[  76-  78, 24.38%]: CrossEntropyWithSoftmax = 3.43672338 * 192; EvalErrorPrediction = 0.78125000 * 192; time = 0.0984s; samplesPerSecond = 1951.6
MPI Rank 1: 07/14/2016 12:41:26:  Epoch[ 1 of 5]-Minibatch[  79-  81, 25.31%]: CrossEntropyWithSoftmax = 3.44585129 * 192; EvalErrorPrediction = 0.82812500 * 192; time = 0.0973s; samplesPerSecond = 1973.7
MPI Rank 1: 07/14/2016 12:41:27:  Epoch[ 1 of 5]-Minibatch[  82-  84, 26.25%]: CrossEntropyWithSoftmax = 3.43498669 * 192; EvalErrorPrediction = 0.76041667 * 192; time = 0.0964s; samplesPerSecond = 1991.7
MPI Rank 1: 07/14/2016 12:41:27:  Epoch[ 1 of 5]-Minibatch[  85-  87, 27.19%]: CrossEntropyWithSoftmax = 3.31632754 * 192; EvalErrorPrediction = 0.75000000 * 192; time = 0.0972s; samplesPerSecond = 1975.2
MPI Rank 1: 07/14/2016 12:41:27:  Epoch[ 1 of 5]-Minibatch[  88-  90, 28.12%]: CrossEntropyWithSoftmax = 3.33946924 * 192; EvalErrorPrediction = 0.80208333 * 192; time = 0.0958s; samplesPerSecond = 2003.2
MPI Rank 1: 07/14/2016 12:41:27:  Epoch[ 1 of 5]-Minibatch[  91-  93, 29.06%]: CrossEntropyWithSoftmax = 3.26118575 * 192; EvalErrorPrediction = 0.84375000 * 192; time = 0.0925s; samplesPerSecond = 2076.1
MPI Rank 1: 07/14/2016 12:41:27:  Epoch[ 1 of 5]-Minibatch[  94-  96, 30.00%]: CrossEntropyWithSoftmax = 3.56686839 * 192; EvalErrorPrediction = 0.85416667 * 192; time = 0.0951s; samplesPerSecond = 2019.7
MPI Rank 1: 07/14/2016 12:41:27:  Epoch[ 1 of 5]-Minibatch[  97-  99, 30.94%]: CrossEntropyWithSoftmax = 3.36674876 * 192; EvalErrorPrediction = 0.85416667 * 192; time = 0.0960s; samplesPerSecond = 2000.9
MPI Rank 1: 07/14/2016 12:41:27:  Epoch[ 1 of 5]-Minibatch[ 100- 102, 31.87%]: CrossEntropyWithSoftmax = 3.28977127 * 192; EvalErrorPrediction = 0.81250000 * 192; time = 0.0940s; samplesPerSecond = 2041.7
MPI Rank 1: 07/14/2016 12:41:27:  Epoch[ 1 of 5]-Minibatch[ 103- 105, 32.81%]: CrossEntropyWithSoftmax = 3.27969909 * 192; EvalErrorPrediction = 0.79166667 * 192; time = 0.0968s; samplesPerSecond = 1983.0
MPI Rank 1: 07/14/2016 12:41:27:  Epoch[ 1 of 5]-Minibatch[ 106- 108, 33.75%]: CrossEntropyWithSoftmax = 3.12259596 * 192; EvalErrorPrediction = 0.72916667 * 192; time = 0.0963s; samplesPerSecond = 1993.7
MPI Rank 1: 07/14/2016 12:41:27:  Epoch[ 1 of 5]-Minibatch[ 109- 111, 34.69%]: CrossEntropyWithSoftmax = 3.41981056 * 192; EvalErrorPrediction = 0.77604167 * 192; time = 0.0941s; samplesPerSecond = 2040.3
MPI Rank 1: 07/14/2016 12:41:27:  Epoch[ 1 of 5]-Minibatch[ 112- 114, 35.62%]: CrossEntropyWithSoftmax = 3.38297602 * 192; EvalErrorPrediction = 0.79166667 * 192; time = 0.0999s; samplesPerSecond = 1921.6
MPI Rank 1: 07/14/2016 12:41:28:  Epoch[ 1 of 5]-Minibatch[ 115- 117, 36.56%]: CrossEntropyWithSoftmax = 3.41994711 * 192; EvalErrorPrediction = 0.82812500 * 192; time = 0.0986s; samplesPerSecond = 1946.5
MPI Rank 1: 07/14/2016 12:41:28:  Epoch[ 1 of 5]-Minibatch[ 118- 120, 37.50%]: CrossEntropyWithSoftmax = 3.24732267 * 192; EvalErrorPrediction = 0.78125000 * 192; time = 0.0980s; samplesPerSecond = 1958.4
MPI Rank 1: 07/14/2016 12:41:28:  Epoch[ 1 of 5]-Minibatch[ 121- 123, 38.44%]: CrossEntropyWithSoftmax = 3.20269035 * 192; EvalErrorPrediction = 0.76041667 * 192; time = 0.0968s; samplesPerSecond = 1982.5
MPI Rank 1: 07/14/2016 12:41:28:  Epoch[ 1 of 5]-Minibatch[ 124- 126, 39.38%]: CrossEntropyWithSoftmax = 3.15326365 * 192; EvalErrorPrediction = 0.74479167 * 192; time = 0.0933s; samplesPerSecond = 2057.7
MPI Rank 1: 07/14/2016 12:41:28:  Epoch[ 1 of 5]-Minibatch[ 127- 129, 40.31%]: CrossEntropyWithSoftmax = 3.21802066 * 192; EvalErrorPrediction = 0.78125000 * 192; time = 0.0987s; samplesPerSecond = 1945.2
MPI Rank 1: 07/14/2016 12:41:28:  Epoch[ 1 of 5]-Minibatch[ 130- 132, 41.25%]: CrossEntropyWithSoftmax = 3.26091070 * 192; EvalErrorPrediction = 0.76041667 * 192; time = 0.0965s; samplesPerSecond = 1990.7
MPI Rank 1: 07/14/2016 12:41:28:  Epoch[ 1 of 5]-Minibatch[ 133- 135, 42.19%]: CrossEntropyWithSoftmax = 2.94987113 * 192; EvalErrorPrediction = 0.68229167 * 192; time = 0.0980s; samplesPerSecond = 1959.6
MPI Rank 1: 07/14/2016 12:41:28:  Epoch[ 1 of 5]-Minibatch[ 136- 138, 43.12%]: CrossEntropyWithSoftmax = 3.01829231 * 192; EvalErrorPrediction = 0.70312500 * 192; time = 0.1000s; samplesPerSecond = 1920.5
MPI Rank 1: 07/14/2016 12:41:28:  Epoch[ 1 of 5]-Minibatch[ 139- 141, 44.06%]: CrossEntropyWithSoftmax = 3.19981302 * 192; EvalErrorPrediction = 0.76562500 * 192; time = 0.0990s; samplesPerSecond = 1939.3
MPI Rank 1: 07/14/2016 12:41:28:  Epoch[ 1 of 5]-Minibatch[ 142- 144, 45.00%]: CrossEntropyWithSoftmax = 3.01620054 * 192; EvalErrorPrediction = 0.72916667 * 192; time = 0.0974s; samplesPerSecond = 1971.2
MPI Rank 1: 07/14/2016 12:41:29:  Epoch[ 1 of 5]-Minibatch[ 145- 147, 45.94%]: CrossEntropyWithSoftmax = 3.07482512 * 192; EvalErrorPrediction = 0.76562500 * 192; time = 0.0978s; samplesPerSecond = 1962.8
MPI Rank 1: 07/14/2016 12:41:29:  Epoch[ 1 of 5]-Minibatch[ 148- 150, 46.88%]: CrossEntropyWithSoftmax = 2.95940261 * 192; EvalErrorPrediction = 0.71875000 * 192; time = 0.0981s; samplesPerSecond = 1957.8
MPI Rank 1: 07/14/2016 12:41:29:  Epoch[ 1 of 5]-Minibatch[ 151- 153, 47.81%]: CrossEntropyWithSoftmax = 3.18955068 * 192; EvalErrorPrediction = 0.78125000 * 192; time = 0.0977s; samplesPerSecond = 1965.1
MPI Rank 1: 07/14/2016 12:41:29:  Epoch[ 1 of 5]-Minibatch[ 154- 156, 48.75%]: CrossEntropyWithSoftmax = 2.80225800 * 192; EvalErrorPrediction = 0.70312500 * 192; time = 0.0979s; samplesPerSecond = 1961.5
MPI Rank 1: 07/14/2016 12:41:29:  Epoch[ 1 of 5]-Minibatch[ 157- 159, 49.69%]: CrossEntropyWithSoftmax = 3.08865913 * 192; EvalErrorPrediction = 0.75520833 * 192; time = 0.0937s; samplesPerSecond = 2048.3
MPI Rank 1: 07/14/2016 12:41:29:  Epoch[ 1 of 5]-Minibatch[ 160- 162, 50.62%]: CrossEntropyWithSoftmax = 2.87171438 * 192; EvalErrorPrediction = 0.69791667 * 192; time = 0.0984s; samplesPerSecond = 1951.0
MPI Rank 1: 07/14/2016 12:41:29:  Epoch[ 1 of 5]-Minibatch[ 163- 165, 51.56%]: CrossEntropyWithSoftmax = 2.90723268 * 192; EvalErrorPrediction = 0.73958333 * 192; time = 0.0992s; samplesPerSecond = 1935.6
MPI Rank 1: 07/14/2016 12:41:29:  Epoch[ 1 of 5]-Minibatch[ 166- 168, 52.50%]: CrossEntropyWithSoftmax = 2.96438386 * 192; EvalErrorPrediction = 0.69270833 * 192; time = 0.0985s; samplesPerSecond = 1949.1
MPI Rank 1: 07/14/2016 12:41:29:  Epoch[ 1 of 5]-Minibatch[ 169- 171, 53.44%]: CrossEntropyWithSoftmax = 2.85407675 * 192; EvalErrorPrediction = 0.67708333 * 192; time = 0.0973s; samplesPerSecond = 1973.6
MPI Rank 1: 07/14/2016 12:41:29:  Epoch[ 1 of 5]-Minibatch[ 172- 174, 54.37%]: CrossEntropyWithSoftmax = 2.64516293 * 192; EvalErrorPrediction = 0.63020833 * 192; time = 0.0980s; samplesPerSecond = 1959.9
MPI Rank 1: 07/14/2016 12:41:30:  Epoch[ 1 of 5]-Minibatch[ 175- 177, 55.31%]: CrossEntropyWithSoftmax = 2.78779884 * 192; EvalErrorPrediction = 0.73437500 * 192; time = 0.0976s; samplesPerSecond = 1967.1
MPI Rank 1: 07/14/2016 12:41:30:  Epoch[ 1 of 5]-Minibatch[ 178- 180, 56.25%]: CrossEntropyWithSoftmax = 2.77691077 * 192; EvalErrorPrediction = 0.68229167 * 192; time = 0.0961s; samplesPerSecond = 1997.2
MPI Rank 1: 07/14/2016 12:41:30:  Epoch[ 1 of 5]-Minibatch[ 181- 183, 57.19%]: CrossEntropyWithSoftmax = 2.93466303 * 192; EvalErrorPrediction = 0.68229167 * 192; time = 0.0964s; samplesPerSecond = 1992.1
MPI Rank 1: 07/14/2016 12:41:30:  Epoch[ 1 of 5]-Minibatch[ 184- 186, 58.13%]: CrossEntropyWithSoftmax = 2.79665615 * 192; EvalErrorPrediction = 0.69791667 * 192; time = 0.0987s; samplesPerSecond = 1944.4
MPI Rank 1: 07/14/2016 12:41:30:  Epoch[ 1 of 5]-Minibatch[ 187- 189, 59.06%]: CrossEntropyWithSoftmax = 2.79141433 * 192; EvalErrorPrediction = 0.75520833 * 192; time = 0.0984s; samplesPerSecond = 1951.7
MPI Rank 1: 07/14/2016 12:41:30:  Epoch[ 1 of 5]-Minibatch[ 190- 192, 60.00%]: CrossEntropyWithSoftmax = 2.85677634 * 192; EvalErrorPrediction = 0.68750000 * 192; time = 0.0986s; samplesPerSecond = 1947.1
MPI Rank 1: 07/14/2016 12:41:30:  Epoch[ 1 of 5]-Minibatch[ 193- 195, 60.94%]: CrossEntropyWithSoftmax = 2.60438340 * 192; EvalErrorPrediction = 0.62500000 * 192; time = 0.0988s; samplesPerSecond = 1943.7
MPI Rank 1: 07/14/2016 12:41:30:  Epoch[ 1 of 5]-Minibatch[ 196- 198, 61.88%]: CrossEntropyWithSoftmax = 2.67867701 * 192; EvalErrorPrediction = 0.66666667 * 192; time = 0.0988s; samplesPerSecond = 1943.9
MPI Rank 1: 07/14/2016 12:41:30:  Epoch[ 1 of 5]-Minibatch[ 199- 201, 62.81%]: CrossEntropyWithSoftmax = 2.35420452 * 192; EvalErrorPrediction = 0.61458333 * 192; time = 0.0993s; samplesPerSecond = 1934.4
MPI Rank 1: 07/14/2016 12:41:30:  Epoch[ 1 of 5]-Minibatch[ 202- 204, 63.75%]: CrossEntropyWithSoftmax = 2.67860524 * 192; EvalErrorPrediction = 0.68750000 * 192; time = 0.0989s; samplesPerSecond = 1941.3
MPI Rank 1: 07/14/2016 12:41:31:  Epoch[ 1 of 5]-Minibatch[ 205- 207, 64.69%]: CrossEntropyWithSoftmax = 2.74438644 * 192; EvalErrorPrediction = 0.65625000 * 192; time = 0.0969s; samplesPerSecond = 1982.4
MPI Rank 1: 07/14/2016 12:41:31:  Epoch[ 1 of 5]-Minibatch[ 208- 210, 65.62%]: CrossEntropyWithSoftmax = 2.61472294 * 192; EvalErrorPrediction = 0.65625000 * 192; time = 0.0955s; samplesPerSecond = 2011.0
MPI Rank 1: 07/14/2016 12:41:31:  Epoch[ 1 of 5]-Minibatch[ 211- 213, 66.56%]: CrossEntropyWithSoftmax = 2.56292238 * 192; EvalErrorPrediction = 0.65104167 * 192; time = 0.0975s; samplesPerSecond = 1970.2
MPI Rank 1: 07/14/2016 12:41:31:  Epoch[ 1 of 5]-Minibatch[ 214- 216, 67.50%]: CrossEntropyWithSoftmax = 2.49905414 * 192; EvalErrorPrediction = 0.68229167 * 192; time = 0.0969s; samplesPerSecond = 1981.9
MPI Rank 1: 07/14/2016 12:41:31:  Epoch[ 1 of 5]-Minibatch[ 217- 219, 68.44%]: CrossEntropyWithSoftmax = 2.77977518 * 192; EvalErrorPrediction = 0.67708333 * 192; time = 0.0972s; samplesPerSecond = 1976.0
MPI Rank 1: 07/14/2016 12:41:31:  Epoch[ 1 of 5]-Minibatch[ 220- 222, 69.38%]: CrossEntropyWithSoftmax = 2.46098943 * 192; EvalErrorPrediction = 0.60416667 * 192; time = 0.0993s; samplesPerSecond = 1934.2
MPI Rank 1: 07/14/2016 12:41:31:  Epoch[ 1 of 5]-Minibatch[ 223- 225, 70.31%]: CrossEntropyWithSoftmax = 2.53972637 * 192; EvalErrorPrediction = 0.60416667 * 192; time = 0.0979s; samplesPerSecond = 1960.2
MPI Rank 1: 07/14/2016 12:41:31:  Epoch[ 1 of 5]-Minibatch[ 226- 228, 71.25%]: CrossEntropyWithSoftmax = 2.58069409 * 192; EvalErrorPrediction = 0.64583333 * 192; time = 0.0983s; samplesPerSecond = 1954.1
MPI Rank 1: 07/14/2016 12:41:31:  Epoch[ 1 of 5]-Minibatch[ 229- 231, 72.19%]: CrossEntropyWithSoftmax = 2.42808307 * 192; EvalErrorPrediction = 0.62500000 * 192; time = 0.0982s; samplesPerSecond = 1955.0
MPI Rank 1: 07/14/2016 12:41:31:  Epoch[ 1 of 5]-Minibatch[ 232- 234, 73.12%]: CrossEntropyWithSoftmax = 2.51795774 * 192; EvalErrorPrediction = 0.66666667 * 192; time = 0.1024s; samplesPerSecond = 1875.1
MPI Rank 1: 07/14/2016 12:41:31:  Epoch[ 1 of 5]-Minibatch[ 235- 237, 74.06%]: CrossEntropyWithSoftmax = 2.31017953 * 192; EvalErrorPrediction = 0.63541667 * 192; time = 0.0980s; samplesPerSecond = 1958.2
MPI Rank 1: 07/14/2016 12:41:32:  Epoch[ 1 of 5]-Minibatch[ 238- 240, 75.00%]: CrossEntropyWithSoftmax = 2.42763250 * 192; EvalErrorPrediction = 0.59375000 * 192; time = 0.0992s; samplesPerSecond = 1935.2
MPI Rank 1: 07/14/2016 12:41:32:  Epoch[ 1 of 5]-Minibatch[ 241- 243, 75.94%]: CrossEntropyWithSoftmax = 2.38337452 * 192; EvalErrorPrediction = 0.63020833 * 192; time = 0.1006s; samplesPerSecond = 1907.8
MPI Rank 1: 07/14/2016 12:41:32:  Epoch[ 1 of 5]-Minibatch[ 244- 246, 76.88%]: CrossEntropyWithSoftmax = 2.45688385 * 192; EvalErrorPrediction = 0.68229167 * 192; time = 0.0978s; samplesPerSecond = 1964.1
MPI Rank 1: 07/14/2016 12:41:32:  Epoch[ 1 of 5]-Minibatch[ 247- 249, 77.81%]: CrossEntropyWithSoftmax = 2.35065649 * 192; EvalErrorPrediction = 0.63020833 * 192; time = 0.0955s; samplesPerSecond = 2010.1
MPI Rank 1: 07/14/2016 12:41:32:  Epoch[ 1 of 5]-Minibatch[ 250- 252, 78.75%]: CrossEntropyWithSoftmax = 2.39950363 * 192; EvalErrorPrediction = 0.63541667 * 192; time = 0.0963s; samplesPerSecond = 1994.8
MPI Rank 1: 07/14/2016 12:41:32:  Epoch[ 1 of 5]-Minibatch[ 253- 255, 79.69%]: CrossEntropyWithSoftmax = 2.48031632 * 192; EvalErrorPrediction = 0.60937500 * 192; time = 0.0981s; samplesPerSecond = 1957.8
MPI Rank 1: 07/14/2016 12:41:32:  Epoch[ 1 of 5]-Minibatch[ 256- 258, 80.62%]: CrossEntropyWithSoftmax = 2.62124157 * 192; EvalErrorPrediction = 0.67708333 * 192; time = 0.0972s; samplesPerSecond = 1974.7
MPI Rank 1: 07/14/2016 12:41:32:  Epoch[ 1 of 5]-Minibatch[ 259- 261, 81.56%]: CrossEntropyWithSoftmax = 2.43263192 * 192; EvalErrorPrediction = 0.65625000 * 192; time = 0.0962s; samplesPerSecond = 1996.3
MPI Rank 1: 07/14/2016 12:41:32:  Epoch[ 1 of 5]-Minibatch[ 262- 264, 82.50%]: CrossEntropyWithSoftmax = 2.13490764 * 192; EvalErrorPrediction = 0.57291667 * 192; time = 0.0983s; samplesPerSecond = 1953.0
MPI Rank 1: 07/14/2016 12:41:32:  Epoch[ 1 of 5]-Minibatch[ 265- 267, 83.44%]: CrossEntropyWithSoftmax = 2.52272390 * 192; EvalErrorPrediction = 0.63541667 * 192; time = 0.0964s; samplesPerSecond = 1991.5
MPI Rank 1: 07/14/2016 12:41:33:  Epoch[ 1 of 5]-Minibatch[ 268- 270, 84.38%]: CrossEntropyWithSoftmax = 2.31215555 * 192; EvalErrorPrediction = 0.63020833 * 192; time = 0.0972s; samplesPerSecond = 1975.5
MPI Rank 1: 07/14/2016 12:41:33:  Epoch[ 1 of 5]-Minibatch[ 271- 273, 85.31%]: CrossEntropyWithSoftmax = 2.33888920 * 192; EvalErrorPrediction = 0.60416667 * 192; time = 0.0950s; samplesPerSecond = 2020.6
MPI Rank 1: 07/14/2016 12:41:33:  Epoch[ 1 of 5]-Minibatch[ 274- 276, 86.25%]: CrossEntropyWithSoftmax = 2.19318149 * 192; EvalErrorPrediction = 0.58854167 * 192; time = 0.0977s; samplesPerSecond = 1964.4
MPI Rank 1: 07/14/2016 12:41:33:  Epoch[ 1 of 5]-Minibatch[ 277- 279, 87.19%]: CrossEntropyWithSoftmax = 2.19368853 * 192; EvalErrorPrediction = 0.55208333 * 192; time = 0.1004s; samplesPerSecond = 1912.6
MPI Rank 1: 07/14/2016 12:41:33:  Epoch[ 1 of 5]-Minibatch[ 280- 282, 88.12%]: CrossEntropyWithSoftmax = 2.31322736 * 192; EvalErrorPrediction = 0.59895833 * 192; time = 0.0982s; samplesPerSecond = 1955.4
MPI Rank 1: 07/14/2016 12:41:33:  Epoch[ 1 of 5]-Minibatch[ 283- 285, 89.06%]: CrossEntropyWithSoftmax = 2.21496162 * 192; EvalErrorPrediction = 0.62500000 * 192; time = 0.0950s; samplesPerSecond = 2021.3
MPI Rank 1: 07/14/2016 12:41:33:  Epoch[ 1 of 5]-Minibatch[ 286- 288, 90.00%]: CrossEntropyWithSoftmax = 2.38257678 * 192; EvalErrorPrediction = 0.64062500 * 192; time = 0.0949s; samplesPerSecond = 2022.7
MPI Rank 1: 07/14/2016 12:41:33:  Epoch[ 1 of 5]-Minibatch[ 289- 291, 90.94%]: CrossEntropyWithSoftmax = 2.34785036 * 192; EvalErrorPrediction = 0.60416667 * 192; time = 0.0961s; samplesPerSecond = 1998.4
MPI Rank 1: 07/14/2016 12:41:33:  Epoch[ 1 of 5]-Minibatch[ 292- 294, 91.88%]: CrossEntropyWithSoftmax = 2.20545861 * 192; EvalErrorPrediction = 0.60416667 * 192; time = 0.0945s; samplesPerSecond = 2031.5
MPI Rank 1: 07/14/2016 12:41:33:  Epoch[ 1 of 5]-Minibatch[ 295- 297, 92.81%]: CrossEntropyWithSoftmax = 2.08751143 * 192; EvalErrorPrediction = 0.57291667 * 192; time = 0.0950s; samplesPerSecond = 2022.0
MPI Rank 1: 07/14/2016 12:41:34:  Epoch[ 1 of 5]-Minibatch[ 298- 300, 93.75%]: CrossEntropyWithSoftmax = 2.28302994 * 192; EvalErrorPrediction = 0.64583333 * 192; time = 0.0973s; samplesPerSecond = 1974.2
MPI Rank 1: 07/14/2016 12:41:34:  Epoch[ 1 of 5]-Minibatch[ 301- 303, 94.69%]: CrossEntropyWithSoftmax = 2.22267854 * 192; EvalErrorPrediction = 0.57291667 * 192; time = 0.0984s; samplesPerSecond = 1952.2
MPI Rank 1: 07/14/2016 12:41:34:  Epoch[ 1 of 5]-Minibatch[ 304- 306, 95.62%]: CrossEntropyWithSoftmax = 2.19855044 * 192; EvalErrorPrediction = 0.60416667 * 192; time = 0.0981s; samplesPerSecond = 1957.3
MPI Rank 1: 07/14/2016 12:41:34:  Epoch[ 1 of 5]-Minibatch[ 307- 309, 96.56%]: CrossEntropyWithSoftmax = 2.49612283 * 192; EvalErrorPrediction = 0.64583333 * 192; time = 0.0963s; samplesPerSecond = 1994.0
MPI Rank 1: 07/14/2016 12:41:34:  Epoch[ 1 of 5]-Minibatch[ 310- 312, 97.50%]: CrossEntropyWithSoftmax = 2.25409762 * 192; EvalErrorPrediction = 0.59375000 * 192; time = 0.0975s; samplesPerSecond = 1968.8
MPI Rank 1: 07/14/2016 12:41:34:  Epoch[ 1 of 5]-Minibatch[ 313- 315, 98.44%]: CrossEntropyWithSoftmax = 2.13085317 * 192; EvalErrorPrediction = 0.58333333 * 192; time = 0.0969s; samplesPerSecond = 1981.2
MPI Rank 1: 07/14/2016 12:41:34:  Epoch[ 1 of 5]-Minibatch[ 316- 318, 99.38%]: CrossEntropyWithSoftmax = 2.28902612 * 192; EvalErrorPrediction = 0.59375000 * 192; time = 0.0999s; samplesPerSecond = 1921.0
MPI Rank 1: 07/14/2016 12:41:34: Finished Epoch[ 1 of 5]: [Training] CrossEntropyWithSoftmax = 3.01292779 * 20480; EvalErrorPrediction = 0.72778320 * 20480; totalSamplesSeen = 20480; learningRatePerSample = 0.015625; epochTime=10.3713s
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:41:34: Starting Epoch 2: learning rate per sample = 0.001953  effective momentum = 0.656119  momentum as time constant = 607.5 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 1: frames [20480..40960] (first utterance at frame 20480), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:41:34: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 07/14/2016 12:41:34:  Epoch[ 2 of 5]-Minibatch[   1-   3, 3.75%]: CrossEntropyWithSoftmax = 2.08671820 * 249; EvalErrorPrediction = 0.55020080 * 249; time = 0.1278s; samplesPerSecond = 1948.3
MPI Rank 1: 07/14/2016 12:41:34:  Epoch[ 2 of 5]-Minibatch[   4-   6, 7.50%]: CrossEntropyWithSoftmax = 2.16912508 * 239; EvalErrorPrediction = 0.57740586 * 239; time = 0.1232s; samplesPerSecond = 1939.4
MPI Rank 1: 07/14/2016 12:41:35:  Epoch[ 2 of 5]-Minibatch[   7-   9, 11.25%]: CrossEntropyWithSoftmax = 2.09087687 * 274; EvalErrorPrediction = 0.55109489 * 274; time = 0.1318s; samplesPerSecond = 2078.2
MPI Rank 1: 07/14/2016 12:41:35:  Epoch[ 2 of 5]-Minibatch[  10-  12, 15.00%]: CrossEntropyWithSoftmax = 2.15400834 * 277; EvalErrorPrediction = 0.61371841 * 277; time = 0.1353s; samplesPerSecond = 2047.8
MPI Rank 1: 07/14/2016 12:41:35:  Epoch[ 2 of 5]-Minibatch[  13-  15, 18.75%]: CrossEntropyWithSoftmax = 2.03468379 * 280; EvalErrorPrediction = 0.54642857 * 280; time = 0.1346s; samplesPerSecond = 2080.5
MPI Rank 1: 07/14/2016 12:41:35:  Epoch[ 2 of 5]-Minibatch[  16-  18, 22.50%]: CrossEntropyWithSoftmax = 2.12707706 * 283; EvalErrorPrediction = 0.59363958 * 283; time = 0.1356s; samplesPerSecond = 2086.5
MPI Rank 1: 07/14/2016 12:41:35:  Epoch[ 2 of 5]-Minibatch[  19-  21, 26.25%]: CrossEntropyWithSoftmax = 2.05140796 * 239; EvalErrorPrediction = 0.56903766 * 239; time = 0.1189s; samplesPerSecond = 2009.9
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     1.07 seconds since last report (0.00 seconds on comm.); 4331 samples processed by 2 workers (2141 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 4.04k samplesPerSecond , throughputPerWorker = 2.02k samplesPerSecond
MPI Rank 1: 07/14/2016 12:41:35:  Epoch[ 2 of 5]-Minibatch[  22-  24, 30.00%]: CrossEntropyWithSoftmax = 2.01525982 * 300; EvalErrorPrediction = 0.54666667 * 300; time = 0.1587s; samplesPerSecond = 1890.7
MPI Rank 1: 07/14/2016 12:41:35:  Epoch[ 2 of 5]-Minibatch[  25-  27, 33.75%]: CrossEntropyWithSoftmax = 2.01429833 * 269; EvalErrorPrediction = 0.54646840 * 269; time = 0.1279s; samplesPerSecond = 2103.2
MPI Rank 1: 07/14/2016 12:41:36:  Epoch[ 2 of 5]-Minibatch[  28-  30, 37.50%]: CrossEntropyWithSoftmax = 2.17091946 * 274; EvalErrorPrediction = 0.56569343 * 274; time = 0.1280s; samplesPerSecond = 2140.4
MPI Rank 1: 07/14/2016 12:41:36:  Epoch[ 2 of 5]-Minibatch[  31-  33, 41.25%]: CrossEntropyWithSoftmax = 2.04765590 * 289; EvalErrorPrediction = 0.58823529 * 289; time = 0.1299s; samplesPerSecond = 2224.7
MPI Rank 1: 07/14/2016 12:41:36:  Epoch[ 2 of 5]-Minibatch[  34-  36, 45.00%]: CrossEntropyWithSoftmax = 2.08198284 * 280; EvalErrorPrediction = 0.62857143 * 280; time = 0.1287s; samplesPerSecond = 2175.8
MPI Rank 1: 07/14/2016 12:41:36:  Epoch[ 2 of 5]-Minibatch[  37-  39, 48.75%]: CrossEntropyWithSoftmax = 2.06262072 * 262; EvalErrorPrediction = 0.53435115 * 262; time = 0.1235s; samplesPerSecond = 2120.7
MPI Rank 1: 07/14/2016 12:41:36:  Epoch[ 2 of 5]-Minibatch[  40-  42, 52.50%]: CrossEntropyWithSoftmax = 2.08065983 * 256; EvalErrorPrediction = 0.56250000 * 256; time = 0.1304s; samplesPerSecond = 1963.3
MPI Rank 1: 07/14/2016 12:41:36:  Epoch[ 2 of 5]-Minibatch[  43-  45, 56.25%]: CrossEntropyWithSoftmax = 1.95307697 * 271; EvalErrorPrediction = 0.54243542 * 271; time = 0.1309s; samplesPerSecond = 2071.0
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     1.00 seconds since last report (0.00 seconds on comm.); 4232 samples processed by 2 workers (2078 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 4.23k samplesPerSecond , throughputPerWorker = 2.11k samplesPerSecond
MPI Rank 1: 07/14/2016 12:41:36:  Epoch[ 2 of 5]-Minibatch[  46-  48, 60.00%]: CrossEntropyWithSoftmax = 2.05133637 * 266; EvalErrorPrediction = 0.59022556 * 266; time = 0.1447s; samplesPerSecond = 1837.8
MPI Rank 1: 07/14/2016 12:41:36:  Epoch[ 2 of 5]-Minibatch[  49-  51, 63.75%]: CrossEntropyWithSoftmax = 2.16121433 * 292; EvalErrorPrediction = 0.61643836 * 292; time = 0.1412s; samplesPerSecond = 2067.8
MPI Rank 1: 07/14/2016 12:41:37:  Epoch[ 2 of 5]-Minibatch[  52-  54, 67.50%]: CrossEntropyWithSoftmax = 2.04937835 * 281; EvalErrorPrediction = 0.56939502 * 281; time = 0.1375s; samplesPerSecond = 2044.1
MPI Rank 1: 07/14/2016 12:41:37:  Epoch[ 2 of 5]-Minibatch[  55-  57, 71.25%]: CrossEntropyWithSoftmax = 1.96573797 * 269; EvalErrorPrediction = 0.50557621 * 269; time = 0.1320s; samplesPerSecond = 2038.4
MPI Rank 1: 07/14/2016 12:41:37:  Epoch[ 2 of 5]-Minibatch[  58-  60, 75.00%]: CrossEntropyWithSoftmax = 1.96927408 * 293; EvalErrorPrediction = 0.54607509 * 293; time = 0.1403s; samplesPerSecond = 2088.7
MPI Rank 1: 07/14/2016 12:41:37:  Epoch[ 2 of 5]-Minibatch[  61-  63, 78.75%]: CrossEntropyWithSoftmax = 1.96602409 * 262; EvalErrorPrediction = 0.51526718 * 262; time = 0.1269s; samplesPerSecond = 2064.1
MPI Rank 1: 07/14/2016 12:41:37:  Epoch[ 2 of 5]-Minibatch[  64-  66, 82.50%]: CrossEntropyWithSoftmax = 2.06123892 * 296; EvalErrorPrediction = 0.55067568 * 296; time = 0.1429s; samplesPerSecond = 2071.1
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     1.01 seconds since last report (0.00 seconds on comm.); 4185 samples processed by 2 workers (2060 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 4.14k samplesPerSecond , throughputPerWorker = 2.07k samplesPerSecond
MPI Rank 1: 07/14/2016 12:41:37:  Epoch[ 2 of 5]-Minibatch[  67-  69, 86.25%]: CrossEntropyWithSoftmax = 1.97564922 * 278; EvalErrorPrediction = 0.51079137 * 278; time = 0.1456s; samplesPerSecond = 1909.2
MPI Rank 1: 07/14/2016 12:41:37:  Epoch[ 2 of 5]-Minibatch[  70-  72, 90.00%]: CrossEntropyWithSoftmax = 2.03003870 * 291; EvalErrorPrediction = 0.53951890 * 291; time = 0.1395s; samplesPerSecond = 2085.9
MPI Rank 1: 07/14/2016 12:41:38:  Epoch[ 2 of 5]-Minibatch[  73-  75, 93.75%]: CrossEntropyWithSoftmax = 2.10265344 * 299; EvalErrorPrediction = 0.56187291 * 299; time = 0.1428s; samplesPerSecond = 2093.9
MPI Rank 1: 07/14/2016 12:41:38:  Epoch[ 2 of 5]-Minibatch[  76-  78, 97.50%]: CrossEntropyWithSoftmax = 1.87884845 * 273; EvalErrorPrediction = 0.51282051 * 273; time = 0.1360s; samplesPerSecond = 2007.2
MPI Rank 1: 07/14/2016 12:41:38:  Epoch[ 2 of 5]-Minibatch[  79-  81, 101.25%]: CrossEntropyWithSoftmax = 1.91420176 * 190; EvalErrorPrediction = 0.52631579 * 190; time = 0.0945s; samplesPerSecond = 2010.5
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.48-seconds latency this time; accumulated time on sync point = 0.48 seconds , average latency = 0.12 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     3.07 seconds since last report (2.06 seconds on comm.); 7732 samples processed by 2 workers (1053 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 2.52k samplesPerSecond , throughputPerWorker = 1.26k samplesPerSecond
MPI Rank 1: 07/14/2016 12:41:40: Finished Epoch[ 2 of 5]: [Training] CrossEntropyWithSoftmax = 2.00885273 * 20480; EvalErrorPrediction = 0.55078125 * 20480; totalSamplesSeen = 40960; learningRatePerSample = 0.001953125; epochTime=6.151s
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:41:40: Starting Epoch 3: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 2: frames [40960..61440] (first utterance at frame 40960), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:41:40: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 07/14/2016 12:41:41:  Epoch[ 3 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.93776302 * 1133; EvalErrorPrediction = 0.55251545 * 1133; time = 0.5311s; samplesPerSecond = 2133.2
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.14-seconds latency this time; accumulated time on sync point = 0.14 seconds , average latency = 0.14 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     1.17 seconds since last report (0.00 seconds on comm.); 4844 samples processed by 2 workers (2261 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 4.13k samplesPerSecond , throughputPerWorker = 2.06k samplesPerSecond
MPI Rank 1: 07/14/2016 12:41:42:  Epoch[ 3 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.95554942 * 1128; EvalErrorPrediction = 0.53989362 * 1128; time = 0.6390s; samplesPerSecond = 1765.4
MPI Rank 1: 07/14/2016 12:41:42:  Epoch[ 3 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.86097969 * 1154; EvalErrorPrediction = 0.51039861 * 1154; time = 0.5113s; samplesPerSecond = 2256.9
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.11-seconds latency this time; accumulated time on sync point = 0.25 seconds , average latency = 0.13 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     1.12 seconds since last report (0.00 seconds on comm.); 4849 samples processed by 2 workers (2269 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 4.33k samplesPerSecond , throughputPerWorker = 2.17k samplesPerSecond
MPI Rank 1: 07/14/2016 12:41:43:  Epoch[ 3 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.88714011 * 1115; EvalErrorPrediction = 0.52376682 * 1115; time = 0.6076s; samplesPerSecond = 1835.0
MPI Rank 1: 07/14/2016 12:41:43:  Epoch[ 3 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.91141402 * 1130; EvalErrorPrediction = 0.54513274 * 1130; time = 0.4947s; samplesPerSecond = 2284.3
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.17-seconds latency this time; accumulated time on sync point = 0.42 seconds , average latency = 0.14 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     1.16 seconds since last report (0.00 seconds on comm.); 4868 samples processed by 2 workers (2273 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 4.21k samplesPerSecond , throughputPerWorker = 2.11k samplesPerSecond
MPI Rank 1: 07/14/2016 12:41:44:  Epoch[ 3 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.90296336 * 1143; EvalErrorPrediction = 0.53980752 * 1143; time = 0.6608s; samplesPerSecond = 1729.7
MPI Rank 1: 07/14/2016 12:41:44:  Epoch[ 3 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.93362099 * 758; EvalErrorPrediction = 0.53562005 * 758; time = 0.3377s; samplesPerSecond = 2244.6
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.76-seconds latency this time; accumulated time on sync point = 1.17 seconds , average latency = 0.29 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     2.21 seconds since last report (1.10 seconds on comm.); 5919 samples processed by 2 workers (758 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 2.68k samplesPerSecond , throughputPerWorker = 1.34k samplesPerSecond
MPI Rank 1: 07/14/2016 12:41:46: Finished Epoch[ 3 of 5]: [Training] CrossEntropyWithSoftmax = 1.89787888 * 20480; EvalErrorPrediction = 0.52875977 * 20480; totalSamplesSeen = 61440; learningRatePerSample = 9.7656251e-05; epochTime=5.65998s
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:41:46: Starting Epoch 4: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:41:46: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 07/14/2016 12:41:47:  Epoch[ 4 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.84821410 * 1146; EvalErrorPrediction = 0.50872600 * 1146; time = 0.4975s; samplesPerSecond = 2303.5
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.10-seconds latency this time; accumulated time on sync point = 0.10 seconds , average latency = 0.10 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     1.12 seconds since last report (0.00 seconds on comm.); 4905 samples processed by 2 workers (2324 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 4.38k samplesPerSecond , throughputPerWorker = 2.19k samplesPerSecond
MPI Rank 1: 07/14/2016 12:41:47:  Epoch[ 4 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.84074472 * 1178; EvalErrorPrediction = 0.50764007 * 1178; time = 0.6187s; samplesPerSecond = 1904.0
MPI Rank 1: 07/14/2016 12:41:48:  Epoch[ 4 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.89617847 * 1141; EvalErrorPrediction = 0.53198948 * 1141; time = 0.4932s; samplesPerSecond = 2313.3
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.09-seconds latency this time; accumulated time on sync point = 0.18 seconds , average latency = 0.09 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     1.11 seconds since last report (0.00 seconds on comm.); 4870 samples processed by 2 workers (2333 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 4.38k samplesPerSecond , throughputPerWorker = 2.19k samplesPerSecond
MPI Rank 1: 07/14/2016 12:41:48:  Epoch[ 4 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.90122104 * 1192; EvalErrorPrediction = 0.53859060 * 1192; time = 0.6190s; samplesPerSecond = 1925.5
MPI Rank 1: 07/14/2016 12:41:49:  Epoch[ 4 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.81959403 * 1192; EvalErrorPrediction = 0.51845638 * 1192; time = 0.5039s; samplesPerSecond = 2365.4
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.22 seconds , average latency = 0.07 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     1.09 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 4.49k samplesPerSecond , throughputPerWorker = 2.25k samplesPerSecond
MPI Rank 1: 07/14/2016 12:41:50:  Epoch[ 4 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.83237505 * 1211; EvalErrorPrediction = 0.50949628 * 1211; time = 0.5906s; samplesPerSecond = 2050.4
MPI Rank 1: 07/14/2016 12:41:50:  Epoch[ 4 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.95195212 * 785; EvalErrorPrediction = 0.54777070 * 785; time = 0.3212s; samplesPerSecond = 2443.6
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.70-seconds latency this time; accumulated time on sync point = 0.91 seconds , average latency = 0.23 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     2.07 seconds since last report (1.05 seconds on comm.); 5789 samples processed by 2 workers (785 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 2.79k samplesPerSecond , throughputPerWorker = 1.40k samplesPerSecond
MPI Rank 1: 07/14/2016 12:41:52: Finished Epoch[ 4 of 5]: [Training] CrossEntropyWithSoftmax = 1.84940336 * 20480; EvalErrorPrediction = 0.51445312 * 20480; totalSamplesSeen = 81920; learningRatePerSample = 9.7656251e-05; epochTime=5.40139s
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:41:52: Starting Epoch 5: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:41:52: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 07/14/2016 12:41:52:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.79235548 * 1175; EvalErrorPrediction = 0.49957447 * 1175; time = 0.5220s; samplesPerSecond = 2251.1
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     1.10 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 4.46k samplesPerSecond , throughputPerWorker = 2.23k samplesPerSecond
MPI Rank 1: 07/14/2016 12:41:53:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.84602168 * 1251; EvalErrorPrediction = 0.52358114 * 1251; time = 0.5772s; samplesPerSecond = 2167.4
MPI Rank 1: 07/14/2016 12:41:53:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.79460940 * 1201; EvalErrorPrediction = 0.50124896 * 1201; time = 0.5172s; samplesPerSecond = 2322.2
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.01 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     1.07 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 4.58k samplesPerSecond , throughputPerWorker = 2.29k samplesPerSecond
MPI Rank 1: 07/14/2016 12:41:54:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.86032081 * 1202; EvalErrorPrediction = 0.50915141 * 1202; time = 0.5498s; samplesPerSecond = 2186.1
MPI Rank 1: 07/14/2016 12:41:54:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.84149612 * 1173; EvalErrorPrediction = 0.51577153 * 1173; time = 0.5007s; samplesPerSecond = 2342.8
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.06-seconds latency this time; accumulated time on sync point = 0.07 seconds , average latency = 0.02 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     1.08 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 4.50k samplesPerSecond , throughputPerWorker = 2.25k samplesPerSecond
MPI Rank 1: 07/14/2016 12:41:55:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87763945 * 1194; EvalErrorPrediction = 0.52680067 * 1194; time = 0.5775s; samplesPerSecond = 2067.5
MPI Rank 1: 07/14/2016 12:41:55:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.79221618 * 827; EvalErrorPrediction = 0.51269649 * 827; time = 0.3608s; samplesPerSecond = 2292.3
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.68-seconds latency this time; accumulated time on sync point = 0.75 seconds , average latency = 0.19 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     2.11 seconds since last report (1.06 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 2.76k samplesPerSecond , throughputPerWorker = 1.38k samplesPerSecond
MPI Rank 1: 07/14/2016 12:41:57: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85300231 * 20480; EvalErrorPrediction = 0.51425781 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 9.7656251e-05; epochTime=5.35607s
MPI Rank 1: 07/14/2016 12:41:57: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 12:41:57: learnRatePerSample reduced to 4.8828126e-05
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:41:57: Starting Epoch 5: learning rate per sample = 0.000049  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:41:57: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 07/14/2016 12:41:58:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.79242721 * 1175; EvalErrorPrediction = 0.49957447 * 1175; time = 0.4883s; samplesPerSecond = 2406.4
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     1.05 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 4.68k samplesPerSecond , throughputPerWorker = 2.34k samplesPerSecond
MPI Rank 1: 07/14/2016 12:41:58:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.84627836 * 1251; EvalErrorPrediction = 0.52278177 * 1251; time = 0.5596s; samplesPerSecond = 2235.6
MPI Rank 1: 07/14/2016 12:41:59:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.79565103 * 1201; EvalErrorPrediction = 0.50707744 * 1201; time = 0.5041s; samplesPerSecond = 2382.5
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.04-seconds latency this time; accumulated time on sync point = 0.04 seconds , average latency = 0.02 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     1.08 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 4.53k samplesPerSecond , throughputPerWorker = 2.27k samplesPerSecond
MPI Rank 1: 07/14/2016 12:41:59:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.86102857 * 1202; EvalErrorPrediction = 0.50998336 * 1202; time = 0.5731s; samplesPerSecond = 2097.3
MPI Rank 1: 07/14/2016 12:42:00:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.84398555 * 1173; EvalErrorPrediction = 0.51832907 * 1173; time = 0.5062s; samplesPerSecond = 2317.4
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.04-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.03 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     1.04 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 4.65k samplesPerSecond , throughputPerWorker = 2.32k samplesPerSecond
MPI Rank 1: 07/14/2016 12:42:00:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87898732 * 1194; EvalErrorPrediction = 0.52512563 * 1194; time = 0.5380s; samplesPerSecond = 2219.5
MPI Rank 1: 07/14/2016 12:42:01:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.79405711 * 827; EvalErrorPrediction = 0.51511487 * 827; time = 0.3455s; samplesPerSecond = 2393.9
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.72-seconds latency this time; accumulated time on sync point = 0.80 seconds , average latency = 0.20 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     2.12 seconds since last report (1.05 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 2.75k samplesPerSecond , throughputPerWorker = 1.37k samplesPerSecond
MPI Rank 1: 07/14/2016 12:42:03: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85426644 * 20480; EvalErrorPrediction = 0.51508789 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 4.8828126e-05; epochTime=5.29456s
MPI Rank 1: 07/14/2016 12:42:03: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 12:42:03: learnRatePerSample reduced to 2.4414063e-05
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:42:03: Starting Epoch 5: learning rate per sample = 0.000024  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:42:03: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 07/14/2016 12:42:03:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.79246348 * 1175; EvalErrorPrediction = 0.49957447 * 1175; time = 0.5000s; samplesPerSecond = 2350.1
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.02 seconds , average latency = 0.02 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     1.08 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 4.55k samplesPerSecond , throughputPerWorker = 2.27k samplesPerSecond
MPI Rank 1: 07/14/2016 12:42:04:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.84641688 * 1251; EvalErrorPrediction = 0.52358114 * 1251; time = 0.5783s; samplesPerSecond = 2163.1
MPI Rank 1: 07/14/2016 12:42:04:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.79624499 * 1201; EvalErrorPrediction = 0.50707744 * 1201; time = 0.4917s; samplesPerSecond = 2442.8
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.05-seconds latency this time; accumulated time on sync point = 0.06 seconds , average latency = 0.03 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     1.06 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 4.60k samplesPerSecond , throughputPerWorker = 2.30k samplesPerSecond
MPI Rank 1: 07/14/2016 12:42:05:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.86139356 * 1202; EvalErrorPrediction = 0.51247920 * 1202; time = 0.5688s; samplesPerSecond = 2113.3
MPI Rank 1: 07/14/2016 12:42:05:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.84547786 * 1173; EvalErrorPrediction = 0.51491901 * 1173; time = 0.4802s; samplesPerSecond = 2442.7
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.05-seconds latency this time; accumulated time on sync point = 0.12 seconds , average latency = 0.04 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     1.05 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 4.60k samplesPerSecond , throughputPerWorker = 2.30k samplesPerSecond
MPI Rank 1: 07/14/2016 12:42:06:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87969458 * 1194; EvalErrorPrediction = 0.52596315 * 1194; time = 0.5743s; samplesPerSecond = 2079.0
MPI Rank 1: 07/14/2016 12:42:06:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.79494286 * 827; EvalErrorPrediction = 0.50906892 * 827; time = 0.3597s; samplesPerSecond = 2298.9
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.72-seconds latency this time; accumulated time on sync point = 0.83 seconds , average latency = 0.21 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     2.13 seconds since last report (1.04 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 2.73k samplesPerSecond , throughputPerWorker = 1.37k samplesPerSecond
MPI Rank 1: 07/14/2016 12:42:08: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85499692 * 20480; EvalErrorPrediction = 0.51547852 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 2.4414063e-05; epochTime=5.327s
MPI Rank 1: 07/14/2016 12:42:08: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 12:42:08: learnRatePerSample reduced to 1.2207031e-05
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:42:08: Starting Epoch 5: learning rate per sample = 0.000012  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:42:08: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 07/14/2016 12:42:09:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.79248172 * 1175; EvalErrorPrediction = 0.49957447 * 1175; time = 0.5031s; samplesPerSecond = 2335.5
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.04-seconds latency this time; accumulated time on sync point = 0.04 seconds , average latency = 0.04 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     1.07 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 4.61k samplesPerSecond , throughputPerWorker = 2.31k samplesPerSecond
MPI Rank 1: 07/14/2016 12:42:09:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.84648880 * 1251; EvalErrorPrediction = 0.52278177 * 1251; time = 0.5598s; samplesPerSecond = 2234.7
MPI Rank 1: 07/14/2016 12:42:10:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.79656264 * 1201; EvalErrorPrediction = 0.50624480 * 1201; time = 0.4980s; samplesPerSecond = 2411.7
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.05 seconds , average latency = 0.03 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     1.05 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 4.65k samplesPerSecond , throughputPerWorker = 2.32k samplesPerSecond
MPI Rank 1: 07/14/2016 12:42:10:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.86158303 * 1202; EvalErrorPrediction = 0.51331115 * 1202; time = 0.5532s; samplesPerSecond = 2172.8
MPI Rank 1: 07/14/2016 12:42:11:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.84631070 * 1173; EvalErrorPrediction = 0.51406650 * 1173; time = 0.5043s; samplesPerSecond = 2326.2
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.04-seconds latency this time; accumulated time on sync point = 0.10 seconds , average latency = 0.03 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     1.06 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 4.57k samplesPerSecond , throughputPerWorker = 2.29k samplesPerSecond
MPI Rank 1: 07/14/2016 12:42:11:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.88007633 * 1194; EvalErrorPrediction = 0.52931323 * 1194; time = 0.5568s; samplesPerSecond = 2144.5
MPI Rank 1: 07/14/2016 12:42:12:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.79541620 * 827; EvalErrorPrediction = 0.50906892 * 827; time = 0.3679s; samplesPerSecond = 2247.8
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.73-seconds latency this time; accumulated time on sync point = 0.83 seconds , average latency = 0.21 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     2.15 seconds since last report (1.03 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 2.72k samplesPerSecond , throughputPerWorker = 1.36k samplesPerSecond
MPI Rank 1: 07/14/2016 12:42:13: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85540764 * 20480; EvalErrorPrediction = 0.51547852 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 1.2207031e-05; epochTime=5.32423s
MPI Rank 1: 07/14/2016 12:42:13: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 12:42:14: learnRatePerSample reduced to 6.1035157e-06
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:42:14: Starting Epoch 5: learning rate per sample = 0.000006  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:42:14: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 07/14/2016 12:42:14:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.79249087 * 1175; EvalErrorPrediction = 0.49957447 * 1175; time = 0.5162s; samplesPerSecond = 2276.2
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     1.08 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 4.54k samplesPerSecond , throughputPerWorker = 2.27k samplesPerSecond
MPI Rank 1: 07/14/2016 12:42:15:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.84652543 * 1251; EvalErrorPrediction = 0.52278177 * 1251; time = 0.5632s; samplesPerSecond = 2221.2
MPI Rank 1: 07/14/2016 12:42:15:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.79672696 * 1201; EvalErrorPrediction = 0.50624480 * 1201; time = 0.4996s; samplesPerSecond = 2403.9
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.06-seconds latency this time; accumulated time on sync point = 0.06 seconds , average latency = 0.03 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     1.07 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 4.57k samplesPerSecond , throughputPerWorker = 2.29k samplesPerSecond
MPI Rank 1: 07/14/2016 12:42:16:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.86168018 * 1202; EvalErrorPrediction = 0.51331115 * 1202; time = 0.5686s; samplesPerSecond = 2114.0
MPI Rank 1: 07/14/2016 12:42:16:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.84675286 * 1173; EvalErrorPrediction = 0.51406650 * 1173; time = 0.5097s; samplesPerSecond = 2301.5
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.06-seconds latency this time; accumulated time on sync point = 0.12 seconds , average latency = 0.04 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     1.06 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 4.56k samplesPerSecond , throughputPerWorker = 2.28k samplesPerSecond
MPI Rank 1: 07/14/2016 12:42:17:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.88027824 * 1194; EvalErrorPrediction = 0.52931323 * 1194; time = 0.5550s; samplesPerSecond = 2151.2
MPI Rank 1: 07/14/2016 12:42:17:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.79567029 * 827; EvalErrorPrediction = 0.50906892 * 827; time = 0.3470s; samplesPerSecond = 2383.2
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.74-seconds latency this time; accumulated time on sync point = 0.86 seconds , average latency = 0.22 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     2.13 seconds since last report (1.03 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 2.74k samplesPerSecond , throughputPerWorker = 1.37k samplesPerSecond
MPI Rank 1: 07/14/2016 12:42:19: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85562974 * 20480; EvalErrorPrediction = 0.51582031 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 6.1035157e-06; epochTime=5.34487s
MPI Rank 1: 07/14/2016 12:42:19: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 12:42:19: learnRatePerSample reduced to 3.0517579e-06
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:42:19: Starting Epoch 5: learning rate per sample = 0.000003  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:42:19: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 07/14/2016 12:42:20:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.79249545 * 1175; EvalErrorPrediction = 0.49957447 * 1175; time = 0.5027s; samplesPerSecond = 2337.3
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.01 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     1.07 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 4.60k samplesPerSecond , throughputPerWorker = 2.30k samplesPerSecond
MPI Rank 1: 07/14/2016 12:42:20:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.84654392 * 1251; EvalErrorPrediction = 0.52278177 * 1251; time = 0.5623s; samplesPerSecond = 2224.7
MPI Rank 1: 07/14/2016 12:42:21:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.79681054 * 1201; EvalErrorPrediction = 0.50624480 * 1201; time = 0.5108s; samplesPerSecond = 2351.4
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.01 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     1.05 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 4.66k samplesPerSecond , throughputPerWorker = 2.33k samplesPerSecond
MPI Rank 1: 07/14/2016 12:42:21:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.86172946 * 1202; EvalErrorPrediction = 0.51331115 * 1202; time = 0.5370s; samplesPerSecond = 2238.3
MPI Rank 1: 07/14/2016 12:42:22:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.84698096 * 1173; EvalErrorPrediction = 0.51491901 * 1173; time = 0.5088s; samplesPerSecond = 2305.4
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.04 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     1.06 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 4.57k samplesPerSecond , throughputPerWorker = 2.28k samplesPerSecond
MPI Rank 1: 07/14/2016 12:42:22:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.88038258 * 1194; EvalErrorPrediction = 0.52931323 * 1194; time = 0.5535s; samplesPerSecond = 2157.0
MPI Rank 1: 07/14/2016 12:42:23:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.79580336 * 827; EvalErrorPrediction = 0.51148730 * 827; time = 0.3392s; samplesPerSecond = 2438.3
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.71-seconds latency this time; accumulated time on sync point = 0.75 seconds , average latency = 0.19 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     2.10 seconds since last report (1.04 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 2.77k samplesPerSecond , throughputPerWorker = 1.39k samplesPerSecond
MPI Rank 1: 07/14/2016 12:42:24: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85574594 * 20480; EvalErrorPrediction = 0.51606445 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 3.0517579e-06; epochTime=5.27976s
MPI Rank 1: 07/14/2016 12:42:24: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 12:42:24: learnRatePerSample reduced to 1.5258789e-06
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:42:25: Starting Epoch 5: learning rate per sample = 0.000002  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:42:25: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 07/14/2016 12:42:25:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.79249774 * 1175; EvalErrorPrediction = 0.49957447 * 1175; time = 0.4990s; samplesPerSecond = 2354.6
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.01 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     1.06 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 4.64k samplesPerSecond , throughputPerWorker = 2.32k samplesPerSecond
MPI Rank 1: 07/14/2016 12:42:26:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.84655321 * 1251; EvalErrorPrediction = 0.52278177 * 1251; time = 0.5582s; samplesPerSecond = 2241.3
MPI Rank 1: 07/14/2016 12:42:26:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.79685269 * 1201; EvalErrorPrediction = 0.50624480 * 1201; time = 0.5111s; samplesPerSecond = 2349.6
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.07-seconds latency this time; accumulated time on sync point = 0.09 seconds , average latency = 0.04 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     1.11 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 4.39k samplesPerSecond , throughputPerWorker = 2.19k samplesPerSecond
MPI Rank 1: 07/14/2016 12:42:27:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.86175428 * 1202; EvalErrorPrediction = 0.51331115 * 1202; time = 0.6015s; samplesPerSecond = 1998.2
MPI Rank 1: 07/14/2016 12:42:27:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.84709684 * 1173; EvalErrorPrediction = 0.51491901 * 1173; time = 0.5125s; samplesPerSecond = 2288.7
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.12 seconds , average latency = 0.04 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     1.06 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 4.56k samplesPerSecond , throughputPerWorker = 2.28k samplesPerSecond
MPI Rank 1: 07/14/2016 12:42:28:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.88043569 * 1194; EvalErrorPrediction = 0.52931323 * 1194; time = 0.5516s; samplesPerSecond = 2164.4
MPI Rank 1: 07/14/2016 12:42:28:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.79587164 * 827; EvalErrorPrediction = 0.51027811 * 827; time = 0.3453s; samplesPerSecond = 2395.0
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.69-seconds latency this time; accumulated time on sync point = 0.81 seconds , average latency = 0.20 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     2.08 seconds since last report (1.03 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 2.80k samplesPerSecond , throughputPerWorker = 1.40k samplesPerSecond
MPI Rank 1: 07/14/2016 12:42:30: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85580548 * 20480; EvalErrorPrediction = 0.51591797 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 1.5258789e-06; epochTime=5.31556s
MPI Rank 1: 07/14/2016 12:42:30: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 12:42:30: learnRatePerSample reduced to 7.6293946e-07
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:42:30: Starting Epoch 5: learning rate per sample = 0.000001  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:42:30: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 07/14/2016 12:42:30:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.79249889 * 1175; EvalErrorPrediction = 0.49957447 * 1175; time = 0.4977s; samplesPerSecond = 2360.9
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.03 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     1.07 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 4.57k samplesPerSecond , throughputPerWorker = 2.29k samplesPerSecond
MPI Rank 1: 07/14/2016 12:42:31:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.84655786 * 1251; EvalErrorPrediction = 0.52278177 * 1251; time = 0.5739s; samplesPerSecond = 2179.6
MPI Rank 1: 07/14/2016 12:42:32:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.79687385 * 1201; EvalErrorPrediction = 0.50624480 * 1201; time = 0.5206s; samplesPerSecond = 2307.1
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.04 seconds , average latency = 0.02 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     1.06 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 4.60k samplesPerSecond , throughputPerWorker = 2.30k samplesPerSecond
MPI Rank 1: 07/14/2016 12:42:32:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.86176674 * 1202; EvalErrorPrediction = 0.51247920 * 1202; time = 0.5414s; samplesPerSecond = 2220.3
MPI Rank 1: 07/14/2016 12:42:33:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.84715525 * 1173; EvalErrorPrediction = 0.51491901 * 1173; time = 0.5002s; samplesPerSecond = 2345.1
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.05-seconds latency this time; accumulated time on sync point = 0.09 seconds , average latency = 0.03 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     1.07 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 4.55k samplesPerSecond , throughputPerWorker = 2.27k samplesPerSecond
MPI Rank 1: 07/14/2016 12:42:33:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.88046248 * 1194; EvalErrorPrediction = 0.52847571 * 1194; time = 0.5676s; samplesPerSecond = 2103.7
MPI Rank 1: 07/14/2016 12:42:34:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.79590625 * 827; EvalErrorPrediction = 0.51148730 * 827; time = 0.3473s; samplesPerSecond = 2381.3
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.69-seconds latency this time; accumulated time on sync point = 0.78 seconds , average latency = 0.20 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     2.08 seconds since last report (1.03 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 2.80k samplesPerSecond , throughputPerWorker = 1.40k samplesPerSecond
MPI Rank 1: 07/14/2016 12:42:35: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85583563 * 20480; EvalErrorPrediction = 0.51591797 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 7.6293946e-07; epochTime=5.28659s
MPI Rank 1: 07/14/2016 12:42:35: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 12:42:35: learnRatePerSample reduced to 3.8146973e-07
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:42:35: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:42:35: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 07/14/2016 12:42:36:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.79249946 * 1175; EvalErrorPrediction = 0.49957447 * 1175; time = 0.5080s; samplesPerSecond = 2313.1
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.01 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     1.06 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 4.64k samplesPerSecond , throughputPerWorker = 2.32k samplesPerSecond
MPI Rank 1: 07/14/2016 12:42:36:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.84656019 * 1251; EvalErrorPrediction = 0.52278177 * 1251; time = 0.5484s; samplesPerSecond = 2281.0
MPI Rank 1: 07/14/2016 12:42:37:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.79688446 * 1201; EvalErrorPrediction = 0.50624480 * 1201; time = 0.5147s; samplesPerSecond = 2333.4
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.04 seconds , average latency = 0.02 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     1.07 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 4.58k samplesPerSecond , throughputPerWorker = 2.29k samplesPerSecond
MPI Rank 1: 07/14/2016 12:42:38:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.86177299 * 1202; EvalErrorPrediction = 0.51247920 * 1202; time = 0.5513s; samplesPerSecond = 2180.3
MPI Rank 1: 07/14/2016 12:42:38:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.84718457 * 1173; EvalErrorPrediction = 0.51491901 * 1173; time = 0.4986s; samplesPerSecond = 2352.4
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.07-seconds latency this time; accumulated time on sync point = 0.11 seconds , average latency = 0.04 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     1.08 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 4.52k samplesPerSecond , throughputPerWorker = 2.26k samplesPerSecond
MPI Rank 1: 07/14/2016 12:42:39:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.88047594 * 1194; EvalErrorPrediction = 0.52847571 * 1194; time = 0.5764s; samplesPerSecond = 2071.5
MPI Rank 1: 07/14/2016 12:42:39:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.79592368 * 827; EvalErrorPrediction = 0.51148730 * 827; time = 0.3442s; samplesPerSecond = 2402.4
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.72-seconds latency this time; accumulated time on sync point = 0.82 seconds , average latency = 0.21 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     2.11 seconds since last report (1.04 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 2.76k samplesPerSecond , throughputPerWorker = 1.38k samplesPerSecond
MPI Rank 1: 07/14/2016 12:42:41: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85585080 * 20480; EvalErrorPrediction = 0.51591797 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 3.8146973e-07; epochTime=5.30989s
MPI Rank 1: 07/14/2016 12:42:41: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 12:42:41: learnRatePerSample reduced to 1.9073487e-07
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:42:41: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:42:41: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 07/14/2016 12:42:41:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.79249975 * 1175; EvalErrorPrediction = 0.49957447 * 1175; time = 0.5182s; samplesPerSecond = 2267.3
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.03 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     1.10 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 4.48k samplesPerSecond , throughputPerWorker = 2.24k samplesPerSecond
MPI Rank 1: 07/14/2016 12:42:42:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.84656136 * 1251; EvalErrorPrediction = 0.52278177 * 1251; time = 0.5765s; samplesPerSecond = 2170.0
MPI Rank 1: 07/14/2016 12:42:42:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.79688976 * 1201; EvalErrorPrediction = 0.50624480 * 1201; time = 0.5045s; samplesPerSecond = 2380.5
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.07-seconds latency this time; accumulated time on sync point = 0.10 seconds , average latency = 0.05 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     1.08 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 4.52k samplesPerSecond , throughputPerWorker = 2.26k samplesPerSecond
MPI Rank 1: 07/14/2016 12:42:43:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.86177611 * 1202; EvalErrorPrediction = 0.51247920 * 1202; time = 0.5757s; samplesPerSecond = 2087.9
MPI Rank 1: 07/14/2016 12:42:44:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.84719926 * 1173; EvalErrorPrediction = 0.51491901 * 1173; time = 0.5010s; samplesPerSecond = 2341.5
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.12 seconds , average latency = 0.04 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     1.04 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 4.68k samplesPerSecond , throughputPerWorker = 2.34k samplesPerSecond
MPI Rank 1: 07/14/2016 12:42:44:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.88048269 * 1194; EvalErrorPrediction = 0.52847571 * 1194; time = 0.5367s; samplesPerSecond = 2224.5
MPI Rank 1: 07/14/2016 12:42:44:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.79593242 * 827; EvalErrorPrediction = 0.51148730 * 827; time = 0.3477s; samplesPerSecond = 2378.4
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.71-seconds latency this time; accumulated time on sync point = 0.83 seconds , average latency = 0.21 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     2.12 seconds since last report (1.05 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 2.75k samplesPerSecond , throughputPerWorker = 1.38k samplesPerSecond
MPI Rank 1: 07/14/2016 12:42:46: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85585841 * 20480; EvalErrorPrediction = 0.51582031 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 1.9073487e-07; epochTime=5.3334s
MPI Rank 1: 07/14/2016 12:42:46: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 12:42:46: learnRatePerSample reduced to 9.5367433e-08
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:42:46: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:42:46: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 07/14/2016 12:42:47:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.79249989 * 1175; EvalErrorPrediction = 0.49957447 * 1175; time = 0.5170s; samplesPerSecond = 2272.6
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     1.08 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 4.55k samplesPerSecond , throughputPerWorker = 2.28k samplesPerSecond
MPI Rank 1: 07/14/2016 12:42:47:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.84656194 * 1251; EvalErrorPrediction = 0.52278177 * 1251; time = 0.5600s; samplesPerSecond = 2233.8
MPI Rank 1: 07/14/2016 12:42:48:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.79689242 * 1201; EvalErrorPrediction = 0.50624480 * 1201; time = 0.5249s; samplesPerSecond = 2288.2
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.01 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     1.07 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 4.58k samplesPerSecond , throughputPerWorker = 2.29k samplesPerSecond
MPI Rank 1: 07/14/2016 12:42:48:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.86177767 * 1202; EvalErrorPrediction = 0.51247920 * 1202; time = 0.5412s; samplesPerSecond = 2221.2
MPI Rank 1: 07/14/2016 12:42:49:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.84720661 * 1173; EvalErrorPrediction = 0.51491901 * 1173; time = 0.5165s; samplesPerSecond = 2271.2
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.04-seconds latency this time; accumulated time on sync point = 0.06 seconds , average latency = 0.02 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     1.08 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 4.48k samplesPerSecond , throughputPerWorker = 2.24k samplesPerSecond
MPI Rank 1: 07/14/2016 12:42:50:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.88048607 * 1194; EvalErrorPrediction = 0.52847571 * 1194; time = 0.5668s; samplesPerSecond = 2106.5
MPI Rank 1: 07/14/2016 12:42:50:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.79593680 * 827; EvalErrorPrediction = 0.51148730 * 827; time = 0.3401s; samplesPerSecond = 2431.9
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.72-seconds latency this time; accumulated time on sync point = 0.77 seconds , average latency = 0.19 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     2.11 seconds since last report (1.04 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 2.76k samplesPerSecond , throughputPerWorker = 1.38k samplesPerSecond
MPI Rank 1: 07/14/2016 12:42:52: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85586222 * 20480; EvalErrorPrediction = 0.51582031 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 9.5367433e-08; epochTime=5.34269s
MPI Rank 1: 07/14/2016 12:42:52: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 12:42:52: learnRatePerSample reduced to 4.7683717e-08
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:42:52: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:42:52: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 07/14/2016 12:42:52:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.79249996 * 1175; EvalErrorPrediction = 0.49957447 * 1175; time = 0.5030s; samplesPerSecond = 2336.1
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.02 seconds , average latency = 0.02 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     1.09 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 4.52k samplesPerSecond , throughputPerWorker = 2.26k samplesPerSecond
MPI Rank 1: 07/14/2016 12:42:53:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.84656223 * 1251; EvalErrorPrediction = 0.52278177 * 1251; time = 0.5815s; samplesPerSecond = 2151.3
MPI Rank 1: 07/14/2016 12:42:53:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.79689375 * 1201; EvalErrorPrediction = 0.50624480 * 1201; time = 0.5161s; samplesPerSecond = 2327.0
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.05-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.04 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     1.09 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 4.47k samplesPerSecond , throughputPerWorker = 2.23k samplesPerSecond
MPI Rank 1: 07/14/2016 12:42:54:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.86177845 * 1202; EvalErrorPrediction = 0.51247920 * 1202; time = 0.5774s; samplesPerSecond = 2081.6
MPI Rank 1: 07/14/2016 12:42:55:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.84721029 * 1173; EvalErrorPrediction = 0.51491901 * 1173; time = 0.5149s; samplesPerSecond = 2278.3
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.05-seconds latency this time; accumulated time on sync point = 0.13 seconds , average latency = 0.04 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     1.08 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 4.49k samplesPerSecond , throughputPerWorker = 2.25k samplesPerSecond
MPI Rank 1: 07/14/2016 12:42:55:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.88048776 * 1194; EvalErrorPrediction = 0.52847571 * 1194; time = 0.5659s; samplesPerSecond = 2109.8
MPI Rank 1: 07/14/2016 12:42:55:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.79593899 * 827; EvalErrorPrediction = 0.51027811 * 827; time = 0.3560s; samplesPerSecond = 2322.9
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.69-seconds latency this time; accumulated time on sync point = 0.82 seconds , average latency = 0.20 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     2.13 seconds since last report (1.07 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 2.74k samplesPerSecond , throughputPerWorker = 1.37k samplesPerSecond
MPI Rank 1: 07/14/2016 12:42:57: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85586413 * 20480; EvalErrorPrediction = 0.51577148 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 4.7683717e-08; epochTime=5.38836s
MPI Rank 1: 07/14/2016 12:42:57: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 12:42:57: learnRatePerSample reduced to 2.3841858e-08
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:42:57: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:42:57: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 07/14/2016 12:42:58:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.79250000 * 1175; EvalErrorPrediction = 0.49957447 * 1175; time = 0.5132s; samplesPerSecond = 2289.4
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.03 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     1.11 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 4.43k samplesPerSecond , throughputPerWorker = 2.22k samplesPerSecond
MPI Rank 1: 07/14/2016 12:42:58:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.84656238 * 1251; EvalErrorPrediction = 0.52278177 * 1251; time = 0.5920s; samplesPerSecond = 2113.3
MPI Rank 1: 07/14/2016 12:42:59:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.79689441 * 1201; EvalErrorPrediction = 0.50624480 * 1201; time = 0.5183s; samplesPerSecond = 2317.1
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.04-seconds latency this time; accumulated time on sync point = 0.07 seconds , average latency = 0.04 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     1.07 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 4.55k samplesPerSecond , throughputPerWorker = 2.27k samplesPerSecond
MPI Rank 1: 07/14/2016 12:43:00:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.86177885 * 1202; EvalErrorPrediction = 0.51247920 * 1202; time = 0.5549s; samplesPerSecond = 2166.0
MPI Rank 1: 07/14/2016 12:43:00:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.84721213 * 1173; EvalErrorPrediction = 0.51491901 * 1173; time = 0.5097s; samplesPerSecond = 2301.4
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.07 seconds , average latency = 0.02 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     1.04 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 4.66k samplesPerSecond , throughputPerWorker = 2.33k samplesPerSecond
MPI Rank 1: 07/14/2016 12:43:01:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.88048860 * 1194; EvalErrorPrediction = 0.52847571 * 1194; time = 0.5322s; samplesPerSecond = 2243.5
MPI Rank 1: 07/14/2016 12:43:01:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.79594009 * 827; EvalErrorPrediction = 0.51027811 * 827; time = 0.3516s; samplesPerSecond = 2351.9
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.74-seconds latency this time; accumulated time on sync point = 0.81 seconds , average latency = 0.20 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     2.14 seconds since last report (1.04 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 2.72k samplesPerSecond , throughputPerWorker = 1.36k samplesPerSecond
MPI Rank 1: 07/14/2016 12:43:03: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85586508 * 20480; EvalErrorPrediction = 0.51577148 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 2.3841858e-08; epochTime=5.36566s
MPI Rank 1: 07/14/2016 12:43:03: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 12:43:03: learnRatePerSample reduced to 1.1920929e-08
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:43:03: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:43:03: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 07/14/2016 12:43:03:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.79250001 * 1175; EvalErrorPrediction = 0.49957447 * 1175; time = 0.5229s; samplesPerSecond = 2247.3
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.02 seconds , average latency = 0.02 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     1.08 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 4.55k samplesPerSecond , throughputPerWorker = 2.27k samplesPerSecond
MPI Rank 1: 07/14/2016 12:43:04:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.84656245 * 1251; EvalErrorPrediction = 0.52278177 * 1251; time = 0.5553s; samplesPerSecond = 2252.7
MPI Rank 1: 07/14/2016 12:43:05:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.79689474 * 1201; EvalErrorPrediction = 0.50624480 * 1201; time = 0.5293s; samplesPerSecond = 2269.2
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.02 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     1.06 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 4.61k samplesPerSecond , throughputPerWorker = 2.30k samplesPerSecond
MPI Rank 1: 07/14/2016 12:43:05:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.86177904 * 1202; EvalErrorPrediction = 0.51247920 * 1202; time = 0.5307s; samplesPerSecond = 2265.1
MPI Rank 1: 07/14/2016 12:43:06:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.84721305 * 1173; EvalErrorPrediction = 0.51491901 * 1173; time = 0.5056s; samplesPerSecond = 2320.1
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.08-seconds latency this time; accumulated time on sync point = 0.10 seconds , average latency = 0.03 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     1.11 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 4.36k samplesPerSecond , throughputPerWorker = 2.18k samplesPerSecond
MPI Rank 1: 07/14/2016 12:43:06:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.88048902 * 1194; EvalErrorPrediction = 0.52847571 * 1194; time = 0.6072s; samplesPerSecond = 1966.3
MPI Rank 1: 07/14/2016 12:43:07:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.79594064 * 827; EvalErrorPrediction = 0.51027811 * 827; time = 0.3612s; samplesPerSecond = 2289.3
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.70-seconds latency this time; accumulated time on sync point = 0.79 seconds , average latency = 0.20 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     2.10 seconds since last report (1.03 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 2.78k samplesPerSecond , throughputPerWorker = 1.39k samplesPerSecond
MPI Rank 1: 07/14/2016 12:43:08: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85586556 * 20480; EvalErrorPrediction = 0.51577148 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 1.1920929e-08; epochTime=5.35014s
MPI Rank 1: 07/14/2016 12:43:08: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 12:43:08: learnRatePerSample reduced to 5.9604646e-09
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:43:08: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:43:08: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 07/14/2016 12:43:09:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.79250002 * 1175; EvalErrorPrediction = 0.49957447 * 1175; time = 0.5119s; samplesPerSecond = 2295.5
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.04-seconds latency this time; accumulated time on sync point = 0.04 seconds , average latency = 0.04 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     1.11 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 4.42k samplesPerSecond , throughputPerWorker = 2.21k samplesPerSecond
MPI Rank 1: 07/14/2016 12:43:10:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.84656249 * 1251; EvalErrorPrediction = 0.52278177 * 1251; time = 0.5975s; samplesPerSecond = 2093.8
MPI Rank 1: 07/14/2016 12:43:10:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.79689491 * 1201; EvalErrorPrediction = 0.50624480 * 1201; time = 0.5250s; samplesPerSecond = 2287.7
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.05-seconds latency this time; accumulated time on sync point = 0.09 seconds , average latency = 0.04 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     1.09 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 4.46k samplesPerSecond , throughputPerWorker = 2.23k samplesPerSecond
MPI Rank 1: 07/14/2016 12:43:11:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.86177914 * 1202; EvalErrorPrediction = 0.51247920 * 1202; time = 0.5692s; samplesPerSecond = 2111.9
MPI Rank 1: 07/14/2016 12:43:11:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.84721351 * 1173; EvalErrorPrediction = 0.51491901 * 1173; time = 0.5179s; samplesPerSecond = 2265.1
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.04-seconds latency this time; accumulated time on sync point = 0.13 seconds , average latency = 0.04 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     1.10 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 4.42k samplesPerSecond , throughputPerWorker = 2.21k samplesPerSecond
MPI Rank 1: 07/14/2016 12:43:12:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.88048924 * 1194; EvalErrorPrediction = 0.52847571 * 1194; time = 0.5813s; samplesPerSecond = 2054.0
MPI Rank 1: 07/14/2016 12:43:12:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.79594091 * 827; EvalErrorPrediction = 0.51027811 * 827; time = 0.3564s; samplesPerSecond = 2320.4
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.71-seconds latency this time; accumulated time on sync point = 0.84 seconds , average latency = 0.21 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     2.15 seconds since last report (1.07 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 2.71k samplesPerSecond , throughputPerWorker = 1.35k samplesPerSecond
MPI Rank 1: 07/14/2016 12:43:14: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85586580 * 20480; EvalErrorPrediction = 0.51577148 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 5.9604646e-09; epochTime=5.45668s
MPI Rank 1: 07/14/2016 12:43:14: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 12:43:14: learnRatePerSample reduced to 2.9802323e-09
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:43:14: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:43:14: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 07/14/2016 12:43:15:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.79250003 * 1175; EvalErrorPrediction = 0.49957447 * 1175; time = 0.5248s; samplesPerSecond = 2239.0
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.01 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     1.09 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 4.50k samplesPerSecond , throughputPerWorker = 2.25k samplesPerSecond
MPI Rank 1: 07/14/2016 12:43:15:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.84656251 * 1251; EvalErrorPrediction = 0.52278177 * 1251; time = 0.5638s; samplesPerSecond = 2219.0
MPI Rank 1: 07/14/2016 12:43:16:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.79689499 * 1201; EvalErrorPrediction = 0.50624480 * 1201; time = 0.5327s; samplesPerSecond = 2254.5
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.02 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     1.08 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 4.52k samplesPerSecond , throughputPerWorker = 2.26k samplesPerSecond
MPI Rank 1: 07/14/2016 12:43:16:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.86177919 * 1202; EvalErrorPrediction = 0.51247920 * 1202; time = 0.5486s; samplesPerSecond = 2191.0
MPI Rank 1: 07/14/2016 12:43:17:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.84721374 * 1173; EvalErrorPrediction = 0.51491901 * 1173; time = 0.5029s; samplesPerSecond = 2332.7
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.07-seconds latency this time; accumulated time on sync point = 0.10 seconds , average latency = 0.03 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     1.08 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 4.48k samplesPerSecond , throughputPerWorker = 2.24k samplesPerSecond
MPI Rank 1: 07/14/2016 12:43:17:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.88048934 * 1194; EvalErrorPrediction = 0.52847571 * 1194; time = 0.5808s; samplesPerSecond = 2055.6
MPI Rank 1: 07/14/2016 12:43:18:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.79594105 * 827; EvalErrorPrediction = 0.51027811 * 827; time = 0.3649s; samplesPerSecond = 2266.1
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.74-seconds latency this time; accumulated time on sync point = 0.84 seconds , average latency = 0.21 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     2.19 seconds since last report (1.07 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 2.67k samplesPerSecond , throughputPerWorker = 1.33k samplesPerSecond
MPI Rank 1: 07/14/2016 12:43:19: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85586592 * 20480; EvalErrorPrediction = 0.51577148 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 2.9802323e-09; epochTime=5.44269s
MPI Rank 1: 07/14/2016 12:43:19: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 12:43:20: learnRatePerSample reduced to 1.4901161e-09
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:43:20: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:43:20: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 07/14/2016 12:43:20:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.79250003 * 1175; EvalErrorPrediction = 0.49957447 * 1175; time = 0.5096s; samplesPerSecond = 2305.7
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     1.08 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 4.57k samplesPerSecond , throughputPerWorker = 2.28k samplesPerSecond
MPI Rank 1: 07/14/2016 12:43:21:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.84656251 * 1251; EvalErrorPrediction = 0.52278177 * 1251; time = 0.5629s; samplesPerSecond = 2222.4
MPI Rank 1: 07/14/2016 12:43:21:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.79689503 * 1201; EvalErrorPrediction = 0.50624480 * 1201; time = 0.4973s; samplesPerSecond = 2414.8
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.02 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     1.07 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 4.59k samplesPerSecond , throughputPerWorker = 2.29k samplesPerSecond
MPI Rank 1: 07/14/2016 12:43:22:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.86177921 * 1202; EvalErrorPrediction = 0.51247920 * 1202; time = 0.5675s; samplesPerSecond = 2117.9
MPI Rank 1: 07/14/2016 12:43:22:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.84721386 * 1173; EvalErrorPrediction = 0.51491901 * 1173; time = 0.5065s; samplesPerSecond = 2315.7
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.05-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.03 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     1.10 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 4.40k samplesPerSecond , throughputPerWorker = 2.20k samplesPerSecond
MPI Rank 1: 07/14/2016 12:43:23:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.88048939 * 1194; EvalErrorPrediction = 0.52847571 * 1194; time = 0.5969s; samplesPerSecond = 2000.5
MPI Rank 1: 07/14/2016 12:43:23:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.79594112 * 827; EvalErrorPrediction = 0.51027811 * 827; time = 0.3676s; samplesPerSecond = 2249.8
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.71-seconds latency this time; accumulated time on sync point = 0.79 seconds , average latency = 0.20 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     2.13 seconds since last report (1.04 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 2.73k samplesPerSecond , throughputPerWorker = 1.37k samplesPerSecond
MPI Rank 1: 07/14/2016 12:43:25: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85586598 * 20480; EvalErrorPrediction = 0.51577148 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 1.4901161e-09; epochTime=5.37679s
MPI Rank 1: 07/14/2016 12:43:25: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 12:43:25: learnRatePerSample reduced to 7.4505807e-10
MPI Rank 1: 07/14/2016 12:43:25: Learn Rate Per Sample for Epoch[5] = 7.4505807e-10 is less than minLearnRate 9.9999997e-10. Training complete.
MPI Rank 1: 07/14/2016 12:43:25: CNTKCommandTrainEnd: speechTrain
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:43:25: Action "train" complete.
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:43:25: __COMPLETED__
MPI Rank 1: ~MPIWrapper
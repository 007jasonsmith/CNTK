CPU info:
    CPU Model Name: Intel(R) Xeon(R) CPU E5-2630 v2 @ 2.60GHz
    Hardware threads: 24
    Total Memory: 264172964 kB
-------------------------------------------------------------------
=== Running mpiexec -n 2 /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/build/1bitsgd/release/bin/cntk configFile=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/ParallelBM/../ParallelBM/cntk.cntk currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data RunDir=/tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_gpu DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/ParallelBM/.. OutputDir=/tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_gpu DeviceId=0 timestamping=true numCPUThreads=12 precision=double speechTrain=[SGD=[ParallelTrain=[parallelizationStartEpoch=2]]] stderr=/tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_gpu/stderr
-------------------------------------------------------------------
Build info: 

		Built time: Jul 14 2016 12:05:02
		Last modified date: Thu Jul 14 10:47:21 2016
		Build type: release
		Build target: GPU
		With 1bit-SGD: yes
		Math lib: mkl
		CUDA_PATH: /usr/local/cuda-7.5
		CUB_PATH: /usr/local/cub-1.4.1
		CUDNN_PATH: /usr/local/cudnn-4.0
		Build Branch: HEAD
		Build SHA1: 72bee394bf461e8f6f0feb593a8416c05f481957
		Built by philly on a77bf6d98305
		Build Path: /home/philly/jenkins/workspace/CNTK-Build-Linux
-------------------------------------------------------------------
-------------------------------------------------------------------
Build info: 

		Built time: Jul 14 2016 12:05:02
		Last modified date: Thu Jul 14 10:47:21 2016
		Build type: release
		Build target: GPU
		With 1bit-SGD: yes
		Math lib: mkl
		CUDA_PATH: /usr/local/cuda-7.5
		CUB_PATH: /usr/local/cub-1.4.1
		CUDNN_PATH: /usr/local/cudnn-4.0
		Build Branch: HEAD
		Build SHA1: 72bee394bf461e8f6f0feb593a8416c05f481957
		Built by philly on a77bf6d98305
		Build Path: /home/philly/jenkins/workspace/CNTK-Build-Linux
-------------------------------------------------------------------
Changed current directory to /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
Changed current directory to /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
MPIWrapper: initializing MPI
MPIWrapper: initializing MPI
ping [requestnodes (before change)]: 2 nodes pinging each other
ping [requestnodes (before change)]: 2 nodes pinging each other
ping [requestnodes (before change)]: all 2 nodes responded
requestnodes [MPIWrapper]: using 2 out of 2 MPI nodes (2 requested); we (1) are in (participating)
ping [requestnodes (after change)]: 2 nodes pinging each other
ping [requestnodes (before change)]: all 2 nodes responded
requestnodes [MPIWrapper]: using 2 out of 2 MPI nodes (2 requested); we (0) are in (participating)
ping [requestnodes (after change)]: 2 nodes pinging each other
ping [requestnodes (after change)]: all 2 nodes responded
mpihelper: we are cog 1 in a gearbox of 2
ping [mpihelper]: 2 nodes pinging each other
ping [requestnodes (after change)]: all 2 nodes responded
mpihelper: we are cog 0 in a gearbox of 2
ping [mpihelper]: 2 nodes pinging each other
ping [mpihelper]: all 2 nodes responded
ping [mpihelper]: all 2 nodes responded
07/14/2016 12:43:27: Redirecting stderr to file /tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_gpu/stderr_speechTrain.logrank0
07/14/2016 12:43:28: Redirecting stderr to file /tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_gpu/stderr_speechTrain.logrank1
MPI Rank 0: 07/14/2016 12:43:27: -------------------------------------------------------------------
MPI Rank 0: 07/14/2016 12:43:27: Build info: 
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:43:27: 		Built time: Jul 14 2016 12:05:02
MPI Rank 0: 07/14/2016 12:43:27: 		Last modified date: Thu Jul 14 10:47:21 2016
MPI Rank 0: 07/14/2016 12:43:27: 		Build type: release
MPI Rank 0: 07/14/2016 12:43:27: 		Build target: GPU
MPI Rank 0: 07/14/2016 12:43:27: 		With 1bit-SGD: yes
MPI Rank 0: 07/14/2016 12:43:27: 		Math lib: mkl
MPI Rank 0: 07/14/2016 12:43:27: 		CUDA_PATH: /usr/local/cuda-7.5
MPI Rank 0: 07/14/2016 12:43:27: 		CUB_PATH: /usr/local/cub-1.4.1
MPI Rank 0: 07/14/2016 12:43:27: 		CUDNN_PATH: /usr/local/cudnn-4.0
MPI Rank 0: 07/14/2016 12:43:27: 		Build Branch: HEAD
MPI Rank 0: 07/14/2016 12:43:27: 		Build SHA1: 72bee394bf461e8f6f0feb593a8416c05f481957
MPI Rank 0: 07/14/2016 12:43:27: 		Built by philly on a77bf6d98305
MPI Rank 0: 07/14/2016 12:43:27: 		Build Path: /home/philly/jenkins/workspace/CNTK-Build-Linux
MPI Rank 0: 07/14/2016 12:43:27: -------------------------------------------------------------------
MPI Rank 0: 07/14/2016 12:43:28: -------------------------------------------------------------------
MPI Rank 0: 07/14/2016 12:43:28: GPU info:
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:43:28: 		Device[0]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3071 MB
MPI Rank 0: 07/14/2016 12:43:28: 		Device[1]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3071 MB
MPI Rank 0: 07/14/2016 12:43:28: 		Device[2]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3071 MB
MPI Rank 0: 07/14/2016 12:43:28: 		Device[3]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3071 MB
MPI Rank 0: 07/14/2016 12:43:28: -------------------------------------------------------------------
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:43:28: Running on localhost at 2016/07/14 12:43:28
MPI Rank 0: 07/14/2016 12:43:28: Command line: 
MPI Rank 0: /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/build/1bitsgd/release/bin/cntk  configFile=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/ParallelBM/../ParallelBM/cntk.cntk  currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data  RunDir=/tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_gpu  DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data  ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/ParallelBM/..  OutputDir=/tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_gpu  DeviceId=0  timestamping=true  numCPUThreads=12  precision=double  speechTrain=[SGD=[ParallelTrain=[parallelizationStartEpoch=2]]]  stderr=/tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_gpu/stderr
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:43:28: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
MPI Rank 0: 07/14/2016 12:43:28: precision = "float"
MPI Rank 0: command = speechTrain
MPI Rank 0: deviceId = $DeviceId$
MPI Rank 0: parallelTrain = true
MPI Rank 0: speechTrain = [
MPI Rank 0:     action = "train"
MPI Rank 0:     modelPath = "$RunDir$/models/cntkSpeech.dnn"
MPI Rank 0:     deviceId = $DeviceId$
MPI Rank 0:     traceLevel = 1
MPI Rank 0:     SimpleNetworkBuilder = [
MPI Rank 0:         layerSizes = 363:512:512:132
MPI Rank 0:         trainingCriterion = "CrossEntropyWithSoftmax"
MPI Rank 0:         evalCriterion = "ErrorPrediction"
MPI Rank 0:         layerTypes = "Sigmoid"
MPI Rank 0:         initValueScale = 1.0
MPI Rank 0:         applyMeanVarNorm = true
MPI Rank 0:         uniformInit = true
MPI Rank 0:         needPrior = true
MPI Rank 0:     ]
MPI Rank 0:     ExperimentalNetworkBuilder = [    // the same as above but with BS. Not active; activate by commenting out the SimpleNetworkBuilder entry above
MPI Rank 0:         layerSizes = 363:512:512:132
MPI Rank 0:         trainingCriterion = 'CE'
MPI Rank 0:         evalCriterion = 'Err'
MPI Rank 0:         applyMeanVarNorm = true
MPI Rank 0:         L = Length(layerSizes)-1    // number of model layers
MPI Rank 0:         features = Input(layerSizes[0], 1, tag='feature') ; labels = Input(layerSizes[Length(layerSizes)-1], 1, tag='label')
MPI Rank 0:         featNorm = if applyMeanVarNorm
MPI Rank 0:                    then MeanVarNorm(features)
MPI Rank 0:                    else features
MPI Rank 0:         layers[layer:1..L-1] = if layer > 1
MPI Rank 0:                                then SBFF(layers[layer-1].Eh, layerSizes[layer], layerSizes[layer-1])
MPI Rank 0:                                else SBFF(featNorm, layerSizes[layer], layerSizes[layer-1])
MPI Rank 0:         outLayer = BFF(layers[L-1].Eh, layerSizes[L], layerSizes[L-1])
MPI Rank 0:         outZ = outLayer.z        // + PastValue(layerSizes[L], 1, outLayer.z)
MPI Rank 0:         CE = if trainingCriterion == 'CE'
MPI Rank 0:              then CrossEntropyWithSoftmax(labels, outZ, tag='criterion')
MPI Rank 0:              else Fail('unknown trainingCriterion ' + trainingCriterion)
MPI Rank 0:         Err = if evalCriterion == 'Err' then
MPI Rank 0:               ErrorPrediction(labels, outZ, tag='evaluation')
MPI Rank 0:               else Fail('unknown evalCriterion ' + evalCriterion)
MPI Rank 0:         logPrior = LogPrior(labels)
MPI Rank 0:         // TODO: how to add a tag to an infix operation?
MPI Rank 0:         ScaledLogLikelihood = Minus (outZ, logPrior, tag='output')
MPI Rank 0:     ]
MPI Rank 0:     SGD = [
MPI Rank 0:         epochSize = 20480
MPI Rank 0:         minibatchSize = 64:256:1024
MPI Rank 0:         learningRatesPerMB = 1.0:0.5:0.1
MPI Rank 0:         numMBsToShowResult = 3
MPI Rank 0:         momentumPerMB = 0.9:0.656119
MPI Rank 0:         dropoutRate = 0.0
MPI Rank 0:         maxEpochs = 5
MPI Rank 0:         keepCheckPointFiles = true
MPI Rank 0:         clippingThresholdPerSample = 1#INF
MPI Rank 0:         ParallelTrain = [
MPI Rank 0:             parallelizationMethod = "BlockMomentumSGD"
MPI Rank 0:             distributedMBReading = true
MPI Rank 0:             syncPerfStats=1
MPI Rank 0:             BlockMomentumSGD = [
MPI Rank 0:                 blockSizePerWorker=2048
MPI Rank 0:                 resetSGDMomentum=true
MPI Rank 0:                 useNesterovMomentum=true
MPI Rank 0:             ]
MPI Rank 0:         ]
MPI Rank 0:         AutoAdjust = [
MPI Rank 0:             reduceLearnRateIfImproveLessThan = 0
MPI Rank 0:             loadBestModel = true
MPI Rank 0:             increaseLearnRateIfImproveMoreThan = 1000000000
MPI Rank 0:             learnRateDecreaseFactor = 0.5
MPI Rank 0:             learnRateIncreaseFactor = 1.382
MPI Rank 0:             autoAdjustLR = "adjustAfterEpoch"
MPI Rank 0:         ]
MPI Rank 0:     ]
MPI Rank 0:     reader = [
MPI Rank 0:         readerType = "HTKMLFReader"
MPI Rank 0:         readMethod = "blockRandomize"
MPI Rank 0:         miniBatchMode = "partial"
MPI Rank 0:         randomize = "auto"
MPI Rank 0:         verbosity = 0
MPI Rank 0:         features = [
MPI Rank 0:             dim = 363
MPI Rank 0:             type = "real"
MPI Rank 0:             scpFile = "glob_0000.scp"
MPI Rank 0:         ]
MPI Rank 0:         labels = [
MPI Rank 0:             mlfFile = "$DataDir$/glob_0000.mlf"
MPI Rank 0:             labelMappingFile = "$DataDir$/state.list"
MPI Rank 0:             labelDim = 132
MPI Rank 0:             labelType = "category"
MPI Rank 0:         ]
MPI Rank 0:     ]
MPI Rank 0: ]
MPI Rank 0: currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
MPI Rank 0: RunDir=/tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_gpu
MPI Rank 0: DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
MPI Rank 0: ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/ParallelBM/..
MPI Rank 0: OutputDir=/tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_gpu
MPI Rank 0: DeviceId=0
MPI Rank 0: timestamping=true
MPI Rank 0: numCPUThreads=12
MPI Rank 0: precision=double
MPI Rank 0: speechTrain=[SGD=[ParallelTrain=[parallelizationStartEpoch=2]]]
MPI Rank 0: stderr=/tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_gpu/stderr
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:43:28: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:43:28: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 0: 07/14/2016 12:43:28: precision = "float"
MPI Rank 0: command = speechTrain
MPI Rank 0: deviceId = 0
MPI Rank 0: parallelTrain = true
MPI Rank 0: speechTrain = [
MPI Rank 0:     action = "train"
MPI Rank 0:     modelPath = "/tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn"
MPI Rank 0:     deviceId = 0
MPI Rank 0:     traceLevel = 1
MPI Rank 0:     SimpleNetworkBuilder = [
MPI Rank 0:         layerSizes = 363:512:512:132
MPI Rank 0:         trainingCriterion = "CrossEntropyWithSoftmax"
MPI Rank 0:         evalCriterion = "ErrorPrediction"
MPI Rank 0:         layerTypes = "Sigmoid"
MPI Rank 0:         initValueScale = 1.0
MPI Rank 0:         applyMeanVarNorm = true
MPI Rank 0:         uniformInit = true
MPI Rank 0:         needPrior = true
MPI Rank 0:     ]
MPI Rank 0:     ExperimentalNetworkBuilder = [    // the same as above but with BS. Not active; activate by commenting out the SimpleNetworkBuilder entry above
MPI Rank 0:         layerSizes = 363:512:512:132
MPI Rank 0:         trainingCriterion = 'CE'
MPI Rank 0:         evalCriterion = 'Err'
MPI Rank 0:         applyMeanVarNorm = true
MPI Rank 0:         L = Length(layerSizes)-1    // number of model layers
MPI Rank 0:         features = Input(layerSizes[0], 1, tag='feature') ; labels = Input(layerSizes[Length(layerSizes)-1], 1, tag='label')
MPI Rank 0:         featNorm = if applyMeanVarNorm
MPI Rank 0:                    then MeanVarNorm(features)
MPI Rank 0:                    else features
MPI Rank 0:         layers[layer:1..L-1] = if layer > 1
MPI Rank 0:                                then SBFF(layers[layer-1].Eh, layerSizes[layer], layerSizes[layer-1])
MPI Rank 0:                                else SBFF(featNorm, layerSizes[layer], layerSizes[layer-1])
MPI Rank 0:         outLayer = BFF(layers[L-1].Eh, layerSizes[L], layerSizes[L-1])
MPI Rank 0:         outZ = outLayer.z        // + PastValue(layerSizes[L], 1, outLayer.z)
MPI Rank 0:         CE = if trainingCriterion == 'CE'
MPI Rank 0:              then CrossEntropyWithSoftmax(labels, outZ, tag='criterion')
MPI Rank 0:              else Fail('unknown trainingCriterion ' + trainingCriterion)
MPI Rank 0:         Err = if evalCriterion == 'Err' then
MPI Rank 0:               ErrorPrediction(labels, outZ, tag='evaluation')
MPI Rank 0:               else Fail('unknown evalCriterion ' + evalCriterion)
MPI Rank 0:         logPrior = LogPrior(labels)
MPI Rank 0:         // TODO: how to add a tag to an infix operation?
MPI Rank 0:         ScaledLogLikelihood = Minus (outZ, logPrior, tag='output')
MPI Rank 0:     ]
MPI Rank 0:     SGD = [
MPI Rank 0:         epochSize = 20480
MPI Rank 0:         minibatchSize = 64:256:1024
MPI Rank 0:         learningRatesPerMB = 1.0:0.5:0.1
MPI Rank 0:         numMBsToShowResult = 3
MPI Rank 0:         momentumPerMB = 0.9:0.656119
MPI Rank 0:         dropoutRate = 0.0
MPI Rank 0:         maxEpochs = 5
MPI Rank 0:         keepCheckPointFiles = true
MPI Rank 0:         clippingThresholdPerSample = 1#INF
MPI Rank 0:         ParallelTrain = [
MPI Rank 0:             parallelizationMethod = "BlockMomentumSGD"
MPI Rank 0:             distributedMBReading = true
MPI Rank 0:             syncPerfStats=1
MPI Rank 0:             BlockMomentumSGD = [
MPI Rank 0:                 blockSizePerWorker=2048
MPI Rank 0:                 resetSGDMomentum=true
MPI Rank 0:                 useNesterovMomentum=true
MPI Rank 0:             ]
MPI Rank 0:         ]
MPI Rank 0:         AutoAdjust = [
MPI Rank 0:             reduceLearnRateIfImproveLessThan = 0
MPI Rank 0:             loadBestModel = true
MPI Rank 0:             increaseLearnRateIfImproveMoreThan = 1000000000
MPI Rank 0:             learnRateDecreaseFactor = 0.5
MPI Rank 0:             learnRateIncreaseFactor = 1.382
MPI Rank 0:             autoAdjustLR = "adjustAfterEpoch"
MPI Rank 0:         ]
MPI Rank 0:     ]
MPI Rank 0:     reader = [
MPI Rank 0:         readerType = "HTKMLFReader"
MPI Rank 0:         readMethod = "blockRandomize"
MPI Rank 0:         miniBatchMode = "partial"
MPI Rank 0:         randomize = "auto"
MPI Rank 0:         verbosity = 0
MPI Rank 0:         features = [
MPI Rank 0:             dim = 363
MPI Rank 0:             type = "real"
MPI Rank 0:             scpFile = "glob_0000.scp"
MPI Rank 0:         ]
MPI Rank 0:         labels = [
MPI Rank 0:             mlfFile = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/glob_0000.mlf"
MPI Rank 0:             labelMappingFile = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/state.list"
MPI Rank 0:             labelDim = 132
MPI Rank 0:             labelType = "category"
MPI Rank 0:         ]
MPI Rank 0:     ]
MPI Rank 0: ]
MPI Rank 0: currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
MPI Rank 0: RunDir=/tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_gpu
MPI Rank 0: DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
MPI Rank 0: ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/ParallelBM/..
MPI Rank 0: OutputDir=/tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_gpu
MPI Rank 0: DeviceId=0
MPI Rank 0: timestamping=true
MPI Rank 0: numCPUThreads=12
MPI Rank 0: precision=double
MPI Rank 0: speechTrain=[SGD=[ParallelTrain=[parallelizationStartEpoch=2]]]
MPI Rank 0: stderr=/tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_gpu/stderr
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:43:28: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:43:28: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 0: configparameters: cntk.cntk:command=speechTrain
MPI Rank 0: configparameters: cntk.cntk:ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/ParallelBM/..
MPI Rank 0: configparameters: cntk.cntk:currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
MPI Rank 0: configparameters: cntk.cntk:DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
MPI Rank 0: configparameters: cntk.cntk:deviceId=0
MPI Rank 0: configparameters: cntk.cntk:numCPUThreads=12
MPI Rank 0: configparameters: cntk.cntk:OutputDir=/tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_gpu
MPI Rank 0: configparameters: cntk.cntk:parallelTrain=true
MPI Rank 0: configparameters: cntk.cntk:precision=double
MPI Rank 0: configparameters: cntk.cntk:RunDir=/tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_gpu
MPI Rank 0: configparameters: cntk.cntk:speechTrain=[
MPI Rank 0:     action = "train"
MPI Rank 0:     modelPath = "/tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn"
MPI Rank 0:     deviceId = 0
MPI Rank 0:     traceLevel = 1
MPI Rank 0:     SimpleNetworkBuilder = [
MPI Rank 0:         layerSizes = 363:512:512:132
MPI Rank 0:         trainingCriterion = "CrossEntropyWithSoftmax"
MPI Rank 0:         evalCriterion = "ErrorPrediction"
MPI Rank 0:         layerTypes = "Sigmoid"
MPI Rank 0:         initValueScale = 1.0
MPI Rank 0:         applyMeanVarNorm = true
MPI Rank 0:         uniformInit = true
MPI Rank 0:         needPrior = true
MPI Rank 0:     ]
MPI Rank 0:     ExperimentalNetworkBuilder = [    // the same as above but with BS. Not active; activate by commenting out the SimpleNetworkBuilder entry above
MPI Rank 0:         layerSizes = 363:512:512:132
MPI Rank 0:         trainingCriterion = 'CE'
MPI Rank 0:         evalCriterion = 'Err'
MPI Rank 0:         applyMeanVarNorm = true
MPI Rank 0:         L = Length(layerSizes)-1    // number of model layers
MPI Rank 0:         features = Input(layerSizes[0], 1, tag='feature') ; labels = Input(layerSizes[Length(layerSizes)-1], 1, tag='label')
MPI Rank 0:         featNorm = if applyMeanVarNorm
MPI Rank 0:                    then MeanVarNorm(features)
MPI Rank 0:                    else features
MPI Rank 0:         layers[layer:1..L-1] = if layer > 1
MPI Rank 0:                                then SBFF(layers[layer-1].Eh, layerSizes[layer], layerSizes[layer-1])
MPI Rank 0:                                else SBFF(featNorm, layerSizes[layer], layerSizes[layer-1])
MPI Rank 0:         outLayer = BFF(layers[L-1].Eh, layerSizes[L], layerSizes[L-1])
MPI Rank 0:         outZ = outLayer.z        // + PastValue(layerSizes[L], 1, outLayer.z)
MPI Rank 0:         CE = if trainingCriterion == 'CE'
MPI Rank 0:              then CrossEntropyWithSoftmax(labels, outZ, tag='criterion')
MPI Rank 0:              else Fail('unknown trainingCriterion ' + trainingCriterion)
MPI Rank 0:         Err = if evalCriterion == 'Err' then
MPI Rank 0:               ErrorPrediction(labels, outZ, tag='evaluation')
MPI Rank 0:               else Fail('unknown evalCriterion ' + evalCriterion)
MPI Rank 0:         logPrior = LogPrior(labels)
MPI Rank 0:         // TODO: how to add a tag to an infix operation?
MPI Rank 0:         ScaledLogLikelihood = Minus (outZ, logPrior, tag='output')
MPI Rank 0:     ]
MPI Rank 0:     SGD = [
MPI Rank 0:         epochSize = 20480
MPI Rank 0:         minibatchSize = 64:256:1024
MPI Rank 0:         learningRatesPerMB = 1.0:0.5:0.1
MPI Rank 0:         numMBsToShowResult = 3
MPI Rank 0:         momentumPerMB = 0.9:0.656119
MPI Rank 0:         dropoutRate = 0.0
MPI Rank 0:         maxEpochs = 5
MPI Rank 0:         keepCheckPointFiles = true
MPI Rank 0:         clippingThresholdPerSample = 1#INF
MPI Rank 0:         ParallelTrain = [
MPI Rank 0:             parallelizationMethod = "BlockMomentumSGD"
MPI Rank 0:             distributedMBReading = true
MPI Rank 0:             syncPerfStats=1
MPI Rank 0:             BlockMomentumSGD = [
MPI Rank 0:                 blockSizePerWorker=2048
MPI Rank 0:                 resetSGDMomentum=true
MPI Rank 0:                 useNesterovMomentum=true
MPI Rank 0:             ]
MPI Rank 0:         ]
MPI Rank 0:         AutoAdjust = [
MPI Rank 0:             reduceLearnRateIfImproveLessThan = 0
MPI Rank 0:             loadBestModel = true
MPI Rank 0:             increaseLearnRateIfImproveMoreThan = 1000000000
MPI Rank 0:             learnRateDecreaseFactor = 0.5
MPI Rank 0:             learnRateIncreaseFactor = 1.382
MPI Rank 0:             autoAdjustLR = "adjustAfterEpoch"
MPI Rank 0:         ]
MPI Rank 0:     ]
MPI Rank 0:     reader = [
MPI Rank 0:         readerType = "HTKMLFReader"
MPI Rank 0:         readMethod = "blockRandomize"
MPI Rank 0:         miniBatchMode = "partial"
MPI Rank 0:         randomize = "auto"
MPI Rank 0:         verbosity = 0
MPI Rank 0:         features = [
MPI Rank 0:             dim = 363
MPI Rank 0:             type = "real"
MPI Rank 0:             scpFile = "glob_0000.scp"
MPI Rank 0:         ]
MPI Rank 0:         labels = [
MPI Rank 0:             mlfFile = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/glob_0000.mlf"
MPI Rank 0:             labelMappingFile = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/state.list"
MPI Rank 0:             labelDim = 132
MPI Rank 0:             labelType = "category"
MPI Rank 0:         ]
MPI Rank 0:     ]
MPI Rank 0: ] [SGD=[ParallelTrain=[parallelizationStartEpoch=2]]]
MPI Rank 0: 
MPI Rank 0: configparameters: cntk.cntk:stderr=/tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_gpu/stderr
MPI Rank 0: configparameters: cntk.cntk:timestamping=true
MPI Rank 0: 07/14/2016 12:43:28: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 0: 07/14/2016 12:43:28: Commands: speechTrain
MPI Rank 0: 07/14/2016 12:43:28: Precision = "double"
MPI Rank 0: 07/14/2016 12:43:28: Using 12 CPU threads.
MPI Rank 0: 07/14/2016 12:43:28: CNTKModelPath: /tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn
MPI Rank 0: 07/14/2016 12:43:28: CNTKCommandTrainInfo: speechTrain : 5
MPI Rank 0: 07/14/2016 12:43:28: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 5
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:43:28: ##############################################################################
MPI Rank 0: 07/14/2016 12:43:28: #                                                                            #
MPI Rank 0: 07/14/2016 12:43:28: # Action "train"                                                             #
MPI Rank 0: 07/14/2016 12:43:28: #                                                                            #
MPI Rank 0: 07/14/2016 12:43:28: ##############################################################################
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:43:28: CNTKCommandTrainBegin: speechTrain
MPI Rank 0: SimpleNetworkBuilder Using GPU 0
MPI Rank 0: reading script file glob_0000.scp ... 948 entries
MPI Rank 0: total 132 state names in state list /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/state.list
MPI Rank 0: htkmlfreader: reading MLF file /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/glob_0000.mlf ... total 948 entries
MPI Rank 0: ...............................................................................................feature set 0: 252734 frames in 948 out of 948 utterances
MPI Rank 0: label set 0: 129 classes
MPI Rank 0: minibatchutterancesource: 948 utterances grouped into 3 chunks, av. chunk size: 316.0 utterances, 84244.7 frames
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:43:28: Creating virgin network.
MPI Rank 0: SetUniformRandomValue (GPU): creating curand object with seed 1, sizeof(ElemType)==8
MPI Rank 0: 
MPI Rank 0: Post-processing network...
MPI Rank 0: 
MPI Rank 0: 7 roots:
MPI Rank 0: 	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
MPI Rank 0: 	EvalErrorPrediction = ErrorPrediction()
MPI Rank 0: 	InvStdOfFeatures = InvStdDev()
MPI Rank 0: 	MeanOfFeatures = Mean()
MPI Rank 0: 	PosteriorProb = Softmax()
MPI Rank 0: 	Prior = Mean()
MPI Rank 0: 	ScaledLogLikelihood = Minus()
MPI Rank 0: 
MPI Rank 0: Validating network. 25 nodes to process in pass 1.
MPI Rank 0: 
MPI Rank 0: Validating --> labels = InputValue() :  -> [132 x *]
MPI Rank 0: Validating --> W2 = LearnableParameter() :  -> [132 x 512]
MPI Rank 0: Validating --> W1 = LearnableParameter() :  -> [512 x 512]
MPI Rank 0: Validating --> W0 = LearnableParameter() :  -> [512 x 363]
MPI Rank 0: Validating --> features = InputValue() :  -> [363 x *]
MPI Rank 0: Validating --> MeanOfFeatures = Mean (features) : [363 x *] -> [363]
MPI Rank 0: Validating --> InvStdOfFeatures = InvStdDev (features) : [363 x *] -> [363]
MPI Rank 0: Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [363 x *], [363], [363] -> [363 x *]
MPI Rank 0: Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [512 x 363], [363 x *] -> [512 x *]
MPI Rank 0: Validating --> B0 = LearnableParameter() :  -> [512 x 1]
MPI Rank 0: Validating --> W0*features+B0 = Plus (W0*features, B0) : [512 x *], [512 x 1] -> [512 x 1 x *]
MPI Rank 0: Validating --> H1 = Sigmoid (W0*features+B0) : [512 x 1 x *] -> [512 x 1 x *]
MPI Rank 0: Validating --> W1*H1 = Times (W1, H1) : [512 x 512], [512 x 1 x *] -> [512 x 1 x *]
MPI Rank 0: Validating --> B1 = LearnableParameter() :  -> [512 x 1]
MPI Rank 0: Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [512 x 1 x *], [512 x 1] -> [512 x 1 x *]
MPI Rank 0: Validating --> H2 = Sigmoid (W1*H1+B1) : [512 x 1 x *] -> [512 x 1 x *]
MPI Rank 0: Validating --> W2*H1 = Times (W2, H2) : [132 x 512], [512 x 1 x *] -> [132 x 1 x *]
MPI Rank 0: Validating --> B2 = LearnableParameter() :  -> [132 x 1]
MPI Rank 0: Validating --> HLast = Plus (W2*H1, B2) : [132 x 1 x *], [132 x 1] -> [132 x 1 x *]
MPI Rank 0: Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [132 x *], [132 x 1 x *] -> [1]
MPI Rank 0: Validating --> EvalErrorPrediction = ErrorPrediction (labels, HLast) : [132 x *], [132 x 1 x *] -> [1]
MPI Rank 0: Validating --> PosteriorProb = Softmax (HLast) : [132 x 1 x *] -> [132 x 1 x *]
MPI Rank 0: Validating --> Prior = Mean (labels) : [132 x *] -> [132]
MPI Rank 0: Validating --> LogOfPrior = Log (Prior) : [132] -> [132]
MPI Rank 0: Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [132 x 1 x *], [132] -> [132 x 1 x *]
MPI Rank 0: 
MPI Rank 0: Validating network. 17 nodes to process in pass 2.
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: Validating network, final pass.
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: 12 out of 25 nodes do not share the minibatch layout with the input data.
MPI Rank 0: 
MPI Rank 0: Post-processing network complete.
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:43:29: Created model with 25 nodes on GPU 0.
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:43:29: Training criterion node(s):
MPI Rank 0: 07/14/2016 12:43:29: 	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:43:29: Evaluation criterion node(s):
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:43:29: 	EvalErrorPrediction = ErrorPrediction
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: Allocating matrices for forward and/or backward propagation.
MPI Rank 0: 
MPI Rank 0: Memory Sharing Structure:
MPI Rank 0: 
MPI Rank 0: (nil): {[EvalErrorPrediction Gradient[1]] [InvStdOfFeatures Gradient[363]] [LogOfPrior Gradient[132]] [MVNormalizedFeatures Gradient[363 x *]] [MeanOfFeatures Gradient[363]] [PosteriorProb Gradient[132 x 1 x *]] [PosteriorProb Value[132 x 1 x *]] [Prior Gradient[132]] [ScaledLogLikelihood Gradient[132 x 1 x *]] [features Gradient[363 x *]] [labels Gradient[132 x *]] }
MPI Rank 0: 0x2dad998: {[features Value[363 x *]] }
MPI Rank 0: 0x3d09428: {[MeanOfFeatures Value[363]] }
MPI Rank 0: 0x3d098f8: {[InvStdOfFeatures Value[363]] }
MPI Rank 0: 0x3d0a638: {[W0 Value[512 x 363]] }
MPI Rank 0: 0x3d17ab8: {[B0 Value[512 x 1]] }
MPI Rank 0: 0x3d19bb8: {[W1 Value[512 x 512]] }
MPI Rank 0: 0x40df458: {[B1 Value[512 x 1]] }
MPI Rank 0: 0x40e05d8: {[W2 Value[132 x 512]] }
MPI Rank 0: 0x40e1288: {[B2 Value[132 x 1]] }
MPI Rank 0: 0x40e20b8: {[labels Value[132 x *]] }
MPI Rank 0: 0x40e3318: {[Prior Value[132]] }
MPI Rank 0: 0x40e8d48: {[EvalErrorPrediction Value[1]] }
MPI Rank 0: 0x40e8ea8: {[ScaledLogLikelihood Value[132 x 1 x *]] }
MPI Rank 0: 0x40e9068: {[CrossEntropyWithSoftmax Value[1]] }
MPI Rank 0: 0x40e94f8: {[W0 Gradient[512 x 363]] [W0*features+B0 Value[512 x 1 x *]] }
MPI Rank 0: 0x40e9628: {[LogOfPrior Value[132]] }
MPI Rank 0: 0x40ead88: {[MVNormalizedFeatures Value[363 x *]] }
MPI Rank 0: 0x40eb548: {[W0*features Value[512 x *]] }
MPI Rank 0: 0x40eb758: {[H1 Value[512 x 1 x *]] [W0*features Gradient[512 x *]] }
MPI Rank 0: 0x40eb8b8: {[W0*features+B0 Gradient[512 x 1 x *]] [W1*H1 Value[512 x 1 x *]] }
MPI Rank 0: 0x40eba78: {[W1 Gradient[512 x 512]] [W1*H1+B1 Value[512 x 1 x *]] }
MPI Rank 0: 0x40ebc38: {[H2 Value[512 x 1 x *]] [W1*H1 Gradient[512 x 1 x *]] }
MPI Rank 0: 0x40ebdf8: {[B0 Gradient[512 x 1]] [H1 Gradient[512 x 1 x *]] [W1*H1+B1 Gradient[512 x 1 x *]] [W2*H1 Value[132 x 1 x *]] }
MPI Rank 0: 0x40ebfb8: {[HLast Value[132 x 1 x *]] [W2 Gradient[132 x 512]] }
MPI Rank 0: 0x40ecb18: {[CrossEntropyWithSoftmax Gradient[1]] }
MPI Rank 0: 0x40eccd8: {[B1 Gradient[512 x 1]] [H2 Gradient[512 x 1 x *]] [HLast Gradient[132 x 1 x *]] }
MPI Rank 0: 0x40ece98: {[W2*H1 Gradient[132 x 1 x *]] }
MPI Rank 0: 0x40ed058: {[B2 Gradient[132 x 1]] }
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:43:29: Precomputing --> 3 PreCompute nodes found.
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:43:29: 	MeanOfFeatures = Mean()
MPI Rank 0: 07/14/2016 12:43:29: 	InvStdOfFeatures = InvStdDev()
MPI Rank 0: 07/14/2016 12:43:29: 	Prior = Mean()
MPI Rank 0: minibatchiterator: epoch 0: frames [0..252734] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
MPI Rank 0: requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:43:31: Precomputing --> Completed.
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:43:31: Starting Epoch 1: learning rate per sample = 0.015625  effective momentum = 0.900000  momentum as time constant = 607.4 samples
MPI Rank 0: minibatchiterator: epoch 0: frames [0..20480] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:43:31: Starting minibatch loop.
MPI Rank 0: 07/14/2016 12:43:31:  Epoch[ 1 of 5]-Minibatch[   1-   3, 0.94%]: CrossEntropyWithSoftmax = 4.57947979 * 192; EvalErrorPrediction = 0.96354167 * 192; time = 0.0192s; samplesPerSecond = 9994.3
MPI Rank 0: 07/14/2016 12:43:31:  Epoch[ 1 of 5]-Minibatch[   4-   6, 1.88%]: CrossEntropyWithSoftmax = 4.45832105 * 192; EvalErrorPrediction = 0.90104167 * 192; time = 0.0171s; samplesPerSecond = 11229.4
MPI Rank 0: 07/14/2016 12:43:31:  Epoch[ 1 of 5]-Minibatch[   7-   9, 2.81%]: CrossEntropyWithSoftmax = 4.29176856 * 192; EvalErrorPrediction = 0.85416667 * 192; time = 0.0185s; samplesPerSecond = 10399.7
MPI Rank 0: 07/14/2016 12:43:31:  Epoch[ 1 of 5]-Minibatch[  10-  12, 3.75%]: CrossEntropyWithSoftmax = 4.15840784 * 192; EvalErrorPrediction = 0.86979167 * 192; time = 0.0185s; samplesPerSecond = 10394.7
MPI Rank 0: 07/14/2016 12:43:31:  Epoch[ 1 of 5]-Minibatch[  13-  15, 4.69%]: CrossEntropyWithSoftmax = 4.21435783 * 192; EvalErrorPrediction = 0.86979167 * 192; time = 0.0185s; samplesPerSecond = 10389.6
MPI Rank 0: 07/14/2016 12:43:31:  Epoch[ 1 of 5]-Minibatch[  16-  18, 5.62%]: CrossEntropyWithSoftmax = 4.14020622 * 192; EvalErrorPrediction = 0.89583333 * 192; time = 0.0185s; samplesPerSecond = 10399.2
MPI Rank 0: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[  19-  21, 6.56%]: CrossEntropyWithSoftmax = 4.04069876 * 192; EvalErrorPrediction = 0.85416667 * 192; time = 0.0185s; samplesPerSecond = 10358.8
MPI Rank 0: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[  22-  24, 7.50%]: CrossEntropyWithSoftmax = 4.04991414 * 192; EvalErrorPrediction = 0.91666667 * 192; time = 0.0185s; samplesPerSecond = 10392.4
MPI Rank 0: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[  25-  27, 8.44%]: CrossEntropyWithSoftmax = 3.88626656 * 192; EvalErrorPrediction = 0.84375000 * 192; time = 0.0185s; samplesPerSecond = 10399.7
MPI Rank 0: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[  28-  30, 9.38%]: CrossEntropyWithSoftmax = 4.00467833 * 192; EvalErrorPrediction = 0.88020833 * 192; time = 0.0185s; samplesPerSecond = 10396.9
MPI Rank 0: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[  31-  33, 10.31%]: CrossEntropyWithSoftmax = 3.94077029 * 192; EvalErrorPrediction = 0.86458333 * 192; time = 0.0185s; samplesPerSecond = 10398.6
MPI Rank 0: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[  34-  36, 11.25%]: CrossEntropyWithSoftmax = 3.78326806 * 192; EvalErrorPrediction = 0.89062500 * 192; time = 0.0185s; samplesPerSecond = 10395.8
MPI Rank 0: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[  37-  39, 12.19%]: CrossEntropyWithSoftmax = 3.94698521 * 192; EvalErrorPrediction = 0.89062500 * 192; time = 0.0185s; samplesPerSecond = 10399.7
MPI Rank 0: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[  40-  42, 13.12%]: CrossEntropyWithSoftmax = 3.66011602 * 192; EvalErrorPrediction = 0.84895833 * 192; time = 0.0185s; samplesPerSecond = 10403.7
MPI Rank 0: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[  43-  45, 14.06%]: CrossEntropyWithSoftmax = 3.98797978 * 192; EvalErrorPrediction = 0.91666667 * 192; time = 0.0184s; samplesPerSecond = 10417.2
MPI Rank 0: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[  46-  48, 15.00%]: CrossEntropyWithSoftmax = 3.76297655 * 192; EvalErrorPrediction = 0.87500000 * 192; time = 0.0185s; samplesPerSecond = 10393.5
MPI Rank 0: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[  49-  51, 15.94%]: CrossEntropyWithSoftmax = 3.69909670 * 192; EvalErrorPrediction = 0.89062500 * 192; time = 0.0185s; samplesPerSecond = 10406.5
MPI Rank 0: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[  52-  54, 16.88%]: CrossEntropyWithSoftmax = 3.83747989 * 192; EvalErrorPrediction = 0.90104167 * 192; time = 0.0185s; samplesPerSecond = 10379.5
MPI Rank 0: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[  55-  57, 17.81%]: CrossEntropyWithSoftmax = 3.82672791 * 192; EvalErrorPrediction = 0.89062500 * 192; time = 0.0185s; samplesPerSecond = 10373.3
MPI Rank 0: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[  58-  60, 18.75%]: CrossEntropyWithSoftmax = 3.56520696 * 192; EvalErrorPrediction = 0.83333333 * 192; time = 0.0185s; samplesPerSecond = 10395.2
MPI Rank 0: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[  61-  63, 19.69%]: CrossEntropyWithSoftmax = 3.40098566 * 192; EvalErrorPrediction = 0.80208333 * 192; time = 0.0185s; samplesPerSecond = 10397.5
MPI Rank 0: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[  64-  66, 20.62%]: CrossEntropyWithSoftmax = 3.50668803 * 192; EvalErrorPrediction = 0.77604167 * 192; time = 0.0185s; samplesPerSecond = 10402.6
MPI Rank 0: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[  67-  69, 21.56%]: CrossEntropyWithSoftmax = 3.82314351 * 192; EvalErrorPrediction = 0.86979167 * 192; time = 0.0184s; samplesPerSecond = 10418.4
MPI Rank 0: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[  70-  72, 22.50%]: CrossEntropyWithSoftmax = 3.51780740 * 192; EvalErrorPrediction = 0.83854167 * 192; time = 0.0184s; samplesPerSecond = 10409.9
MPI Rank 0: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[  73-  75, 23.44%]: CrossEntropyWithSoftmax = 3.32189431 * 192; EvalErrorPrediction = 0.79687500 * 192; time = 0.0185s; samplesPerSecond = 10402.0
MPI Rank 0: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[  76-  78, 24.38%]: CrossEntropyWithSoftmax = 3.42533640 * 192; EvalErrorPrediction = 0.77604167 * 192; time = 0.0185s; samplesPerSecond = 10399.2
MPI Rank 0: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[  79-  81, 25.31%]: CrossEntropyWithSoftmax = 3.42902377 * 192; EvalErrorPrediction = 0.81770833 * 192; time = 0.0185s; samplesPerSecond = 10399.7
MPI Rank 0: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[  82-  84, 26.25%]: CrossEntropyWithSoftmax = 3.42017745 * 192; EvalErrorPrediction = 0.76041667 * 192; time = 0.0184s; samplesPerSecond = 10421.8
MPI Rank 0: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[  85-  87, 27.19%]: CrossEntropyWithSoftmax = 3.30346679 * 192; EvalErrorPrediction = 0.73437500 * 192; time = 0.0185s; samplesPerSecond = 10399.2
MPI Rank 0: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[  88-  90, 28.12%]: CrossEntropyWithSoftmax = 3.31343403 * 192; EvalErrorPrediction = 0.79687500 * 192; time = 0.0185s; samplesPerSecond = 10382.9
MPI Rank 0: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[  91-  93, 29.06%]: CrossEntropyWithSoftmax = 3.22956709 * 192; EvalErrorPrediction = 0.83854167 * 192; time = 0.0185s; samplesPerSecond = 10394.1
MPI Rank 0: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[  94-  96, 30.00%]: CrossEntropyWithSoftmax = 3.54894307 * 192; EvalErrorPrediction = 0.84895833 * 192; time = 0.0185s; samplesPerSecond = 10373.9
MPI Rank 0: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[  97-  99, 30.94%]: CrossEntropyWithSoftmax = 3.33751842 * 192; EvalErrorPrediction = 0.85416667 * 192; time = 0.0184s; samplesPerSecond = 10408.8
MPI Rank 0: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[ 100- 102, 31.87%]: CrossEntropyWithSoftmax = 3.25951347 * 192; EvalErrorPrediction = 0.80729167 * 192; time = 0.0185s; samplesPerSecond = 10394.1
MPI Rank 0: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[ 103- 105, 32.81%]: CrossEntropyWithSoftmax = 3.24586699 * 192; EvalErrorPrediction = 0.78125000 * 192; time = 0.0185s; samplesPerSecond = 10386.2
MPI Rank 0: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[ 106- 108, 33.75%]: CrossEntropyWithSoftmax = 3.06725828 * 192; EvalErrorPrediction = 0.71875000 * 192; time = 0.0185s; samplesPerSecond = 10393.5
MPI Rank 0: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[ 109- 111, 34.69%]: CrossEntropyWithSoftmax = 3.39973653 * 192; EvalErrorPrediction = 0.77083333 * 192; time = 0.0185s; samplesPerSecond = 10387.4
MPI Rank 0: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[ 112- 114, 35.62%]: CrossEntropyWithSoftmax = 3.34798378 * 192; EvalErrorPrediction = 0.78645833 * 192; time = 0.0185s; samplesPerSecond = 10394.7
MPI Rank 0: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[ 115- 117, 36.56%]: CrossEntropyWithSoftmax = 3.38133778 * 192; EvalErrorPrediction = 0.82291667 * 192; time = 0.0185s; samplesPerSecond = 10391.3
MPI Rank 0: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[ 118- 120, 37.50%]: CrossEntropyWithSoftmax = 3.19074044 * 192; EvalErrorPrediction = 0.74479167 * 192; time = 0.0185s; samplesPerSecond = 10403.7
MPI Rank 0: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[ 121- 123, 38.44%]: CrossEntropyWithSoftmax = 3.14306337 * 192; EvalErrorPrediction = 0.74479167 * 192; time = 0.0185s; samplesPerSecond = 10405.9
MPI Rank 0: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[ 124- 126, 39.38%]: CrossEntropyWithSoftmax = 3.10036521 * 192; EvalErrorPrediction = 0.72916667 * 192; time = 0.0185s; samplesPerSecond = 10385.7
MPI Rank 0: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[ 127- 129, 40.31%]: CrossEntropyWithSoftmax = 3.17040971 * 192; EvalErrorPrediction = 0.76562500 * 192; time = 0.0185s; samplesPerSecond = 10390.7
MPI Rank 0: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[ 130- 132, 41.25%]: CrossEntropyWithSoftmax = 3.19888148 * 192; EvalErrorPrediction = 0.75520833 * 192; time = 0.0185s; samplesPerSecond = 10386.8
MPI Rank 0: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[ 133- 135, 42.19%]: CrossEntropyWithSoftmax = 2.91247084 * 192; EvalErrorPrediction = 0.66145833 * 192; time = 0.0185s; samplesPerSecond = 10399.2
MPI Rank 0: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[ 136- 138, 43.12%]: CrossEntropyWithSoftmax = 2.96972038 * 192; EvalErrorPrediction = 0.70833333 * 192; time = 0.0185s; samplesPerSecond = 10403.1
MPI Rank 0: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[ 139- 141, 44.06%]: CrossEntropyWithSoftmax = 3.15632232 * 192; EvalErrorPrediction = 0.76041667 * 192; time = 0.0184s; samplesPerSecond = 10408.8
MPI Rank 0: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[ 142- 144, 45.00%]: CrossEntropyWithSoftmax = 2.98075176 * 192; EvalErrorPrediction = 0.71354167 * 192; time = 0.0185s; samplesPerSecond = 10402.0
MPI Rank 0: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[ 145- 147, 45.94%]: CrossEntropyWithSoftmax = 3.03076846 * 192; EvalErrorPrediction = 0.77604167 * 192; time = 0.0185s; samplesPerSecond = 10399.7
MPI Rank 0: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[ 148- 150, 46.88%]: CrossEntropyWithSoftmax = 2.91480722 * 192; EvalErrorPrediction = 0.71354167 * 192; time = 0.0184s; samplesPerSecond = 10410.5
MPI Rank 0: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[ 151- 153, 47.81%]: CrossEntropyWithSoftmax = 3.16155322 * 192; EvalErrorPrediction = 0.75520833 * 192; time = 0.0185s; samplesPerSecond = 10405.4
MPI Rank 0: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[ 154- 156, 48.75%]: CrossEntropyWithSoftmax = 2.76157172 * 192; EvalErrorPrediction = 0.69791667 * 192; time = 0.0185s; samplesPerSecond = 10405.9
MPI Rank 0: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[ 157- 159, 49.69%]: CrossEntropyWithSoftmax = 3.06347679 * 192; EvalErrorPrediction = 0.75520833 * 192; time = 0.0185s; samplesPerSecond = 10394.7
MPI Rank 0: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[ 160- 162, 50.62%]: CrossEntropyWithSoftmax = 2.84053583 * 192; EvalErrorPrediction = 0.69791667 * 192; time = 0.0185s; samplesPerSecond = 10388.5
MPI Rank 0: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[ 163- 165, 51.56%]: CrossEntropyWithSoftmax = 2.87795860 * 192; EvalErrorPrediction = 0.75000000 * 192; time = 0.0185s; samplesPerSecond = 10405.9
MPI Rank 0: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[ 166- 168, 52.50%]: CrossEntropyWithSoftmax = 2.92198252 * 192; EvalErrorPrediction = 0.70833333 * 192; time = 0.0185s; samplesPerSecond = 10382.3
MPI Rank 0: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[ 169- 171, 53.44%]: CrossEntropyWithSoftmax = 2.81241750 * 192; EvalErrorPrediction = 0.66145833 * 192; time = 0.0185s; samplesPerSecond = 10400.3
MPI Rank 0: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[ 172- 174, 54.37%]: CrossEntropyWithSoftmax = 2.62682593 * 192; EvalErrorPrediction = 0.64062500 * 192; time = 0.0185s; samplesPerSecond = 10401.4
MPI Rank 0: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[ 175- 177, 55.31%]: CrossEntropyWithSoftmax = 2.75758644 * 192; EvalErrorPrediction = 0.73437500 * 192; time = 0.0185s; samplesPerSecond = 10396.4
MPI Rank 0: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[ 178- 180, 56.25%]: CrossEntropyWithSoftmax = 2.74763961 * 192; EvalErrorPrediction = 0.67187500 * 192; time = 0.0185s; samplesPerSecond = 10396.9
MPI Rank 0: 07/14/2016 12:43:33:  Epoch[ 1 of 5]-Minibatch[ 181- 183, 57.19%]: CrossEntropyWithSoftmax = 2.90905834 * 192; EvalErrorPrediction = 0.68229167 * 192; time = 0.0184s; samplesPerSecond = 10412.7
MPI Rank 0: 07/14/2016 12:43:33:  Epoch[ 1 of 5]-Minibatch[ 184- 186, 58.13%]: CrossEntropyWithSoftmax = 2.76756973 * 192; EvalErrorPrediction = 0.70833333 * 192; time = 0.0185s; samplesPerSecond = 10384.6
MPI Rank 0: 07/14/2016 12:43:33:  Epoch[ 1 of 5]-Minibatch[ 187- 189, 59.06%]: CrossEntropyWithSoftmax = 2.76599748 * 192; EvalErrorPrediction = 0.75520833 * 192; time = 0.0185s; samplesPerSecond = 10379.5
MPI Rank 0: 07/14/2016 12:43:33:  Epoch[ 1 of 5]-Minibatch[ 190- 192, 60.00%]: CrossEntropyWithSoftmax = 2.83171014 * 192; EvalErrorPrediction = 0.70833333 * 192; time = 0.0185s; samplesPerSecond = 10368.3
MPI Rank 0: 07/14/2016 12:43:33:  Epoch[ 1 of 5]-Minibatch[ 193- 195, 60.94%]: CrossEntropyWithSoftmax = 2.59593490 * 192; EvalErrorPrediction = 0.61458333 * 192; time = 0.0185s; samplesPerSecond = 10400.3
MPI Rank 0: 07/14/2016 12:43:33:  Epoch[ 1 of 5]-Minibatch[ 196- 198, 61.88%]: CrossEntropyWithSoftmax = 2.64965270 * 192; EvalErrorPrediction = 0.66666667 * 192; time = 0.0185s; samplesPerSecond = 10389.6
MPI Rank 0: 07/14/2016 12:43:33:  Epoch[ 1 of 5]-Minibatch[ 199- 201, 62.81%]: CrossEntropyWithSoftmax = 2.33442260 * 192; EvalErrorPrediction = 0.60937500 * 192; time = 0.0184s; samplesPerSecond = 10407.1
MPI Rank 0: 07/14/2016 12:43:33:  Epoch[ 1 of 5]-Minibatch[ 202- 204, 63.75%]: CrossEntropyWithSoftmax = 2.67195863 * 192; EvalErrorPrediction = 0.67187500 * 192; time = 0.0185s; samplesPerSecond = 10380.1
MPI Rank 0: 07/14/2016 12:43:33:  Epoch[ 1 of 5]-Minibatch[ 205- 207, 64.69%]: CrossEntropyWithSoftmax = 2.72367540 * 192; EvalErrorPrediction = 0.66145833 * 192; time = 0.0185s; samplesPerSecond = 10383.4
MPI Rank 0: 07/14/2016 12:43:33:  Epoch[ 1 of 5]-Minibatch[ 208- 210, 65.62%]: CrossEntropyWithSoftmax = 2.59572337 * 192; EvalErrorPrediction = 0.68229167 * 192; time = 0.0185s; samplesPerSecond = 10391.9
MPI Rank 0: 07/14/2016 12:43:33:  Epoch[ 1 of 5]-Minibatch[ 211- 213, 66.56%]: CrossEntropyWithSoftmax = 2.53202795 * 192; EvalErrorPrediction = 0.63541667 * 192; time = 0.0185s; samplesPerSecond = 10405.9
MPI Rank 0: 07/14/2016 12:43:33:  Epoch[ 1 of 5]-Minibatch[ 214- 216, 67.50%]: CrossEntropyWithSoftmax = 2.50336278 * 192; EvalErrorPrediction = 0.67187500 * 192; time = 0.0184s; samplesPerSecond = 10418.4
MPI Rank 0: 07/14/2016 12:43:33:  Epoch[ 1 of 5]-Minibatch[ 217- 219, 68.44%]: CrossEntropyWithSoftmax = 2.77076318 * 192; EvalErrorPrediction = 0.68750000 * 192; time = 0.0185s; samplesPerSecond = 10395.2
MPI Rank 0: 07/14/2016 12:43:33:  Epoch[ 1 of 5]-Minibatch[ 220- 222, 69.38%]: CrossEntropyWithSoftmax = 2.45308521 * 192; EvalErrorPrediction = 0.59895833 * 192; time = 0.0185s; samplesPerSecond = 10396.9
MPI Rank 0: 07/14/2016 12:43:33:  Epoch[ 1 of 5]-Minibatch[ 223- 225, 70.31%]: CrossEntropyWithSoftmax = 2.54598920 * 192; EvalErrorPrediction = 0.60937500 * 192; time = 0.0185s; samplesPerSecond = 10381.7
MPI Rank 0: 07/14/2016 12:43:33:  Epoch[ 1 of 5]-Minibatch[ 226- 228, 71.25%]: CrossEntropyWithSoftmax = 2.58558089 * 192; EvalErrorPrediction = 0.65625000 * 192; time = 0.0185s; samplesPerSecond = 10402.6
MPI Rank 0: 07/14/2016 12:43:33:  Epoch[ 1 of 5]-Minibatch[ 229- 231, 72.19%]: CrossEntropyWithSoftmax = 2.41075660 * 192; EvalErrorPrediction = 0.61458333 * 192; time = 0.0185s; samplesPerSecond = 10405.4
MPI Rank 0: 07/14/2016 12:43:33:  Epoch[ 1 of 5]-Minibatch[ 232- 234, 73.12%]: CrossEntropyWithSoftmax = 2.52012028 * 192; EvalErrorPrediction = 0.66145833 * 192; time = 0.0185s; samplesPerSecond = 10397.5
MPI Rank 0: 07/14/2016 12:43:33:  Epoch[ 1 of 5]-Minibatch[ 235- 237, 74.06%]: CrossEntropyWithSoftmax = 2.30719546 * 192; EvalErrorPrediction = 0.62500000 * 192; time = 0.0184s; samplesPerSecond = 10408.2
MPI Rank 0: 07/14/2016 12:43:33:  Epoch[ 1 of 5]-Minibatch[ 238- 240, 75.00%]: CrossEntropyWithSoftmax = 2.42100657 * 192; EvalErrorPrediction = 0.59895833 * 192; time = 0.0185s; samplesPerSecond = 10381.7
MPI Rank 0: 07/14/2016 12:43:33:  Epoch[ 1 of 5]-Minibatch[ 241- 243, 75.94%]: CrossEntropyWithSoftmax = 2.39894546 * 192; EvalErrorPrediction = 0.63541667 * 192; time = 0.0185s; samplesPerSecond = 10401.4
MPI Rank 0: 07/14/2016 12:43:33:  Epoch[ 1 of 5]-Minibatch[ 244- 246, 76.88%]: CrossEntropyWithSoftmax = 2.44970724 * 192; EvalErrorPrediction = 0.67187500 * 192; time = 0.0185s; samplesPerSecond = 10400.9
MPI Rank 0: 07/14/2016 12:43:33:  Epoch[ 1 of 5]-Minibatch[ 247- 249, 77.81%]: CrossEntropyWithSoftmax = 2.33418475 * 192; EvalErrorPrediction = 0.63541667 * 192; time = 0.0185s; samplesPerSecond = 10399.7
MPI Rank 0: 07/14/2016 12:43:33:  Epoch[ 1 of 5]-Minibatch[ 250- 252, 78.75%]: CrossEntropyWithSoftmax = 2.37997032 * 192; EvalErrorPrediction = 0.61458333 * 192; time = 0.0185s; samplesPerSecond = 10399.2
MPI Rank 0: 07/14/2016 12:43:33:  Epoch[ 1 of 5]-Minibatch[ 253- 255, 79.69%]: CrossEntropyWithSoftmax = 2.47517097 * 192; EvalErrorPrediction = 0.59895833 * 192; time = 0.0185s; samplesPerSecond = 10399.7
MPI Rank 0: 07/14/2016 12:43:33:  Epoch[ 1 of 5]-Minibatch[ 256- 258, 80.62%]: CrossEntropyWithSoftmax = 2.60900086 * 192; EvalErrorPrediction = 0.69270833 * 192; time = 0.0185s; samplesPerSecond = 10405.9
MPI Rank 0: 07/14/2016 12:43:33:  Epoch[ 1 of 5]-Minibatch[ 259- 261, 81.56%]: CrossEntropyWithSoftmax = 2.43300244 * 192; EvalErrorPrediction = 0.65104167 * 192; time = 0.0185s; samplesPerSecond = 10394.1
MPI Rank 0: 07/14/2016 12:43:33:  Epoch[ 1 of 5]-Minibatch[ 262- 264, 82.50%]: CrossEntropyWithSoftmax = 2.12996515 * 192; EvalErrorPrediction = 0.56250000 * 192; time = 0.0185s; samplesPerSecond = 10391.9
MPI Rank 0: 07/14/2016 12:43:33:  Epoch[ 1 of 5]-Minibatch[ 265- 267, 83.44%]: CrossEntropyWithSoftmax = 2.51181403 * 192; EvalErrorPrediction = 0.62500000 * 192; time = 0.0184s; samplesPerSecond = 10407.1
MPI Rank 0: 07/14/2016 12:43:33:  Epoch[ 1 of 5]-Minibatch[ 268- 270, 84.38%]: CrossEntropyWithSoftmax = 2.29330120 * 192; EvalErrorPrediction = 0.60416667 * 192; time = 0.0185s; samplesPerSecond = 10399.2
MPI Rank 0: 07/14/2016 12:43:33:  Epoch[ 1 of 5]-Minibatch[ 271- 273, 85.31%]: CrossEntropyWithSoftmax = 2.33352411 * 192; EvalErrorPrediction = 0.60416667 * 192; time = 0.0185s; samplesPerSecond = 10399.7
MPI Rank 0: 07/14/2016 12:43:33:  Epoch[ 1 of 5]-Minibatch[ 274- 276, 86.25%]: CrossEntropyWithSoftmax = 2.17790026 * 192; EvalErrorPrediction = 0.57812500 * 192; time = 0.0185s; samplesPerSecond = 10398.1
MPI Rank 0: 07/14/2016 12:43:33:  Epoch[ 1 of 5]-Minibatch[ 277- 279, 87.19%]: CrossEntropyWithSoftmax = 2.18521155 * 192; EvalErrorPrediction = 0.54166667 * 192; time = 0.0185s; samplesPerSecond = 10395.2
MPI Rank 0: 07/14/2016 12:43:33:  Epoch[ 1 of 5]-Minibatch[ 280- 282, 88.12%]: CrossEntropyWithSoftmax = 2.29833071 * 192; EvalErrorPrediction = 0.58854167 * 192; time = 0.0185s; samplesPerSecond = 10403.1
MPI Rank 0: 07/14/2016 12:43:33:  Epoch[ 1 of 5]-Minibatch[ 283- 285, 89.06%]: CrossEntropyWithSoftmax = 2.21483298 * 192; EvalErrorPrediction = 0.61458333 * 192; time = 0.0185s; samplesPerSecond = 10399.7
MPI Rank 0: 07/14/2016 12:43:33:  Epoch[ 1 of 5]-Minibatch[ 286- 288, 90.00%]: CrossEntropyWithSoftmax = 2.37232627 * 192; EvalErrorPrediction = 0.61979167 * 192; time = 0.0185s; samplesPerSecond = 10386.2
MPI Rank 0: 07/14/2016 12:43:33:  Epoch[ 1 of 5]-Minibatch[ 289- 291, 90.94%]: CrossEntropyWithSoftmax = 2.34396058 * 192; EvalErrorPrediction = 0.60416667 * 192; time = 0.0185s; samplesPerSecond = 10400.9
MPI Rank 0: 07/14/2016 12:43:33:  Epoch[ 1 of 5]-Minibatch[ 292- 294, 91.88%]: CrossEntropyWithSoftmax = 2.18334302 * 192; EvalErrorPrediction = 0.63020833 * 192; time = 0.0185s; samplesPerSecond = 10400.3
MPI Rank 0: 07/14/2016 12:43:33:  Epoch[ 1 of 5]-Minibatch[ 295- 297, 92.81%]: CrossEntropyWithSoftmax = 2.07753101 * 192; EvalErrorPrediction = 0.57812500 * 192; time = 0.0185s; samplesPerSecond = 10398.6
MPI Rank 0: 07/14/2016 12:43:33:  Epoch[ 1 of 5]-Minibatch[ 298- 300, 93.75%]: CrossEntropyWithSoftmax = 2.26265833 * 192; EvalErrorPrediction = 0.63020833 * 192; time = 0.0185s; samplesPerSecond = 10405.4
MPI Rank 0: 07/14/2016 12:43:33:  Epoch[ 1 of 5]-Minibatch[ 301- 303, 94.69%]: CrossEntropyWithSoftmax = 2.21675905 * 192; EvalErrorPrediction = 0.58333333 * 192; time = 0.0185s; samplesPerSecond = 10403.7
MPI Rank 0: 07/14/2016 12:43:33:  Epoch[ 1 of 5]-Minibatch[ 304- 306, 95.62%]: CrossEntropyWithSoftmax = 2.18990385 * 192; EvalErrorPrediction = 0.58333333 * 192; time = 0.0185s; samplesPerSecond = 10400.9
MPI Rank 0: 07/14/2016 12:43:33:  Epoch[ 1 of 5]-Minibatch[ 307- 309, 96.56%]: CrossEntropyWithSoftmax = 2.48513433 * 192; EvalErrorPrediction = 0.64583333 * 192; time = 0.0185s; samplesPerSecond = 10401.4
MPI Rank 0: 07/14/2016 12:43:33:  Epoch[ 1 of 5]-Minibatch[ 310- 312, 97.50%]: CrossEntropyWithSoftmax = 2.25336704 * 192; EvalErrorPrediction = 0.59895833 * 192; time = 0.0185s; samplesPerSecond = 10399.7
MPI Rank 0: 07/14/2016 12:43:33:  Epoch[ 1 of 5]-Minibatch[ 313- 315, 98.44%]: CrossEntropyWithSoftmax = 2.13039619 * 192; EvalErrorPrediction = 0.55729167 * 192; time = 0.0185s; samplesPerSecond = 10391.3
MPI Rank 0: 07/14/2016 12:43:33:  Epoch[ 1 of 5]-Minibatch[ 316- 318, 99.38%]: CrossEntropyWithSoftmax = 2.27299748 * 192; EvalErrorPrediction = 0.60416667 * 192; time = 0.0185s; samplesPerSecond = 10400.9
MPI Rank 0: 07/14/2016 12:43:33: Finished Epoch[ 1 of 5]: [Training] CrossEntropyWithSoftmax = 2.99723568 * 20480; EvalErrorPrediction = 0.72426758 * 20480; totalSamplesSeen = 20480; learningRatePerSample = 0.015625; epochTime=1.97715s
MPI Rank 0: 07/14/2016 12:43:33: SGD: Saving checkpoint model '/tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.1'
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:43:33: Starting Epoch 2: learning rate per sample = 0.001953  effective momentum = 0.656119  momentum as time constant = 607.5 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 1: frames [20480..40960] (first utterance at frame 20480), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:43:33: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 07/14/2016 12:43:33:  Epoch[ 2 of 5]-Minibatch[   1-   3, 3.75%]: CrossEntropyWithSoftmax = 2.25388628 * 519; EvalErrorPrediction = 0.63391137 * 519; time = 0.0343s; samplesPerSecond = 15144.9
MPI Rank 0: 07/14/2016 12:43:33:  Epoch[ 2 of 5]-Minibatch[   4-   6, 7.50%]: CrossEntropyWithSoftmax = 2.01477571 * 529; EvalErrorPrediction = 0.53686200 * 529; time = 0.0306s; samplesPerSecond = 17266.7
MPI Rank 0: 07/14/2016 12:43:34:  Epoch[ 2 of 5]-Minibatch[   7-   9, 11.25%]: CrossEntropyWithSoftmax = 2.03638222 * 494; EvalErrorPrediction = 0.55060729 * 494; time = 0.0229s; samplesPerSecond = 21528.8
MPI Rank 0: 07/14/2016 12:43:34:  Epoch[ 2 of 5]-Minibatch[  10-  12, 15.00%]: CrossEntropyWithSoftmax = 1.97591869 * 491; EvalErrorPrediction = 0.54378819 * 491; time = 0.0270s; samplesPerSecond = 18189.2
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     0.16 seconds since last report (0.00 seconds on comm.); 4331 samples processed by 2 workers (2190 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 26.27k samplesPerSecond , throughputPerWorker = 13.14k samplesPerSecond
MPI Rank 0: 07/14/2016 12:43:34:  Epoch[ 2 of 5]-Minibatch[  13-  15, 18.75%]: CrossEntropyWithSoftmax = 2.12486189 * 488; EvalErrorPrediction = 0.53483607 * 488; time = 0.0653s; samplesPerSecond = 7469.1
MPI Rank 0: 07/14/2016 12:43:34:  Epoch[ 2 of 5]-Minibatch[  16-  18, 22.50%]: CrossEntropyWithSoftmax = 1.99682461 * 485; EvalErrorPrediction = 0.55670103 * 485; time = 0.0270s; samplesPerSecond = 17966.3
MPI Rank 0: 07/14/2016 12:43:34:  Epoch[ 2 of 5]-Minibatch[  19-  21, 26.25%]: CrossEntropyWithSoftmax = 1.98681980 * 529; EvalErrorPrediction = 0.55576560 * 529; time = 0.0374s; samplesPerSecond = 14152.0
MPI Rank 0: 07/14/2016 12:43:34:  Epoch[ 2 of 5]-Minibatch[  22-  24, 30.00%]: CrossEntropyWithSoftmax = 1.94891082 * 468; EvalErrorPrediction = 0.55341880 * 468; time = 0.0257s; samplesPerSecond = 18177.6
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.06 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     0.15 seconds since last report (0.00 seconds on comm.); 4232 samples processed by 2 workers (2154 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 27.81k samplesPerSecond , throughputPerWorker = 13.91k samplesPerSecond
MPI Rank 0: 07/14/2016 12:43:34:  Epoch[ 2 of 5]-Minibatch[  25-  27, 33.75%]: CrossEntropyWithSoftmax = 1.99768818 * 499; EvalErrorPrediction = 0.53507014 * 499; time = 0.0522s; samplesPerSecond = 9559.4
MPI Rank 0: 07/14/2016 12:43:34:  Epoch[ 2 of 5]-Minibatch[  28-  30, 37.50%]: CrossEntropyWithSoftmax = 2.17844696 * 494; EvalErrorPrediction = 0.57692308 * 494; time = 0.0274s; samplesPerSecond = 18049.6
MPI Rank 0: 07/14/2016 12:43:34:  Epoch[ 2 of 5]-Minibatch[  31-  33, 41.25%]: CrossEntropyWithSoftmax = 1.96255558 * 479; EvalErrorPrediction = 0.53027140 * 479; time = 0.0269s; samplesPerSecond = 17827.2
MPI Rank 0: 07/14/2016 12:43:34:  Epoch[ 2 of 5]-Minibatch[  34-  36, 45.00%]: CrossEntropyWithSoftmax = 1.99612126 * 488; EvalErrorPrediction = 0.54303279 * 488; time = 0.0269s; samplesPerSecond = 18111.6
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     0.15 seconds since last report (0.00 seconds on comm.); 4185 samples processed by 2 workers (2125 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 28.19k samplesPerSecond , throughputPerWorker = 14.10k samplesPerSecond
MPI Rank 0: 07/14/2016 12:43:34:  Epoch[ 2 of 5]-Minibatch[  37-  39, 48.75%]: CrossEntropyWithSoftmax = 1.89743886 * 506; EvalErrorPrediction = 0.52766798 * 506; time = 0.0583s; samplesPerSecond = 8682.8
MPI Rank 0: 07/14/2016 12:43:34:  Epoch[ 2 of 5]-Minibatch[  40-  42, 52.50%]: CrossEntropyWithSoftmax = 1.85536959 * 512; EvalErrorPrediction = 0.52929688 * 512; time = 0.0259s; samplesPerSecond = 19793.6
MPI Rank 0: 07/14/2016 12:43:34:  Epoch[ 2 of 5]-Minibatch[  43-  45, 56.25%]: CrossEntropyWithSoftmax = 1.92579626 * 497; EvalErrorPrediction = 0.49496982 * 497; time = 0.0227s; samplesPerSecond = 21855.8
MPI Rank 0: 07/14/2016 12:43:34:  Epoch[ 2 of 5]-Minibatch[  46-  48, 60.00%]: CrossEntropyWithSoftmax = 1.85664750 * 502; EvalErrorPrediction = 0.52988048 * 502; time = 0.0271s; samplesPerSecond = 18530.1
MPI Rank 0: 07/14/2016 12:43:34:  Epoch[ 2 of 5]-Minibatch[  49-  51, 63.75%]: CrossEntropyWithSoftmax = 2.05622489 * 476; EvalErrorPrediction = 0.56932773 * 476; time = 0.0214s; samplesPerSecond = 22277.3
MPI Rank 0: 07/14/2016 12:43:34:  Epoch[ 2 of 5]-Minibatch[  52-  54, 67.50%]: CrossEntropyWithSoftmax = 2.00110796 * 487; EvalErrorPrediction = 0.53388090 * 487; time = 0.0148s; samplesPerSecond = 32810.1
MPI Rank 0: 07/14/2016 12:43:34:  Epoch[ 2 of 5]-Minibatch[  55-  57, 71.25%]: CrossEntropyWithSoftmax = 1.90438413 * 499; EvalErrorPrediction = 0.51903808 * 499; time = 0.0150s; samplesPerSecond = 33213.5
MPI Rank 0: 07/14/2016 12:43:34:  Epoch[ 2 of 5]-Minibatch[  58-  60, 75.00%]: CrossEntropyWithSoftmax = 1.93538095 * 475; EvalErrorPrediction = 0.51789474 * 475; time = 0.0146s; samplesPerSecond = 32460.9
MPI Rank 0: 07/14/2016 12:43:34:  Epoch[ 2 of 5]-Minibatch[  61-  63, 78.75%]: CrossEntropyWithSoftmax = 1.92688744 * 506; EvalErrorPrediction = 0.53952569 * 506; time = 0.0150s; samplesPerSecond = 33837.1
MPI Rank 0: 07/14/2016 12:43:34:  Epoch[ 2 of 5]-Minibatch[  64-  66, 82.50%]: CrossEntropyWithSoftmax = 1.93689941 * 472; EvalErrorPrediction = 0.53389831 * 472; time = 0.0146s; samplesPerSecond = 32359.8
MPI Rank 0: 07/14/2016 12:43:34:  Epoch[ 2 of 5]-Minibatch[  67-  69, 86.25%]: CrossEntropyWithSoftmax = 1.87278053 * 490; EvalErrorPrediction = 0.53061224 * 490; time = 0.0148s; samplesPerSecond = 33132.7
MPI Rank 0: 07/14/2016 12:43:34:  Epoch[ 2 of 5]-Minibatch[  70-  72, 90.00%]: CrossEntropyWithSoftmax = 1.93056324 * 477; EvalErrorPrediction = 0.50943396 * 477; time = 0.0147s; samplesPerSecond = 32524.2
MPI Rank 0: 07/14/2016 12:43:34:  Epoch[ 2 of 5]-Minibatch[  73-  75, 93.75%]: CrossEntropyWithSoftmax = 1.92122823 * 469; EvalErrorPrediction = 0.52878465 * 469; time = 0.0145s; samplesPerSecond = 32238.1
MPI Rank 0: 07/14/2016 12:43:34:  Epoch[ 2 of 5]-Minibatch[  76-  78, 97.50%]: CrossEntropyWithSoftmax = 1.92998622 * 495; EvalErrorPrediction = 0.53131313 * 495; time = 0.0148s; samplesPerSecond = 33380.5
MPI Rank 0: 07/14/2016 12:43:34:  Epoch[ 2 of 5]-Minibatch[  79-  81, 101.25%]: CrossEntropyWithSoftmax = 1.87322468 * 322; EvalErrorPrediction = 0.54968944 * 322; time = 0.0098s; samplesPerSecond = 32988.4
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     0.25 seconds since last report (0.00 seconds on comm.); 7732 samples processed by 2 workers (6679 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 30.95k samplesPerSecond , throughputPerWorker = 15.48k samplesPerSecond
MPI Rank 0: 07/14/2016 12:43:34: Finished Epoch[ 2 of 5]: [Training] CrossEntropyWithSoftmax = 1.99875653 * 20480; EvalErrorPrediction = 0.54526367 * 20480; totalSamplesSeen = 40960; learningRatePerSample = 0.001953125; epochTime=0.715377s
MPI Rank 0: 07/14/2016 12:43:34: SGD: Saving checkpoint model '/tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.2'
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:43:34: Starting Epoch 3: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 2: frames [40960..61440] (first utterance at frame 40960), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:43:34: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 07/14/2016 12:43:34:  Epoch[ 3 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.86678794 * 1939; EvalErrorPrediction = 0.50489943 * 1939; time = 0.0942s; samplesPerSecond = 20574.5
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     0.12 seconds since last report (0.00 seconds on comm.); 4844 samples processed by 2 workers (2583 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 39.33k samplesPerSecond , throughputPerWorker = 19.66k samplesPerSecond
MPI Rank 0: 07/14/2016 12:43:34:  Epoch[ 3 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.88063301 * 1944; EvalErrorPrediction = 0.53497942 * 1944; time = 0.0786s; samplesPerSecond = 24727.8
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.01 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     0.12 seconds since last report (0.01 seconds on comm.); 4849 samples processed by 2 workers (2580 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 41.67k samplesPerSecond , throughputPerWorker = 20.84k samplesPerSecond
MPI Rank 0: 07/14/2016 12:43:34:  Epoch[ 3 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.90227906 * 1918; EvalErrorPrediction = 0.52346194 * 1918; time = 0.0891s; samplesPerSecond = 21530.5
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.01 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     0.12 seconds since last report (0.00 seconds on comm.); 4868 samples processed by 2 workers (2595 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 41.86k samplesPerSecond , throughputPerWorker = 20.93k samplesPerSecond
MPI Rank 0: 07/14/2016 12:43:35:  Epoch[ 3 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.88640712 * 1957; EvalErrorPrediction = 0.52376086 * 1957; time = 0.0898s; samplesPerSecond = 21804.0
MPI Rank 0: 07/14/2016 12:43:35:  Epoch[ 3 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.86518475 * 1942; EvalErrorPrediction = 0.52008239 * 1942; time = 0.0601s; samplesPerSecond = 32297.8
MPI Rank 0: 07/14/2016 12:43:35:  Epoch[ 3 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.85598666 * 1929; EvalErrorPrediction = 0.51270088 * 1929; time = 0.0432s; samplesPerSecond = 44695.2
MPI Rank 0: 07/14/2016 12:43:35:  Epoch[ 3 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.88794294 * 1290; EvalErrorPrediction = 0.51937984 * 1290; time = 0.0335s; samplesPerSecond = 38501.7
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.01 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     0.15 seconds since last report (0.00 seconds on comm.); 5919 samples processed by 2 workers (5161 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 40.53k samplesPerSecond , throughputPerWorker = 20.26k samplesPerSecond
MPI Rank 0: 07/14/2016 12:43:35: Finished Epoch[ 3 of 5]: [Training] CrossEntropyWithSoftmax = 1.88572700 * 20480; EvalErrorPrediction = 0.52416992 * 20480; totalSamplesSeen = 61440; learningRatePerSample = 9.7656251e-05; epochTime=0.50202s
MPI Rank 0: 07/14/2016 12:43:35: SGD: Saving checkpoint model '/tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.3'
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:43:35: Starting Epoch 4: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:43:35: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 07/14/2016 12:43:35:  Epoch[ 4 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.89976988 * 1926; EvalErrorPrediction = 0.52128764 * 1926; time = 0.0712s; samplesPerSecond = 27041.8
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     0.12 seconds since last report (0.01 seconds on comm.); 4905 samples processed by 2 workers (2581 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 40.52k samplesPerSecond , throughputPerWorker = 20.26k samplesPerSecond
MPI Rank 0: 07/14/2016 12:43:35:  Epoch[ 4 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.79499440 * 1894; EvalErrorPrediction = 0.50844773 * 1894; time = 0.0943s; samplesPerSecond = 20095.1
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.05 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     0.11 seconds since last report (0.01 seconds on comm.); 4870 samples processed by 2 workers (2537 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 42.43k samplesPerSecond , throughputPerWorker = 21.22k samplesPerSecond
MPI Rank 0: 07/14/2016 12:43:35:  Epoch[ 4 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.84956803 * 1931; EvalErrorPrediction = 0.51475919 * 1931; time = 0.0892s; samplesPerSecond = 21649.4
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.04-seconds latency this time; accumulated time on sync point = 0.09 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     0.12 seconds since last report (0.01 seconds on comm.); 4916 samples processed by 2 workers (2513 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 41.83k samplesPerSecond , throughputPerWorker = 20.91k samplesPerSecond
MPI Rank 0: 07/14/2016 12:43:35:  Epoch[ 4 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.82336020 * 1880; EvalErrorPrediction = 0.50159574 * 1880; time = 0.0944s; samplesPerSecond = 19924.5
MPI Rank 0: 07/14/2016 12:43:35:  Epoch[ 4 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.79200574 * 1880; EvalErrorPrediction = 0.49627660 * 1880; time = 0.0570s; samplesPerSecond = 33003.9
MPI Rank 0: 07/14/2016 12:43:35:  Epoch[ 4 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.80502326 * 1861; EvalErrorPrediction = 0.50994089 * 1861; time = 0.0417s; samplesPerSecond = 44585.5
MPI Rank 0: 07/14/2016 12:43:35:  Epoch[ 4 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.81515951 * 1263; EvalErrorPrediction = 0.48851940 * 1263; time = 0.0276s; samplesPerSecond = 45716.1
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.09 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     0.14 seconds since last report (0.00 seconds on comm.); 5789 samples processed by 2 workers (5004 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 42.29k samplesPerSecond , throughputPerWorker = 21.15k samplesPerSecond
MPI Rank 0: 07/14/2016 12:43:35: Finished Epoch[ 4 of 5]: [Training] CrossEntropyWithSoftmax = 1.83787473 * 20480; EvalErrorPrediction = 0.51215820 * 20480; totalSamplesSeen = 81920; learningRatePerSample = 9.7656251e-05; epochTime=0.49037s
MPI Rank 0: 07/14/2016 12:43:35: SGD: Saving checkpoint model '/tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.4'
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:43:35: Starting Epoch 5: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:43:35: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 07/14/2016 12:43:35:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80055910 * 1897; EvalErrorPrediction = 0.49868213 * 1897; time = 0.0684s; samplesPerSecond = 27739.2
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     0.12 seconds since last report (0.01 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 39.95k samplesPerSecond , throughputPerWorker = 19.97k samplesPerSecond
MPI Rank 0: 07/14/2016 12:43:36:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86746838 * 1821; EvalErrorPrediction = 0.51455244 * 1821; time = 0.1011s; samplesPerSecond = 18016.5
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.06 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     0.11 seconds since last report (0.01 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 42.52k samplesPerSecond , throughputPerWorker = 21.26k samplesPerSecond
MPI Rank 0: 07/14/2016 12:43:36:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.89216516 * 1871; EvalErrorPrediction = 0.52057723 * 1871; time = 0.0873s; samplesPerSecond = 21429.1
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     0.11 seconds since last report (0.01 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 42.37k samplesPerSecond , throughputPerWorker = 21.18k samplesPerSecond
MPI Rank 0: 07/14/2016 12:43:36:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.81968853 * 1870; EvalErrorPrediction = 0.49144385 * 1870; time = 0.0916s; samplesPerSecond = 20406.4
MPI Rank 0: 07/14/2016 12:43:36:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.89739279 * 1899; EvalErrorPrediction = 0.51711427 * 1899; time = 0.0587s; samplesPerSecond = 32332.2
MPI Rank 0: 07/14/2016 12:43:36:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.85833241 * 1878; EvalErrorPrediction = 0.52236422 * 1878; time = 0.0406s; samplesPerSecond = 46308.6
MPI Rank 0: 07/14/2016 12:43:36:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.86115648 * 1221; EvalErrorPrediction = 0.50696151 * 1221; time = 0.0270s; samplesPerSecond = 45265.8
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     0.14 seconds since last report (0.00 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 42.98k samplesPerSecond , throughputPerWorker = 21.49k samplesPerSecond
MPI Rank 0: 07/14/2016 12:43:36: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84363929 * 20480; EvalErrorPrediction = 0.51025391 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 9.7656251e-05; epochTime=0.488215s
MPI Rank 0: 07/14/2016 12:43:36: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 12:43:36: learnRatePerSample reduced to 4.8828126e-05
MPI Rank 0: 07/14/2016 12:43:36: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:43:36: Starting Epoch 5: learning rate per sample = 0.000049  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:43:36: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 07/14/2016 12:43:36:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80064927 * 1897; EvalErrorPrediction = 0.49815498 * 1897; time = 0.0725s; samplesPerSecond = 26171.7
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.02 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     0.12 seconds since last report (0.01 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 40.67k samplesPerSecond , throughputPerWorker = 20.33k samplesPerSecond
MPI Rank 0: 07/14/2016 12:43:36:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86833563 * 1821; EvalErrorPrediction = 0.51510159 * 1821; time = 0.0948s; samplesPerSecond = 19218.0
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.05 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     0.12 seconds since last report (0.01 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 42.45k samplesPerSecond , throughputPerWorker = 21.23k samplesPerSecond
MPI Rank 0: 07/14/2016 12:43:36:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.89383486 * 1871; EvalErrorPrediction = 0.52111170 * 1871; time = 0.0881s; samplesPerSecond = 21248.3
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     0.11 seconds since last report (0.01 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 42.32k samplesPerSecond , throughputPerWorker = 21.16k samplesPerSecond
MPI Rank 0: 07/14/2016 12:43:36:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.82119679 * 1870; EvalErrorPrediction = 0.49251337 * 1870; time = 0.0913s; samplesPerSecond = 20491.1
MPI Rank 0: 07/14/2016 12:43:36:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.89901122 * 1899; EvalErrorPrediction = 0.51869405 * 1899; time = 0.0593s; samplesPerSecond = 32019.8
MPI Rank 0: 07/14/2016 12:43:37:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.86037327 * 1878; EvalErrorPrediction = 0.52342918 * 1878; time = 0.0409s; samplesPerSecond = 45947.2
MPI Rank 0: 07/14/2016 12:43:37:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.86390618 * 1221; EvalErrorPrediction = 0.50941851 * 1221; time = 0.0270s; samplesPerSecond = 45198.8
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     0.14 seconds since last report (0.00 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 42.61k samplesPerSecond , throughputPerWorker = 21.31k samplesPerSecond
MPI Rank 0: 07/14/2016 12:43:37: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84493298 * 20480; EvalErrorPrediction = 0.51040039 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 4.8828126e-05; epochTime=0.487498s
MPI Rank 0: 07/14/2016 12:43:37: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 12:43:37: learnRatePerSample reduced to 2.4414063e-05
MPI Rank 0: 07/14/2016 12:43:37: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:43:37: Starting Epoch 5: learning rate per sample = 0.000024  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:43:37: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 07/14/2016 12:43:37:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80069673 * 1897; EvalErrorPrediction = 0.49868213 * 1897; time = 0.0716s; samplesPerSecond = 26498.9
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.02 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     0.12 seconds since last report (0.01 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 40.76k samplesPerSecond , throughputPerWorker = 20.38k samplesPerSecond
MPI Rank 0: 07/14/2016 12:43:37:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86881421 * 1821; EvalErrorPrediction = 0.51345415 * 1821; time = 0.0945s; samplesPerSecond = 19265.2
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.05 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     0.12 seconds since last report (0.01 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 42.44k samplesPerSecond , throughputPerWorker = 21.22k samplesPerSecond
MPI Rank 0: 07/14/2016 12:43:37:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.89481082 * 1871; EvalErrorPrediction = 0.51897381 * 1871; time = 0.0879s; samplesPerSecond = 21274.4
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     0.11 seconds since last report (0.01 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 42.52k samplesPerSecond , throughputPerWorker = 21.26k samplesPerSecond
MPI Rank 0: 07/14/2016 12:43:37:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.82214273 * 1870; EvalErrorPrediction = 0.49465241 * 1870; time = 0.0913s; samplesPerSecond = 20491.1
MPI Rank 0: 07/14/2016 12:43:37:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.90008573 * 1899; EvalErrorPrediction = 0.52185361 * 1899; time = 0.0597s; samplesPerSecond = 31823.4
MPI Rank 0: 07/14/2016 12:43:37:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.86165710 * 1878; EvalErrorPrediction = 0.52289670 * 1878; time = 0.0410s; samplesPerSecond = 45794.8
MPI Rank 0: 07/14/2016 12:43:37:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.86530783 * 1221; EvalErrorPrediction = 0.50941851 * 1221; time = 0.0270s; samplesPerSecond = 45265.8
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     0.14 seconds since last report (0.00 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 42.49k samplesPerSecond , throughputPerWorker = 21.25k samplesPerSecond
MPI Rank 0: 07/14/2016 12:43:37: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84568574 * 20480; EvalErrorPrediction = 0.51049805 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 2.4414063e-05; epochTime=0.487105s
MPI Rank 0: 07/14/2016 12:43:37: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 12:43:37: learnRatePerSample reduced to 1.2207031e-05
MPI Rank 0: 07/14/2016 12:43:37: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:43:37: Starting Epoch 5: learning rate per sample = 0.000012  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:43:37: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 07/14/2016 12:43:37:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80072106 * 1897; EvalErrorPrediction = 0.49762783 * 1897; time = 0.0716s; samplesPerSecond = 26497.0
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.02 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     0.12 seconds since last report (0.01 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 40.85k samplesPerSecond , throughputPerWorker = 20.43k samplesPerSecond
MPI Rank 0: 07/14/2016 12:43:38:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86906602 * 1821; EvalErrorPrediction = 0.51345415 * 1821; time = 0.0949s; samplesPerSecond = 19194.3
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.05 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     0.12 seconds since last report (0.01 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 42.19k samplesPerSecond , throughputPerWorker = 21.09k samplesPerSecond
MPI Rank 0: 07/14/2016 12:43:38:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.89534508 * 1871; EvalErrorPrediction = 0.51897381 * 1871; time = 0.0883s; samplesPerSecond = 21182.4
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     0.11 seconds since last report (0.01 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 42.42k samplesPerSecond , throughputPerWorker = 21.21k samplesPerSecond
MPI Rank 0: 07/14/2016 12:43:38:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.82269026 * 1870; EvalErrorPrediction = 0.49465241 * 1870; time = 0.0914s; samplesPerSecond = 20464.7
MPI Rank 0: 07/14/2016 12:43:38:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.90075815 * 1899; EvalErrorPrediction = 0.52132701 * 1899; time = 0.0593s; samplesPerSecond = 32038.2
MPI Rank 0: 07/14/2016 12:43:38:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.86244120 * 1878; EvalErrorPrediction = 0.52342918 * 1878; time = 0.0405s; samplesPerSecond = 46326.9
MPI Rank 0: 07/14/2016 12:43:38:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.86601864 * 1221; EvalErrorPrediction = 0.51187551 * 1221; time = 0.0272s; samplesPerSecond = 44942.6
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     0.14 seconds since last report (0.00 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 42.70k samplesPerSecond , throughputPerWorker = 21.35k samplesPerSecond
MPI Rank 0: 07/14/2016 12:43:38: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84611027 * 20480; EvalErrorPrediction = 0.51083984 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 1.2207031e-05; epochTime=0.487116s
MPI Rank 0: 07/14/2016 12:43:38: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 12:43:38: learnRatePerSample reduced to 6.1035157e-06
MPI Rank 0: 07/14/2016 12:43:38: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:43:38: Starting Epoch 5: learning rate per sample = 0.000006  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:43:38: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 07/14/2016 12:43:38:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80073339 * 1897; EvalErrorPrediction = 0.49762783 * 1897; time = 0.0715s; samplesPerSecond = 26532.2
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.02 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     0.12 seconds since last report (0.01 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 40.98k samplesPerSecond , throughputPerWorker = 20.49k samplesPerSecond
MPI Rank 0: 07/14/2016 12:43:38:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86919523 * 1821; EvalErrorPrediction = 0.51290500 * 1821; time = 0.0943s; samplesPerSecond = 19305.2
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.05 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     0.11 seconds since last report (0.01 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 42.72k samplesPerSecond , throughputPerWorker = 21.36k samplesPerSecond
MPI Rank 0: 07/14/2016 12:43:38:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.89562551 * 1871; EvalErrorPrediction = 0.51950828 * 1871; time = 0.0872s; samplesPerSecond = 21444.6
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     0.12 seconds since last report (0.01 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 42.07k samplesPerSecond , throughputPerWorker = 21.04k samplesPerSecond
MPI Rank 0: 07/14/2016 12:43:38:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.82298742 * 1870; EvalErrorPrediction = 0.49625668 * 1870; time = 0.0925s; samplesPerSecond = 20221.7
MPI Rank 0: 07/14/2016 12:43:38:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.90114315 * 1899; EvalErrorPrediction = 0.52238020 * 1899; time = 0.0584s; samplesPerSecond = 32511.0
MPI Rank 0: 07/14/2016 12:43:38:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.86288926 * 1878; EvalErrorPrediction = 0.52396166 * 1878; time = 0.0414s; samplesPerSecond = 45401.8
MPI Rank 0: 07/14/2016 12:43:38:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.86638702 * 1221; EvalErrorPrediction = 0.51187551 * 1221; time = 0.0271s; samplesPerSecond = 45062.0
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     0.14 seconds since last report (0.00 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 42.66k samplesPerSecond , throughputPerWorker = 21.33k samplesPerSecond
MPI Rank 0: 07/14/2016 12:43:38: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84633999 * 20480; EvalErrorPrediction = 0.51123047 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 6.1035157e-06; epochTime=0.486386s
MPI Rank 0: 07/14/2016 12:43:38: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 12:43:39: learnRatePerSample reduced to 3.0517579e-06
MPI Rank 0: 07/14/2016 12:43:39: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:43:39: Starting Epoch 5: learning rate per sample = 0.000003  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:43:39: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 07/14/2016 12:43:39:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80073959 * 1897; EvalErrorPrediction = 0.49762783 * 1897; time = 0.0718s; samplesPerSecond = 26412.9
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     0.12 seconds since last report (0.01 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 40.42k samplesPerSecond , throughputPerWorker = 20.21k samplesPerSecond
MPI Rank 0: 07/14/2016 12:43:39:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86926069 * 1821; EvalErrorPrediction = 0.51345415 * 1821; time = 0.0957s; samplesPerSecond = 19022.1
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.05 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     0.11 seconds since last report (0.01 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 42.65k samplesPerSecond , throughputPerWorker = 21.33k samplesPerSecond
MPI Rank 0: 07/14/2016 12:43:39:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.89576929 * 1871; EvalErrorPrediction = 0.51950828 * 1871; time = 0.0874s; samplesPerSecond = 21399.5
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     0.11 seconds since last report (0.01 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 42.48k samplesPerSecond , throughputPerWorker = 21.24k samplesPerSecond
MPI Rank 0: 07/14/2016 12:43:39:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.82314256 * 1870; EvalErrorPrediction = 0.49679144 * 1870; time = 0.0913s; samplesPerSecond = 20479.5
MPI Rank 0: 07/14/2016 12:43:39:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.90135030 * 1899; EvalErrorPrediction = 0.52185361 * 1899; time = 0.0584s; samplesPerSecond = 32539.4
MPI Rank 0: 07/14/2016 12:43:39:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.86313105 * 1878; EvalErrorPrediction = 0.52449414 * 1878; time = 0.0414s; samplesPerSecond = 45393.0
MPI Rank 0: 07/14/2016 12:43:39:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.86657721 * 1221; EvalErrorPrediction = 0.51187551 * 1221; time = 0.0271s; samplesPerSecond = 45017.1
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     0.14 seconds since last report (0.00 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 42.75k samplesPerSecond , throughputPerWorker = 21.37k samplesPerSecond
MPI Rank 0: 07/14/2016 12:43:39: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84646018 * 20480; EvalErrorPrediction = 0.51127930 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 3.0517579e-06; epochTime=0.486827s
MPI Rank 0: 07/14/2016 12:43:39: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 12:43:39: learnRatePerSample reduced to 1.5258789e-06
MPI Rank 0: 07/14/2016 12:43:39: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:43:39: Starting Epoch 5: learning rate per sample = 0.000002  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:43:39: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 07/14/2016 12:43:39:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80074270 * 1897; EvalErrorPrediction = 0.49762783 * 1897; time = 0.0727s; samplesPerSecond = 26106.1
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.02 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     0.12 seconds since last report (0.01 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 40.64k samplesPerSecond , throughputPerWorker = 20.32k samplesPerSecond
MPI Rank 0: 07/14/2016 12:43:39:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86929363 * 1821; EvalErrorPrediction = 0.51345415 * 1821; time = 0.0951s; samplesPerSecond = 19143.4
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.05 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     0.12 seconds since last report (0.01 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 42.34k samplesPerSecond , throughputPerWorker = 21.17k samplesPerSecond
MPI Rank 0: 07/14/2016 12:43:40:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.89584210 * 1871; EvalErrorPrediction = 0.51897381 * 1871; time = 0.0879s; samplesPerSecond = 21285.8
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     0.11 seconds since last report (0.01 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 42.39k samplesPerSecond , throughputPerWorker = 21.19k samplesPerSecond
MPI Rank 0: 07/14/2016 12:43:40:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.82322186 * 1870; EvalErrorPrediction = 0.49732620 * 1870; time = 0.0910s; samplesPerSecond = 20543.8
MPI Rank 0: 07/14/2016 12:43:40:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.90145790 * 1899; EvalErrorPrediction = 0.52185361 * 1899; time = 0.0583s; samplesPerSecond = 32590.8
MPI Rank 0: 07/14/2016 12:43:40:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.86325694 * 1878; EvalErrorPrediction = 0.52396166 * 1878; time = 0.0405s; samplesPerSecond = 46422.0
MPI Rank 0: 07/14/2016 12:43:40:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.86667428 * 1221; EvalErrorPrediction = 0.51187551 * 1221; time = 0.0270s; samplesPerSecond = 45173.7
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     0.14 seconds since last report (0.00 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 43.09k samplesPerSecond , throughputPerWorker = 21.55k samplesPerSecond
MPI Rank 0: 07/14/2016 12:43:40: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84652175 * 20480; EvalErrorPrediction = 0.51123047 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 1.5258789e-06; epochTime=0.48618s
MPI Rank 0: 07/14/2016 12:43:40: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 12:43:40: learnRatePerSample reduced to 7.6293946e-07
MPI Rank 0: 07/14/2016 12:43:40: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:43:40: Starting Epoch 5: learning rate per sample = 0.000001  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:43:40: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 07/14/2016 12:43:40:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80074425 * 1897; EvalErrorPrediction = 0.49762783 * 1897; time = 0.0707s; samplesPerSecond = 26840.8
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     0.12 seconds since last report (0.01 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 40.81k samplesPerSecond , throughputPerWorker = 20.40k samplesPerSecond
MPI Rank 0: 07/14/2016 12:43:40:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86931015 * 1821; EvalErrorPrediction = 0.51345415 * 1821; time = 0.0955s; samplesPerSecond = 19067.7
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.05 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     0.11 seconds since last report (0.01 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 42.52k samplesPerSecond , throughputPerWorker = 21.26k samplesPerSecond
MPI Rank 0: 07/14/2016 12:43:40:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.89587874 * 1871; EvalErrorPrediction = 0.51897381 * 1871; time = 0.0879s; samplesPerSecond = 21275.4
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     0.11 seconds since last report (0.01 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 42.57k samplesPerSecond , throughputPerWorker = 21.28k samplesPerSecond
MPI Rank 0: 07/14/2016 12:43:40:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.82326196 * 1870; EvalErrorPrediction = 0.49732620 * 1870; time = 0.0910s; samplesPerSecond = 20554.4
MPI Rank 0: 07/14/2016 12:43:40:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.90151275 * 1899; EvalErrorPrediction = 0.52132701 * 1899; time = 0.0586s; samplesPerSecond = 32385.7
MPI Rank 0: 07/14/2016 12:43:40:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.86332122 * 1878; EvalErrorPrediction = 0.52396166 * 1878; time = 0.0414s; samplesPerSecond = 45398.5
MPI Rank 0: 07/14/2016 12:43:40:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.86672338 * 1221; EvalErrorPrediction = 0.51187551 * 1221; time = 0.0270s; samplesPerSecond = 45254.1
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     0.14 seconds since last report (0.00 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 42.69k samplesPerSecond , throughputPerWorker = 21.34k samplesPerSecond
MPI Rank 0: 07/14/2016 12:43:40: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84655293 * 20480; EvalErrorPrediction = 0.51118164 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 7.6293946e-07; epochTime=0.485978s
MPI Rank 0: 07/14/2016 12:43:40: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 12:43:41: learnRatePerSample reduced to 3.8146973e-07
MPI Rank 0: 07/14/2016 12:43:41: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:43:41: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:43:41: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 07/14/2016 12:43:41:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80074503 * 1897; EvalErrorPrediction = 0.49762783 * 1897; time = 0.0725s; samplesPerSecond = 26153.3
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.02 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     0.12 seconds since last report (0.01 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 40.64k samplesPerSecond , throughputPerWorker = 20.32k samplesPerSecond
MPI Rank 0: 07/14/2016 12:43:41:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86931843 * 1821; EvalErrorPrediction = 0.51345415 * 1821; time = 0.0943s; samplesPerSecond = 19313.2
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.05 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     0.11 seconds since last report (0.01 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 42.65k samplesPerSecond , throughputPerWorker = 21.32k samplesPerSecond
MPI Rank 0: 07/14/2016 12:43:41:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.89589712 * 1871; EvalErrorPrediction = 0.51897381 * 1871; time = 0.0875s; samplesPerSecond = 21394.6
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     0.11 seconds since last report (0.01 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 42.39k samplesPerSecond , throughputPerWorker = 21.20k samplesPerSecond
MPI Rank 0: 07/14/2016 12:43:41:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.82328212 * 1870; EvalErrorPrediction = 0.49732620 * 1870; time = 0.0916s; samplesPerSecond = 20418.0
MPI Rank 0: 07/14/2016 12:43:41:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.90154044 * 1899; EvalErrorPrediction = 0.52132701 * 1899; time = 0.0592s; samplesPerSecond = 32078.2
MPI Rank 0: 07/14/2016 12:43:41:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.86335370 * 1878; EvalErrorPrediction = 0.52396166 * 1878; time = 0.0404s; samplesPerSecond = 46456.4
MPI Rank 0: 07/14/2016 12:43:41:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.86674809 * 1221; EvalErrorPrediction = 0.51187551 * 1221; time = 0.0266s; samplesPerSecond = 45936.8
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     0.14 seconds since last report (0.00 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 42.93k samplesPerSecond , throughputPerWorker = 21.47k samplesPerSecond
MPI Rank 0: 07/14/2016 12:43:41: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84656861 * 20480; EvalErrorPrediction = 0.51118164 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 3.8146973e-07; epochTime=0.485864s
MPI Rank 0: 07/14/2016 12:43:41: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 12:43:41: learnRatePerSample reduced to 1.9073487e-07
MPI Rank 0: 07/14/2016 12:43:41: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:43:41: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:43:41: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 07/14/2016 12:43:41:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80074542 * 1897; EvalErrorPrediction = 0.49762783 * 1897; time = 0.0725s; samplesPerSecond = 26166.6
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.02 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     0.12 seconds since last report (0.01 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 40.56k samplesPerSecond , throughputPerWorker = 20.28k samplesPerSecond
MPI Rank 0: 07/14/2016 12:43:41:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86932257 * 1821; EvalErrorPrediction = 0.51345415 * 1821; time = 0.0950s; samplesPerSecond = 19178.3
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.05 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     0.11 seconds since last report (0.01 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 42.50k samplesPerSecond , throughputPerWorker = 21.25k samplesPerSecond
MPI Rank 0: 07/14/2016 12:43:41:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.89590632 * 1871; EvalErrorPrediction = 0.51897381 * 1871; time = 0.0879s; samplesPerSecond = 21295.7
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     0.12 seconds since last report (0.01 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 41.97k samplesPerSecond , throughputPerWorker = 20.98k samplesPerSecond
MPI Rank 0: 07/14/2016 12:43:42:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.82329223 * 1870; EvalErrorPrediction = 0.49786096 * 1870; time = 0.0923s; samplesPerSecond = 20269.9
MPI Rank 0: 07/14/2016 12:43:42:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.90155435 * 1899; EvalErrorPrediction = 0.52132701 * 1899; time = 0.0587s; samplesPerSecond = 32346.5
MPI Rank 0: 07/14/2016 12:43:42:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.86337003 * 1878; EvalErrorPrediction = 0.52396166 * 1878; time = 0.0416s; samplesPerSecond = 45190.9
MPI Rank 0: 07/14/2016 12:43:42:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.86676047 * 1221; EvalErrorPrediction = 0.51187551 * 1221; time = 0.0271s; samplesPerSecond = 45108.6
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     0.14 seconds since last report (0.00 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 42.53k samplesPerSecond , throughputPerWorker = 21.27k samplesPerSecond
MPI Rank 0: 07/14/2016 12:43:42: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84657648 * 20480; EvalErrorPrediction = 0.51118164 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 1.9073487e-07; epochTime=0.48894s
MPI Rank 0: 07/14/2016 12:43:42: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 12:43:42: learnRatePerSample reduced to 9.5367433e-08
MPI Rank 0: 07/14/2016 12:43:42: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:43:42: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:43:42: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 07/14/2016 12:43:42:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80074562 * 1897; EvalErrorPrediction = 0.49762783 * 1897; time = 0.0726s; samplesPerSecond = 26116.9
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.02 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     0.12 seconds since last report (0.01 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 40.39k samplesPerSecond , throughputPerWorker = 20.20k samplesPerSecond
MPI Rank 0: 07/14/2016 12:43:42:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86932464 * 1821; EvalErrorPrediction = 0.51345415 * 1821; time = 0.0949s; samplesPerSecond = 19183.6
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.05 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     0.12 seconds since last report (0.01 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 42.34k samplesPerSecond , throughputPerWorker = 21.17k samplesPerSecond
MPI Rank 0: 07/14/2016 12:43:42:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.89591093 * 1871; EvalErrorPrediction = 0.51950828 * 1871; time = 0.0883s; samplesPerSecond = 21183.1
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     0.11 seconds since last report (0.01 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 42.26k samplesPerSecond , throughputPerWorker = 21.13k samplesPerSecond
MPI Rank 0: 07/14/2016 12:43:42:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.82329729 * 1870; EvalErrorPrediction = 0.49786096 * 1870; time = 0.0914s; samplesPerSecond = 20459.5
MPI Rank 0: 07/14/2016 12:43:42:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.90156133 * 1899; EvalErrorPrediction = 0.52132701 * 1899; time = 0.0592s; samplesPerSecond = 32088.0
MPI Rank 0: 07/14/2016 12:43:42:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.86337821 * 1878; EvalErrorPrediction = 0.52396166 * 1878; time = 0.0414s; samplesPerSecond = 45402.9
MPI Rank 0: 07/14/2016 12:43:42:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.86676668 * 1221; EvalErrorPrediction = 0.51187551 * 1221; time = 0.0267s; samplesPerSecond = 45651.7
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     0.14 seconds since last report (0.00 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 42.59k samplesPerSecond , throughputPerWorker = 21.29k samplesPerSecond
MPI Rank 0: 07/14/2016 12:43:42: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84658042 * 20480; EvalErrorPrediction = 0.51123047 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 9.5367433e-08; epochTime=0.488849s
MPI Rank 0: 07/14/2016 12:43:42: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 12:43:42: learnRatePerSample reduced to 4.7683717e-08
MPI Rank 0: 07/14/2016 12:43:42: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:43:43: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:43:43: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 07/14/2016 12:43:43:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80074571 * 1897; EvalErrorPrediction = 0.49762783 * 1897; time = 0.0717s; samplesPerSecond = 26468.5
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.02 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     0.12 seconds since last report (0.01 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 40.92k samplesPerSecond , throughputPerWorker = 20.46k samplesPerSecond
MPI Rank 0: 07/14/2016 12:43:43:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86932568 * 1821; EvalErrorPrediction = 0.51345415 * 1821; time = 0.0942s; samplesPerSecond = 19329.2
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.05 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     0.11 seconds since last report (0.01 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 42.50k samplesPerSecond , throughputPerWorker = 21.25k samplesPerSecond
MPI Rank 0: 07/14/2016 12:43:43:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.89591323 * 1871; EvalErrorPrediction = 0.51950828 * 1871; time = 0.0881s; samplesPerSecond = 21244.0
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.07 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     0.11 seconds since last report (0.01 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 42.46k samplesPerSecond , throughputPerWorker = 21.23k samplesPerSecond
MPI Rank 0: 07/14/2016 12:43:43:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.82329983 * 1870; EvalErrorPrediction = 0.49786096 * 1870; time = 0.0912s; samplesPerSecond = 20499.2
MPI Rank 0: 07/14/2016 12:43:43:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.90156482 * 1899; EvalErrorPrediction = 0.52132701 * 1899; time = 0.0591s; samplesPerSecond = 32118.9
MPI Rank 0: 07/14/2016 12:43:43:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.86338231 * 1878; EvalErrorPrediction = 0.52396166 * 1878; time = 0.0409s; samplesPerSecond = 45930.3
MPI Rank 0: 07/14/2016 12:43:43:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.86676978 * 1221; EvalErrorPrediction = 0.51187551 * 1221; time = 0.0265s; samplesPerSecond = 46058.1
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.07 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     0.14 seconds since last report (0.00 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 42.95k samplesPerSecond , throughputPerWorker = 21.47k samplesPerSecond
MPI Rank 0: 07/14/2016 12:43:43: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84658239 * 20480; EvalErrorPrediction = 0.51123047 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 4.7683717e-08; epochTime=0.485186s
MPI Rank 0: 07/14/2016 12:43:43: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 12:43:43: learnRatePerSample reduced to 2.3841858e-08
MPI Rank 0: 07/14/2016 12:43:43: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:43:43: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:43:43: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 07/14/2016 12:43:43:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80074576 * 1897; EvalErrorPrediction = 0.49762783 * 1897; time = 0.0725s; samplesPerSecond = 26149.3
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.02 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     0.12 seconds since last report (0.01 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 40.60k samplesPerSecond , throughputPerWorker = 20.30k samplesPerSecond
MPI Rank 0: 07/14/2016 12:43:43:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86932620 * 1821; EvalErrorPrediction = 0.51345415 * 1821; time = 0.0944s; samplesPerSecond = 19292.1
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.05 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     0.12 seconds since last report (0.01 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 42.37k samplesPerSecond , throughputPerWorker = 21.19k samplesPerSecond
MPI Rank 0: 07/14/2016 12:43:43:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.89591438 * 1871; EvalErrorPrediction = 0.51950828 * 1871; time = 0.0889s; samplesPerSecond = 21035.7
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     0.12 seconds since last report (0.01 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 42.17k samplesPerSecond , throughputPerWorker = 21.09k samplesPerSecond
MPI Rank 0: 07/14/2016 12:43:44:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.82330109 * 1870; EvalErrorPrediction = 0.49786096 * 1870; time = 0.0914s; samplesPerSecond = 20451.5
MPI Rank 0: 07/14/2016 12:43:44:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.90156657 * 1899; EvalErrorPrediction = 0.52132701 * 1899; time = 0.0587s; samplesPerSecond = 32374.7
MPI Rank 0: 07/14/2016 12:43:44:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.86338436 * 1878; EvalErrorPrediction = 0.52449414 * 1878; time = 0.0410s; samplesPerSecond = 45857.4
MPI Rank 0: 07/14/2016 12:43:44:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.86677134 * 1221; EvalErrorPrediction = 0.51187551 * 1221; time = 0.0265s; samplesPerSecond = 46030.3
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     0.14 seconds since last report (0.00 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 42.96k samplesPerSecond , throughputPerWorker = 21.48k samplesPerSecond
MPI Rank 0: 07/14/2016 12:43:44: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84658338 * 20480; EvalErrorPrediction = 0.51127930 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 2.3841858e-08; epochTime=0.487214s
MPI Rank 0: 07/14/2016 12:43:44: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 12:43:44: learnRatePerSample reduced to 1.1920929e-08
MPI Rank 0: 07/14/2016 12:43:44: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:43:44: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:43:44: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 07/14/2016 12:43:44:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80074579 * 1897; EvalErrorPrediction = 0.49762783 * 1897; time = 0.0721s; samplesPerSecond = 26324.6
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.02 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     0.12 seconds since last report (0.01 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 40.65k samplesPerSecond , throughputPerWorker = 20.32k samplesPerSecond
MPI Rank 0: 07/14/2016 12:43:44:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86932646 * 1821; EvalErrorPrediction = 0.51345415 * 1821; time = 0.0947s; samplesPerSecond = 19232.4
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.05 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     0.12 seconds since last report (0.01 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 42.25k samplesPerSecond , throughputPerWorker = 21.12k samplesPerSecond
MPI Rank 0: 07/14/2016 12:43:44:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.89591496 * 1871; EvalErrorPrediction = 0.51950828 * 1871; time = 0.0885s; samplesPerSecond = 21133.4
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     0.11 seconds since last report (0.01 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 42.43k samplesPerSecond , throughputPerWorker = 21.21k samplesPerSecond
MPI Rank 0: 07/14/2016 12:43:44:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.82330173 * 1870; EvalErrorPrediction = 0.49786096 * 1870; time = 0.0915s; samplesPerSecond = 20443.4
MPI Rank 0: 07/14/2016 12:43:44:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.90156744 * 1899; EvalErrorPrediction = 0.52132701 * 1899; time = 0.0583s; samplesPerSecond = 32587.4
MPI Rank 0: 07/14/2016 12:43:44:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.86338539 * 1878; EvalErrorPrediction = 0.52449414 * 1878; time = 0.0414s; samplesPerSecond = 45383.1
MPI Rank 0: 07/14/2016 12:43:44:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.86677211 * 1221; EvalErrorPrediction = 0.51187551 * 1221; time = 0.0270s; samplesPerSecond = 45155.3
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     0.14 seconds since last report (0.00 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 42.71k samplesPerSecond , throughputPerWorker = 21.36k samplesPerSecond
MPI Rank 0: 07/14/2016 12:43:44: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84658387 * 20480; EvalErrorPrediction = 0.51127930 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 1.1920929e-08; epochTime=0.487499s
MPI Rank 0: 07/14/2016 12:43:44: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 12:43:44: learnRatePerSample reduced to 5.9604646e-09
MPI Rank 0: 07/14/2016 12:43:44: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:43:44: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:43:44: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 07/14/2016 12:43:45:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80074580 * 1897; EvalErrorPrediction = 0.49762783 * 1897; time = 0.0720s; samplesPerSecond = 26361.1
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.02 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     0.12 seconds since last report (0.01 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 40.84k samplesPerSecond , throughputPerWorker = 20.42k samplesPerSecond
MPI Rank 0: 07/14/2016 12:43:45:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86932659 * 1821; EvalErrorPrediction = 0.51345415 * 1821; time = 0.0941s; samplesPerSecond = 19344.1
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.05 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     0.11 seconds since last report (0.01 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 42.48k samplesPerSecond , throughputPerWorker = 21.24k samplesPerSecond
MPI Rank 0: 07/14/2016 12:43:45:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.89591525 * 1871; EvalErrorPrediction = 0.51950828 * 1871; time = 0.0884s; samplesPerSecond = 21162.5
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     0.12 seconds since last report (0.01 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 41.94k samplesPerSecond , throughputPerWorker = 20.97k samplesPerSecond
MPI Rank 0: 07/14/2016 12:43:45:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.82330204 * 1870; EvalErrorPrediction = 0.49786096 * 1870; time = 0.0923s; samplesPerSecond = 20254.5
MPI Rank 0: 07/14/2016 12:43:45:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.90156788 * 1899; EvalErrorPrediction = 0.52132701 * 1899; time = 0.0587s; samplesPerSecond = 32371.3
MPI Rank 0: 07/14/2016 12:43:45:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.86338590 * 1878; EvalErrorPrediction = 0.52449414 * 1878; time = 0.0409s; samplesPerSecond = 45928.1
MPI Rank 0: 07/14/2016 12:43:45:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.86677250 * 1221; EvalErrorPrediction = 0.51187551 * 1221; time = 0.0261s; samplesPerSecond = 46869.6
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     0.13 seconds since last report (0.00 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 43.18k samplesPerSecond , throughputPerWorker = 21.59k samplesPerSecond
MPI Rank 0: 07/14/2016 12:43:45: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84658412 * 20480; EvalErrorPrediction = 0.51127930 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 5.9604646e-09; epochTime=0.486143s
MPI Rank 0: 07/14/2016 12:43:45: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 12:43:45: learnRatePerSample reduced to 2.9802323e-09
MPI Rank 0: 07/14/2016 12:43:45: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:43:45: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:43:45: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 07/14/2016 12:43:45:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80074581 * 1897; EvalErrorPrediction = 0.49762783 * 1897; time = 0.0724s; samplesPerSecond = 26189.4
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.02 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     0.12 seconds since last report (0.01 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 40.63k samplesPerSecond , throughputPerWorker = 20.31k samplesPerSecond
MPI Rank 0: 07/14/2016 12:43:45:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86932665 * 1821; EvalErrorPrediction = 0.51345415 * 1821; time = 0.0944s; samplesPerSecond = 19293.9
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.05 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     0.11 seconds since last report (0.01 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 42.61k samplesPerSecond , throughputPerWorker = 21.31k samplesPerSecond
MPI Rank 0: 07/14/2016 12:43:45:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.89591539 * 1871; EvalErrorPrediction = 0.51950828 * 1871; time = 0.0878s; samplesPerSecond = 21302.8
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     0.11 seconds since last report (0.01 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 42.39k samplesPerSecond , throughputPerWorker = 21.19k samplesPerSecond
MPI Rank 0: 07/14/2016 12:43:45:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.82330220 * 1870; EvalErrorPrediction = 0.49786096 * 1870; time = 0.0913s; samplesPerSecond = 20479.9
MPI Rank 0: 07/14/2016 12:43:45:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.90156809 * 1899; EvalErrorPrediction = 0.52132701 * 1899; time = 0.0587s; samplesPerSecond = 32328.9
MPI Rank 0: 07/14/2016 12:43:46:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.86338616 * 1878; EvalErrorPrediction = 0.52449414 * 1878; time = 0.0409s; samplesPerSecond = 45913.5
MPI Rank 0: 07/14/2016 12:43:46:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.86677270 * 1221; EvalErrorPrediction = 0.51187551 * 1221; time = 0.0270s; samplesPerSecond = 45172.0
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     0.14 seconds since last report (0.00 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 42.74k samplesPerSecond , throughputPerWorker = 21.37k samplesPerSecond
MPI Rank 0: 07/14/2016 12:43:46: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84658424 * 20480; EvalErrorPrediction = 0.51127930 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 2.9802323e-09; epochTime=0.48659s
MPI Rank 0: 07/14/2016 12:43:46: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 12:43:46: learnRatePerSample reduced to 1.4901161e-09
MPI Rank 0: 07/14/2016 12:43:46: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:43:46: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:43:46: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 07/14/2016 12:43:46:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80074581 * 1897; EvalErrorPrediction = 0.49762783 * 1897; time = 0.0706s; samplesPerSecond = 26867.8
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     0.12 seconds since last report (0.01 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 40.85k samplesPerSecond , throughputPerWorker = 20.42k samplesPerSecond
MPI Rank 0: 07/14/2016 12:43:46:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86932668 * 1821; EvalErrorPrediction = 0.51345415 * 1821; time = 0.0960s; samplesPerSecond = 18977.3
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.05 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     0.11 seconds since last report (0.01 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 42.53k samplesPerSecond , throughputPerWorker = 21.27k samplesPerSecond
MPI Rank 0: 07/14/2016 12:43:46:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.89591546 * 1871; EvalErrorPrediction = 0.51950828 * 1871; time = 0.0878s; samplesPerSecond = 21319.0
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     0.11 seconds since last report (0.01 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 42.35k samplesPerSecond , throughputPerWorker = 21.18k samplesPerSecond
MPI Rank 0: 07/14/2016 12:43:46:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.82330228 * 1870; EvalErrorPrediction = 0.49786096 * 1870; time = 0.0912s; samplesPerSecond = 20497.6
MPI Rank 0: 07/14/2016 12:43:46:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.90156820 * 1899; EvalErrorPrediction = 0.52132701 * 1899; time = 0.0587s; samplesPerSecond = 32373.0
MPI Rank 0: 07/14/2016 12:43:46:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.86338629 * 1878; EvalErrorPrediction = 0.52449414 * 1878; time = 0.0409s; samplesPerSecond = 45888.8
MPI Rank 0: 07/14/2016 12:43:46:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.86677279 * 1221; EvalErrorPrediction = 0.51187551 * 1221; time = 0.0270s; samplesPerSecond = 45143.6
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     0.14 seconds since last report (0.00 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 42.77k samplesPerSecond , throughputPerWorker = 21.38k samplesPerSecond
MPI Rank 0: 07/14/2016 12:43:46: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84658431 * 20480; EvalErrorPrediction = 0.51127930 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 1.4901161e-09; epochTime=0.486174s
MPI Rank 0: 07/14/2016 12:43:46: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 12:43:46: learnRatePerSample reduced to 7.4505807e-10
MPI Rank 0: 07/14/2016 12:43:46: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 07/14/2016 12:43:46: Learn Rate Per Sample for Epoch[5] = 7.4505807e-10 is less than minLearnRate 9.9999997e-10. Training complete.
MPI Rank 0: 07/14/2016 12:43:46: CNTKCommandTrainEnd: speechTrain
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:43:46: Action "train" complete.
MPI Rank 0: 
MPI Rank 0: 07/14/2016 12:43:46: __COMPLETED__
MPI Rank 0: ~MPIWrapper
MPI Rank 1: 07/14/2016 12:43:28: -------------------------------------------------------------------
MPI Rank 1: 07/14/2016 12:43:28: Build info: 
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:43:28: 		Built time: Jul 14 2016 12:05:02
MPI Rank 1: 07/14/2016 12:43:28: 		Last modified date: Thu Jul 14 10:47:21 2016
MPI Rank 1: 07/14/2016 12:43:28: 		Build type: release
MPI Rank 1: 07/14/2016 12:43:28: 		Build target: GPU
MPI Rank 1: 07/14/2016 12:43:28: 		With 1bit-SGD: yes
MPI Rank 1: 07/14/2016 12:43:28: 		Math lib: mkl
MPI Rank 1: 07/14/2016 12:43:28: 		CUDA_PATH: /usr/local/cuda-7.5
MPI Rank 1: 07/14/2016 12:43:28: 		CUB_PATH: /usr/local/cub-1.4.1
MPI Rank 1: 07/14/2016 12:43:28: 		CUDNN_PATH: /usr/local/cudnn-4.0
MPI Rank 1: 07/14/2016 12:43:28: 		Build Branch: HEAD
MPI Rank 1: 07/14/2016 12:43:28: 		Build SHA1: 72bee394bf461e8f6f0feb593a8416c05f481957
MPI Rank 1: 07/14/2016 12:43:28: 		Built by philly on a77bf6d98305
MPI Rank 1: 07/14/2016 12:43:28: 		Build Path: /home/philly/jenkins/workspace/CNTK-Build-Linux
MPI Rank 1: 07/14/2016 12:43:28: -------------------------------------------------------------------
MPI Rank 1: 07/14/2016 12:43:29: -------------------------------------------------------------------
MPI Rank 1: 07/14/2016 12:43:29: GPU info:
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:43:29: 		Device[0]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3071 MB
MPI Rank 1: 07/14/2016 12:43:29: 		Device[1]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3071 MB
MPI Rank 1: 07/14/2016 12:43:29: 		Device[2]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3071 MB
MPI Rank 1: 07/14/2016 12:43:29: 		Device[3]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3071 MB
MPI Rank 1: 07/14/2016 12:43:29: -------------------------------------------------------------------
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:43:29: Running on localhost at 2016/07/14 12:43:29
MPI Rank 1: 07/14/2016 12:43:29: Command line: 
MPI Rank 1: /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/build/1bitsgd/release/bin/cntk  configFile=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/ParallelBM/../ParallelBM/cntk.cntk  currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data  RunDir=/tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_gpu  DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data  ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/ParallelBM/..  OutputDir=/tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_gpu  DeviceId=0  timestamping=true  numCPUThreads=12  precision=double  speechTrain=[SGD=[ParallelTrain=[parallelizationStartEpoch=2]]]  stderr=/tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_gpu/stderr
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:43:29: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
MPI Rank 1: 07/14/2016 12:43:29: precision = "float"
MPI Rank 1: command = speechTrain
MPI Rank 1: deviceId = $DeviceId$
MPI Rank 1: parallelTrain = true
MPI Rank 1: speechTrain = [
MPI Rank 1:     action = "train"
MPI Rank 1:     modelPath = "$RunDir$/models/cntkSpeech.dnn"
MPI Rank 1:     deviceId = $DeviceId$
MPI Rank 1:     traceLevel = 1
MPI Rank 1:     SimpleNetworkBuilder = [
MPI Rank 1:         layerSizes = 363:512:512:132
MPI Rank 1:         trainingCriterion = "CrossEntropyWithSoftmax"
MPI Rank 1:         evalCriterion = "ErrorPrediction"
MPI Rank 1:         layerTypes = "Sigmoid"
MPI Rank 1:         initValueScale = 1.0
MPI Rank 1:         applyMeanVarNorm = true
MPI Rank 1:         uniformInit = true
MPI Rank 1:         needPrior = true
MPI Rank 1:     ]
MPI Rank 1:     ExperimentalNetworkBuilder = [    // the same as above but with BS. Not active; activate by commenting out the SimpleNetworkBuilder entry above
MPI Rank 1:         layerSizes = 363:512:512:132
MPI Rank 1:         trainingCriterion = 'CE'
MPI Rank 1:         evalCriterion = 'Err'
MPI Rank 1:         applyMeanVarNorm = true
MPI Rank 1:         L = Length(layerSizes)-1    // number of model layers
MPI Rank 1:         features = Input(layerSizes[0], 1, tag='feature') ; labels = Input(layerSizes[Length(layerSizes)-1], 1, tag='label')
MPI Rank 1:         featNorm = if applyMeanVarNorm
MPI Rank 1:                    then MeanVarNorm(features)
MPI Rank 1:                    else features
MPI Rank 1:         layers[layer:1..L-1] = if layer > 1
MPI Rank 1:                                then SBFF(layers[layer-1].Eh, layerSizes[layer], layerSizes[layer-1])
MPI Rank 1:                                else SBFF(featNorm, layerSizes[layer], layerSizes[layer-1])
MPI Rank 1:         outLayer = BFF(layers[L-1].Eh, layerSizes[L], layerSizes[L-1])
MPI Rank 1:         outZ = outLayer.z        // + PastValue(layerSizes[L], 1, outLayer.z)
MPI Rank 1:         CE = if trainingCriterion == 'CE'
MPI Rank 1:              then CrossEntropyWithSoftmax(labels, outZ, tag='criterion')
MPI Rank 1:              else Fail('unknown trainingCriterion ' + trainingCriterion)
MPI Rank 1:         Err = if evalCriterion == 'Err' then
MPI Rank 1:               ErrorPrediction(labels, outZ, tag='evaluation')
MPI Rank 1:               else Fail('unknown evalCriterion ' + evalCriterion)
MPI Rank 1:         logPrior = LogPrior(labels)
MPI Rank 1:         // TODO: how to add a tag to an infix operation?
MPI Rank 1:         ScaledLogLikelihood = Minus (outZ, logPrior, tag='output')
MPI Rank 1:     ]
MPI Rank 1:     SGD = [
MPI Rank 1:         epochSize = 20480
MPI Rank 1:         minibatchSize = 64:256:1024
MPI Rank 1:         learningRatesPerMB = 1.0:0.5:0.1
MPI Rank 1:         numMBsToShowResult = 3
MPI Rank 1:         momentumPerMB = 0.9:0.656119
MPI Rank 1:         dropoutRate = 0.0
MPI Rank 1:         maxEpochs = 5
MPI Rank 1:         keepCheckPointFiles = true
MPI Rank 1:         clippingThresholdPerSample = 1#INF
MPI Rank 1:         ParallelTrain = [
MPI Rank 1:             parallelizationMethod = "BlockMomentumSGD"
MPI Rank 1:             distributedMBReading = true
MPI Rank 1:             syncPerfStats=1
MPI Rank 1:             BlockMomentumSGD = [
MPI Rank 1:                 blockSizePerWorker=2048
MPI Rank 1:                 resetSGDMomentum=true
MPI Rank 1:                 useNesterovMomentum=true
MPI Rank 1:             ]
MPI Rank 1:         ]
MPI Rank 1:         AutoAdjust = [
MPI Rank 1:             reduceLearnRateIfImproveLessThan = 0
MPI Rank 1:             loadBestModel = true
MPI Rank 1:             increaseLearnRateIfImproveMoreThan = 1000000000
MPI Rank 1:             learnRateDecreaseFactor = 0.5
MPI Rank 1:             learnRateIncreaseFactor = 1.382
MPI Rank 1:             autoAdjustLR = "adjustAfterEpoch"
MPI Rank 1:         ]
MPI Rank 1:     ]
MPI Rank 1:     reader = [
MPI Rank 1:         readerType = "HTKMLFReader"
MPI Rank 1:         readMethod = "blockRandomize"
MPI Rank 1:         miniBatchMode = "partial"
MPI Rank 1:         randomize = "auto"
MPI Rank 1:         verbosity = 0
MPI Rank 1:         features = [
MPI Rank 1:             dim = 363
MPI Rank 1:             type = "real"
MPI Rank 1:             scpFile = "glob_0000.scp"
MPI Rank 1:         ]
MPI Rank 1:         labels = [
MPI Rank 1:             mlfFile = "$DataDir$/glob_0000.mlf"
MPI Rank 1:             labelMappingFile = "$DataDir$/state.list"
MPI Rank 1:             labelDim = 132
MPI Rank 1:             labelType = "category"
MPI Rank 1:         ]
MPI Rank 1:     ]
MPI Rank 1: ]
MPI Rank 1: currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
MPI Rank 1: RunDir=/tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_gpu
MPI Rank 1: DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
MPI Rank 1: ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/ParallelBM/..
MPI Rank 1: OutputDir=/tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_gpu
MPI Rank 1: DeviceId=0
MPI Rank 1: timestamping=true
MPI Rank 1: numCPUThreads=12
MPI Rank 1: precision=double
MPI Rank 1: speechTrain=[SGD=[ParallelTrain=[parallelizationStartEpoch=2]]]
MPI Rank 1: stderr=/tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_gpu/stderr
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:43:29: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:43:29: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 1: 07/14/2016 12:43:29: precision = "float"
MPI Rank 1: command = speechTrain
MPI Rank 1: deviceId = 0
MPI Rank 1: parallelTrain = true
MPI Rank 1: speechTrain = [
MPI Rank 1:     action = "train"
MPI Rank 1:     modelPath = "/tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn"
MPI Rank 1:     deviceId = 0
MPI Rank 1:     traceLevel = 1
MPI Rank 1:     SimpleNetworkBuilder = [
MPI Rank 1:         layerSizes = 363:512:512:132
MPI Rank 1:         trainingCriterion = "CrossEntropyWithSoftmax"
MPI Rank 1:         evalCriterion = "ErrorPrediction"
MPI Rank 1:         layerTypes = "Sigmoid"
MPI Rank 1:         initValueScale = 1.0
MPI Rank 1:         applyMeanVarNorm = true
MPI Rank 1:         uniformInit = true
MPI Rank 1:         needPrior = true
MPI Rank 1:     ]
MPI Rank 1:     ExperimentalNetworkBuilder = [    // the same as above but with BS. Not active; activate by commenting out the SimpleNetworkBuilder entry above
MPI Rank 1:         layerSizes = 363:512:512:132
MPI Rank 1:         trainingCriterion = 'CE'
MPI Rank 1:         evalCriterion = 'Err'
MPI Rank 1:         applyMeanVarNorm = true
MPI Rank 1:         L = Length(layerSizes)-1    // number of model layers
MPI Rank 1:         features = Input(layerSizes[0], 1, tag='feature') ; labels = Input(layerSizes[Length(layerSizes)-1], 1, tag='label')
MPI Rank 1:         featNorm = if applyMeanVarNorm
MPI Rank 1:                    then MeanVarNorm(features)
MPI Rank 1:                    else features
MPI Rank 1:         layers[layer:1..L-1] = if layer > 1
MPI Rank 1:                                then SBFF(layers[layer-1].Eh, layerSizes[layer], layerSizes[layer-1])
MPI Rank 1:                                else SBFF(featNorm, layerSizes[layer], layerSizes[layer-1])
MPI Rank 1:         outLayer = BFF(layers[L-1].Eh, layerSizes[L], layerSizes[L-1])
MPI Rank 1:         outZ = outLayer.z        // + PastValue(layerSizes[L], 1, outLayer.z)
MPI Rank 1:         CE = if trainingCriterion == 'CE'
MPI Rank 1:              then CrossEntropyWithSoftmax(labels, outZ, tag='criterion')
MPI Rank 1:              else Fail('unknown trainingCriterion ' + trainingCriterion)
MPI Rank 1:         Err = if evalCriterion == 'Err' then
MPI Rank 1:               ErrorPrediction(labels, outZ, tag='evaluation')
MPI Rank 1:               else Fail('unknown evalCriterion ' + evalCriterion)
MPI Rank 1:         logPrior = LogPrior(labels)
MPI Rank 1:         // TODO: how to add a tag to an infix operation?
MPI Rank 1:         ScaledLogLikelihood = Minus (outZ, logPrior, tag='output')
MPI Rank 1:     ]
MPI Rank 1:     SGD = [
MPI Rank 1:         epochSize = 20480
MPI Rank 1:         minibatchSize = 64:256:1024
MPI Rank 1:         learningRatesPerMB = 1.0:0.5:0.1
MPI Rank 1:         numMBsToShowResult = 3
MPI Rank 1:         momentumPerMB = 0.9:0.656119
MPI Rank 1:         dropoutRate = 0.0
MPI Rank 1:         maxEpochs = 5
MPI Rank 1:         keepCheckPointFiles = true
MPI Rank 1:         clippingThresholdPerSample = 1#INF
MPI Rank 1:         ParallelTrain = [
MPI Rank 1:             parallelizationMethod = "BlockMomentumSGD"
MPI Rank 1:             distributedMBReading = true
MPI Rank 1:             syncPerfStats=1
MPI Rank 1:             BlockMomentumSGD = [
MPI Rank 1:                 blockSizePerWorker=2048
MPI Rank 1:                 resetSGDMomentum=true
MPI Rank 1:                 useNesterovMomentum=true
MPI Rank 1:             ]
MPI Rank 1:         ]
MPI Rank 1:         AutoAdjust = [
MPI Rank 1:             reduceLearnRateIfImproveLessThan = 0
MPI Rank 1:             loadBestModel = true
MPI Rank 1:             increaseLearnRateIfImproveMoreThan = 1000000000
MPI Rank 1:             learnRateDecreaseFactor = 0.5
MPI Rank 1:             learnRateIncreaseFactor = 1.382
MPI Rank 1:             autoAdjustLR = "adjustAfterEpoch"
MPI Rank 1:         ]
MPI Rank 1:     ]
MPI Rank 1:     reader = [
MPI Rank 1:         readerType = "HTKMLFReader"
MPI Rank 1:         readMethod = "blockRandomize"
MPI Rank 1:         miniBatchMode = "partial"
MPI Rank 1:         randomize = "auto"
MPI Rank 1:         verbosity = 0
MPI Rank 1:         features = [
MPI Rank 1:             dim = 363
MPI Rank 1:             type = "real"
MPI Rank 1:             scpFile = "glob_0000.scp"
MPI Rank 1:         ]
MPI Rank 1:         labels = [
MPI Rank 1:             mlfFile = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/glob_0000.mlf"
MPI Rank 1:             labelMappingFile = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/state.list"
MPI Rank 1:             labelDim = 132
MPI Rank 1:             labelType = "category"
MPI Rank 1:         ]
MPI Rank 1:     ]
MPI Rank 1: ]
MPI Rank 1: currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
MPI Rank 1: RunDir=/tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_gpu
MPI Rank 1: DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
MPI Rank 1: ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/ParallelBM/..
MPI Rank 1: OutputDir=/tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_gpu
MPI Rank 1: DeviceId=0
MPI Rank 1: timestamping=true
MPI Rank 1: numCPUThreads=12
MPI Rank 1: precision=double
MPI Rank 1: speechTrain=[SGD=[ParallelTrain=[parallelizationStartEpoch=2]]]
MPI Rank 1: stderr=/tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_gpu/stderr
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:43:29: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:43:29: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 1: configparameters: cntk.cntk:command=speechTrain
MPI Rank 1: configparameters: cntk.cntk:ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/ParallelBM/..
MPI Rank 1: configparameters: cntk.cntk:currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
MPI Rank 1: configparameters: cntk.cntk:DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
MPI Rank 1: configparameters: cntk.cntk:deviceId=0
MPI Rank 1: configparameters: cntk.cntk:numCPUThreads=12
MPI Rank 1: configparameters: cntk.cntk:OutputDir=/tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_gpu
MPI Rank 1: configparameters: cntk.cntk:parallelTrain=true
MPI Rank 1: configparameters: cntk.cntk:precision=double
MPI Rank 1: configparameters: cntk.cntk:RunDir=/tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_gpu
MPI Rank 1: configparameters: cntk.cntk:speechTrain=[
MPI Rank 1:     action = "train"
MPI Rank 1:     modelPath = "/tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn"
MPI Rank 1:     deviceId = 0
MPI Rank 1:     traceLevel = 1
MPI Rank 1:     SimpleNetworkBuilder = [
MPI Rank 1:         layerSizes = 363:512:512:132
MPI Rank 1:         trainingCriterion = "CrossEntropyWithSoftmax"
MPI Rank 1:         evalCriterion = "ErrorPrediction"
MPI Rank 1:         layerTypes = "Sigmoid"
MPI Rank 1:         initValueScale = 1.0
MPI Rank 1:         applyMeanVarNorm = true
MPI Rank 1:         uniformInit = true
MPI Rank 1:         needPrior = true
MPI Rank 1:     ]
MPI Rank 1:     ExperimentalNetworkBuilder = [    // the same as above but with BS. Not active; activate by commenting out the SimpleNetworkBuilder entry above
MPI Rank 1:         layerSizes = 363:512:512:132
MPI Rank 1:         trainingCriterion = 'CE'
MPI Rank 1:         evalCriterion = 'Err'
MPI Rank 1:         applyMeanVarNorm = true
MPI Rank 1:         L = Length(layerSizes)-1    // number of model layers
MPI Rank 1:         features = Input(layerSizes[0], 1, tag='feature') ; labels = Input(layerSizes[Length(layerSizes)-1], 1, tag='label')
MPI Rank 1:         featNorm = if applyMeanVarNorm
MPI Rank 1:                    then MeanVarNorm(features)
MPI Rank 1:                    else features
MPI Rank 1:         layers[layer:1..L-1] = if layer > 1
MPI Rank 1:                                then SBFF(layers[layer-1].Eh, layerSizes[layer], layerSizes[layer-1])
MPI Rank 1:                                else SBFF(featNorm, layerSizes[layer], layerSizes[layer-1])
MPI Rank 1:         outLayer = BFF(layers[L-1].Eh, layerSizes[L], layerSizes[L-1])
MPI Rank 1:         outZ = outLayer.z        // + PastValue(layerSizes[L], 1, outLayer.z)
MPI Rank 1:         CE = if trainingCriterion == 'CE'
MPI Rank 1:              then CrossEntropyWithSoftmax(labels, outZ, tag='criterion')
MPI Rank 1:              else Fail('unknown trainingCriterion ' + trainingCriterion)
MPI Rank 1:         Err = if evalCriterion == 'Err' then
MPI Rank 1:               ErrorPrediction(labels, outZ, tag='evaluation')
MPI Rank 1:               else Fail('unknown evalCriterion ' + evalCriterion)
MPI Rank 1:         logPrior = LogPrior(labels)
MPI Rank 1:         // TODO: how to add a tag to an infix operation?
MPI Rank 1:         ScaledLogLikelihood = Minus (outZ, logPrior, tag='output')
MPI Rank 1:     ]
MPI Rank 1:     SGD = [
MPI Rank 1:         epochSize = 20480
MPI Rank 1:         minibatchSize = 64:256:1024
MPI Rank 1:         learningRatesPerMB = 1.0:0.5:0.1
MPI Rank 1:         numMBsToShowResult = 3
MPI Rank 1:         momentumPerMB = 0.9:0.656119
MPI Rank 1:         dropoutRate = 0.0
MPI Rank 1:         maxEpochs = 5
MPI Rank 1:         keepCheckPointFiles = true
MPI Rank 1:         clippingThresholdPerSample = 1#INF
MPI Rank 1:         ParallelTrain = [
MPI Rank 1:             parallelizationMethod = "BlockMomentumSGD"
MPI Rank 1:             distributedMBReading = true
MPI Rank 1:             syncPerfStats=1
MPI Rank 1:             BlockMomentumSGD = [
MPI Rank 1:                 blockSizePerWorker=2048
MPI Rank 1:                 resetSGDMomentum=true
MPI Rank 1:                 useNesterovMomentum=true
MPI Rank 1:             ]
MPI Rank 1:         ]
MPI Rank 1:         AutoAdjust = [
MPI Rank 1:             reduceLearnRateIfImproveLessThan = 0
MPI Rank 1:             loadBestModel = true
MPI Rank 1:             increaseLearnRateIfImproveMoreThan = 1000000000
MPI Rank 1:             learnRateDecreaseFactor = 0.5
MPI Rank 1:             learnRateIncreaseFactor = 1.382
MPI Rank 1:             autoAdjustLR = "adjustAfterEpoch"
MPI Rank 1:         ]
MPI Rank 1:     ]
MPI Rank 1:     reader = [
MPI Rank 1:         readerType = "HTKMLFReader"
MPI Rank 1:         readMethod = "blockRandomize"
MPI Rank 1:         miniBatchMode = "partial"
MPI Rank 1:         randomize = "auto"
MPI Rank 1:         verbosity = 0
MPI Rank 1:         features = [
MPI Rank 1:             dim = 363
MPI Rank 1:             type = "real"
MPI Rank 1:             scpFile = "glob_0000.scp"
MPI Rank 1:         ]
MPI Rank 1:         labels = [
MPI Rank 1:             mlfFile = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/glob_0000.mlf"
MPI Rank 1:             labelMappingFile = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/state.list"
MPI Rank 1:             labelDim = 132
MPI Rank 1:             labelType = "category"
MPI Rank 1:         ]
MPI Rank 1:     ]
MPI Rank 1: ] [SGD=[ParallelTrain=[parallelizationStartEpoch=2]]]
MPI Rank 1: 
MPI Rank 1: configparameters: cntk.cntk:stderr=/tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_gpu/stderr
MPI Rank 1: configparameters: cntk.cntk:timestamping=true
MPI Rank 1: 07/14/2016 12:43:29: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 1: 07/14/2016 12:43:29: Commands: speechTrain
MPI Rank 1: 07/14/2016 12:43:29: Precision = "double"
MPI Rank 1: 07/14/2016 12:43:29: Using 12 CPU threads.
MPI Rank 1: 07/14/2016 12:43:29: CNTKModelPath: /tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn
MPI Rank 1: 07/14/2016 12:43:29: CNTKCommandTrainInfo: speechTrain : 5
MPI Rank 1: 07/14/2016 12:43:29: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 5
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:43:29: ##############################################################################
MPI Rank 1: 07/14/2016 12:43:29: #                                                                            #
MPI Rank 1: 07/14/2016 12:43:29: # Action "train"                                                             #
MPI Rank 1: 07/14/2016 12:43:29: #                                                                            #
MPI Rank 1: 07/14/2016 12:43:29: ##############################################################################
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:43:29: CNTKCommandTrainBegin: speechTrain
MPI Rank 1: SimpleNetworkBuilder Using GPU 0
MPI Rank 1: reading script file glob_0000.scp ... 948 entries
MPI Rank 1: total 132 state names in state list /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/state.list
MPI Rank 1: htkmlfreader: reading MLF file /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/glob_0000.mlf ... total 948 entries
MPI Rank 1: ...............................................................................................feature set 0: 252734 frames in 948 out of 948 utterances
MPI Rank 1: label set 0: 129 classes
MPI Rank 1: minibatchutterancesource: 948 utterances grouped into 3 chunks, av. chunk size: 316.0 utterances, 84244.7 frames
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:43:29: Creating virgin network.
MPI Rank 1: SetUniformRandomValue (GPU): creating curand object with seed 1, sizeof(ElemType)==8
MPI Rank 1: 
MPI Rank 1: Post-processing network...
MPI Rank 1: 
MPI Rank 1: 7 roots:
MPI Rank 1: 	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
MPI Rank 1: 	EvalErrorPrediction = ErrorPrediction()
MPI Rank 1: 	InvStdOfFeatures = InvStdDev()
MPI Rank 1: 	MeanOfFeatures = Mean()
MPI Rank 1: 	PosteriorProb = Softmax()
MPI Rank 1: 	Prior = Mean()
MPI Rank 1: 	ScaledLogLikelihood = Minus()
MPI Rank 1: 
MPI Rank 1: Validating network. 25 nodes to process in pass 1.
MPI Rank 1: 
MPI Rank 1: Validating --> labels = InputValue() :  -> [132 x *]
MPI Rank 1: Validating --> W2 = LearnableParameter() :  -> [132 x 512]
MPI Rank 1: Validating --> W1 = LearnableParameter() :  -> [512 x 512]
MPI Rank 1: Validating --> W0 = LearnableParameter() :  -> [512 x 363]
MPI Rank 1: Validating --> features = InputValue() :  -> [363 x *]
MPI Rank 1: Validating --> MeanOfFeatures = Mean (features) : [363 x *] -> [363]
MPI Rank 1: Validating --> InvStdOfFeatures = InvStdDev (features) : [363 x *] -> [363]
MPI Rank 1: Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [363 x *], [363], [363] -> [363 x *]
MPI Rank 1: Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [512 x 363], [363 x *] -> [512 x *]
MPI Rank 1: Validating --> B0 = LearnableParameter() :  -> [512 x 1]
MPI Rank 1: Validating --> W0*features+B0 = Plus (W0*features, B0) : [512 x *], [512 x 1] -> [512 x 1 x *]
MPI Rank 1: Validating --> H1 = Sigmoid (W0*features+B0) : [512 x 1 x *] -> [512 x 1 x *]
MPI Rank 1: Validating --> W1*H1 = Times (W1, H1) : [512 x 512], [512 x 1 x *] -> [512 x 1 x *]
MPI Rank 1: Validating --> B1 = LearnableParameter() :  -> [512 x 1]
MPI Rank 1: Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [512 x 1 x *], [512 x 1] -> [512 x 1 x *]
MPI Rank 1: Validating --> H2 = Sigmoid (W1*H1+B1) : [512 x 1 x *] -> [512 x 1 x *]
MPI Rank 1: Validating --> W2*H1 = Times (W2, H2) : [132 x 512], [512 x 1 x *] -> [132 x 1 x *]
MPI Rank 1: Validating --> B2 = LearnableParameter() :  -> [132 x 1]
MPI Rank 1: Validating --> HLast = Plus (W2*H1, B2) : [132 x 1 x *], [132 x 1] -> [132 x 1 x *]
MPI Rank 1: Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [132 x *], [132 x 1 x *] -> [1]
MPI Rank 1: Validating --> EvalErrorPrediction = ErrorPrediction (labels, HLast) : [132 x *], [132 x 1 x *] -> [1]
MPI Rank 1: Validating --> PosteriorProb = Softmax (HLast) : [132 x 1 x *] -> [132 x 1 x *]
MPI Rank 1: Validating --> Prior = Mean (labels) : [132 x *] -> [132]
MPI Rank 1: Validating --> LogOfPrior = Log (Prior) : [132] -> [132]
MPI Rank 1: Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [132 x 1 x *], [132] -> [132 x 1 x *]
MPI Rank 1: 
MPI Rank 1: Validating network. 17 nodes to process in pass 2.
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: Validating network, final pass.
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: 12 out of 25 nodes do not share the minibatch layout with the input data.
MPI Rank 1: 
MPI Rank 1: Post-processing network complete.
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:43:29: Created model with 25 nodes on GPU 0.
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:43:29: Training criterion node(s):
MPI Rank 1: 07/14/2016 12:43:29: 	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:43:29: Evaluation criterion node(s):
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:43:29: 	EvalErrorPrediction = ErrorPrediction
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: Allocating matrices for forward and/or backward propagation.
MPI Rank 1: 
MPI Rank 1: Memory Sharing Structure:
MPI Rank 1: 
MPI Rank 1: (nil): {[EvalErrorPrediction Gradient[1]] [InvStdOfFeatures Gradient[363]] [LogOfPrior Gradient[132]] [MVNormalizedFeatures Gradient[363 x *]] [MeanOfFeatures Gradient[363]] [PosteriorProb Gradient[132 x 1 x *]] [PosteriorProb Value[132 x 1 x *]] [Prior Gradient[132]] [ScaledLogLikelihood Gradient[132 x 1 x *]] [features Gradient[363 x *]] [labels Gradient[132 x *]] }
MPI Rank 1: 0x2a39a78: {[features Value[363 x *]] }
MPI Rank 1: 0x32cb8f8: {[MeanOfFeatures Value[363]] }
MPI Rank 1: 0x32cbd98: {[InvStdOfFeatures Value[363]] }
MPI Rank 1: 0x32ccac8: {[W0 Value[512 x 363]] }
MPI Rank 1: 0x3839e68: {[labels Value[132 x *]] }
MPI Rank 1: 0x383b0c8: {[Prior Value[132]] }
MPI Rank 1: 0x3840968: {[EvalErrorPrediction Value[1]] }
MPI Rank 1: 0x3840c68: {[ScaledLogLikelihood Value[132 x 1 x *]] }
MPI Rank 1: 0x3840e28: {[CrossEntropyWithSoftmax Value[1]] }
MPI Rank 1: 0x38412b8: {[W0 Gradient[512 x 363]] [W0*features+B0 Value[512 x 1 x *]] }
MPI Rank 1: 0x3841428: {[LogOfPrior Value[132]] }
MPI Rank 1: 0x3842fc8: {[B0 Value[512 x 1]] }
MPI Rank 1: 0x3845138: {[W1 Value[512 x 512]] }
MPI Rank 1: 0x3845f08: {[B1 Value[512 x 1]] }
MPI Rank 1: 0x38470a8: {[W2 Value[132 x 512]] }
MPI Rank 1: 0x3847af8: {[B2 Value[132 x 1]] }
MPI Rank 1: 0x3b22b78: {[MVNormalizedFeatures Value[363 x *]] }
MPI Rank 1: 0x3b23338: {[W0*features Value[512 x *]] }
MPI Rank 1: 0x3b23548: {[H1 Value[512 x 1 x *]] [W0*features Gradient[512 x *]] }
MPI Rank 1: 0x3b236a8: {[W0*features+B0 Gradient[512 x 1 x *]] [W1*H1 Value[512 x 1 x *]] }
MPI Rank 1: 0x3b23808: {[W1 Gradient[512 x 512]] [W1*H1+B1 Value[512 x 1 x *]] }
MPI Rank 1: 0x3b239c8: {[H2 Value[512 x 1 x *]] [W1*H1 Gradient[512 x 1 x *]] }
MPI Rank 1: 0x3b23b88: {[B0 Gradient[512 x 1]] [H1 Gradient[512 x 1 x *]] [W1*H1+B1 Gradient[512 x 1 x *]] [W2*H1 Value[132 x 1 x *]] }
MPI Rank 1: 0x3b23d48: {[HLast Value[132 x 1 x *]] [W2 Gradient[132 x 512]] }
MPI Rank 1: 0x3b248a8: {[CrossEntropyWithSoftmax Gradient[1]] }
MPI Rank 1: 0x3b24a68: {[B1 Gradient[512 x 1]] [H2 Gradient[512 x 1 x *]] [HLast Gradient[132 x 1 x *]] }
MPI Rank 1: 0x3b24c28: {[W2*H1 Gradient[132 x 1 x *]] }
MPI Rank 1: 0x3b24de8: {[B2 Gradient[132 x 1]] }
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:43:29: Precomputing --> 3 PreCompute nodes found.
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:43:29: 	MeanOfFeatures = Mean()
MPI Rank 1: 07/14/2016 12:43:29: 	InvStdOfFeatures = InvStdDev()
MPI Rank 1: 07/14/2016 12:43:29: 	Prior = Mean()
MPI Rank 1: minibatchiterator: epoch 0: frames [0..252734] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
MPI Rank 1: requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:43:31: Precomputing --> Completed.
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:43:31: Starting Epoch 1: learning rate per sample = 0.015625  effective momentum = 0.900000  momentum as time constant = 607.4 samples
MPI Rank 1: minibatchiterator: epoch 0: frames [0..20480] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:43:31: Starting minibatch loop.
MPI Rank 1: 07/14/2016 12:43:31:  Epoch[ 1 of 5]-Minibatch[   1-   3, 0.94%]: CrossEntropyWithSoftmax = 4.57947979 * 192; EvalErrorPrediction = 0.96354167 * 192; time = 0.0199s; samplesPerSecond = 9627.0
MPI Rank 1: 07/14/2016 12:43:31:  Epoch[ 1 of 5]-Minibatch[   4-   6, 1.88%]: CrossEntropyWithSoftmax = 4.45832105 * 192; EvalErrorPrediction = 0.90104167 * 192; time = 0.0184s; samplesPerSecond = 10407.1
MPI Rank 1: 07/14/2016 12:43:31:  Epoch[ 1 of 5]-Minibatch[   7-   9, 2.81%]: CrossEntropyWithSoftmax = 4.29176856 * 192; EvalErrorPrediction = 0.85416667 * 192; time = 0.0185s; samplesPerSecond = 10393.0
MPI Rank 1: 07/14/2016 12:43:31:  Epoch[ 1 of 5]-Minibatch[  10-  12, 3.75%]: CrossEntropyWithSoftmax = 4.15840784 * 192; EvalErrorPrediction = 0.86979167 * 192; time = 0.0185s; samplesPerSecond = 10393.0
MPI Rank 1: 07/14/2016 12:43:31:  Epoch[ 1 of 5]-Minibatch[  13-  15, 4.69%]: CrossEntropyWithSoftmax = 4.21435783 * 192; EvalErrorPrediction = 0.86979167 * 192; time = 0.0185s; samplesPerSecond = 10391.9
MPI Rank 1: 07/14/2016 12:43:31:  Epoch[ 1 of 5]-Minibatch[  16-  18, 5.62%]: CrossEntropyWithSoftmax = 4.14020622 * 192; EvalErrorPrediction = 0.89583333 * 192; time = 0.0185s; samplesPerSecond = 10399.2
MPI Rank 1: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[  19-  21, 6.56%]: CrossEntropyWithSoftmax = 4.04069876 * 192; EvalErrorPrediction = 0.85416667 * 192; time = 0.0185s; samplesPerSecond = 10351.5
MPI Rank 1: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[  22-  24, 7.50%]: CrossEntropyWithSoftmax = 4.04991414 * 192; EvalErrorPrediction = 0.91666667 * 192; time = 0.0185s; samplesPerSecond = 10378.9
MPI Rank 1: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[  25-  27, 8.44%]: CrossEntropyWithSoftmax = 3.88626656 * 192; EvalErrorPrediction = 0.84375000 * 192; time = 0.0184s; samplesPerSecond = 10408.2
MPI Rank 1: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[  28-  30, 9.38%]: CrossEntropyWithSoftmax = 4.00467833 * 192; EvalErrorPrediction = 0.88020833 * 192; time = 0.0185s; samplesPerSecond = 10396.4
MPI Rank 1: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[  31-  33, 10.31%]: CrossEntropyWithSoftmax = 3.94077029 * 192; EvalErrorPrediction = 0.86458333 * 192; time = 0.0185s; samplesPerSecond = 10393.5
MPI Rank 1: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[  34-  36, 11.25%]: CrossEntropyWithSoftmax = 3.78326806 * 192; EvalErrorPrediction = 0.89062500 * 192; time = 0.0185s; samplesPerSecond = 10392.4
MPI Rank 1: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[  37-  39, 12.19%]: CrossEntropyWithSoftmax = 3.94698521 * 192; EvalErrorPrediction = 0.89062500 * 192; time = 0.0185s; samplesPerSecond = 10396.9
MPI Rank 1: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[  40-  42, 13.12%]: CrossEntropyWithSoftmax = 3.66011602 * 192; EvalErrorPrediction = 0.84895833 * 192; time = 0.0185s; samplesPerSecond = 10401.4
MPI Rank 1: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[  43-  45, 14.06%]: CrossEntropyWithSoftmax = 3.98797978 * 192; EvalErrorPrediction = 0.91666667 * 192; time = 0.0185s; samplesPerSecond = 10395.2
MPI Rank 1: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[  46-  48, 15.00%]: CrossEntropyWithSoftmax = 3.76297655 * 192; EvalErrorPrediction = 0.87500000 * 192; time = 0.0185s; samplesPerSecond = 10380.6
MPI Rank 1: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[  49-  51, 15.94%]: CrossEntropyWithSoftmax = 3.69909670 * 192; EvalErrorPrediction = 0.89062500 * 192; time = 0.0185s; samplesPerSecond = 10393.0
MPI Rank 1: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[  52-  54, 16.88%]: CrossEntropyWithSoftmax = 3.83747989 * 192; EvalErrorPrediction = 0.90104167 * 192; time = 0.0185s; samplesPerSecond = 10387.9
MPI Rank 1: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[  55-  57, 17.81%]: CrossEntropyWithSoftmax = 3.82672791 * 192; EvalErrorPrediction = 0.89062500 * 192; time = 0.0185s; samplesPerSecond = 10360.5
MPI Rank 1: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[  58-  60, 18.75%]: CrossEntropyWithSoftmax = 3.56520696 * 192; EvalErrorPrediction = 0.83333333 * 192; time = 0.0185s; samplesPerSecond = 10403.1
MPI Rank 1: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[  61-  63, 19.69%]: CrossEntropyWithSoftmax = 3.40098566 * 192; EvalErrorPrediction = 0.80208333 * 192; time = 0.0185s; samplesPerSecond = 10395.2
MPI Rank 1: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[  64-  66, 20.62%]: CrossEntropyWithSoftmax = 3.50668803 * 192; EvalErrorPrediction = 0.77604167 * 192; time = 0.0185s; samplesPerSecond = 10401.4
MPI Rank 1: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[  67-  69, 21.56%]: CrossEntropyWithSoftmax = 3.82314351 * 192; EvalErrorPrediction = 0.86979167 * 192; time = 0.0184s; samplesPerSecond = 10408.8
MPI Rank 1: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[  70-  72, 22.50%]: CrossEntropyWithSoftmax = 3.51780740 * 192; EvalErrorPrediction = 0.83854167 * 192; time = 0.0185s; samplesPerSecond = 10403.7
MPI Rank 1: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[  73-  75, 23.44%]: CrossEntropyWithSoftmax = 3.32189431 * 192; EvalErrorPrediction = 0.79687500 * 192; time = 0.0185s; samplesPerSecond = 10400.3
MPI Rank 1: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[  76-  78, 24.38%]: CrossEntropyWithSoftmax = 3.42533640 * 192; EvalErrorPrediction = 0.77604167 * 192; time = 0.0185s; samplesPerSecond = 10396.9
MPI Rank 1: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[  79-  81, 25.31%]: CrossEntropyWithSoftmax = 3.42902377 * 192; EvalErrorPrediction = 0.81770833 * 192; time = 0.0185s; samplesPerSecond = 10402.6
MPI Rank 1: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[  82-  84, 26.25%]: CrossEntropyWithSoftmax = 3.42017745 * 192; EvalErrorPrediction = 0.76041667 * 192; time = 0.0184s; samplesPerSecond = 10412.7
MPI Rank 1: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[  85-  87, 27.19%]: CrossEntropyWithSoftmax = 3.30346679 * 192; EvalErrorPrediction = 0.73437500 * 192; time = 0.0185s; samplesPerSecond = 10397.5
MPI Rank 1: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[  88-  90, 28.12%]: CrossEntropyWithSoftmax = 3.31343403 * 192; EvalErrorPrediction = 0.79687500 * 192; time = 0.0185s; samplesPerSecond = 10385.1
MPI Rank 1: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[  91-  93, 29.06%]: CrossEntropyWithSoftmax = 3.22956709 * 192; EvalErrorPrediction = 0.83854167 * 192; time = 0.0185s; samplesPerSecond = 10386.2
MPI Rank 1: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[  94-  96, 30.00%]: CrossEntropyWithSoftmax = 3.54894307 * 192; EvalErrorPrediction = 0.84895833 * 192; time = 0.0185s; samplesPerSecond = 10376.1
MPI Rank 1: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[  97-  99, 30.94%]: CrossEntropyWithSoftmax = 3.33751842 * 192; EvalErrorPrediction = 0.85416667 * 192; time = 0.0184s; samplesPerSecond = 10408.2
MPI Rank 1: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[ 100- 102, 31.87%]: CrossEntropyWithSoftmax = 3.25951347 * 192; EvalErrorPrediction = 0.80729167 * 192; time = 0.0185s; samplesPerSecond = 10390.7
MPI Rank 1: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[ 103- 105, 32.81%]: CrossEntropyWithSoftmax = 3.24586699 * 192; EvalErrorPrediction = 0.78125000 * 192; time = 0.0185s; samplesPerSecond = 10376.7
MPI Rank 1: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[ 106- 108, 33.75%]: CrossEntropyWithSoftmax = 3.06725828 * 192; EvalErrorPrediction = 0.71875000 * 192; time = 0.0185s; samplesPerSecond = 10401.4
MPI Rank 1: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[ 109- 111, 34.69%]: CrossEntropyWithSoftmax = 3.39973653 * 192; EvalErrorPrediction = 0.77083333 * 192; time = 0.0185s; samplesPerSecond = 10385.7
MPI Rank 1: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[ 112- 114, 35.62%]: CrossEntropyWithSoftmax = 3.34798378 * 192; EvalErrorPrediction = 0.78645833 * 192; time = 0.0185s; samplesPerSecond = 10395.2
MPI Rank 1: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[ 115- 117, 36.56%]: CrossEntropyWithSoftmax = 3.38133778 * 192; EvalErrorPrediction = 0.82291667 * 192; time = 0.0185s; samplesPerSecond = 10388.5
MPI Rank 1: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[ 118- 120, 37.50%]: CrossEntropyWithSoftmax = 3.19074044 * 192; EvalErrorPrediction = 0.74479167 * 192; time = 0.0185s; samplesPerSecond = 10401.4
MPI Rank 1: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[ 121- 123, 38.44%]: CrossEntropyWithSoftmax = 3.14306337 * 192; EvalErrorPrediction = 0.74479167 * 192; time = 0.0185s; samplesPerSecond = 10405.4
MPI Rank 1: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[ 124- 126, 39.38%]: CrossEntropyWithSoftmax = 3.10036521 * 192; EvalErrorPrediction = 0.72916667 * 192; time = 0.0185s; samplesPerSecond = 10372.8
MPI Rank 1: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[ 127- 129, 40.31%]: CrossEntropyWithSoftmax = 3.17040971 * 192; EvalErrorPrediction = 0.76562500 * 192; time = 0.0185s; samplesPerSecond = 10388.5
MPI Rank 1: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[ 130- 132, 41.25%]: CrossEntropyWithSoftmax = 3.19888148 * 192; EvalErrorPrediction = 0.75520833 * 192; time = 0.0185s; samplesPerSecond = 10392.4
MPI Rank 1: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[ 133- 135, 42.19%]: CrossEntropyWithSoftmax = 2.91247084 * 192; EvalErrorPrediction = 0.66145833 * 192; time = 0.0185s; samplesPerSecond = 10394.7
MPI Rank 1: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[ 136- 138, 43.12%]: CrossEntropyWithSoftmax = 2.96972038 * 192; EvalErrorPrediction = 0.70833333 * 192; time = 0.0185s; samplesPerSecond = 10404.8
MPI Rank 1: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[ 139- 141, 44.06%]: CrossEntropyWithSoftmax = 3.15632232 * 192; EvalErrorPrediction = 0.76041667 * 192; time = 0.0184s; samplesPerSecond = 10408.8
MPI Rank 1: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[ 142- 144, 45.00%]: CrossEntropyWithSoftmax = 2.98075176 * 192; EvalErrorPrediction = 0.71354167 * 192; time = 0.0185s; samplesPerSecond = 10395.8
MPI Rank 1: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[ 145- 147, 45.94%]: CrossEntropyWithSoftmax = 3.03076846 * 192; EvalErrorPrediction = 0.77604167 * 192; time = 0.0185s; samplesPerSecond = 10399.7
MPI Rank 1: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[ 148- 150, 46.88%]: CrossEntropyWithSoftmax = 2.91480722 * 192; EvalErrorPrediction = 0.71354167 * 192; time = 0.0185s; samplesPerSecond = 10390.2
MPI Rank 1: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[ 151- 153, 47.81%]: CrossEntropyWithSoftmax = 3.16155322 * 192; EvalErrorPrediction = 0.75520833 * 192; time = 0.0185s; samplesPerSecond = 10390.2
MPI Rank 1: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[ 154- 156, 48.75%]: CrossEntropyWithSoftmax = 2.76157172 * 192; EvalErrorPrediction = 0.69791667 * 192; time = 0.0185s; samplesPerSecond = 10400.3
MPI Rank 1: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[ 157- 159, 49.69%]: CrossEntropyWithSoftmax = 3.06347679 * 192; EvalErrorPrediction = 0.75520833 * 192; time = 0.0185s; samplesPerSecond = 10394.1
MPI Rank 1: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[ 160- 162, 50.62%]: CrossEntropyWithSoftmax = 2.84053583 * 192; EvalErrorPrediction = 0.69791667 * 192; time = 0.0185s; samplesPerSecond = 10395.2
MPI Rank 1: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[ 163- 165, 51.56%]: CrossEntropyWithSoftmax = 2.87795860 * 192; EvalErrorPrediction = 0.75000000 * 192; time = 0.0185s; samplesPerSecond = 10392.4
MPI Rank 1: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[ 166- 168, 52.50%]: CrossEntropyWithSoftmax = 2.92198252 * 192; EvalErrorPrediction = 0.70833333 * 192; time = 0.0185s; samplesPerSecond = 10391.3
MPI Rank 1: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[ 169- 171, 53.44%]: CrossEntropyWithSoftmax = 2.81241750 * 192; EvalErrorPrediction = 0.66145833 * 192; time = 0.0185s; samplesPerSecond = 10394.7
MPI Rank 1: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[ 172- 174, 54.37%]: CrossEntropyWithSoftmax = 2.62682593 * 192; EvalErrorPrediction = 0.64062500 * 192; time = 0.0185s; samplesPerSecond = 10402.6
MPI Rank 1: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[ 175- 177, 55.31%]: CrossEntropyWithSoftmax = 2.75758644 * 192; EvalErrorPrediction = 0.73437500 * 192; time = 0.0185s; samplesPerSecond = 10394.1
MPI Rank 1: 07/14/2016 12:43:32:  Epoch[ 1 of 5]-Minibatch[ 178- 180, 56.25%]: CrossEntropyWithSoftmax = 2.74763961 * 192; EvalErrorPrediction = 0.67187500 * 192; time = 0.0185s; samplesPerSecond = 10397.5
MPI Rank 1: 07/14/2016 12:43:33:  Epoch[ 1 of 5]-Minibatch[ 181- 183, 57.19%]: CrossEntropyWithSoftmax = 2.90905834 * 192; EvalErrorPrediction = 0.68229167 * 192; time = 0.0185s; samplesPerSecond = 10396.9
MPI Rank 1: 07/14/2016 12:43:33:  Epoch[ 1 of 5]-Minibatch[ 184- 186, 58.13%]: CrossEntropyWithSoftmax = 2.76756973 * 192; EvalErrorPrediction = 0.70833333 * 192; time = 0.0185s; samplesPerSecond = 10377.8
MPI Rank 1: 07/14/2016 12:43:33:  Epoch[ 1 of 5]-Minibatch[ 187- 189, 59.06%]: CrossEntropyWithSoftmax = 2.76599748 * 192; EvalErrorPrediction = 0.75520833 * 192; time = 0.0185s; samplesPerSecond = 10386.8
MPI Rank 1: 07/14/2016 12:43:33:  Epoch[ 1 of 5]-Minibatch[ 190- 192, 60.00%]: CrossEntropyWithSoftmax = 2.83171014 * 192; EvalErrorPrediction = 0.70833333 * 192; time = 0.0185s; samplesPerSecond = 10363.3
MPI Rank 1: 07/14/2016 12:43:33:  Epoch[ 1 of 5]-Minibatch[ 193- 195, 60.94%]: CrossEntropyWithSoftmax = 2.59593490 * 192; EvalErrorPrediction = 0.61458333 * 192; time = 0.0185s; samplesPerSecond = 10396.4
MPI Rank 1: 07/14/2016 12:43:33:  Epoch[ 1 of 5]-Minibatch[ 196- 198, 61.88%]: CrossEntropyWithSoftmax = 2.64965270 * 192; EvalErrorPrediction = 0.66666667 * 192; time = 0.0185s; samplesPerSecond = 10393.5
MPI Rank 1: 07/14/2016 12:43:33:  Epoch[ 1 of 5]-Minibatch[ 199- 201, 62.81%]: CrossEntropyWithSoftmax = 2.33442260 * 192; EvalErrorPrediction = 0.60937500 * 192; time = 0.0185s; samplesPerSecond = 10399.2
MPI Rank 1: 07/14/2016 12:43:33:  Epoch[ 1 of 5]-Minibatch[ 202- 204, 63.75%]: CrossEntropyWithSoftmax = 2.67195863 * 192; EvalErrorPrediction = 0.67187500 * 192; time = 0.0185s; samplesPerSecond = 10375.6
MPI Rank 1: 07/14/2016 12:43:33:  Epoch[ 1 of 5]-Minibatch[ 205- 207, 64.69%]: CrossEntropyWithSoftmax = 2.72367540 * 192; EvalErrorPrediction = 0.66145833 * 192; time = 0.0185s; samplesPerSecond = 10377.8
MPI Rank 1: 07/14/2016 12:43:33:  Epoch[ 1 of 5]-Minibatch[ 208- 210, 65.62%]: CrossEntropyWithSoftmax = 2.59572337 * 192; EvalErrorPrediction = 0.68229167 * 192; time = 0.0185s; samplesPerSecond = 10396.4
MPI Rank 1: 07/14/2016 12:43:33:  Epoch[ 1 of 5]-Minibatch[ 211- 213, 66.56%]: CrossEntropyWithSoftmax = 2.53202795 * 192; EvalErrorPrediction = 0.63541667 * 192; time = 0.0185s; samplesPerSecond = 10403.7
MPI Rank 1: 07/14/2016 12:43:33:  Epoch[ 1 of 5]-Minibatch[ 214- 216, 67.50%]: CrossEntropyWithSoftmax = 2.50336278 * 192; EvalErrorPrediction = 0.67187500 * 192; time = 0.0184s; samplesPerSecond = 10407.1
MPI Rank 1: 07/14/2016 12:43:33:  Epoch[ 1 of 5]-Minibatch[ 217- 219, 68.44%]: CrossEntropyWithSoftmax = 2.77076318 * 192; EvalErrorPrediction = 0.68750000 * 192; time = 0.0185s; samplesPerSecond = 10395.8
MPI Rank 1: 07/14/2016 12:43:33:  Epoch[ 1 of 5]-Minibatch[ 220- 222, 69.38%]: CrossEntropyWithSoftmax = 2.45308521 * 192; EvalErrorPrediction = 0.59895833 * 192; time = 0.0185s; samplesPerSecond = 10396.4
MPI Rank 1: 07/14/2016 12:43:33:  Epoch[ 1 of 5]-Minibatch[ 223- 225, 70.31%]: CrossEntropyWithSoftmax = 2.54598920 * 192; EvalErrorPrediction = 0.60937500 * 192; time = 0.0185s; samplesPerSecond = 10378.9
MPI Rank 1: 07/14/2016 12:43:33:  Epoch[ 1 of 5]-Minibatch[ 226- 228, 71.25%]: CrossEntropyWithSoftmax = 2.58558089 * 192; EvalErrorPrediction = 0.65625000 * 192; time = 0.0185s; samplesPerSecond = 10405.9
MPI Rank 1: 07/14/2016 12:43:33:  Epoch[ 1 of 5]-Minibatch[ 229- 231, 72.19%]: CrossEntropyWithSoftmax = 2.41075660 * 192; EvalErrorPrediction = 0.61458333 * 192; time = 0.0185s; samplesPerSecond = 10396.4
MPI Rank 1: 07/14/2016 12:43:33:  Epoch[ 1 of 5]-Minibatch[ 232- 234, 73.12%]: CrossEntropyWithSoftmax = 2.52012028 * 192; EvalErrorPrediction = 0.66145833 * 192; time = 0.0185s; samplesPerSecond = 10393.5
MPI Rank 1: 07/14/2016 12:43:33:  Epoch[ 1 of 5]-Minibatch[ 235- 237, 74.06%]: CrossEntropyWithSoftmax = 2.30719546 * 192; EvalErrorPrediction = 0.62500000 * 192; time = 0.0184s; samplesPerSecond = 10412.1
MPI Rank 1: 07/14/2016 12:43:33:  Epoch[ 1 of 5]-Minibatch[ 238- 240, 75.00%]: CrossEntropyWithSoftmax = 2.42100657 * 192; EvalErrorPrediction = 0.59895833 * 192; time = 0.0185s; samplesPerSecond = 10373.9
MPI Rank 1: 07/14/2016 12:43:33:  Epoch[ 1 of 5]-Minibatch[ 241- 243, 75.94%]: CrossEntropyWithSoftmax = 2.39894546 * 192; EvalErrorPrediction = 0.63541667 * 192; time = 0.0185s; samplesPerSecond = 10405.4
MPI Rank 1: 07/14/2016 12:43:33:  Epoch[ 1 of 5]-Minibatch[ 244- 246, 76.88%]: CrossEntropyWithSoftmax = 2.44970724 * 192; EvalErrorPrediction = 0.67187500 * 192; time = 0.0185s; samplesPerSecond = 10399.2
MPI Rank 1: 07/14/2016 12:43:33:  Epoch[ 1 of 5]-Minibatch[ 247- 249, 77.81%]: CrossEntropyWithSoftmax = 2.33418475 * 192; EvalErrorPrediction = 0.63541667 * 192; time = 0.0185s; samplesPerSecond = 10396.9
MPI Rank 1: 07/14/2016 12:43:33:  Epoch[ 1 of 5]-Minibatch[ 250- 252, 78.75%]: CrossEntropyWithSoftmax = 2.37997032 * 192; EvalErrorPrediction = 0.61458333 * 192; time = 0.0185s; samplesPerSecond = 10399.2
MPI Rank 1: 07/14/2016 12:43:33:  Epoch[ 1 of 5]-Minibatch[ 253- 255, 79.69%]: CrossEntropyWithSoftmax = 2.47517097 * 192; EvalErrorPrediction = 0.59895833 * 192; time = 0.0185s; samplesPerSecond = 10396.9
MPI Rank 1: 07/14/2016 12:43:33:  Epoch[ 1 of 5]-Minibatch[ 256- 258, 80.62%]: CrossEntropyWithSoftmax = 2.60900086 * 192; EvalErrorPrediction = 0.69270833 * 192; time = 0.0185s; samplesPerSecond = 10404.8
MPI Rank 1: 07/14/2016 12:43:33:  Epoch[ 1 of 5]-Minibatch[ 259- 261, 81.56%]: CrossEntropyWithSoftmax = 2.43300244 * 192; EvalErrorPrediction = 0.65104167 * 192; time = 0.0185s; samplesPerSecond = 10382.9
MPI Rank 1: 07/14/2016 12:43:33:  Epoch[ 1 of 5]-Minibatch[ 262- 264, 82.50%]: CrossEntropyWithSoftmax = 2.12996515 * 192; EvalErrorPrediction = 0.56250000 * 192; time = 0.0185s; samplesPerSecond = 10400.9
MPI Rank 1: 07/14/2016 12:43:33:  Epoch[ 1 of 5]-Minibatch[ 265- 267, 83.44%]: CrossEntropyWithSoftmax = 2.51181403 * 192; EvalErrorPrediction = 0.62500000 * 192; time = 0.0185s; samplesPerSecond = 10399.2
MPI Rank 1: 07/14/2016 12:43:33:  Epoch[ 1 of 5]-Minibatch[ 268- 270, 84.38%]: CrossEntropyWithSoftmax = 2.29330120 * 192; EvalErrorPrediction = 0.60416667 * 192; time = 0.0185s; samplesPerSecond = 10392.4
MPI Rank 1: 07/14/2016 12:43:33:  Epoch[ 1 of 5]-Minibatch[ 271- 273, 85.31%]: CrossEntropyWithSoftmax = 2.33352411 * 192; EvalErrorPrediction = 0.60416667 * 192; time = 0.0185s; samplesPerSecond = 10402.0
MPI Rank 1: 07/14/2016 12:43:33:  Epoch[ 1 of 5]-Minibatch[ 274- 276, 86.25%]: CrossEntropyWithSoftmax = 2.17790026 * 192; EvalErrorPrediction = 0.57812500 * 192; time = 0.0185s; samplesPerSecond = 10394.1
MPI Rank 1: 07/14/2016 12:43:33:  Epoch[ 1 of 5]-Minibatch[ 277- 279, 87.19%]: CrossEntropyWithSoftmax = 2.18521155 * 192; EvalErrorPrediction = 0.54166667 * 192; time = 0.0185s; samplesPerSecond = 10394.1
MPI Rank 1: 07/14/2016 12:43:33:  Epoch[ 1 of 5]-Minibatch[ 280- 282, 88.12%]: CrossEntropyWithSoftmax = 2.29833071 * 192; EvalErrorPrediction = 0.58854167 * 192; time = 0.0185s; samplesPerSecond = 10393.5
MPI Rank 1: 07/14/2016 12:43:33:  Epoch[ 1 of 5]-Minibatch[ 283- 285, 89.06%]: CrossEntropyWithSoftmax = 2.21483298 * 192; EvalErrorPrediction = 0.61458333 * 192; time = 0.0185s; samplesPerSecond = 10404.2
MPI Rank 1: 07/14/2016 12:43:33:  Epoch[ 1 of 5]-Minibatch[ 286- 288, 90.00%]: CrossEntropyWithSoftmax = 2.37232627 * 192; EvalErrorPrediction = 0.61979167 * 192; time = 0.0185s; samplesPerSecond = 10382.3
MPI Rank 1: 07/14/2016 12:43:33:  Epoch[ 1 of 5]-Minibatch[ 289- 291, 90.94%]: CrossEntropyWithSoftmax = 2.34396058 * 192; EvalErrorPrediction = 0.60416667 * 192; time = 0.0185s; samplesPerSecond = 10398.6
MPI Rank 1: 07/14/2016 12:43:33:  Epoch[ 1 of 5]-Minibatch[ 292- 294, 91.88%]: CrossEntropyWithSoftmax = 2.18334302 * 192; EvalErrorPrediction = 0.63020833 * 192; time = 0.0185s; samplesPerSecond = 10399.2
MPI Rank 1: 07/14/2016 12:43:33:  Epoch[ 1 of 5]-Minibatch[ 295- 297, 92.81%]: CrossEntropyWithSoftmax = 2.07753101 * 192; EvalErrorPrediction = 0.57812500 * 192; time = 0.0185s; samplesPerSecond = 10398.6
MPI Rank 1: 07/14/2016 12:43:33:  Epoch[ 1 of 5]-Minibatch[ 298- 300, 93.75%]: CrossEntropyWithSoftmax = 2.26265833 * 192; EvalErrorPrediction = 0.63020833 * 192; time = 0.0185s; samplesPerSecond = 10398.1
MPI Rank 1: 07/14/2016 12:43:33:  Epoch[ 1 of 5]-Minibatch[ 301- 303, 94.69%]: CrossEntropyWithSoftmax = 2.21675905 * 192; EvalErrorPrediction = 0.58333333 * 192; time = 0.0184s; samplesPerSecond = 10407.6
MPI Rank 1: 07/14/2016 12:43:33:  Epoch[ 1 of 5]-Minibatch[ 304- 306, 95.62%]: CrossEntropyWithSoftmax = 2.18990385 * 192; EvalErrorPrediction = 0.58333333 * 192; time = 0.0185s; samplesPerSecond = 10393.0
MPI Rank 1: 07/14/2016 12:43:33:  Epoch[ 1 of 5]-Minibatch[ 307- 309, 96.56%]: CrossEntropyWithSoftmax = 2.48513433 * 192; EvalErrorPrediction = 0.64583333 * 192; time = 0.0185s; samplesPerSecond = 10405.9
MPI Rank 1: 07/14/2016 12:43:33:  Epoch[ 1 of 5]-Minibatch[ 310- 312, 97.50%]: CrossEntropyWithSoftmax = 2.25336704 * 192; EvalErrorPrediction = 0.59895833 * 192; time = 0.0185s; samplesPerSecond = 10391.3
MPI Rank 1: 07/14/2016 12:43:33:  Epoch[ 1 of 5]-Minibatch[ 313- 315, 98.44%]: CrossEntropyWithSoftmax = 2.13039619 * 192; EvalErrorPrediction = 0.55729167 * 192; time = 0.0185s; samplesPerSecond = 10392.4
MPI Rank 1: 07/14/2016 12:43:33:  Epoch[ 1 of 5]-Minibatch[ 316- 318, 99.38%]: CrossEntropyWithSoftmax = 2.27299748 * 192; EvalErrorPrediction = 0.60416667 * 192; time = 0.0185s; samplesPerSecond = 10395.8
MPI Rank 1: 07/14/2016 12:43:33: Finished Epoch[ 1 of 5]: [Training] CrossEntropyWithSoftmax = 2.99723568 * 20480; EvalErrorPrediction = 0.72426758 * 20480; totalSamplesSeen = 20480; learningRatePerSample = 0.015625; epochTime=1.97914s
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:43:33: Starting Epoch 2: learning rate per sample = 0.001953  effective momentum = 0.656119  momentum as time constant = 607.5 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 1: frames [20480..40960] (first utterance at frame 20480), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:43:33: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 07/14/2016 12:43:33:  Epoch[ 2 of 5]-Minibatch[   1-   3, 3.75%]: CrossEntropyWithSoftmax = 2.06713643 * 249; EvalErrorPrediction = 0.52208835 * 249; time = 0.0170s; samplesPerSecond = 14678.1
MPI Rank 1: 07/14/2016 12:43:33:  Epoch[ 2 of 5]-Minibatch[   4-   6, 7.50%]: CrossEntropyWithSoftmax = 2.16835808 * 239; EvalErrorPrediction = 0.57740586 * 239; time = 0.0209s; samplesPerSecond = 11425.0
MPI Rank 1: 07/14/2016 12:43:33:  Epoch[ 2 of 5]-Minibatch[   7-   9, 11.25%]: CrossEntropyWithSoftmax = 2.07984091 * 274; EvalErrorPrediction = 0.55109489 * 274; time = 0.0258s; samplesPerSecond = 10636.2
MPI Rank 1: 07/14/2016 12:43:34:  Epoch[ 2 of 5]-Minibatch[  10-  12, 15.00%]: CrossEntropyWithSoftmax = 2.16277557 * 277; EvalErrorPrediction = 0.60288809 * 277; time = 0.0279s; samplesPerSecond = 9937.6
MPI Rank 1: 07/14/2016 12:43:34:  Epoch[ 2 of 5]-Minibatch[  13-  15, 18.75%]: CrossEntropyWithSoftmax = 2.02360967 * 280; EvalErrorPrediction = 0.54642857 * 280; time = 0.0237s; samplesPerSecond = 11825.3
MPI Rank 1: 07/14/2016 12:43:34:  Epoch[ 2 of 5]-Minibatch[  16-  18, 22.50%]: CrossEntropyWithSoftmax = 2.11391771 * 283; EvalErrorPrediction = 0.59717314 * 283; time = 0.0154s; samplesPerSecond = 18405.3
MPI Rank 1: 07/14/2016 12:43:34:  Epoch[ 2 of 5]-Minibatch[  19-  21, 26.25%]: CrossEntropyWithSoftmax = 2.06691231 * 239; EvalErrorPrediction = 0.57322176 * 239; time = 0.0102s; samplesPerSecond = 23422.2
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     0.16 seconds since last report (0.00 seconds on comm.); 4331 samples processed by 2 workers (2141 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 26.25k samplesPerSecond , throughputPerWorker = 13.13k samplesPerSecond
MPI Rank 1: 07/14/2016 12:43:34:  Epoch[ 2 of 5]-Minibatch[  22-  24, 30.00%]: CrossEntropyWithSoftmax = 2.00607609 * 300; EvalErrorPrediction = 0.53666667 * 300; time = 0.0215s; samplesPerSecond = 13932.8
MPI Rank 1: 07/14/2016 12:43:34:  Epoch[ 2 of 5]-Minibatch[  25-  27, 33.75%]: CrossEntropyWithSoftmax = 1.99849291 * 269; EvalErrorPrediction = 0.53159851 * 269; time = 0.0215s; samplesPerSecond = 12507.6
MPI Rank 1: 07/14/2016 12:43:34:  Epoch[ 2 of 5]-Minibatch[  28-  30, 37.50%]: CrossEntropyWithSoftmax = 2.14699482 * 274; EvalErrorPrediction = 0.57299270 * 274; time = 0.0235s; samplesPerSecond = 11641.2
MPI Rank 1: 07/14/2016 12:43:34:  Epoch[ 2 of 5]-Minibatch[  31-  33, 41.25%]: CrossEntropyWithSoftmax = 2.04126317 * 289; EvalErrorPrediction = 0.58477509 * 289; time = 0.0127s; samplesPerSecond = 22844.0
MPI Rank 1: 07/14/2016 12:43:34:  Epoch[ 2 of 5]-Minibatch[  34-  36, 45.00%]: CrossEntropyWithSoftmax = 2.06113963 * 280; EvalErrorPrediction = 0.61785714 * 280; time = 0.0214s; samplesPerSecond = 13098.2
MPI Rank 1: 07/14/2016 12:43:34:  Epoch[ 2 of 5]-Minibatch[  37-  39, 48.75%]: CrossEntropyWithSoftmax = 2.05149355 * 262; EvalErrorPrediction = 0.53435115 * 262; time = 0.0220s; samplesPerSecond = 11934.6
MPI Rank 1: 07/14/2016 12:43:34:  Epoch[ 2 of 5]-Minibatch[  40-  42, 52.50%]: CrossEntropyWithSoftmax = 2.07615796 * 256; EvalErrorPrediction = 0.56640625 * 256; time = 0.0240s; samplesPerSecond = 10655.1
MPI Rank 1: 07/14/2016 12:43:34:  Epoch[ 2 of 5]-Minibatch[  43-  45, 56.25%]: CrossEntropyWithSoftmax = 1.93205618 * 271; EvalErrorPrediction = 0.53874539 * 271; time = 0.0108s; samplesPerSecond = 25111.2
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     0.15 seconds since last report (0.00 seconds on comm.); 4232 samples processed by 2 workers (2078 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 27.81k samplesPerSecond , throughputPerWorker = 13.91k samplesPerSecond
MPI Rank 1: 07/14/2016 12:43:34:  Epoch[ 2 of 5]-Minibatch[  46-  48, 60.00%]: CrossEntropyWithSoftmax = 2.05205732 * 266; EvalErrorPrediction = 0.58270677 * 266; time = 0.0238s; samplesPerSecond = 11196.2
MPI Rank 1: 07/14/2016 12:43:34:  Epoch[ 2 of 5]-Minibatch[  49-  51, 63.75%]: CrossEntropyWithSoftmax = 2.14681400 * 292; EvalErrorPrediction = 0.60616438 * 292; time = 0.0207s; samplesPerSecond = 14079.1
MPI Rank 1: 07/14/2016 12:43:34:  Epoch[ 2 of 5]-Minibatch[  52-  54, 67.50%]: CrossEntropyWithSoftmax = 2.06088333 * 281; EvalErrorPrediction = 0.56583630 * 281; time = 0.0243s; samplesPerSecond = 11585.2
MPI Rank 1: 07/14/2016 12:43:34:  Epoch[ 2 of 5]-Minibatch[  55-  57, 71.25%]: CrossEntropyWithSoftmax = 1.96455898 * 269; EvalErrorPrediction = 0.51672862 * 269; time = 0.0203s; samplesPerSecond = 13247.3
MPI Rank 1: 07/14/2016 12:43:34:  Epoch[ 2 of 5]-Minibatch[  58-  60, 75.00%]: CrossEntropyWithSoftmax = 1.95106467 * 293; EvalErrorPrediction = 0.52559727 * 293; time = 0.0224s; samplesPerSecond = 13051.8
MPI Rank 1: 07/14/2016 12:43:34:  Epoch[ 2 of 5]-Minibatch[  61-  63, 78.75%]: CrossEntropyWithSoftmax = 1.95943138 * 262; EvalErrorPrediction = 0.51145038 * 262; time = 0.0220s; samplesPerSecond = 11900.4
MPI Rank 1: 07/14/2016 12:43:34:  Epoch[ 2 of 5]-Minibatch[  64-  66, 82.50%]: CrossEntropyWithSoftmax = 2.07155768 * 296; EvalErrorPrediction = 0.54729730 * 296; time = 0.0107s; samplesPerSecond = 27550.3
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     0.15 seconds since last report (0.00 seconds on comm.); 4185 samples processed by 2 workers (2060 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 28.19k samplesPerSecond , throughputPerWorker = 14.10k samplesPerSecond
MPI Rank 1: 07/14/2016 12:43:34:  Epoch[ 2 of 5]-Minibatch[  67-  69, 86.25%]: CrossEntropyWithSoftmax = 1.95713212 * 278; EvalErrorPrediction = 0.50719424 * 278; time = 0.0195s; samplesPerSecond = 14245.5
MPI Rank 1: 07/14/2016 12:43:34:  Epoch[ 2 of 5]-Minibatch[  70-  72, 90.00%]: CrossEntropyWithSoftmax = 2.03053119 * 291; EvalErrorPrediction = 0.53608247 * 291; time = 0.0216s; samplesPerSecond = 13490.3
MPI Rank 1: 07/14/2016 12:43:34:  Epoch[ 2 of 5]-Minibatch[  73-  75, 93.75%]: CrossEntropyWithSoftmax = 2.09969286 * 299; EvalErrorPrediction = 0.55852843 * 299; time = 0.0303s; samplesPerSecond = 9856.6
MPI Rank 1: 07/14/2016 12:43:34:  Epoch[ 2 of 5]-Minibatch[  76-  78, 97.50%]: CrossEntropyWithSoftmax = 1.85965889 * 273; EvalErrorPrediction = 0.50183150 * 273; time = 0.0237s; samplesPerSecond = 11521.4
MPI Rank 1: 07/14/2016 12:43:34:  Epoch[ 2 of 5]-Minibatch[  79-  81, 101.25%]: CrossEntropyWithSoftmax = 1.89805579 * 190; EvalErrorPrediction = 0.51578947 * 190; time = 0.0130s; samplesPerSecond = 14565.0
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.01 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     0.25 seconds since last report (0.14 seconds on comm.); 7732 samples processed by 2 workers (1053 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 30.98k samplesPerSecond , throughputPerWorker = 15.49k samplesPerSecond
MPI Rank 1: 07/14/2016 12:43:34: Finished Epoch[ 2 of 5]: [Training] CrossEntropyWithSoftmax = 1.99875653 * 20480; EvalErrorPrediction = 0.54526367 * 20480; totalSamplesSeen = 40960; learningRatePerSample = 0.001953125; epochTime=0.715382s
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:43:34: Starting Epoch 3: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 2: frames [40960..61440] (first utterance at frame 40960), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:43:34: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 07/14/2016 12:43:34:  Epoch[ 3 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.92990384 * 1133; EvalErrorPrediction = 0.54368932 * 1133; time = 0.0455s; samplesPerSecond = 24911.5
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.02 seconds , average latency = 0.02 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     0.12 seconds since last report (0.02 seconds on comm.); 4844 samples processed by 2 workers (2261 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 39.37k samplesPerSecond , throughputPerWorker = 19.68k samplesPerSecond
MPI Rank 1: 07/14/2016 12:43:34:  Epoch[ 3 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.93806210 * 1128; EvalErrorPrediction = 0.52659574 * 1128; time = 0.0747s; samplesPerSecond = 15098.8
MPI Rank 1: 07/14/2016 12:43:34:  Epoch[ 3 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.84931024 * 1154; EvalErrorPrediction = 0.51473137 * 1154; time = 0.0551s; samplesPerSecond = 20962.0
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.02 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     0.12 seconds since last report (0.00 seconds on comm.); 4849 samples processed by 2 workers (2269 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 41.68k samplesPerSecond , throughputPerWorker = 20.84k samplesPerSecond
MPI Rank 1: 07/14/2016 12:43:34:  Epoch[ 3 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.88039762 * 1115; EvalErrorPrediction = 0.51748879 * 1115; time = 0.0611s; samplesPerSecond = 18243.4
MPI Rank 1: 07/14/2016 12:43:35:  Epoch[ 3 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.89689671 * 1130; EvalErrorPrediction = 0.54336283 * 1130; time = 0.0405s; samplesPerSecond = 27933.7
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.04 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     0.12 seconds since last report (0.01 seconds on comm.); 4868 samples processed by 2 workers (2273 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 41.85k samplesPerSecond , throughputPerWorker = 20.92k samplesPerSecond
MPI Rank 1: 07/14/2016 12:43:35:  Epoch[ 3 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.88822901 * 1143; EvalErrorPrediction = 0.53893263 * 1143; time = 0.0757s; samplesPerSecond = 15098.1
MPI Rank 1: 07/14/2016 12:43:35:  Epoch[ 3 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.92708667 * 758; EvalErrorPrediction = 0.53693931 * 758; time = 0.0498s; samplesPerSecond = 15211.1
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.05 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     0.15 seconds since last report (0.08 seconds on comm.); 5919 samples processed by 2 workers (758 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 40.53k samplesPerSecond , throughputPerWorker = 20.26k samplesPerSecond
MPI Rank 1: 07/14/2016 12:43:35: Finished Epoch[ 3 of 5]: [Training] CrossEntropyWithSoftmax = 1.88572700 * 20480; EvalErrorPrediction = 0.52416992 * 20480; totalSamplesSeen = 61440; learningRatePerSample = 9.7656251e-05; epochTime=0.50203s
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:43:35: Starting Epoch 4: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:43:35: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 07/14/2016 12:43:35:  Epoch[ 4 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.83907230 * 1146; EvalErrorPrediction = 0.51308901 * 1146; time = 0.0598s; samplesPerSecond = 19154.9
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     0.12 seconds since last report (0.00 seconds on comm.); 4905 samples processed by 2 workers (2324 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 40.56k samplesPerSecond , throughputPerWorker = 20.28k samplesPerSecond
MPI Rank 1: 07/14/2016 12:43:35:  Epoch[ 4 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.83174615 * 1178; EvalErrorPrediction = 0.50509338 * 1178; time = 0.0580s; samplesPerSecond = 20301.9
MPI Rank 1: 07/14/2016 12:43:35:  Epoch[ 4 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.89682396 * 1141; EvalErrorPrediction = 0.53812445 * 1141; time = 0.0539s; samplesPerSecond = 21152.3
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     0.11 seconds since last report (0.00 seconds on comm.); 4870 samples processed by 2 workers (2333 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 42.43k samplesPerSecond , throughputPerWorker = 21.22k samplesPerSecond
MPI Rank 1: 07/14/2016 12:43:35:  Epoch[ 4 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.88667869 * 1192; EvalErrorPrediction = 0.53271812 * 1192; time = 0.0607s; samplesPerSecond = 19651.5
MPI Rank 1: 07/14/2016 12:43:35:  Epoch[ 4 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.80769004 * 1192; EvalErrorPrediction = 0.52265101 * 1192; time = 0.0610s; samplesPerSecond = 19555.4
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     0.12 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 41.83k samplesPerSecond , throughputPerWorker = 20.92k samplesPerSecond
MPI Rank 1: 07/14/2016 12:43:35:  Epoch[ 4 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.82030293 * 1211; EvalErrorPrediction = 0.49958712 * 1211; time = 0.0564s; samplesPerSecond = 21469.3
MPI Rank 1: 07/14/2016 12:43:35:  Epoch[ 4 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.94035074 * 785; EvalErrorPrediction = 0.54267516 * 785; time = 0.0369s; samplesPerSecond = 21293.9
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.02 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     0.14 seconds since last report (0.07 seconds on comm.); 5789 samples processed by 2 workers (785 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 42.29k samplesPerSecond , throughputPerWorker = 21.14k samplesPerSecond
MPI Rank 1: 07/14/2016 12:43:35: Finished Epoch[ 4 of 5]: [Training] CrossEntropyWithSoftmax = 1.83787473 * 20480; EvalErrorPrediction = 0.51215820 * 20480; totalSamplesSeen = 81920; learningRatePerSample = 9.7656251e-05; epochTime=0.490371s
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:43:35: Starting Epoch 5: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:43:35: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 07/14/2016 12:43:35:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.78955055 * 1175; EvalErrorPrediction = 0.49021277 * 1175; time = 0.0591s; samplesPerSecond = 19885.6
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     0.12 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 39.98k samplesPerSecond , throughputPerWorker = 19.99k samplesPerSecond
MPI Rank 1: 07/14/2016 12:43:36:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.83857800 * 1251; EvalErrorPrediction = 0.51239009 * 1251; time = 0.0608s; samplesPerSecond = 20567.5
MPI Rank 1: 07/14/2016 12:43:36:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.78033156 * 1201; EvalErrorPrediction = 0.50374688 * 1201; time = 0.0572s; samplesPerSecond = 20992.5
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     0.11 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 42.52k samplesPerSecond , throughputPerWorker = 21.26k samplesPerSecond
MPI Rank 1: 07/14/2016 12:43:36:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.85251684 * 1202; EvalErrorPrediction = 0.51331115 * 1202; time = 0.0575s; samplesPerSecond = 20910.5
MPI Rank 1: 07/14/2016 12:43:36:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.83755982 * 1173; EvalErrorPrediction = 0.50809889 * 1173; time = 0.0579s; samplesPerSecond = 20248.9
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     0.11 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 42.37k samplesPerSecond , throughputPerWorker = 21.18k samplesPerSecond
MPI Rank 1: 07/14/2016 12:43:36:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.86874300 * 1194; EvalErrorPrediction = 0.52680067 * 1194; time = 0.0565s; samplesPerSecond = 21136.1
MPI Rank 1: 07/14/2016 12:43:36:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.78761926 * 827; EvalErrorPrediction = 0.51753325 * 827; time = 0.0353s; samplesPerSecond = 23432.4
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     0.14 seconds since last report (0.07 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 42.98k samplesPerSecond , throughputPerWorker = 21.49k samplesPerSecond
MPI Rank 1: 07/14/2016 12:43:36: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84363929 * 20480; EvalErrorPrediction = 0.51025391 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 9.7656251e-05; epochTime=0.48821s
MPI Rank 1: 07/14/2016 12:43:36: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 12:43:36: learnRatePerSample reduced to 4.8828126e-05
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:43:36: Starting Epoch 5: learning rate per sample = 0.000049  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:43:36: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 07/14/2016 12:43:36:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.78962087 * 1175; EvalErrorPrediction = 0.49021277 * 1175; time = 0.0585s; samplesPerSecond = 20078.6
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     0.12 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 40.70k samplesPerSecond , throughputPerWorker = 20.35k samplesPerSecond
MPI Rank 1: 07/14/2016 12:43:36:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.83882454 * 1251; EvalErrorPrediction = 0.50759392 * 1251; time = 0.0588s; samplesPerSecond = 21266.5
MPI Rank 1: 07/14/2016 12:43:36:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.78134486 * 1201; EvalErrorPrediction = 0.50208160 * 1201; time = 0.0593s; samplesPerSecond = 20248.5
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     0.12 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 42.45k samplesPerSecond , throughputPerWorker = 21.23k samplesPerSecond
MPI Rank 1: 07/14/2016 12:43:36:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.85328151 * 1202; EvalErrorPrediction = 0.51247920 * 1202; time = 0.0556s; samplesPerSecond = 21630.8
MPI Rank 1: 07/14/2016 12:43:36:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.84014759 * 1173; EvalErrorPrediction = 0.50895141 * 1173; time = 0.0584s; samplesPerSecond = 20083.2
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     0.11 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 42.31k samplesPerSecond , throughputPerWorker = 21.15k samplesPerSecond
MPI Rank 1: 07/14/2016 12:43:36:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.86995428 * 1194; EvalErrorPrediction = 0.52847571 * 1194; time = 0.0562s; samplesPerSecond = 21230.4
MPI Rank 1: 07/14/2016 12:43:36:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.78946637 * 827; EvalErrorPrediction = 0.51511487 * 827; time = 0.0358s; samplesPerSecond = 23110.2
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     0.14 seconds since last report (0.07 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 42.62k samplesPerSecond , throughputPerWorker = 21.31k samplesPerSecond
MPI Rank 1: 07/14/2016 12:43:37: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84493298 * 20480; EvalErrorPrediction = 0.51040039 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 4.8828126e-05; epochTime=0.4875s
MPI Rank 1: 07/14/2016 12:43:37: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 12:43:37: learnRatePerSample reduced to 2.4414063e-05
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:43:37: Starting Epoch 5: learning rate per sample = 0.000024  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:43:37: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 07/14/2016 12:43:37:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.78965640 * 1175; EvalErrorPrediction = 0.49021277 * 1175; time = 0.0590s; samplesPerSecond = 19900.1
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     0.12 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 40.80k samplesPerSecond , throughputPerWorker = 20.40k samplesPerSecond
MPI Rank 1: 07/14/2016 12:43:37:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.83895707 * 1251; EvalErrorPrediction = 0.50839329 * 1251; time = 0.0584s; samplesPerSecond = 21405.1
MPI Rank 1: 07/14/2016 12:43:37:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.78192244 * 1201; EvalErrorPrediction = 0.50208160 * 1201; time = 0.0593s; samplesPerSecond = 20242.7
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     0.12 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 42.44k samplesPerSecond , throughputPerWorker = 21.22k samplesPerSecond
MPI Rank 1: 07/14/2016 12:43:37:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.85367784 * 1202; EvalErrorPrediction = 0.51497504 * 1202; time = 0.0556s; samplesPerSecond = 21622.2
MPI Rank 1: 07/14/2016 12:43:37:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.84169854 * 1173; EvalErrorPrediction = 0.50809889 * 1173; time = 0.0579s; samplesPerSecond = 20267.8
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     0.11 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 42.51k samplesPerSecond , throughputPerWorker = 21.26k samplesPerSecond
MPI Rank 1: 07/14/2016 12:43:37:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87059172 * 1194; EvalErrorPrediction = 0.52680067 * 1194; time = 0.0562s; samplesPerSecond = 21262.6
MPI Rank 1: 07/14/2016 12:43:37:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.79036013 * 827; EvalErrorPrediction = 0.51269649 * 827; time = 0.0362s; samplesPerSecond = 22831.4
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     0.14 seconds since last report (0.07 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 42.51k samplesPerSecond , throughputPerWorker = 21.25k samplesPerSecond
MPI Rank 1: 07/14/2016 12:43:37: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84568574 * 20480; EvalErrorPrediction = 0.51049805 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 2.4414063e-05; epochTime=0.487111s
MPI Rank 1: 07/14/2016 12:43:37: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 12:43:37: learnRatePerSample reduced to 1.2207031e-05
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:43:37: Starting Epoch 5: learning rate per sample = 0.000012  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:43:37: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 07/14/2016 12:43:37:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.78967425 * 1175; EvalErrorPrediction = 0.49021277 * 1175; time = 0.0586s; samplesPerSecond = 20037.2
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     0.12 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 40.90k samplesPerSecond , throughputPerWorker = 20.45k samplesPerSecond
MPI Rank 1: 07/14/2016 12:43:37:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.83902575 * 1251; EvalErrorPrediction = 0.50839329 * 1251; time = 0.0584s; samplesPerSecond = 21435.9
MPI Rank 1: 07/14/2016 12:43:38:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.78223129 * 1201; EvalErrorPrediction = 0.50291424 * 1201; time = 0.0598s; samplesPerSecond = 20089.0
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     0.12 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 42.18k samplesPerSecond , throughputPerWorker = 21.09k samplesPerSecond
MPI Rank 1: 07/14/2016 12:43:38:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.85388363 * 1202; EvalErrorPrediction = 0.51580699 * 1202; time = 0.0559s; samplesPerSecond = 21495.8
MPI Rank 1: 07/14/2016 12:43:38:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.84256302 * 1173; EvalErrorPrediction = 0.51065644 * 1173; time = 0.0579s; samplesPerSecond = 20251.7
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     0.11 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 42.42k samplesPerSecond , throughputPerWorker = 21.21k samplesPerSecond
MPI Rank 1: 07/14/2016 12:43:38:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87093833 * 1194; EvalErrorPrediction = 0.52763819 * 1194; time = 0.0563s; samplesPerSecond = 21225.5
MPI Rank 1: 07/14/2016 12:43:38:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.79083879 * 827; EvalErrorPrediction = 0.51269649 * 827; time = 0.0358s; samplesPerSecond = 23093.5
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     0.14 seconds since last report (0.07 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 42.70k samplesPerSecond , throughputPerWorker = 21.35k samplesPerSecond
MPI Rank 1: 07/14/2016 12:43:38: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84611027 * 20480; EvalErrorPrediction = 0.51083984 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 1.2207031e-05; epochTime=0.487118s
MPI Rank 1: 07/14/2016 12:43:38: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 12:43:38: learnRatePerSample reduced to 6.1035157e-06
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:43:38: Starting Epoch 5: learning rate per sample = 0.000006  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:43:38: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 07/14/2016 12:43:38:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.78968320 * 1175; EvalErrorPrediction = 0.49021277 * 1175; time = 0.0585s; samplesPerSecond = 20082.7
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     0.12 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 41.02k samplesPerSecond , throughputPerWorker = 20.51k samplesPerSecond
MPI Rank 1: 07/14/2016 12:43:38:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.83906070 * 1251; EvalErrorPrediction = 0.50839329 * 1251; time = 0.0583s; samplesPerSecond = 21459.1
MPI Rank 1: 07/14/2016 12:43:38:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.78239105 * 1201; EvalErrorPrediction = 0.50291424 * 1201; time = 0.0588s; samplesPerSecond = 20409.6
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     0.11 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 42.72k samplesPerSecond , throughputPerWorker = 21.36k samplesPerSecond
MPI Rank 1: 07/14/2016 12:43:38:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.85398908 * 1202; EvalErrorPrediction = 0.51663894 * 1202; time = 0.0553s; samplesPerSecond = 21727.3
MPI Rank 1: 07/14/2016 12:43:38:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.84302155 * 1173; EvalErrorPrediction = 0.51150895 * 1173; time = 0.0579s; samplesPerSecond = 20268.5
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     0.12 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 42.05k samplesPerSecond , throughputPerWorker = 21.03k samplesPerSecond
MPI Rank 1: 07/14/2016 12:43:38:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87112259 * 1194; EvalErrorPrediction = 0.52763819 * 1194; time = 0.0575s; samplesPerSecond = 20782.2
MPI Rank 1: 07/14/2016 12:43:38:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.79109571 * 827; EvalErrorPrediction = 0.51269649 * 827; time = 0.0353s; samplesPerSecond = 23399.9
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     0.14 seconds since last report (0.07 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 42.68k samplesPerSecond , throughputPerWorker = 21.34k samplesPerSecond
MPI Rank 1: 07/14/2016 12:43:38: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84633999 * 20480; EvalErrorPrediction = 0.51123047 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 6.1035157e-06; epochTime=0.486392s
MPI Rank 1: 07/14/2016 12:43:38: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 12:43:39: learnRatePerSample reduced to 3.0517579e-06
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:43:39: Starting Epoch 5: learning rate per sample = 0.000003  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:43:39: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 07/14/2016 12:43:39:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.78968768 * 1175; EvalErrorPrediction = 0.49021277 * 1175; time = 0.0611s; samplesPerSecond = 19229.2
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     0.12 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 40.46k samplesPerSecond , throughputPerWorker = 20.23k samplesPerSecond
MPI Rank 1: 07/14/2016 12:43:39:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.83907833 * 1251; EvalErrorPrediction = 0.50839329 * 1251; time = 0.0573s; samplesPerSecond = 21846.2
MPI Rank 1: 07/14/2016 12:43:39:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.78247230 * 1201; EvalErrorPrediction = 0.50291424 * 1201; time = 0.0589s; samplesPerSecond = 20397.4
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     0.11 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 42.65k samplesPerSecond , throughputPerWorker = 21.33k samplesPerSecond
MPI Rank 1: 07/14/2016 12:43:39:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.85404253 * 1202; EvalErrorPrediction = 0.51663894 * 1202; time = 0.0555s; samplesPerSecond = 21670.9
MPI Rank 1: 07/14/2016 12:43:39:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.84325796 * 1173; EvalErrorPrediction = 0.51236147 * 1173; time = 0.0580s; samplesPerSecond = 20240.9
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     0.11 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 42.47k samplesPerSecond , throughputPerWorker = 21.23k samplesPerSecond
MPI Rank 1: 07/14/2016 12:43:39:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87121808 * 1194; EvalErrorPrediction = 0.52763819 * 1194; time = 0.0563s; samplesPerSecond = 21222.9
MPI Rank 1: 07/14/2016 12:43:39:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.79123019 * 827; EvalErrorPrediction = 0.51027811 * 827; time = 0.0362s; samplesPerSecond = 22826.4
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.02 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     0.14 seconds since last report (0.07 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 42.76k samplesPerSecond , throughputPerWorker = 21.38k samplesPerSecond
MPI Rank 1: 07/14/2016 12:43:39: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84646018 * 20480; EvalErrorPrediction = 0.51127930 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 3.0517579e-06; epochTime=0.486827s
MPI Rank 1: 07/14/2016 12:43:39: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 12:43:39: learnRatePerSample reduced to 1.5258789e-06
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:43:39: Starting Epoch 5: learning rate per sample = 0.000002  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:43:39: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 07/14/2016 12:43:39:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.78968993 * 1175; EvalErrorPrediction = 0.49021277 * 1175; time = 0.0597s; samplesPerSecond = 19679.4
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     0.12 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 40.68k samplesPerSecond , throughputPerWorker = 20.34k samplesPerSecond
MPI Rank 1: 07/14/2016 12:43:39:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.83908718 * 1251; EvalErrorPrediction = 0.50839329 * 1251; time = 0.0580s; samplesPerSecond = 21560.0
MPI Rank 1: 07/14/2016 12:43:39:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.78251328 * 1201; EvalErrorPrediction = 0.50291424 * 1201; time = 0.0598s; samplesPerSecond = 20081.3
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     0.12 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 42.34k samplesPerSecond , throughputPerWorker = 21.17k samplesPerSecond
MPI Rank 1: 07/14/2016 12:43:40:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.85406946 * 1202; EvalErrorPrediction = 0.51663894 * 1202; time = 0.0554s; samplesPerSecond = 21702.2
MPI Rank 1: 07/14/2016 12:43:40:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.84337803 * 1173; EvalErrorPrediction = 0.51236147 * 1173; time = 0.0584s; samplesPerSecond = 20073.9
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     0.11 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 42.38k samplesPerSecond , throughputPerWorker = 21.19k samplesPerSecond
MPI Rank 1: 07/14/2016 12:43:40:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87126675 * 1194; EvalErrorPrediction = 0.52763819 * 1194; time = 0.0559s; samplesPerSecond = 21348.5
MPI Rank 1: 07/14/2016 12:43:40:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.79129918 * 827; EvalErrorPrediction = 0.51027811 * 827; time = 0.0353s; samplesPerSecond = 23432.4
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     0.14 seconds since last report (0.07 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 43.09k samplesPerSecond , throughputPerWorker = 21.55k samplesPerSecond
MPI Rank 1: 07/14/2016 12:43:40: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84652175 * 20480; EvalErrorPrediction = 0.51123047 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 1.5258789e-06; epochTime=0.486181s
MPI Rank 1: 07/14/2016 12:43:40: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 12:43:40: learnRatePerSample reduced to 7.6293946e-07
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:43:40: Starting Epoch 5: learning rate per sample = 0.000001  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:43:40: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 07/14/2016 12:43:40:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.78969105 * 1175; EvalErrorPrediction = 0.49021277 * 1175; time = 0.0601s; samplesPerSecond = 19537.1
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     0.12 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 40.85k samplesPerSecond , throughputPerWorker = 20.42k samplesPerSecond
MPI Rank 1: 07/14/2016 12:43:40:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.83909162 * 1251; EvalErrorPrediction = 0.50839329 * 1251; time = 0.0571s; samplesPerSecond = 21913.5
MPI Rank 1: 07/14/2016 12:43:40:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.78253385 * 1201; EvalErrorPrediction = 0.50291424 * 1201; time = 0.0593s; samplesPerSecond = 20258.8
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     0.11 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 42.52k samplesPerSecond , throughputPerWorker = 21.26k samplesPerSecond
MPI Rank 1: 07/14/2016 12:43:40:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.85408297 * 1202; EvalErrorPrediction = 0.51663894 * 1202; time = 0.0555s; samplesPerSecond = 21653.0
MPI Rank 1: 07/14/2016 12:43:40:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.84343854 * 1173; EvalErrorPrediction = 0.51236147 * 1173; time = 0.0579s; samplesPerSecond = 20264.3
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     0.11 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 42.57k samplesPerSecond , throughputPerWorker = 21.28k samplesPerSecond
MPI Rank 1: 07/14/2016 12:43:40:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87129133 * 1194; EvalErrorPrediction = 0.52763819 * 1194; time = 0.0559s; samplesPerSecond = 21365.3
MPI Rank 1: 07/14/2016 12:43:40:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.79133413 * 827; EvalErrorPrediction = 0.51027811 * 827; time = 0.0341s; samplesPerSecond = 24221.7
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     0.14 seconds since last report (0.07 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 42.69k samplesPerSecond , throughputPerWorker = 21.35k samplesPerSecond
MPI Rank 1: 07/14/2016 12:43:40: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84655293 * 20480; EvalErrorPrediction = 0.51118164 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 7.6293946e-07; epochTime=0.48598s
MPI Rank 1: 07/14/2016 12:43:40: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 12:43:41: learnRatePerSample reduced to 3.8146973e-07
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:43:41: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:43:41: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 07/14/2016 12:43:41:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.78969161 * 1175; EvalErrorPrediction = 0.49021277 * 1175; time = 0.0595s; samplesPerSecond = 19736.3
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     0.12 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 40.68k samplesPerSecond , throughputPerWorker = 20.34k samplesPerSecond
MPI Rank 1: 07/14/2016 12:43:41:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.83909384 * 1251; EvalErrorPrediction = 0.50839329 * 1251; time = 0.0582s; samplesPerSecond = 21487.5
MPI Rank 1: 07/14/2016 12:43:41:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.78254416 * 1201; EvalErrorPrediction = 0.50291424 * 1201; time = 0.0589s; samplesPerSecond = 20406.4
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     0.11 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 42.65k samplesPerSecond , throughputPerWorker = 21.32k samplesPerSecond
MPI Rank 1: 07/14/2016 12:43:41:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.85408974 * 1202; EvalErrorPrediction = 0.51663894 * 1202; time = 0.0555s; samplesPerSecond = 21656.5
MPI Rank 1: 07/14/2016 12:43:41:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.84346892 * 1173; EvalErrorPrediction = 0.51236147 * 1173; time = 0.0579s; samplesPerSecond = 20271.7
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     0.11 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 42.39k samplesPerSecond , throughputPerWorker = 21.20k samplesPerSecond
MPI Rank 1: 07/14/2016 12:43:41:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87130368 * 1194; EvalErrorPrediction = 0.52763819 * 1194; time = 0.0565s; samplesPerSecond = 21134.6
MPI Rank 1: 07/14/2016 12:43:41:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.79135174 * 827; EvalErrorPrediction = 0.51027811 * 827; time = 0.0358s; samplesPerSecond = 23118.0
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     0.14 seconds since last report (0.07 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 42.93k samplesPerSecond , throughputPerWorker = 21.46k samplesPerSecond
MPI Rank 1: 07/14/2016 12:43:41: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84656861 * 20480; EvalErrorPrediction = 0.51118164 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 3.8146973e-07; epochTime=0.485855s
MPI Rank 1: 07/14/2016 12:43:41: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 12:43:41: learnRatePerSample reduced to 1.9073487e-07
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:43:41: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:43:41: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 07/14/2016 12:43:41:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.78969189 * 1175; EvalErrorPrediction = 0.49021277 * 1175; time = 0.0596s; samplesPerSecond = 19716.4
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     0.12 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 40.60k samplesPerSecond , throughputPerWorker = 20.30k samplesPerSecond
MPI Rank 1: 07/14/2016 12:43:41:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.83909495 * 1251; EvalErrorPrediction = 0.50839329 * 1251; time = 0.0583s; samplesPerSecond = 21450.6
MPI Rank 1: 07/14/2016 12:43:41:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.78254932 * 1201; EvalErrorPrediction = 0.50291424 * 1201; time = 0.0593s; samplesPerSecond = 20254.0
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     0.11 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 42.50k samplesPerSecond , throughputPerWorker = 21.25k samplesPerSecond
MPI Rank 1: 07/14/2016 12:43:41:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.85409313 * 1202; EvalErrorPrediction = 0.51663894 * 1202; time = 0.0555s; samplesPerSecond = 21671.3
MPI Rank 1: 07/14/2016 12:43:42:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.84348413 * 1173; EvalErrorPrediction = 0.51236147 * 1173; time = 0.0584s; samplesPerSecond = 20097.3
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     0.12 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 41.97k samplesPerSecond , throughputPerWorker = 20.99k samplesPerSecond
MPI Rank 1: 07/14/2016 12:43:42:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87130987 * 1194; EvalErrorPrediction = 0.52680067 * 1194; time = 0.0571s; samplesPerSecond = 20897.9
MPI Rank 1: 07/14/2016 12:43:42:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.79136057 * 827; EvalErrorPrediction = 0.51027811 * 827; time = 0.0363s; samplesPerSecond = 22813.2
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     0.14 seconds since last report (0.07 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 42.52k samplesPerSecond , throughputPerWorker = 21.26k samplesPerSecond
MPI Rank 1: 07/14/2016 12:43:42: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84657648 * 20480; EvalErrorPrediction = 0.51118164 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 1.9073487e-07; epochTime=0.48894s
MPI Rank 1: 07/14/2016 12:43:42: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 12:43:42: learnRatePerSample reduced to 9.5367433e-08
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:43:42: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:43:42: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 07/14/2016 12:43:42:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.78969203 * 1175; EvalErrorPrediction = 0.49021277 * 1175; time = 0.0604s; samplesPerSecond = 19468.8
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     0.12 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 40.43k samplesPerSecond , throughputPerWorker = 20.21k samplesPerSecond
MPI Rank 1: 07/14/2016 12:43:42:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.83909551 * 1251; EvalErrorPrediction = 0.50839329 * 1251; time = 0.0583s; samplesPerSecond = 21459.1
MPI Rank 1: 07/14/2016 12:43:42:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.78255190 * 1201; EvalErrorPrediction = 0.50291424 * 1201; time = 0.0593s; samplesPerSecond = 20253.0
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     0.12 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 42.34k samplesPerSecond , throughputPerWorker = 21.17k samplesPerSecond
MPI Rank 1: 07/14/2016 12:43:42:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.85409482 * 1202; EvalErrorPrediction = 0.51663894 * 1202; time = 0.0559s; samplesPerSecond = 21507.7
MPI Rank 1: 07/14/2016 12:43:42:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.84349175 * 1173; EvalErrorPrediction = 0.51236147 * 1173; time = 0.0585s; samplesPerSecond = 20068.1
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     0.11 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 42.26k samplesPerSecond , throughputPerWorker = 21.13k samplesPerSecond
MPI Rank 1: 07/14/2016 12:43:42:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87131297 * 1194; EvalErrorPrediction = 0.52680067 * 1194; time = 0.0563s; samplesPerSecond = 21217.6
MPI Rank 1: 07/14/2016 12:43:42:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.79136499 * 827; EvalErrorPrediction = 0.51027811 * 827; time = 0.0358s; samplesPerSecond = 23118.6
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     0.14 seconds since last report (0.07 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 42.59k samplesPerSecond , throughputPerWorker = 21.29k samplesPerSecond
MPI Rank 1: 07/14/2016 12:43:42: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84658042 * 20480; EvalErrorPrediction = 0.51123047 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 9.5367433e-08; epochTime=0.488852s
MPI Rank 1: 07/14/2016 12:43:42: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 12:43:42: learnRatePerSample reduced to 4.7683717e-08
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:43:43: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:43:43: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 07/14/2016 12:43:43:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.78969210 * 1175; EvalErrorPrediction = 0.49021277 * 1175; time = 0.0587s; samplesPerSecond = 20017.0
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     0.12 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 40.95k samplesPerSecond , throughputPerWorker = 20.48k samplesPerSecond
MPI Rank 1: 07/14/2016 12:43:43:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.83909579 * 1251; EvalErrorPrediction = 0.50839329 * 1251; time = 0.0582s; samplesPerSecond = 21480.5
MPI Rank 1: 07/14/2016 12:43:43:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.78255320 * 1201; EvalErrorPrediction = 0.50291424 * 1201; time = 0.0583s; samplesPerSecond = 20595.0
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     0.11 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 42.50k samplesPerSecond , throughputPerWorker = 21.25k samplesPerSecond
MPI Rank 1: 07/14/2016 12:43:43:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.85409567 * 1202; EvalErrorPrediction = 0.51663894 * 1202; time = 0.0565s; samplesPerSecond = 21260.0
MPI Rank 1: 07/14/2016 12:43:43:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.84349556 * 1173; EvalErrorPrediction = 0.51236147 * 1173; time = 0.0580s; samplesPerSecond = 20218.6
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     0.11 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 42.47k samplesPerSecond , throughputPerWorker = 21.23k samplesPerSecond
MPI Rank 1: 07/14/2016 12:43:43:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87131452 * 1194; EvalErrorPrediction = 0.52680067 * 1194; time = 0.0560s; samplesPerSecond = 21306.2
MPI Rank 1: 07/14/2016 12:43:43:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.79136720 * 827; EvalErrorPrediction = 0.51027811 * 827; time = 0.0357s; samplesPerSecond = 23138.0
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     0.14 seconds since last report (0.07 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 42.95k samplesPerSecond , throughputPerWorker = 21.47k samplesPerSecond
MPI Rank 1: 07/14/2016 12:43:43: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84658239 * 20480; EvalErrorPrediction = 0.51123047 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 4.7683717e-08; epochTime=0.485188s
MPI Rank 1: 07/14/2016 12:43:43: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 12:43:43: learnRatePerSample reduced to 2.3841858e-08
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:43:43: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:43:43: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 07/14/2016 12:43:43:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.78969213 * 1175; EvalErrorPrediction = 0.49021277 * 1175; time = 0.0596s; samplesPerSecond = 19712.1
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     0.12 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 40.64k samplesPerSecond , throughputPerWorker = 20.32k samplesPerSecond
MPI Rank 1: 07/14/2016 12:43:43:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.83909593 * 1251; EvalErrorPrediction = 0.50839329 * 1251; time = 0.0582s; samplesPerSecond = 21476.8
MPI Rank 1: 07/14/2016 12:43:43:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.78255384 * 1201; EvalErrorPrediction = 0.50291424 * 1201; time = 0.0588s; samplesPerSecond = 20423.8
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     0.12 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 42.35k samplesPerSecond , throughputPerWorker = 21.17k samplesPerSecond
MPI Rank 1: 07/14/2016 12:43:43:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.85409609 * 1202; EvalErrorPrediction = 0.51663894 * 1202; time = 0.0564s; samplesPerSecond = 21303.4
MPI Rank 1: 07/14/2016 12:43:43:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.84349747 * 1173; EvalErrorPrediction = 0.51236147 * 1173; time = 0.0585s; samplesPerSecond = 20039.0
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     0.12 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 42.20k samplesPerSecond , throughputPerWorker = 21.10k samplesPerSecond
MPI Rank 1: 07/14/2016 12:43:44:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87131530 * 1194; EvalErrorPrediction = 0.52680067 * 1194; time = 0.0563s; samplesPerSecond = 21219.1
MPI Rank 1: 07/14/2016 12:43:44:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.79136831 * 827; EvalErrorPrediction = 0.51027811 * 827; time = 0.0353s; samplesPerSecond = 23459.7
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     0.14 seconds since last report (0.07 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 42.96k samplesPerSecond , throughputPerWorker = 21.48k samplesPerSecond
MPI Rank 1: 07/14/2016 12:43:44: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84658338 * 20480; EvalErrorPrediction = 0.51127930 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 2.3841858e-08; epochTime=0.487222s
MPI Rank 1: 07/14/2016 12:43:44: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 12:43:44: learnRatePerSample reduced to 1.1920929e-08
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:43:44: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:43:44: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 07/14/2016 12:43:44:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.78969215 * 1175; EvalErrorPrediction = 0.49021277 * 1175; time = 0.0592s; samplesPerSecond = 19858.0
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     0.12 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 40.69k samplesPerSecond , throughputPerWorker = 20.34k samplesPerSecond
MPI Rank 1: 07/14/2016 12:43:44:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.83909600 * 1251; EvalErrorPrediction = 0.50839329 * 1251; time = 0.0585s; samplesPerSecond = 21380.6
MPI Rank 1: 07/14/2016 12:43:44:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.78255416 * 1201; EvalErrorPrediction = 0.50291424 * 1201; time = 0.0588s; samplesPerSecond = 20408.2
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     0.12 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 42.25k samplesPerSecond , throughputPerWorker = 21.12k samplesPerSecond
MPI Rank 1: 07/14/2016 12:43:44:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.85409630 * 1202; EvalErrorPrediction = 0.51663894 * 1202; time = 0.0566s; samplesPerSecond = 21237.1
MPI Rank 1: 07/14/2016 12:43:44:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.84349842 * 1173; EvalErrorPrediction = 0.51236147 * 1173; time = 0.0579s; samplesPerSecond = 20262.9
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     0.11 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 42.42k samplesPerSecond , throughputPerWorker = 21.21k samplesPerSecond
MPI Rank 1: 07/14/2016 12:43:44:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87131569 * 1194; EvalErrorPrediction = 0.52680067 * 1194; time = 0.0565s; samplesPerSecond = 21150.7
MPI Rank 1: 07/14/2016 12:43:44:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.79136886 * 827; EvalErrorPrediction = 0.51027811 * 827; time = 0.0353s; samplesPerSecond = 23457.7
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     0.14 seconds since last report (0.07 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 42.72k samplesPerSecond , throughputPerWorker = 21.36k samplesPerSecond
MPI Rank 1: 07/14/2016 12:43:44: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84658387 * 20480; EvalErrorPrediction = 0.51127930 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 1.1920929e-08; epochTime=0.487501s
MPI Rank 1: 07/14/2016 12:43:44: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 12:43:44: learnRatePerSample reduced to 5.9604646e-09
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:43:44: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:43:44: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 07/14/2016 12:43:45:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.78969216 * 1175; EvalErrorPrediction = 0.49021277 * 1175; time = 0.0591s; samplesPerSecond = 19870.8
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     0.12 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 40.89k samplesPerSecond , throughputPerWorker = 20.44k samplesPerSecond
MPI Rank 1: 07/14/2016 12:43:45:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.83909603 * 1251; EvalErrorPrediction = 0.50839329 * 1251; time = 0.0580s; samplesPerSecond = 21573.1
MPI Rank 1: 07/14/2016 12:43:45:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.78255433 * 1201; EvalErrorPrediction = 0.50291424 * 1201; time = 0.0593s; samplesPerSecond = 20259.8
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     0.11 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 42.48k samplesPerSecond , throughputPerWorker = 21.24k samplesPerSecond
MPI Rank 1: 07/14/2016 12:43:45:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.85409641 * 1202; EvalErrorPrediction = 0.51663894 * 1202; time = 0.0555s; samplesPerSecond = 21644.4
MPI Rank 1: 07/14/2016 12:43:45:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.84349890 * 1173; EvalErrorPrediction = 0.51236147 * 1173; time = 0.0588s; samplesPerSecond = 19940.5
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     0.12 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 41.94k samplesPerSecond , throughputPerWorker = 20.97k samplesPerSecond
MPI Rank 1: 07/14/2016 12:43:45:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87131588 * 1194; EvalErrorPrediction = 0.52680067 * 1194; time = 0.0568s; samplesPerSecond = 21033.7
MPI Rank 1: 07/14/2016 12:43:45:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.79136914 * 827; EvalErrorPrediction = 0.51027811 * 827; time = 0.0352s; samplesPerSecond = 23466.3
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     0.13 seconds since last report (0.07 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 43.19k samplesPerSecond , throughputPerWorker = 21.59k samplesPerSecond
MPI Rank 1: 07/14/2016 12:43:45: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84658412 * 20480; EvalErrorPrediction = 0.51127930 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 5.9604646e-09; epochTime=0.486145s
MPI Rank 1: 07/14/2016 12:43:45: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 12:43:45: learnRatePerSample reduced to 2.9802323e-09
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:43:45: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:43:45: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 07/14/2016 12:43:45:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.78969217 * 1175; EvalErrorPrediction = 0.49021277 * 1175; time = 0.0596s; samplesPerSecond = 19718.1
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     0.12 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 40.66k samplesPerSecond , throughputPerWorker = 20.33k samplesPerSecond
MPI Rank 1: 07/14/2016 12:43:45:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.83909605 * 1251; EvalErrorPrediction = 0.50839329 * 1251; time = 0.0582s; samplesPerSecond = 21487.5
MPI Rank 1: 07/14/2016 12:43:45:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.78255441 * 1201; EvalErrorPrediction = 0.50291424 * 1201; time = 0.0588s; samplesPerSecond = 20415.1
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     0.11 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 42.61k samplesPerSecond , throughputPerWorker = 21.31k samplesPerSecond
MPI Rank 1: 07/14/2016 12:43:45:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.85409646 * 1202; EvalErrorPrediction = 0.51663894 * 1202; time = 0.0557s; samplesPerSecond = 21569.4
MPI Rank 1: 07/14/2016 12:43:45:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.84349913 * 1173; EvalErrorPrediction = 0.51236147 * 1173; time = 0.0580s; samplesPerSecond = 20209.2
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     0.11 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 42.39k samplesPerSecond , throughputPerWorker = 21.19k samplesPerSecond
MPI Rank 1: 07/14/2016 12:43:45:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87131598 * 1194; EvalErrorPrediction = 0.52680067 * 1194; time = 0.0562s; samplesPerSecond = 21245.9
MPI Rank 1: 07/14/2016 12:43:45:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.79136928 * 827; EvalErrorPrediction = 0.51027811 * 827; time = 0.0353s; samplesPerSecond = 23435.7
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     0.14 seconds since last report (0.07 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 42.75k samplesPerSecond , throughputPerWorker = 21.37k samplesPerSecond
MPI Rank 1: 07/14/2016 12:43:46: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84658424 * 20480; EvalErrorPrediction = 0.51127930 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 2.9802323e-09; epochTime=0.486591s
MPI Rank 1: 07/14/2016 12:43:46: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 12:43:46: learnRatePerSample reduced to 1.4901161e-09
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:43:46: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:43:46: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 07/14/2016 12:43:46:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.78969217 * 1175; EvalErrorPrediction = 0.49021277 * 1175; time = 0.0601s; samplesPerSecond = 19551.1
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     0.12 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 40.89k samplesPerSecond , throughputPerWorker = 20.44k samplesPerSecond
MPI Rank 1: 07/14/2016 12:43:46:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.83909606 * 1251; EvalErrorPrediction = 0.50839329 * 1251; time = 0.0570s; samplesPerSecond = 21935.4
MPI Rank 1: 07/14/2016 12:43:46:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.78255445 * 1201; EvalErrorPrediction = 0.50291424 * 1201; time = 0.0593s; samplesPerSecond = 20253.0
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     0.11 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 42.53k samplesPerSecond , throughputPerWorker = 21.27k samplesPerSecond
MPI Rank 1: 07/14/2016 12:43:46:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.85409649 * 1202; EvalErrorPrediction = 0.51663894 * 1202; time = 0.0554s; samplesPerSecond = 21705.0
MPI Rank 1: 07/14/2016 12:43:46:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.84349925 * 1173; EvalErrorPrediction = 0.51236147 * 1173; time = 0.0583s; samplesPerSecond = 20112.8
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     0.11 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 42.36k samplesPerSecond , throughputPerWorker = 21.18k samplesPerSecond
MPI Rank 1: 07/14/2016 12:43:46:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87131603 * 1194; EvalErrorPrediction = 0.52680067 * 1194; time = 0.0561s; samplesPerSecond = 21274.3
MPI Rank 1: 07/14/2016 12:43:46:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.79136935 * 827; EvalErrorPrediction = 0.51027811 * 827; time = 0.0353s; samplesPerSecond = 23449.0
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     0.14 seconds since last report (0.07 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 42.76k samplesPerSecond , throughputPerWorker = 21.38k samplesPerSecond
MPI Rank 1: 07/14/2016 12:43:46: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84658431 * 20480; EvalErrorPrediction = 0.51127930 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 1.4901161e-09; epochTime=0.486174s
MPI Rank 1: 07/14/2016 12:43:46: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160714124049.71991/Speech/DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 12:43:46: learnRatePerSample reduced to 7.4505807e-10
MPI Rank 1: 07/14/2016 12:43:46: Learn Rate Per Sample for Epoch[5] = 7.4505807e-10 is less than minLearnRate 9.9999997e-10. Training complete.
MPI Rank 1: 07/14/2016 12:43:46: CNTKCommandTrainEnd: speechTrain
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:43:46: Action "train" complete.
MPI Rank 1: 
MPI Rank 1: 07/14/2016 12:43:46: __COMPLETED__
MPI Rank 1: ~MPIWrapper
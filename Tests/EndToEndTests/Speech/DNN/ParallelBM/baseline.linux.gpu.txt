CPU info:
    CPU Model Name: Intel(R) Xeon(R) CPU E5-2630 v2 @ 2.60GHz
    Hardware threads: 24
    Total Memory: 264172964 kB
-------------------------------------------------------------------
=== Running mpiexec -n 2 /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/build/1bitsgd/debug/bin/cntk configFile=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/ParallelBM/../ParallelBM/cntk.cntk currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data RunDir=/tmp/cntk-test-20160713164744.999927/Speech/DNN_ParallelBM@debug_gpu DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/ParallelBM/.. OutputDir=/tmp/cntk-test-20160713164744.999927/Speech/DNN_ParallelBM@debug_gpu DeviceId=0 timestamping=true numCPUThreads=12 precision=double speechTrain=[SGD=[ParallelTrain=[parallelizationStartEpoch=2]]] stderr=/tmp/cntk-test-20160713164744.999927/Speech/DNN_ParallelBM@debug_gpu/stderr
-------------------------------------------------------------------
Build info: 

		Built time: Jul 13 2016 15:56:58
		Last modified date: Tue Jul 12 10:36:36 2016
		Build type: debug
		Build target: GPU
		With 1bit-SGD: yes
		Math lib: mkl
		CUDA_PATH: /usr/local/cuda-7.5
		CUB_PATH: /usr/local/cub-1.4.1
		CUDNN_PATH: /usr/local/cudnn-4.0
		Build Branch: HEAD
		Build SHA1: 539ab7467b022b4ffa087721bcf20d18485c8d0d
		Built by philly on a77bf6d98305
		Build Path: /home/philly/jenkins/workspace/CNTK-Build-Linux
-------------------------------------------------------------------
-------------------------------------------------------------------
Build info: 

		Built time: Jul 13 2016 15:56:58
		Last modified date: Tue Jul 12 10:36:36 2016
		Build type: debug
		Build target: GPU
		With 1bit-SGD: yes
		Math lib: mkl
		CUDA_PATH: /usr/local/cuda-7.5
		CUB_PATH: /usr/local/cub-1.4.1
		CUDNN_PATH: /usr/local/cudnn-4.0
		Build Branch: HEAD
		Build SHA1: 539ab7467b022b4ffa087721bcf20d18485c8d0d
		Built by philly on a77bf6d98305
		Build Path: /home/philly/jenkins/workspace/CNTK-Build-Linux
-------------------------------------------------------------------
Changed current directory to /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
Changed current directory to /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
MPIWrapper: initializing MPI
MPIWrapper: initializing MPI
ping [requestnodes (before change)]: 2 nodes pinging each other
ping [requestnodes (before change)]: 2 nodes pinging each other
ping [requestnodes (before change)]: all 2 nodes responded
requestnodes [MPIWrapper]: using 2 out of 2 MPI nodes (2 requested); we (1) are in (participating)
ping [requestnodes (before change)]: all 2 nodes responded
requestnodes [MPIWrapper]: using 2 out of 2 MPI nodes (2 requested); we (0) are in (participating)
ping [requestnodes (after change)]: 2 nodes pinging each other
ping [requestnodes (after change)]: all 2 nodes responded
mpihelper: we are cog 0 in a gearbox of 2
ping [mpihelper]: 2 nodes pinging each other
ping [requestnodes (after change)]: 2 nodes pinging each other
ping [requestnodes (after change)]: all 2 nodes responded
mpihelper: we are cog 1 in a gearbox of 2
ping [mpihelper]: 2 nodes pinging each other
ping [mpihelper]: all 2 nodes responded
ping [mpihelper]: all 2 nodes responded
07/13/2016 16:48:11: Redirecting stderr to file /tmp/cntk-test-20160713164744.999927/Speech/DNN_ParallelBM@debug_gpu/stderr_speechTrain.logrank0
07/13/2016 16:48:11: Redirecting stderr to file /tmp/cntk-test-20160713164744.999927/Speech/DNN_ParallelBM@debug_gpu/stderr_speechTrain.logrank1
MPI Rank 0: 07/13/2016 16:48:11: -------------------------------------------------------------------
MPI Rank 0: 07/13/2016 16:48:11: Build info: 
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:48:11: 		Built time: Jul 13 2016 15:56:58
MPI Rank 0: 07/13/2016 16:48:11: 		Last modified date: Tue Jul 12 10:36:36 2016
MPI Rank 0: 07/13/2016 16:48:11: 		Build type: debug
MPI Rank 0: 07/13/2016 16:48:11: 		Build target: GPU
MPI Rank 0: 07/13/2016 16:48:11: 		With 1bit-SGD: yes
MPI Rank 0: 07/13/2016 16:48:11: 		Math lib: mkl
MPI Rank 0: 07/13/2016 16:48:11: 		CUDA_PATH: /usr/local/cuda-7.5
MPI Rank 0: 07/13/2016 16:48:11: 		CUB_PATH: /usr/local/cub-1.4.1
MPI Rank 0: 07/13/2016 16:48:11: 		CUDNN_PATH: /usr/local/cudnn-4.0
MPI Rank 0: 07/13/2016 16:48:11: 		Build Branch: HEAD
MPI Rank 0: 07/13/2016 16:48:11: 		Build SHA1: 539ab7467b022b4ffa087721bcf20d18485c8d0d
MPI Rank 0: 07/13/2016 16:48:11: 		Built by philly on a77bf6d98305
MPI Rank 0: 07/13/2016 16:48:11: 		Build Path: /home/philly/jenkins/workspace/CNTK-Build-Linux
MPI Rank 0: 07/13/2016 16:48:11: -------------------------------------------------------------------
MPI Rank 0: 07/13/2016 16:48:12: -------------------------------------------------------------------
MPI Rank 0: 07/13/2016 16:48:12: GPU info:
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:48:12: 		Device[0]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3071 MB
MPI Rank 0: 07/13/2016 16:48:12: 		Device[1]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3071 MB
MPI Rank 0: 07/13/2016 16:48:12: 		Device[2]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3071 MB
MPI Rank 0: 07/13/2016 16:48:12: 		Device[3]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3071 MB
MPI Rank 0: 07/13/2016 16:48:12: -------------------------------------------------------------------
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:48:12: Running on localhost at 2016/07/13 16:48:12
MPI Rank 0: 07/13/2016 16:48:12: Command line: 
MPI Rank 0: /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/build/1bitsgd/debug/bin/cntk  configFile=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/ParallelBM/../ParallelBM/cntk.cntk  currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data  RunDir=/tmp/cntk-test-20160713164744.999927/Speech/DNN_ParallelBM@debug_gpu  DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data  ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/ParallelBM/..  OutputDir=/tmp/cntk-test-20160713164744.999927/Speech/DNN_ParallelBM@debug_gpu  DeviceId=0  timestamping=true  numCPUThreads=12  precision=double  speechTrain=[SGD=[ParallelTrain=[parallelizationStartEpoch=2]]]  stderr=/tmp/cntk-test-20160713164744.999927/Speech/DNN_ParallelBM@debug_gpu/stderr
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:48:12: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
MPI Rank 0: 07/13/2016 16:48:12: precision = "float"
MPI Rank 0: command = speechTrain
MPI Rank 0: deviceId = $DeviceId$
MPI Rank 0: parallelTrain = true
MPI Rank 0: speechTrain = [
MPI Rank 0:     action = "train"
MPI Rank 0:     modelPath = "$RunDir$/models/cntkSpeech.dnn"
MPI Rank 0:     deviceId = $DeviceId$
MPI Rank 0:     traceLevel = 1
MPI Rank 0:     SimpleNetworkBuilder = [
MPI Rank 0:         layerSizes = 363:512:512:132
MPI Rank 0:         trainingCriterion = "CrossEntropyWithSoftmax"
MPI Rank 0:         evalCriterion = "ErrorPrediction"
MPI Rank 0:         layerTypes = "Sigmoid"
MPI Rank 0:         initValueScale = 1.0
MPI Rank 0:         applyMeanVarNorm = true
MPI Rank 0:         uniformInit = true
MPI Rank 0:         needPrior = true
MPI Rank 0:     ]
MPI Rank 0:     ExperimentalNetworkBuilder = [    // the same as above but with BS. Not active; activate by commenting out the SimpleNetworkBuilder entry above
MPI Rank 0:         layerSizes = 363:512:512:132
MPI Rank 0:         trainingCriterion = 'CE'
MPI Rank 0:         evalCriterion = 'Err'
MPI Rank 0:         applyMeanVarNorm = true
MPI Rank 0:         L = Length(layerSizes)-1    // number of model layers
MPI Rank 0:         features = Input(layerSizes[0], 1, tag='feature') ; labels = Input(layerSizes[Length(layerSizes)-1], 1, tag='label')
MPI Rank 0:         featNorm = if applyMeanVarNorm
MPI Rank 0:                    then MeanVarNorm(features)
MPI Rank 0:                    else features
MPI Rank 0:         layers[layer:1..L-1] = if layer > 1
MPI Rank 0:                                then SBFF(layers[layer-1].Eh, layerSizes[layer], layerSizes[layer-1])
MPI Rank 0:                                else SBFF(featNorm, layerSizes[layer], layerSizes[layer-1])
MPI Rank 0:         outLayer = BFF(layers[L-1].Eh, layerSizes[L], layerSizes[L-1])
MPI Rank 0:         outZ = outLayer.z        // + PastValue(layerSizes[L], 1, outLayer.z)
MPI Rank 0:         CE = if trainingCriterion == 'CE'
MPI Rank 0:              then CrossEntropyWithSoftmax(labels, outZ, tag='criterion')
MPI Rank 0:              else Fail('unknown trainingCriterion ' + trainingCriterion)
MPI Rank 0:         Err = if evalCriterion == 'Err' then
MPI Rank 0:               ErrorPrediction(labels, outZ, tag='evaluation')
MPI Rank 0:               else Fail('unknown evalCriterion ' + evalCriterion)
MPI Rank 0:         logPrior = LogPrior(labels)
MPI Rank 0:         // TODO: how to add a tag to an infix operation?
MPI Rank 0:         ScaledLogLikelihood = Minus (outZ, logPrior, tag='output')
MPI Rank 0:     ]
MPI Rank 0:     SGD = [
MPI Rank 0:         epochSize = 20480
MPI Rank 0:         minibatchSize = 64:256:1024
MPI Rank 0:         learningRatesPerMB = 1.0:0.5:0.1
MPI Rank 0:         numMBsToShowResult = 3
MPI Rank 0:         momentumPerMB = 0.9:0.656119
MPI Rank 0:         dropoutRate = 0.0
MPI Rank 0:         maxEpochs = 5
MPI Rank 0:         keepCheckPointFiles = true
MPI Rank 0:         clippingThresholdPerSample = 1#INF
MPI Rank 0:         ParallelTrain = [
MPI Rank 0:             parallelizationMethod = "BlockMomentumSGD"
MPI Rank 0:             distributedMBReading = true
MPI Rank 0:             syncPerfStats=1
MPI Rank 0:             BlockMomentumSGD = [
MPI Rank 0:                 blockSizePerWorker=2048
MPI Rank 0:                 resetSGDMomentum=true
MPI Rank 0:                 useNesterovMomentum=true
MPI Rank 0:             ]
MPI Rank 0:         ]
MPI Rank 0:         AutoAdjust = [
MPI Rank 0:             reduceLearnRateIfImproveLessThan = 0
MPI Rank 0:             loadBestModel = true
MPI Rank 0:             increaseLearnRateIfImproveMoreThan = 1000000000
MPI Rank 0:             learnRateDecreaseFactor = 0.5
MPI Rank 0:             learnRateIncreaseFactor = 1.382
MPI Rank 0:             autoAdjustLR = "adjustAfterEpoch"
MPI Rank 0:         ]
MPI Rank 0:     ]
MPI Rank 0:     reader = [
MPI Rank 0:         readerType = "HTKMLFReader"
MPI Rank 0:         readMethod = "blockRandomize"
MPI Rank 0:         miniBatchMode = "partial"
MPI Rank 0:         randomize = "auto"
MPI Rank 0:         verbosity = 0
MPI Rank 0:         features = [
MPI Rank 0:             dim = 363
MPI Rank 0:             type = "real"
MPI Rank 0:             scpFile = "glob_0000.scp"
MPI Rank 0:         ]
MPI Rank 0:         labels = [
MPI Rank 0:             mlfFile = "$DataDir$/glob_0000.mlf"
MPI Rank 0:             labelMappingFile = "$DataDir$/state.list"
MPI Rank 0:             labelDim = 132
MPI Rank 0:             labelType = "category"
MPI Rank 0:         ]
MPI Rank 0:     ]
MPI Rank 0: ]
MPI Rank 0: currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
MPI Rank 0: RunDir=/tmp/cntk-test-20160713164744.999927/Speech/DNN_ParallelBM@debug_gpu
MPI Rank 0: DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
MPI Rank 0: ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/ParallelBM/..
MPI Rank 0: OutputDir=/tmp/cntk-test-20160713164744.999927/Speech/DNN_ParallelBM@debug_gpu
MPI Rank 0: DeviceId=0
MPI Rank 0: timestamping=true
MPI Rank 0: numCPUThreads=12
MPI Rank 0: precision=double
MPI Rank 0: speechTrain=[SGD=[ParallelTrain=[parallelizationStartEpoch=2]]]
MPI Rank 0: stderr=/tmp/cntk-test-20160713164744.999927/Speech/DNN_ParallelBM@debug_gpu/stderr
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:48:12: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:48:12: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 0: 07/13/2016 16:48:12: precision = "float"
MPI Rank 0: command = speechTrain
MPI Rank 0: deviceId = 0
MPI Rank 0: parallelTrain = true
MPI Rank 0: speechTrain = [
MPI Rank 0:     action = "train"
MPI Rank 0:     modelPath = "/tmp/cntk-test-20160713164744.999927/Speech/DNN_ParallelBM@debug_gpu/models/cntkSpeech.dnn"
MPI Rank 0:     deviceId = 0
MPI Rank 0:     traceLevel = 1
MPI Rank 0:     SimpleNetworkBuilder = [
MPI Rank 0:         layerSizes = 363:512:512:132
MPI Rank 0:         trainingCriterion = "CrossEntropyWithSoftmax"
MPI Rank 0:         evalCriterion = "ErrorPrediction"
MPI Rank 0:         layerTypes = "Sigmoid"
MPI Rank 0:         initValueScale = 1.0
MPI Rank 0:         applyMeanVarNorm = true
MPI Rank 0:         uniformInit = true
MPI Rank 0:         needPrior = true
MPI Rank 0:     ]
MPI Rank 0:     ExperimentalNetworkBuilder = [    // the same as above but with BS. Not active; activate by commenting out the SimpleNetworkBuilder entry above
MPI Rank 0:         layerSizes = 363:512:512:132
MPI Rank 0:         trainingCriterion = 'CE'
MPI Rank 0:         evalCriterion = 'Err'
MPI Rank 0:         applyMeanVarNorm = true
MPI Rank 0:         L = Length(layerSizes)-1    // number of model layers
MPI Rank 0:         features = Input(layerSizes[0], 1, tag='feature') ; labels = Input(layerSizes[Length(layerSizes)-1], 1, tag='label')
MPI Rank 0:         featNorm = if applyMeanVarNorm
MPI Rank 0:                    then MeanVarNorm(features)
MPI Rank 0:                    else features
MPI Rank 0:         layers[layer:1..L-1] = if layer > 1
MPI Rank 0:                                then SBFF(layers[layer-1].Eh, layerSizes[layer], layerSizes[layer-1])
MPI Rank 0:                                else SBFF(featNorm, layerSizes[layer], layerSizes[layer-1])
MPI Rank 0:         outLayer = BFF(layers[L-1].Eh, layerSizes[L], layerSizes[L-1])
MPI Rank 0:         outZ = outLayer.z        // + PastValue(layerSizes[L], 1, outLayer.z)
MPI Rank 0:         CE = if trainingCriterion == 'CE'
MPI Rank 0:              then CrossEntropyWithSoftmax(labels, outZ, tag='criterion')
MPI Rank 0:              else Fail('unknown trainingCriterion ' + trainingCriterion)
MPI Rank 0:         Err = if evalCriterion == 'Err' then
MPI Rank 0:               ErrorPrediction(labels, outZ, tag='evaluation')
MPI Rank 0:               else Fail('unknown evalCriterion ' + evalCriterion)
MPI Rank 0:         logPrior = LogPrior(labels)
MPI Rank 0:         // TODO: how to add a tag to an infix operation?
MPI Rank 0:         ScaledLogLikelihood = Minus (outZ, logPrior, tag='output')
MPI Rank 0:     ]
MPI Rank 0:     SGD = [
MPI Rank 0:         epochSize = 20480
MPI Rank 0:         minibatchSize = 64:256:1024
MPI Rank 0:         learningRatesPerMB = 1.0:0.5:0.1
MPI Rank 0:         numMBsToShowResult = 3
MPI Rank 0:         momentumPerMB = 0.9:0.656119
MPI Rank 0:         dropoutRate = 0.0
MPI Rank 0:         maxEpochs = 5
MPI Rank 0:         keepCheckPointFiles = true
MPI Rank 0:         clippingThresholdPerSample = 1#INF
MPI Rank 0:         ParallelTrain = [
MPI Rank 0:             parallelizationMethod = "BlockMomentumSGD"
MPI Rank 0:             distributedMBReading = true
MPI Rank 0:             syncPerfStats=1
MPI Rank 0:             BlockMomentumSGD = [
MPI Rank 0:                 blockSizePerWorker=2048
MPI Rank 0:                 resetSGDMomentum=true
MPI Rank 0:                 useNesterovMomentum=true
MPI Rank 0:             ]
MPI Rank 0:         ]
MPI Rank 0:         AutoAdjust = [
MPI Rank 0:             reduceLearnRateIfImproveLessThan = 0
MPI Rank 0:             loadBestModel = true
MPI Rank 0:             increaseLearnRateIfImproveMoreThan = 1000000000
MPI Rank 0:             learnRateDecreaseFactor = 0.5
MPI Rank 0:             learnRateIncreaseFactor = 1.382
MPI Rank 0:             autoAdjustLR = "adjustAfterEpoch"
MPI Rank 0:         ]
MPI Rank 0:     ]
MPI Rank 0:     reader = [
MPI Rank 0:         readerType = "HTKMLFReader"
MPI Rank 0:         readMethod = "blockRandomize"
MPI Rank 0:         miniBatchMode = "partial"
MPI Rank 0:         randomize = "auto"
MPI Rank 0:         verbosity = 0
MPI Rank 0:         features = [
MPI Rank 0:             dim = 363
MPI Rank 0:             type = "real"
MPI Rank 0:             scpFile = "glob_0000.scp"
MPI Rank 0:         ]
MPI Rank 0:         labels = [
MPI Rank 0:             mlfFile = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/glob_0000.mlf"
MPI Rank 0:             labelMappingFile = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/state.list"
MPI Rank 0:             labelDim = 132
MPI Rank 0:             labelType = "category"
MPI Rank 0:         ]
MPI Rank 0:     ]
MPI Rank 0: ]
MPI Rank 0: currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
MPI Rank 0: RunDir=/tmp/cntk-test-20160713164744.999927/Speech/DNN_ParallelBM@debug_gpu
MPI Rank 0: DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
MPI Rank 0: ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/ParallelBM/..
MPI Rank 0: OutputDir=/tmp/cntk-test-20160713164744.999927/Speech/DNN_ParallelBM@debug_gpu
MPI Rank 0: DeviceId=0
MPI Rank 0: timestamping=true
MPI Rank 0: numCPUThreads=12
MPI Rank 0: precision=double
MPI Rank 0: speechTrain=[SGD=[ParallelTrain=[parallelizationStartEpoch=2]]]
MPI Rank 0: stderr=/tmp/cntk-test-20160713164744.999927/Speech/DNN_ParallelBM@debug_gpu/stderr
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:48:12: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:48:12: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 0: configparameters: cntk.cntk:command=speechTrain
MPI Rank 0: configparameters: cntk.cntk:ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/ParallelBM/..
MPI Rank 0: configparameters: cntk.cntk:currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
MPI Rank 0: configparameters: cntk.cntk:DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
MPI Rank 0: configparameters: cntk.cntk:deviceId=0
MPI Rank 0: configparameters: cntk.cntk:numCPUThreads=12
MPI Rank 0: configparameters: cntk.cntk:OutputDir=/tmp/cntk-test-20160713164744.999927/Speech/DNN_ParallelBM@debug_gpu
MPI Rank 0: configparameters: cntk.cntk:parallelTrain=true
MPI Rank 0: configparameters: cntk.cntk:precision=double
MPI Rank 0: configparameters: cntk.cntk:RunDir=/tmp/cntk-test-20160713164744.999927/Speech/DNN_ParallelBM@debug_gpu
MPI Rank 0: configparameters: cntk.cntk:speechTrain=[
MPI Rank 0:     action = "train"
MPI Rank 0:     modelPath = "/tmp/cntk-test-20160713164744.999927/Speech/DNN_ParallelBM@debug_gpu/models/cntkSpeech.dnn"
MPI Rank 0:     deviceId = 0
MPI Rank 0:     traceLevel = 1
MPI Rank 0:     SimpleNetworkBuilder = [
MPI Rank 0:         layerSizes = 363:512:512:132
MPI Rank 0:         trainingCriterion = "CrossEntropyWithSoftmax"
MPI Rank 0:         evalCriterion = "ErrorPrediction"
MPI Rank 0:         layerTypes = "Sigmoid"
MPI Rank 0:         initValueScale = 1.0
MPI Rank 0:         applyMeanVarNorm = true
MPI Rank 0:         uniformInit = true
MPI Rank 0:         needPrior = true
MPI Rank 0:     ]
MPI Rank 0:     ExperimentalNetworkBuilder = [    // the same as above but with BS. Not active; activate by commenting out the SimpleNetworkBuilder entry above
MPI Rank 0:         layerSizes = 363:512:512:132
MPI Rank 0:         trainingCriterion = 'CE'
MPI Rank 0:         evalCriterion = 'Err'
MPI Rank 0:         applyMeanVarNorm = true
MPI Rank 0:         L = Length(layerSizes)-1    // number of model layers
MPI Rank 0:         features = Input(layerSizes[0], 1, tag='feature') ; labels = Input(layerSizes[Length(layerSizes)-1], 1, tag='label')
MPI Rank 0:         featNorm = if applyMeanVarNorm
MPI Rank 0:                    then MeanVarNorm(features)
MPI Rank 0:                    else features
MPI Rank 0:         layers[layer:1..L-1] = if layer > 1
MPI Rank 0:                                then SBFF(layers[layer-1].Eh, layerSizes[layer], layerSizes[layer-1])
MPI Rank 0:                                else SBFF(featNorm, layerSizes[layer], layerSizes[layer-1])
MPI Rank 0:         outLayer = BFF(layers[L-1].Eh, layerSizes[L], layerSizes[L-1])
MPI Rank 0:         outZ = outLayer.z        // + PastValue(layerSizes[L], 1, outLayer.z)
MPI Rank 0:         CE = if trainingCriterion == 'CE'
MPI Rank 0:              then CrossEntropyWithSoftmax(labels, outZ, tag='criterion')
MPI Rank 0:              else Fail('unknown trainingCriterion ' + trainingCriterion)
MPI Rank 0:         Err = if evalCriterion == 'Err' then
MPI Rank 0:               ErrorPrediction(labels, outZ, tag='evaluation')
MPI Rank 0:               else Fail('unknown evalCriterion ' + evalCriterion)
MPI Rank 0:         logPrior = LogPrior(labels)
MPI Rank 0:         // TODO: how to add a tag to an infix operation?
MPI Rank 0:         ScaledLogLikelihood = Minus (outZ, logPrior, tag='output')
MPI Rank 0:     ]
MPI Rank 0:     SGD = [
MPI Rank 0:         epochSize = 20480
MPI Rank 0:         minibatchSize = 64:256:1024
MPI Rank 0:         learningRatesPerMB = 1.0:0.5:0.1
MPI Rank 0:         numMBsToShowResult = 3
MPI Rank 0:         momentumPerMB = 0.9:0.656119
MPI Rank 0:         dropoutRate = 0.0
MPI Rank 0:         maxEpochs = 5
MPI Rank 0:         keepCheckPointFiles = true
MPI Rank 0:         clippingThresholdPerSample = 1#INF
MPI Rank 0:         ParallelTrain = [
MPI Rank 0:             parallelizationMethod = "BlockMomentumSGD"
MPI Rank 0:             distributedMBReading = true
MPI Rank 0:             syncPerfStats=1
MPI Rank 0:             BlockMomentumSGD = [
MPI Rank 0:                 blockSizePerWorker=2048
MPI Rank 0:                 resetSGDMomentum=true
MPI Rank 0:                 useNesterovMomentum=true
MPI Rank 0:             ]
MPI Rank 0:         ]
MPI Rank 0:         AutoAdjust = [
MPI Rank 0:             reduceLearnRateIfImproveLessThan = 0
MPI Rank 0:             loadBestModel = true
MPI Rank 0:             increaseLearnRateIfImproveMoreThan = 1000000000
MPI Rank 0:             learnRateDecreaseFactor = 0.5
MPI Rank 0:             learnRateIncreaseFactor = 1.382
MPI Rank 0:             autoAdjustLR = "adjustAfterEpoch"
MPI Rank 0:         ]
MPI Rank 0:     ]
MPI Rank 0:     reader = [
MPI Rank 0:         readerType = "HTKMLFReader"
MPI Rank 0:         readMethod = "blockRandomize"
MPI Rank 0:         miniBatchMode = "partial"
MPI Rank 0:         randomize = "auto"
MPI Rank 0:         verbosity = 0
MPI Rank 0:         features = [
MPI Rank 0:             dim = 363
MPI Rank 0:             type = "real"
MPI Rank 0:             scpFile = "glob_0000.scp"
MPI Rank 0:         ]
MPI Rank 0:         labels = [
MPI Rank 0:             mlfFile = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/glob_0000.mlf"
MPI Rank 0:             labelMappingFile = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/state.list"
MPI Rank 0:             labelDim = 132
MPI Rank 0:             labelType = "category"
MPI Rank 0:         ]
MPI Rank 0:     ]
MPI Rank 0: ] [SGD=[ParallelTrain=[parallelizationStartEpoch=2]]]
MPI Rank 0: 
MPI Rank 0: configparameters: cntk.cntk:stderr=/tmp/cntk-test-20160713164744.999927/Speech/DNN_ParallelBM@debug_gpu/stderr
MPI Rank 0: configparameters: cntk.cntk:timestamping=true
MPI Rank 0: 07/13/2016 16:48:12: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 0: 07/13/2016 16:48:12: Commands: speechTrain
MPI Rank 0: 07/13/2016 16:48:12: Precision = "double"
MPI Rank 0: 07/13/2016 16:48:12: Using 12 CPU threads.
MPI Rank 0: 07/13/2016 16:48:12: CNTKModelPath: /tmp/cntk-test-20160713164744.999927/Speech/DNN_ParallelBM@debug_gpu/models/cntkSpeech.dnn
MPI Rank 0: 07/13/2016 16:48:12: CNTKCommandTrainInfo: speechTrain : 5
MPI Rank 0: 07/13/2016 16:48:12: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 5
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:48:12: ##############################################################################
MPI Rank 0: 07/13/2016 16:48:12: #                                                                            #
MPI Rank 0: 07/13/2016 16:48:12: # Action "train"                                                             #
MPI Rank 0: 07/13/2016 16:48:12: #                                                                            #
MPI Rank 0: 07/13/2016 16:48:12: ##############################################################################
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:48:12: CNTKCommandTrainBegin: speechTrain
MPI Rank 0: SimpleNetworkBuilder Using GPU 0
MPI Rank 0: reading script file glob_0000.scp ... 948 entries
MPI Rank 0: total 132 state names in state list /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/state.list
MPI Rank 0: htkmlfreader: reading MLF file /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/glob_0000.mlf ... total 948 entries
MPI Rank 0: ...............................................................................................feature set 0: 252734 frames in 948 out of 948 utterances
MPI Rank 0: label set 0: 129 classes
MPI Rank 0: minibatchutterancesource: 948 utterances grouped into 3 chunks, av. chunk size: 316.0 utterances, 84244.7 frames
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:48:12: Creating virgin network.
MPI Rank 0: SetUniformRandomValue (GPU): creating curand object with seed 1, sizeof(ElemType)==8
MPI Rank 0: 
MPI Rank 0: Post-processing network...
MPI Rank 0: 
MPI Rank 0: 7 roots:
MPI Rank 0: 	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
MPI Rank 0: 	EvalErrorPrediction = ErrorPrediction()
MPI Rank 0: 	InvStdOfFeatures = InvStdDev()
MPI Rank 0: 	MeanOfFeatures = Mean()
MPI Rank 0: 	PosteriorProb = Softmax()
MPI Rank 0: 	Prior = Mean()
MPI Rank 0: 	ScaledLogLikelihood = Minus()
MPI Rank 0: 
MPI Rank 0: Validating network. 25 nodes to process in pass 1.
MPI Rank 0: 
MPI Rank 0: Validating --> labels = InputValue() :  -> [132 x *]
MPI Rank 0: Validating --> W2 = LearnableParameter() :  -> [132 x 512]
MPI Rank 0: Validating --> W1 = LearnableParameter() :  -> [512 x 512]
MPI Rank 0: Validating --> W0 = LearnableParameter() :  -> [512 x 363]
MPI Rank 0: Validating --> features = InputValue() :  -> [363 x *]
MPI Rank 0: Validating --> MeanOfFeatures = Mean (features) : [363 x *] -> [363]
MPI Rank 0: Validating --> InvStdOfFeatures = InvStdDev (features) : [363 x *] -> [363]
MPI Rank 0: Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [363 x *], [363], [363] -> [363 x *]
MPI Rank 0: Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [512 x 363], [363 x *] -> [512 x *]
MPI Rank 0: Validating --> B0 = LearnableParameter() :  -> [512 x 1]
MPI Rank 0: Validating --> W0*features+B0 = Plus (W0*features, B0) : [512 x *], [512 x 1] -> [512 x 1 x *]
MPI Rank 0: Validating --> H1 = Sigmoid (W0*features+B0) : [512 x 1 x *] -> [512 x 1 x *]
MPI Rank 0: Validating --> W1*H1 = Times (W1, H1) : [512 x 512], [512 x 1 x *] -> [512 x 1 x *]
MPI Rank 0: Validating --> B1 = LearnableParameter() :  -> [512 x 1]
MPI Rank 0: Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [512 x 1 x *], [512 x 1] -> [512 x 1 x *]
MPI Rank 0: Validating --> H2 = Sigmoid (W1*H1+B1) : [512 x 1 x *] -> [512 x 1 x *]
MPI Rank 0: Validating --> W2*H1 = Times (W2, H2) : [132 x 512], [512 x 1 x *] -> [132 x 1 x *]
MPI Rank 0: Validating --> B2 = LearnableParameter() :  -> [132 x 1]
MPI Rank 0: Validating --> HLast = Plus (W2*H1, B2) : [132 x 1 x *], [132 x 1] -> [132 x 1 x *]
MPI Rank 0: Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [132 x *], [132 x 1 x *] -> [1]
MPI Rank 0: Validating --> EvalErrorPrediction = ErrorPrediction (labels, HLast) : [132 x *], [132 x 1 x *] -> [1]
MPI Rank 0: Validating --> PosteriorProb = Softmax (HLast) : [132 x 1 x *] -> [132 x 1 x *]
MPI Rank 0: Validating --> Prior = Mean (labels) : [132 x *] -> [132]
MPI Rank 0: Validating --> LogOfPrior = Log (Prior) : [132] -> [132]
MPI Rank 0: Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [132 x 1 x *], [132] -> [132 x 1 x *]
MPI Rank 0: 
MPI Rank 0: Validating network. 17 nodes to process in pass 2.
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: Validating network, final pass.
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: 12 out of 25 nodes do not share the minibatch layout with the input data.
MPI Rank 0: 
MPI Rank 0: Post-processing network complete.
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:48:13: Created model with 25 nodes on GPU 0.
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:48:13: Training criterion node(s):
MPI Rank 0: 07/13/2016 16:48:13: 	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:48:13: Evaluation criterion node(s):
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:48:13: 	EvalErrorPrediction = ErrorPrediction
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: Allocating matrices for forward and/or backward propagation.
MPI Rank 0: 
MPI Rank 0: Memory Sharing Structure:
MPI Rank 0: 
MPI Rank 0: (nil): {[EvalErrorPrediction Gradient[1]] [InvStdOfFeatures Gradient[363]] [LogOfPrior Gradient[132]] [MVNormalizedFeatures Gradient[363 x *]] [MeanOfFeatures Gradient[363]] [PosteriorProb Gradient[132 x 1 x *]] [PosteriorProb Value[132 x 1 x *]] [Prior Gradient[132]] [ScaledLogLikelihood Gradient[132 x 1 x *]] [features Gradient[363 x *]] [labels Gradient[132 x *]] }
MPI Rank 0: 0x39d8728: {[features Value[363 x *]] }
MPI Rank 0: 0x7fc5c93d93c8: {[B0 Value[512 x 1]] }
MPI Rank 0: 0x7fc5c93db6f8: {[W1 Value[512 x 512]] }
MPI Rank 0: 0x7fc5cab98aa8: {[B1 Value[512 x 1]] }
MPI Rank 0: 0x7fc5cab99c28: {[W2 Value[132 x 512]] }
MPI Rank 0: 0x7fc5cab9a8d8: {[B2 Value[132 x 1]] }
MPI Rank 0: 0x7fc5cab9b708: {[labels Value[132 x *]] }
MPI Rank 0: 0x7fc5cab9c968: {[Prior Value[132]] }
MPI Rank 0: 0x7fc5caba2488: {[EvalErrorPrediction Value[1]] }
MPI Rank 0: 0x7fc5caba25e8: {[ScaledLogLikelihood Value[132 x 1 x *]] }
MPI Rank 0: 0x7fc5caba27a8: {[CrossEntropyWithSoftmax Value[1]] }
MPI Rank 0: 0x7fc5caba2d28: {[LogOfPrior Value[132]] }
MPI Rank 0: 0x7fc5caba3f48: {[MVNormalizedFeatures Value[363 x *]] }
MPI Rank 0: 0x7fc5caba4648: {[W0*features Value[512 x *]] }
MPI Rank 0: 0x7fc5caba4b78: {[W0 Gradient[512 x 363]] [W0*features+B0 Value[512 x 1 x *]] }
MPI Rank 0: 0x7fc5caba4cd8: {[H1 Value[512 x 1 x *]] [W0*features Gradient[512 x *]] }
MPI Rank 0: 0x7fc5caba4e98: {[W0*features+B0 Gradient[512 x 1 x *]] [W1*H1 Value[512 x 1 x *]] }
MPI Rank 0: 0x7fc5caba5058: {[W1 Gradient[512 x 512]] [W1*H1+B1 Value[512 x 1 x *]] }
MPI Rank 0: 0x7fc5caba5218: {[H2 Value[512 x 1 x *]] [W1*H1 Gradient[512 x 1 x *]] }
MPI Rank 0: 0x7fc5caba53d8: {[B0 Gradient[512 x 1]] [H1 Gradient[512 x 1 x *]] [W1*H1+B1 Gradient[512 x 1 x *]] [W2*H1 Value[132 x 1 x *]] }
MPI Rank 0: 0x7fc5caba5598: {[HLast Value[132 x 1 x *]] [W2 Gradient[132 x 512]] }
MPI Rank 0: 0x7fc5caba60f8: {[CrossEntropyWithSoftmax Gradient[1]] }
MPI Rank 0: 0x7fc5caba62b8: {[B1 Gradient[512 x 1]] [H2 Gradient[512 x 1 x *]] [HLast Gradient[132 x 1 x *]] }
MPI Rank 0: 0x7fc5caba6478: {[W2*H1 Gradient[132 x 1 x *]] }
MPI Rank 0: 0x7fc5caba6638: {[B2 Gradient[132 x 1]] }
MPI Rank 0: 0x7fc5e6796478: {[MeanOfFeatures Value[363]] }
MPI Rank 0: 0x7fc5e6796968: {[InvStdOfFeatures Value[363]] }
MPI Rank 0: 0x7fc5e67976b8: {[W0 Value[512 x 363]] }
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:48:13: Precomputing --> 3 PreCompute nodes found.
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:48:13: 	MeanOfFeatures = Mean()
MPI Rank 0: 07/13/2016 16:48:13: 	InvStdOfFeatures = InvStdDev()
MPI Rank 0: 07/13/2016 16:48:13: 	Prior = Mean()
MPI Rank 0: minibatchiterator: epoch 0: frames [0..252734] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
MPI Rank 0: requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:48:26: Precomputing --> Completed.
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:48:26: Starting Epoch 1: learning rate per sample = 0.015625  effective momentum = 0.900000  momentum as time constant = 607.4 samples
MPI Rank 0: minibatchiterator: epoch 0: frames [0..20480] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:48:26: Starting minibatch loop.
MPI Rank 0: 07/13/2016 16:48:26:  Epoch[ 1 of 5]-Minibatch[   1-   3, 0.94%]: CrossEntropyWithSoftmax = 4.57947979 * 192; EvalErrorPrediction = 0.96354167 * 192; time = 0.0472s; samplesPerSecond = 4069.7
MPI Rank 0: 07/13/2016 16:48:26:  Epoch[ 1 of 5]-Minibatch[   4-   6, 1.88%]: CrossEntropyWithSoftmax = 4.45832105 * 192; EvalErrorPrediction = 0.90104167 * 192; time = 0.0468s; samplesPerSecond = 4106.9
MPI Rank 0: 07/13/2016 16:48:26:  Epoch[ 1 of 5]-Minibatch[   7-   9, 2.81%]: CrossEntropyWithSoftmax = 4.29176856 * 192; EvalErrorPrediction = 0.85416667 * 192; time = 0.0468s; samplesPerSecond = 4098.8
MPI Rank 0: 07/13/2016 16:48:26:  Epoch[ 1 of 5]-Minibatch[  10-  12, 3.75%]: CrossEntropyWithSoftmax = 4.15840784 * 192; EvalErrorPrediction = 0.86979167 * 192; time = 0.0450s; samplesPerSecond = 4267.6
MPI Rank 0: 07/13/2016 16:48:26:  Epoch[ 1 of 5]-Minibatch[  13-  15, 4.69%]: CrossEntropyWithSoftmax = 4.21435783 * 192; EvalErrorPrediction = 0.86979167 * 192; time = 0.0457s; samplesPerSecond = 4203.7
MPI Rank 0: 07/13/2016 16:48:26:  Epoch[ 1 of 5]-Minibatch[  16-  18, 5.62%]: CrossEntropyWithSoftmax = 4.14020622 * 192; EvalErrorPrediction = 0.89583333 * 192; time = 0.0444s; samplesPerSecond = 4321.3
MPI Rank 0: 07/13/2016 16:48:26:  Epoch[ 1 of 5]-Minibatch[  19-  21, 6.56%]: CrossEntropyWithSoftmax = 4.04069876 * 192; EvalErrorPrediction = 0.85416667 * 192; time = 0.0453s; samplesPerSecond = 4238.5
MPI Rank 0: 07/13/2016 16:48:26:  Epoch[ 1 of 5]-Minibatch[  22-  24, 7.50%]: CrossEntropyWithSoftmax = 4.04991414 * 192; EvalErrorPrediction = 0.91666667 * 192; time = 0.0457s; samplesPerSecond = 4205.1
MPI Rank 0: 07/13/2016 16:48:26:  Epoch[ 1 of 5]-Minibatch[  25-  27, 8.44%]: CrossEntropyWithSoftmax = 3.88626656 * 192; EvalErrorPrediction = 0.84375000 * 192; time = 0.0433s; samplesPerSecond = 4434.0
MPI Rank 0: 07/13/2016 16:48:26:  Epoch[ 1 of 5]-Minibatch[  28-  30, 9.38%]: CrossEntropyWithSoftmax = 4.00467833 * 192; EvalErrorPrediction = 0.88020833 * 192; time = 0.0425s; samplesPerSecond = 4521.8
MPI Rank 0: 07/13/2016 16:48:26:  Epoch[ 1 of 5]-Minibatch[  31-  33, 10.31%]: CrossEntropyWithSoftmax = 3.94077029 * 192; EvalErrorPrediction = 0.86458333 * 192; time = 0.0421s; samplesPerSecond = 4559.4
MPI Rank 0: 07/13/2016 16:48:26:  Epoch[ 1 of 5]-Minibatch[  34-  36, 11.25%]: CrossEntropyWithSoftmax = 3.78326806 * 192; EvalErrorPrediction = 0.89062500 * 192; time = 0.0421s; samplesPerSecond = 4565.1
MPI Rank 0: 07/13/2016 16:48:26:  Epoch[ 1 of 5]-Minibatch[  37-  39, 12.19%]: CrossEntropyWithSoftmax = 3.94698521 * 192; EvalErrorPrediction = 0.89062500 * 192; time = 0.0421s; samplesPerSecond = 4564.4
MPI Rank 0: 07/13/2016 16:48:27:  Epoch[ 1 of 5]-Minibatch[  40-  42, 13.12%]: CrossEntropyWithSoftmax = 3.66011602 * 192; EvalErrorPrediction = 0.84895833 * 192; time = 0.0421s; samplesPerSecond = 4556.7
MPI Rank 0: 07/13/2016 16:48:27:  Epoch[ 1 of 5]-Minibatch[  43-  45, 14.06%]: CrossEntropyWithSoftmax = 3.98797978 * 192; EvalErrorPrediction = 0.91666667 * 192; time = 0.0421s; samplesPerSecond = 4557.8
MPI Rank 0: 07/13/2016 16:48:27:  Epoch[ 1 of 5]-Minibatch[  46-  48, 15.00%]: CrossEntropyWithSoftmax = 3.76297655 * 192; EvalErrorPrediction = 0.87500000 * 192; time = 0.0421s; samplesPerSecond = 4563.2
MPI Rank 0: 07/13/2016 16:48:27:  Epoch[ 1 of 5]-Minibatch[  49-  51, 15.94%]: CrossEntropyWithSoftmax = 3.69909670 * 192; EvalErrorPrediction = 0.89062500 * 192; time = 0.0420s; samplesPerSecond = 4568.4
MPI Rank 0: 07/13/2016 16:48:27:  Epoch[ 1 of 5]-Minibatch[  52-  54, 16.88%]: CrossEntropyWithSoftmax = 3.83747989 * 192; EvalErrorPrediction = 0.90104167 * 192; time = 0.0421s; samplesPerSecond = 4564.3
MPI Rank 0: 07/13/2016 16:48:27:  Epoch[ 1 of 5]-Minibatch[  55-  57, 17.81%]: CrossEntropyWithSoftmax = 3.82672791 * 192; EvalErrorPrediction = 0.89062500 * 192; time = 0.0419s; samplesPerSecond = 4579.8
MPI Rank 0: 07/13/2016 16:48:27:  Epoch[ 1 of 5]-Minibatch[  58-  60, 18.75%]: CrossEntropyWithSoftmax = 3.56520696 * 192; EvalErrorPrediction = 0.83333333 * 192; time = 0.0420s; samplesPerSecond = 4574.3
MPI Rank 0: 07/13/2016 16:48:27:  Epoch[ 1 of 5]-Minibatch[  61-  63, 19.69%]: CrossEntropyWithSoftmax = 3.40098566 * 192; EvalErrorPrediction = 0.80208333 * 192; time = 0.0415s; samplesPerSecond = 4630.6
MPI Rank 0: 07/13/2016 16:48:27:  Epoch[ 1 of 5]-Minibatch[  64-  66, 20.62%]: CrossEntropyWithSoftmax = 3.50668803 * 192; EvalErrorPrediction = 0.77604167 * 192; time = 0.0420s; samplesPerSecond = 4572.0
MPI Rank 0: 07/13/2016 16:48:27:  Epoch[ 1 of 5]-Minibatch[  67-  69, 21.56%]: CrossEntropyWithSoftmax = 3.82314351 * 192; EvalErrorPrediction = 0.86979167 * 192; time = 0.0421s; samplesPerSecond = 4564.1
MPI Rank 0: 07/13/2016 16:48:27:  Epoch[ 1 of 5]-Minibatch[  70-  72, 22.50%]: CrossEntropyWithSoftmax = 3.51780740 * 192; EvalErrorPrediction = 0.83854167 * 192; time = 0.0420s; samplesPerSecond = 4566.2
MPI Rank 0: 07/13/2016 16:48:27:  Epoch[ 1 of 5]-Minibatch[  73-  75, 23.44%]: CrossEntropyWithSoftmax = 3.32189431 * 192; EvalErrorPrediction = 0.79687500 * 192; time = 0.0420s; samplesPerSecond = 4567.8
MPI Rank 0: 07/13/2016 16:48:27:  Epoch[ 1 of 5]-Minibatch[  76-  78, 24.38%]: CrossEntropyWithSoftmax = 3.42533640 * 192; EvalErrorPrediction = 0.77604167 * 192; time = 0.0421s; samplesPerSecond = 4558.1
MPI Rank 0: 07/13/2016 16:48:27:  Epoch[ 1 of 5]-Minibatch[  79-  81, 25.31%]: CrossEntropyWithSoftmax = 3.42902377 * 192; EvalErrorPrediction = 0.81770833 * 192; time = 0.0421s; samplesPerSecond = 4556.5
MPI Rank 0: 07/13/2016 16:48:27:  Epoch[ 1 of 5]-Minibatch[  82-  84, 26.25%]: CrossEntropyWithSoftmax = 3.42017745 * 192; EvalErrorPrediction = 0.76041667 * 192; time = 0.0421s; samplesPerSecond = 4561.1
MPI Rank 0: 07/13/2016 16:48:27:  Epoch[ 1 of 5]-Minibatch[  85-  87, 27.19%]: CrossEntropyWithSoftmax = 3.30346679 * 192; EvalErrorPrediction = 0.73437500 * 192; time = 0.0421s; samplesPerSecond = 4557.3
MPI Rank 0: 07/13/2016 16:48:27:  Epoch[ 1 of 5]-Minibatch[  88-  90, 28.12%]: CrossEntropyWithSoftmax = 3.31343403 * 192; EvalErrorPrediction = 0.79687500 * 192; time = 0.0421s; samplesPerSecond = 4562.3
MPI Rank 0: 07/13/2016 16:48:27:  Epoch[ 1 of 5]-Minibatch[  91-  93, 29.06%]: CrossEntropyWithSoftmax = 3.22956709 * 192; EvalErrorPrediction = 0.83854167 * 192; time = 0.0416s; samplesPerSecond = 4612.6
MPI Rank 0: 07/13/2016 16:48:27:  Epoch[ 1 of 5]-Minibatch[  94-  96, 30.00%]: CrossEntropyWithSoftmax = 3.54894307 * 192; EvalErrorPrediction = 0.84895833 * 192; time = 0.0421s; samplesPerSecond = 4564.3
MPI Rank 0: 07/13/2016 16:48:27:  Epoch[ 1 of 5]-Minibatch[  97-  99, 30.94%]: CrossEntropyWithSoftmax = 3.33751842 * 192; EvalErrorPrediction = 0.85416667 * 192; time = 0.0421s; samplesPerSecond = 4565.3
MPI Rank 0: 07/13/2016 16:48:27:  Epoch[ 1 of 5]-Minibatch[ 100- 102, 31.87%]: CrossEntropyWithSoftmax = 3.25951347 * 192; EvalErrorPrediction = 0.80729167 * 192; time = 0.0421s; samplesPerSecond = 4563.6
MPI Rank 0: 07/13/2016 16:48:27:  Epoch[ 1 of 5]-Minibatch[ 103- 105, 32.81%]: CrossEntropyWithSoftmax = 3.24586699 * 192; EvalErrorPrediction = 0.78125000 * 192; time = 0.0421s; samplesPerSecond = 4563.1
MPI Rank 0: 07/13/2016 16:48:27:  Epoch[ 1 of 5]-Minibatch[ 106- 108, 33.75%]: CrossEntropyWithSoftmax = 3.06725828 * 192; EvalErrorPrediction = 0.71875000 * 192; time = 0.0421s; samplesPerSecond = 4562.6
MPI Rank 0: 07/13/2016 16:48:28:  Epoch[ 1 of 5]-Minibatch[ 109- 111, 34.69%]: CrossEntropyWithSoftmax = 3.39973653 * 192; EvalErrorPrediction = 0.77083333 * 192; time = 0.0421s; samplesPerSecond = 4563.9
MPI Rank 0: 07/13/2016 16:48:28:  Epoch[ 1 of 5]-Minibatch[ 112- 114, 35.62%]: CrossEntropyWithSoftmax = 3.34798378 * 192; EvalErrorPrediction = 0.78645833 * 192; time = 0.0421s; samplesPerSecond = 4561.5
MPI Rank 0: 07/13/2016 16:48:28:  Epoch[ 1 of 5]-Minibatch[ 115- 117, 36.56%]: CrossEntropyWithSoftmax = 3.38133778 * 192; EvalErrorPrediction = 0.82291667 * 192; time = 0.0421s; samplesPerSecond = 4560.0
MPI Rank 0: 07/13/2016 16:48:28:  Epoch[ 1 of 5]-Minibatch[ 118- 120, 37.50%]: CrossEntropyWithSoftmax = 3.19074044 * 192; EvalErrorPrediction = 0.74479167 * 192; time = 0.0421s; samplesPerSecond = 4562.1
MPI Rank 0: 07/13/2016 16:48:28:  Epoch[ 1 of 5]-Minibatch[ 121- 123, 38.44%]: CrossEntropyWithSoftmax = 3.14306337 * 192; EvalErrorPrediction = 0.74479167 * 192; time = 0.0422s; samplesPerSecond = 4554.6
MPI Rank 0: 07/13/2016 16:48:28:  Epoch[ 1 of 5]-Minibatch[ 124- 126, 39.38%]: CrossEntropyWithSoftmax = 3.10036521 * 192; EvalErrorPrediction = 0.72916667 * 192; time = 0.0427s; samplesPerSecond = 4497.2
MPI Rank 0: 07/13/2016 16:48:28:  Epoch[ 1 of 5]-Minibatch[ 127- 129, 40.31%]: CrossEntropyWithSoftmax = 3.17040971 * 192; EvalErrorPrediction = 0.76562500 * 192; time = 0.0431s; samplesPerSecond = 4454.8
MPI Rank 0: 07/13/2016 16:48:28:  Epoch[ 1 of 5]-Minibatch[ 130- 132, 41.25%]: CrossEntropyWithSoftmax = 3.19888148 * 192; EvalErrorPrediction = 0.75520833 * 192; time = 0.0435s; samplesPerSecond = 4417.4
MPI Rank 0: 07/13/2016 16:48:28:  Epoch[ 1 of 5]-Minibatch[ 133- 135, 42.19%]: CrossEntropyWithSoftmax = 2.91247084 * 192; EvalErrorPrediction = 0.66145833 * 192; time = 0.0434s; samplesPerSecond = 4426.4
MPI Rank 0: 07/13/2016 16:48:28:  Epoch[ 1 of 5]-Minibatch[ 136- 138, 43.12%]: CrossEntropyWithSoftmax = 2.96972038 * 192; EvalErrorPrediction = 0.70833333 * 192; time = 0.0421s; samplesPerSecond = 4558.6
MPI Rank 0: 07/13/2016 16:48:28:  Epoch[ 1 of 5]-Minibatch[ 139- 141, 44.06%]: CrossEntropyWithSoftmax = 3.15632232 * 192; EvalErrorPrediction = 0.76041667 * 192; time = 0.0421s; samplesPerSecond = 4557.8
MPI Rank 0: 07/13/2016 16:48:28:  Epoch[ 1 of 5]-Minibatch[ 142- 144, 45.00%]: CrossEntropyWithSoftmax = 2.98075176 * 192; EvalErrorPrediction = 0.71354167 * 192; time = 0.0421s; samplesPerSecond = 4557.6
MPI Rank 0: 07/13/2016 16:48:28:  Epoch[ 1 of 5]-Minibatch[ 145- 147, 45.94%]: CrossEntropyWithSoftmax = 3.03076846 * 192; EvalErrorPrediction = 0.77604167 * 192; time = 0.0422s; samplesPerSecond = 4554.6
MPI Rank 0: 07/13/2016 16:48:28:  Epoch[ 1 of 5]-Minibatch[ 148- 150, 46.88%]: CrossEntropyWithSoftmax = 2.91480722 * 192; EvalErrorPrediction = 0.71354167 * 192; time = 0.0421s; samplesPerSecond = 4556.1
MPI Rank 0: 07/13/2016 16:48:28:  Epoch[ 1 of 5]-Minibatch[ 151- 153, 47.81%]: CrossEntropyWithSoftmax = 3.16155322 * 192; EvalErrorPrediction = 0.75520833 * 192; time = 0.0421s; samplesPerSecond = 4559.5
MPI Rank 0: 07/13/2016 16:48:28:  Epoch[ 1 of 5]-Minibatch[ 154- 156, 48.75%]: CrossEntropyWithSoftmax = 2.76157172 * 192; EvalErrorPrediction = 0.69791667 * 192; time = 0.0422s; samplesPerSecond = 4554.7
MPI Rank 0: 07/13/2016 16:48:28:  Epoch[ 1 of 5]-Minibatch[ 157- 159, 49.69%]: CrossEntropyWithSoftmax = 3.06347679 * 192; EvalErrorPrediction = 0.75520833 * 192; time = 0.0421s; samplesPerSecond = 4561.2
MPI Rank 0: 07/13/2016 16:48:28:  Epoch[ 1 of 5]-Minibatch[ 160- 162, 50.62%]: CrossEntropyWithSoftmax = 2.84053583 * 192; EvalErrorPrediction = 0.69791667 * 192; time = 0.0428s; samplesPerSecond = 4491.0
MPI Rank 0: 07/13/2016 16:48:28:  Epoch[ 1 of 5]-Minibatch[ 163- 165, 51.56%]: CrossEntropyWithSoftmax = 2.87795860 * 192; EvalErrorPrediction = 0.75000000 * 192; time = 0.0421s; samplesPerSecond = 4557.2
MPI Rank 0: 07/13/2016 16:48:28:  Epoch[ 1 of 5]-Minibatch[ 166- 168, 52.50%]: CrossEntropyWithSoftmax = 2.92198252 * 192; EvalErrorPrediction = 0.70833333 * 192; time = 0.0420s; samplesPerSecond = 4571.5
MPI Rank 0: 07/13/2016 16:48:28:  Epoch[ 1 of 5]-Minibatch[ 169- 171, 53.44%]: CrossEntropyWithSoftmax = 2.81241750 * 192; EvalErrorPrediction = 0.66145833 * 192; time = 0.0431s; samplesPerSecond = 4450.0
MPI Rank 0: 07/13/2016 16:48:28:  Epoch[ 1 of 5]-Minibatch[ 172- 174, 54.37%]: CrossEntropyWithSoftmax = 2.62682593 * 192; EvalErrorPrediction = 0.64062500 * 192; time = 0.0421s; samplesPerSecond = 4561.1
MPI Rank 0: 07/13/2016 16:48:28:  Epoch[ 1 of 5]-Minibatch[ 175- 177, 55.31%]: CrossEntropyWithSoftmax = 2.75758644 * 192; EvalErrorPrediction = 0.73437500 * 192; time = 0.0421s; samplesPerSecond = 4561.4
MPI Rank 0: 07/13/2016 16:48:28:  Epoch[ 1 of 5]-Minibatch[ 178- 180, 56.25%]: CrossEntropyWithSoftmax = 2.74763961 * 192; EvalErrorPrediction = 0.67187500 * 192; time = 0.0421s; samplesPerSecond = 4562.5
MPI Rank 0: 07/13/2016 16:48:29:  Epoch[ 1 of 5]-Minibatch[ 181- 183, 57.19%]: CrossEntropyWithSoftmax = 2.90905834 * 192; EvalErrorPrediction = 0.68229167 * 192; time = 0.0421s; samplesPerSecond = 4562.4
MPI Rank 0: 07/13/2016 16:48:29:  Epoch[ 1 of 5]-Minibatch[ 184- 186, 58.13%]: CrossEntropyWithSoftmax = 2.76756973 * 192; EvalErrorPrediction = 0.70833333 * 192; time = 0.0421s; samplesPerSecond = 4558.7
MPI Rank 0: 07/13/2016 16:48:29:  Epoch[ 1 of 5]-Minibatch[ 187- 189, 59.06%]: CrossEntropyWithSoftmax = 2.76599748 * 192; EvalErrorPrediction = 0.75520833 * 192; time = 0.0421s; samplesPerSecond = 4562.8
MPI Rank 0: 07/13/2016 16:48:29:  Epoch[ 1 of 5]-Minibatch[ 190- 192, 60.00%]: CrossEntropyWithSoftmax = 2.83171014 * 192; EvalErrorPrediction = 0.70833333 * 192; time = 0.0421s; samplesPerSecond = 4558.3
MPI Rank 0: 07/13/2016 16:48:29:  Epoch[ 1 of 5]-Minibatch[ 193- 195, 60.94%]: CrossEntropyWithSoftmax = 2.59593490 * 192; EvalErrorPrediction = 0.61458333 * 192; time = 0.0421s; samplesPerSecond = 4563.1
MPI Rank 0: 07/13/2016 16:48:29:  Epoch[ 1 of 5]-Minibatch[ 196- 198, 61.88%]: CrossEntropyWithSoftmax = 2.64965270 * 192; EvalErrorPrediction = 0.66666667 * 192; time = 0.0421s; samplesPerSecond = 4565.6
MPI Rank 0: 07/13/2016 16:48:29:  Epoch[ 1 of 5]-Minibatch[ 199- 201, 62.81%]: CrossEntropyWithSoftmax = 2.33442260 * 192; EvalErrorPrediction = 0.60937500 * 192; time = 0.0421s; samplesPerSecond = 4565.7
MPI Rank 0: 07/13/2016 16:48:29:  Epoch[ 1 of 5]-Minibatch[ 202- 204, 63.75%]: CrossEntropyWithSoftmax = 2.67195863 * 192; EvalErrorPrediction = 0.67187500 * 192; time = 0.0421s; samplesPerSecond = 4561.0
MPI Rank 0: 07/13/2016 16:48:29:  Epoch[ 1 of 5]-Minibatch[ 205- 207, 64.69%]: CrossEntropyWithSoftmax = 2.72367540 * 192; EvalErrorPrediction = 0.66145833 * 192; time = 0.0420s; samplesPerSecond = 4567.1
MPI Rank 0: 07/13/2016 16:48:29:  Epoch[ 1 of 5]-Minibatch[ 208- 210, 65.62%]: CrossEntropyWithSoftmax = 2.59572337 * 192; EvalErrorPrediction = 0.68229167 * 192; time = 0.0421s; samplesPerSecond = 4565.1
MPI Rank 0: 07/13/2016 16:48:29:  Epoch[ 1 of 5]-Minibatch[ 211- 213, 66.56%]: CrossEntropyWithSoftmax = 2.53202795 * 192; EvalErrorPrediction = 0.63541667 * 192; time = 0.0428s; samplesPerSecond = 4490.8
MPI Rank 0: 07/13/2016 16:48:29:  Epoch[ 1 of 5]-Minibatch[ 214- 216, 67.50%]: CrossEntropyWithSoftmax = 2.50336278 * 192; EvalErrorPrediction = 0.67187500 * 192; time = 0.0434s; samplesPerSecond = 4422.3
MPI Rank 0: 07/13/2016 16:48:29:  Epoch[ 1 of 5]-Minibatch[ 217- 219, 68.44%]: CrossEntropyWithSoftmax = 2.77076318 * 192; EvalErrorPrediction = 0.68750000 * 192; time = 0.0433s; samplesPerSecond = 4431.0
MPI Rank 0: 07/13/2016 16:48:29:  Epoch[ 1 of 5]-Minibatch[ 220- 222, 69.38%]: CrossEntropyWithSoftmax = 2.45308521 * 192; EvalErrorPrediction = 0.59895833 * 192; time = 0.0440s; samplesPerSecond = 4364.8
MPI Rank 0: 07/13/2016 16:48:29:  Epoch[ 1 of 5]-Minibatch[ 223- 225, 70.31%]: CrossEntropyWithSoftmax = 2.54598920 * 192; EvalErrorPrediction = 0.60937500 * 192; time = 0.0435s; samplesPerSecond = 4413.2
MPI Rank 0: 07/13/2016 16:48:29:  Epoch[ 1 of 5]-Minibatch[ 226- 228, 71.25%]: CrossEntropyWithSoftmax = 2.58558089 * 192; EvalErrorPrediction = 0.65625000 * 192; time = 0.0420s; samplesPerSecond = 4566.6
MPI Rank 0: 07/13/2016 16:48:29:  Epoch[ 1 of 5]-Minibatch[ 229- 231, 72.19%]: CrossEntropyWithSoftmax = 2.41075660 * 192; EvalErrorPrediction = 0.61458333 * 192; time = 0.0420s; samplesPerSecond = 4567.8
MPI Rank 0: 07/13/2016 16:48:29:  Epoch[ 1 of 5]-Minibatch[ 232- 234, 73.12%]: CrossEntropyWithSoftmax = 2.52012028 * 192; EvalErrorPrediction = 0.66145833 * 192; time = 0.0420s; samplesPerSecond = 4572.5
MPI Rank 0: 07/13/2016 16:48:29:  Epoch[ 1 of 5]-Minibatch[ 235- 237, 74.06%]: CrossEntropyWithSoftmax = 2.30719546 * 192; EvalErrorPrediction = 0.62500000 * 192; time = 0.0420s; samplesPerSecond = 4576.1
MPI Rank 0: 07/13/2016 16:48:29:  Epoch[ 1 of 5]-Minibatch[ 238- 240, 75.00%]: CrossEntropyWithSoftmax = 2.42100657 * 192; EvalErrorPrediction = 0.59895833 * 192; time = 0.0419s; samplesPerSecond = 4579.1
MPI Rank 0: 07/13/2016 16:48:29:  Epoch[ 1 of 5]-Minibatch[ 241- 243, 75.94%]: CrossEntropyWithSoftmax = 2.39894546 * 192; EvalErrorPrediction = 0.63541667 * 192; time = 0.0420s; samplesPerSecond = 4575.2
MPI Rank 0: 07/13/2016 16:48:29:  Epoch[ 1 of 5]-Minibatch[ 244- 246, 76.88%]: CrossEntropyWithSoftmax = 2.44970724 * 192; EvalErrorPrediction = 0.67187500 * 192; time = 0.0419s; samplesPerSecond = 4582.9
MPI Rank 0: 07/13/2016 16:48:29:  Epoch[ 1 of 5]-Minibatch[ 247- 249, 77.81%]: CrossEntropyWithSoftmax = 2.33418475 * 192; EvalErrorPrediction = 0.63541667 * 192; time = 0.0419s; samplesPerSecond = 4580.6
MPI Rank 0: 07/13/2016 16:48:29:  Epoch[ 1 of 5]-Minibatch[ 250- 252, 78.75%]: CrossEntropyWithSoftmax = 2.37997032 * 192; EvalErrorPrediction = 0.61458333 * 192; time = 0.0419s; samplesPerSecond = 4578.1
MPI Rank 0: 07/13/2016 16:48:30:  Epoch[ 1 of 5]-Minibatch[ 253- 255, 79.69%]: CrossEntropyWithSoftmax = 2.47517097 * 192; EvalErrorPrediction = 0.59895833 * 192; time = 0.0420s; samplesPerSecond = 4576.2
MPI Rank 0: 07/13/2016 16:48:30:  Epoch[ 1 of 5]-Minibatch[ 256- 258, 80.62%]: CrossEntropyWithSoftmax = 2.60900086 * 192; EvalErrorPrediction = 0.69270833 * 192; time = 0.0424s; samplesPerSecond = 4524.6
MPI Rank 0: 07/13/2016 16:48:30:  Epoch[ 1 of 5]-Minibatch[ 259- 261, 81.56%]: CrossEntropyWithSoftmax = 2.43300244 * 192; EvalErrorPrediction = 0.65104167 * 192; time = 0.0421s; samplesPerSecond = 4565.8
MPI Rank 0: 07/13/2016 16:48:30:  Epoch[ 1 of 5]-Minibatch[ 262- 264, 82.50%]: CrossEntropyWithSoftmax = 2.12996515 * 192; EvalErrorPrediction = 0.56250000 * 192; time = 0.0420s; samplesPerSecond = 4566.9
MPI Rank 0: 07/13/2016 16:48:30:  Epoch[ 1 of 5]-Minibatch[ 265- 267, 83.44%]: CrossEntropyWithSoftmax = 2.51181403 * 192; EvalErrorPrediction = 0.62500000 * 192; time = 0.0420s; samplesPerSecond = 4570.7
MPI Rank 0: 07/13/2016 16:48:30:  Epoch[ 1 of 5]-Minibatch[ 268- 270, 84.38%]: CrossEntropyWithSoftmax = 2.29330120 * 192; EvalErrorPrediction = 0.60416667 * 192; time = 0.0420s; samplesPerSecond = 4576.1
MPI Rank 0: 07/13/2016 16:48:30:  Epoch[ 1 of 5]-Minibatch[ 271- 273, 85.31%]: CrossEntropyWithSoftmax = 2.33352411 * 192; EvalErrorPrediction = 0.60416667 * 192; time = 0.0423s; samplesPerSecond = 4543.7
MPI Rank 0: 07/13/2016 16:48:30:  Epoch[ 1 of 5]-Minibatch[ 274- 276, 86.25%]: CrossEntropyWithSoftmax = 2.17790026 * 192; EvalErrorPrediction = 0.57812500 * 192; time = 0.0434s; samplesPerSecond = 4419.3
MPI Rank 0: 07/13/2016 16:48:30:  Epoch[ 1 of 5]-Minibatch[ 277- 279, 87.19%]: CrossEntropyWithSoftmax = 2.18521155 * 192; EvalErrorPrediction = 0.54166667 * 192; time = 0.0420s; samplesPerSecond = 4574.6
MPI Rank 0: 07/13/2016 16:48:30:  Epoch[ 1 of 5]-Minibatch[ 280- 282, 88.12%]: CrossEntropyWithSoftmax = 2.29833071 * 192; EvalErrorPrediction = 0.58854167 * 192; time = 0.0430s; samplesPerSecond = 4468.3
MPI Rank 0: 07/13/2016 16:48:30:  Epoch[ 1 of 5]-Minibatch[ 283- 285, 89.06%]: CrossEntropyWithSoftmax = 2.21483298 * 192; EvalErrorPrediction = 0.61458333 * 192; time = 0.0421s; samplesPerSecond = 4565.9
MPI Rank 0: 07/13/2016 16:48:30:  Epoch[ 1 of 5]-Minibatch[ 286- 288, 90.00%]: CrossEntropyWithSoftmax = 2.37232627 * 192; EvalErrorPrediction = 0.61979167 * 192; time = 0.0420s; samplesPerSecond = 4568.8
MPI Rank 0: 07/13/2016 16:48:30:  Epoch[ 1 of 5]-Minibatch[ 289- 291, 90.94%]: CrossEntropyWithSoftmax = 2.34396058 * 192; EvalErrorPrediction = 0.60416667 * 192; time = 0.0435s; samplesPerSecond = 4418.6
MPI Rank 0: 07/13/2016 16:48:30:  Epoch[ 1 of 5]-Minibatch[ 292- 294, 91.88%]: CrossEntropyWithSoftmax = 2.18334302 * 192; EvalErrorPrediction = 0.63020833 * 192; time = 0.0434s; samplesPerSecond = 4425.7
MPI Rank 0: 07/13/2016 16:48:30:  Epoch[ 1 of 5]-Minibatch[ 295- 297, 92.81%]: CrossEntropyWithSoftmax = 2.07753101 * 192; EvalErrorPrediction = 0.57812500 * 192; time = 0.0436s; samplesPerSecond = 4405.4
MPI Rank 0: 07/13/2016 16:48:30:  Epoch[ 1 of 5]-Minibatch[ 298- 300, 93.75%]: CrossEntropyWithSoftmax = 2.26265833 * 192; EvalErrorPrediction = 0.63020833 * 192; time = 0.0421s; samplesPerSecond = 4565.2
MPI Rank 0: 07/13/2016 16:48:30:  Epoch[ 1 of 5]-Minibatch[ 301- 303, 94.69%]: CrossEntropyWithSoftmax = 2.21675905 * 192; EvalErrorPrediction = 0.58333333 * 192; time = 0.0421s; samplesPerSecond = 4557.5
MPI Rank 0: 07/13/2016 16:48:30:  Epoch[ 1 of 5]-Minibatch[ 304- 306, 95.62%]: CrossEntropyWithSoftmax = 2.18990385 * 192; EvalErrorPrediction = 0.58333333 * 192; time = 0.0421s; samplesPerSecond = 4565.7
MPI Rank 0: 07/13/2016 16:48:30:  Epoch[ 1 of 5]-Minibatch[ 307- 309, 96.56%]: CrossEntropyWithSoftmax = 2.48513433 * 192; EvalErrorPrediction = 0.64583333 * 192; time = 0.0421s; samplesPerSecond = 4559.5
MPI Rank 0: 07/13/2016 16:48:30:  Epoch[ 1 of 5]-Minibatch[ 310- 312, 97.50%]: CrossEntropyWithSoftmax = 2.25336704 * 192; EvalErrorPrediction = 0.59895833 * 192; time = 0.0420s; samplesPerSecond = 4572.4
MPI Rank 0: 07/13/2016 16:48:30:  Epoch[ 1 of 5]-Minibatch[ 313- 315, 98.44%]: CrossEntropyWithSoftmax = 2.13039619 * 192; EvalErrorPrediction = 0.55729167 * 192; time = 0.0431s; samplesPerSecond = 4453.8
MPI Rank 0: 07/13/2016 16:48:30:  Epoch[ 1 of 5]-Minibatch[ 316- 318, 99.38%]: CrossEntropyWithSoftmax = 2.27299748 * 192; EvalErrorPrediction = 0.60416667 * 192; time = 0.0422s; samplesPerSecond = 4554.9
MPI Rank 0: 07/13/2016 16:48:30: Finished Epoch[ 1 of 5]: [Training] CrossEntropyWithSoftmax = 2.99723568 * 20480; EvalErrorPrediction = 0.72426758 * 20480; totalSamplesSeen = 20480; learningRatePerSample = 0.015625; epochTime=4.55016s
MPI Rank 0: 07/13/2016 16:48:31: SGD: Saving checkpoint model '/tmp/cntk-test-20160713164744.999927/Speech/DNN_ParallelBM@debug_gpu/models/cntkSpeech.dnn.1'
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:48:31: Starting Epoch 2: learning rate per sample = 0.001953  effective momentum = 0.656119  momentum as time constant = 607.5 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 1: frames [20480..40960] (first utterance at frame 20480), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:48:31: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 07/13/2016 16:48:31:  Epoch[ 2 of 5]-Minibatch[   1-   3, 3.75%]: CrossEntropyWithSoftmax = 2.25388628 * 519; EvalErrorPrediction = 0.63391137 * 519; time = 0.0734s; samplesPerSecond = 7074.4
MPI Rank 0: 07/13/2016 16:48:31:  Epoch[ 2 of 5]-Minibatch[   4-   6, 7.50%]: CrossEntropyWithSoftmax = 2.01477571 * 529; EvalErrorPrediction = 0.53686200 * 529; time = 0.0687s; samplesPerSecond = 7704.3
MPI Rank 0: 07/13/2016 16:48:31:  Epoch[ 2 of 5]-Minibatch[   7-   9, 11.25%]: CrossEntropyWithSoftmax = 2.03638222 * 494; EvalErrorPrediction = 0.55060729 * 494; time = 0.0605s; samplesPerSecond = 8171.2
MPI Rank 0: 07/13/2016 16:48:31:  Epoch[ 2 of 5]-Minibatch[  10-  12, 15.00%]: CrossEntropyWithSoftmax = 1.97591869 * 491; EvalErrorPrediction = 0.54378819 * 491; time = 0.0611s; samplesPerSecond = 8033.4
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.07-seconds latency this time; accumulated time on sync point = 0.07 seconds , average latency = 0.07 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     0.37 seconds since last report (0.00 seconds on comm.); 4331 samples processed by 2 workers (2190 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 11.55k samplesPerSecond , throughputPerWorker = 5.77k samplesPerSecond
MPI Rank 0: 07/13/2016 16:48:31:  Epoch[ 2 of 5]-Minibatch[  13-  15, 18.75%]: CrossEntropyWithSoftmax = 2.12486189 * 488; EvalErrorPrediction = 0.53483607 * 488; time = 0.1345s; samplesPerSecond = 3629.5
MPI Rank 0: 07/13/2016 16:48:31:  Epoch[ 2 of 5]-Minibatch[  16-  18, 22.50%]: CrossEntropyWithSoftmax = 1.99682461 * 485; EvalErrorPrediction = 0.55670103 * 485; time = 0.0596s; samplesPerSecond = 8141.4
MPI Rank 0: 07/13/2016 16:48:31:  Epoch[ 2 of 5]-Minibatch[  19-  21, 26.25%]: CrossEntropyWithSoftmax = 1.98681980 * 529; EvalErrorPrediction = 0.55576560 * 529; time = 0.0646s; samplesPerSecond = 8188.9
MPI Rank 0: 07/13/2016 16:48:31:  Epoch[ 2 of 5]-Minibatch[  22-  24, 30.00%]: CrossEntropyWithSoftmax = 1.94891082 * 468; EvalErrorPrediction = 0.55341880 * 468; time = 0.0599s; samplesPerSecond = 7809.1
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.07-seconds latency this time; accumulated time on sync point = 0.14 seconds , average latency = 0.07 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     0.34 seconds since last report (0.00 seconds on comm.); 4232 samples processed by 2 workers (2154 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 12.27k samplesPerSecond , throughputPerWorker = 6.14k samplesPerSecond
MPI Rank 0: 07/13/2016 16:48:31:  Epoch[ 2 of 5]-Minibatch[  25-  27, 33.75%]: CrossEntropyWithSoftmax = 1.99768818 * 499; EvalErrorPrediction = 0.53507014 * 499; time = 0.1428s; samplesPerSecond = 3494.0
MPI Rank 0: 07/13/2016 16:48:31:  Epoch[ 2 of 5]-Minibatch[  28-  30, 37.50%]: CrossEntropyWithSoftmax = 2.17844696 * 494; EvalErrorPrediction = 0.57692308 * 494; time = 0.0605s; samplesPerSecond = 8166.2
MPI Rank 0: 07/13/2016 16:48:31:  Epoch[ 2 of 5]-Minibatch[  31-  33, 41.25%]: CrossEntropyWithSoftmax = 1.96255558 * 479; EvalErrorPrediction = 0.53027140 * 479; time = 0.0562s; samplesPerSecond = 8530.1
MPI Rank 0: 07/13/2016 16:48:31:  Epoch[ 2 of 5]-Minibatch[  34-  36, 45.00%]: CrossEntropyWithSoftmax = 1.99612126 * 488; EvalErrorPrediction = 0.54303279 * 488; time = 0.0598s; samplesPerSecond = 8158.4
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.06-seconds latency this time; accumulated time on sync point = 0.20 seconds , average latency = 0.07 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     0.33 seconds since last report (0.00 seconds on comm.); 4185 samples processed by 2 workers (2125 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 12.64k samplesPerSecond , throughputPerWorker = 6.32k samplesPerSecond
MPI Rank 0: 07/13/2016 16:48:32:  Epoch[ 2 of 5]-Minibatch[  37-  39, 48.75%]: CrossEntropyWithSoftmax = 1.89743886 * 506; EvalErrorPrediction = 0.52766798 * 506; time = 0.1346s; samplesPerSecond = 3759.4
MPI Rank 0: 07/13/2016 16:48:32:  Epoch[ 2 of 5]-Minibatch[  40-  42, 52.50%]: CrossEntropyWithSoftmax = 1.85536959 * 512; EvalErrorPrediction = 0.52929688 * 512; time = 0.0559s; samplesPerSecond = 9166.4
MPI Rank 0: 07/13/2016 16:48:32:  Epoch[ 2 of 5]-Minibatch[  43-  45, 56.25%]: CrossEntropyWithSoftmax = 1.92579626 * 497; EvalErrorPrediction = 0.49496982 * 497; time = 0.0606s; samplesPerSecond = 8200.5
MPI Rank 0: 07/13/2016 16:48:32:  Epoch[ 2 of 5]-Minibatch[  46-  48, 60.00%]: CrossEntropyWithSoftmax = 1.85664750 * 502; EvalErrorPrediction = 0.52988048 * 502; time = 0.0596s; samplesPerSecond = 8416.9
MPI Rank 0: 07/13/2016 16:48:32:  Epoch[ 2 of 5]-Minibatch[  49-  51, 63.75%]: CrossEntropyWithSoftmax = 2.05622489 * 476; EvalErrorPrediction = 0.56932773 * 476; time = 0.0489s; samplesPerSecond = 9732.6
MPI Rank 0: 07/13/2016 16:48:32:  Epoch[ 2 of 5]-Minibatch[  52-  54, 67.50%]: CrossEntropyWithSoftmax = 2.00110796 * 487; EvalErrorPrediction = 0.53388090 * 487; time = 0.0497s; samplesPerSecond = 9808.3
MPI Rank 0: 07/13/2016 16:48:32:  Epoch[ 2 of 5]-Minibatch[  55-  57, 71.25%]: CrossEntropyWithSoftmax = 1.90438413 * 499; EvalErrorPrediction = 0.51903808 * 499; time = 0.0496s; samplesPerSecond = 10068.6
MPI Rank 0: 07/13/2016 16:48:32:  Epoch[ 2 of 5]-Minibatch[  58-  60, 75.00%]: CrossEntropyWithSoftmax = 1.93538095 * 475; EvalErrorPrediction = 0.51789474 * 475; time = 0.0491s; samplesPerSecond = 9664.5
MPI Rank 0: 07/13/2016 16:48:32:  Epoch[ 2 of 5]-Minibatch[  61-  63, 78.75%]: CrossEntropyWithSoftmax = 1.92688744 * 506; EvalErrorPrediction = 0.53952569 * 506; time = 0.0498s; samplesPerSecond = 10163.5
MPI Rank 0: 07/13/2016 16:48:32:  Epoch[ 2 of 5]-Minibatch[  64-  66, 82.50%]: CrossEntropyWithSoftmax = 1.93689941 * 472; EvalErrorPrediction = 0.53389831 * 472; time = 0.0492s; samplesPerSecond = 9601.7
MPI Rank 0: 07/13/2016 16:48:32:  Epoch[ 2 of 5]-Minibatch[  67-  69, 86.25%]: CrossEntropyWithSoftmax = 1.87278053 * 490; EvalErrorPrediction = 0.53061224 * 490; time = 0.0489s; samplesPerSecond = 10024.8
MPI Rank 0: 07/13/2016 16:48:32:  Epoch[ 2 of 5]-Minibatch[  70-  72, 90.00%]: CrossEntropyWithSoftmax = 1.93056324 * 477; EvalErrorPrediction = 0.50943396 * 477; time = 0.0479s; samplesPerSecond = 9952.8
MPI Rank 0: 07/13/2016 16:48:32:  Epoch[ 2 of 5]-Minibatch[  73-  75, 93.75%]: CrossEntropyWithSoftmax = 1.92122823 * 469; EvalErrorPrediction = 0.52878465 * 469; time = 0.0489s; samplesPerSecond = 9592.2
MPI Rank 0: 07/13/2016 16:48:32:  Epoch[ 2 of 5]-Minibatch[  76-  78, 97.50%]: CrossEntropyWithSoftmax = 1.92998622 * 495; EvalErrorPrediction = 0.53131313 * 495; time = 0.0491s; samplesPerSecond = 10089.9
MPI Rank 0: 07/13/2016 16:48:32:  Epoch[ 2 of 5]-Minibatch[  79-  81, 101.25%]: CrossEntropyWithSoftmax = 1.87322468 * 322; EvalErrorPrediction = 0.54968944 * 322; time = 0.0227s; samplesPerSecond = 14180.6
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.20 seconds , average latency = 0.05 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     0.70 seconds since last report (0.00 seconds on comm.); 7732 samples processed by 2 workers (6679 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 11.02k samplesPerSecond , throughputPerWorker = 5.51k samplesPerSecond
MPI Rank 0: 07/13/2016 16:48:32: Finished Epoch[ 2 of 5]: [Training] CrossEntropyWithSoftmax = 1.99875653 * 20480; EvalErrorPrediction = 0.54526367 * 20480; totalSamplesSeen = 40960; learningRatePerSample = 0.001953125; epochTime=1.75275s
MPI Rank 0: 07/13/2016 16:48:32: SGD: Saving checkpoint model '/tmp/cntk-test-20160713164744.999927/Speech/DNN_ParallelBM@debug_gpu/models/cntkSpeech.dnn.2'
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:48:32: Starting Epoch 3: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 2: frames [40960..61440] (first utterance at frame 40960), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:48:33: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 07/13/2016 16:48:33:  Epoch[ 3 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.86678794 * 1939; EvalErrorPrediction = 0.50489943 * 1939; time = 0.1756s; samplesPerSecond = 11043.5
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     0.27 seconds since last report (0.00 seconds on comm.); 4844 samples processed by 2 workers (2583 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 17.77k samplesPerSecond , throughputPerWorker = 8.88k samplesPerSecond
MPI Rank 0: 07/13/2016 16:48:33:  Epoch[ 3 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.88063301 * 1944; EvalErrorPrediction = 0.53497942 * 1944; time = 0.1672s; samplesPerSecond = 11630.2
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     0.23 seconds since last report (0.00 seconds on comm.); 4849 samples processed by 2 workers (2580 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 21.54k samplesPerSecond , throughputPerWorker = 10.77k samplesPerSecond
MPI Rank 0: 07/13/2016 16:48:33:  Epoch[ 3 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.90227906 * 1918; EvalErrorPrediction = 0.52346194 * 1918; time = 0.1671s; samplesPerSecond = 11477.8
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     0.24 seconds since last report (0.00 seconds on comm.); 4868 samples processed by 2 workers (2595 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 20.57k samplesPerSecond , throughputPerWorker = 10.28k samplesPerSecond
MPI Rank 0: 07/13/2016 16:48:33:  Epoch[ 3 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.88640712 * 1957; EvalErrorPrediction = 0.52376086 * 1957; time = 0.1865s; samplesPerSecond = 10490.6
MPI Rank 0: 07/13/2016 16:48:33:  Epoch[ 3 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.86518475 * 1942; EvalErrorPrediction = 0.52008239 * 1942; time = 0.1517s; samplesPerSecond = 12798.2
MPI Rank 0: 07/13/2016 16:48:34:  Epoch[ 3 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.85598666 * 1929; EvalErrorPrediction = 0.51270088 * 1929; time = 0.1432s; samplesPerSecond = 13471.8
MPI Rank 0: 07/13/2016 16:48:34:  Epoch[ 3 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.88794294 * 1290; EvalErrorPrediction = 0.51937984 * 1290; time = 0.0645s; samplesPerSecond = 20000.0
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     0.37 seconds since last report (0.00 seconds on comm.); 5919 samples processed by 2 workers (5161 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 16.01k samplesPerSecond , throughputPerWorker = 8.00k samplesPerSecond
MPI Rank 0: 07/13/2016 16:48:34: Finished Epoch[ 3 of 5]: [Training] CrossEntropyWithSoftmax = 1.88572700 * 20480; EvalErrorPrediction = 0.52416992 * 20480; totalSamplesSeen = 61440; learningRatePerSample = 9.7656251e-05; epochTime=1.10438s
MPI Rank 0: 07/13/2016 16:48:34: SGD: Saving checkpoint model '/tmp/cntk-test-20160713164744.999927/Speech/DNN_ParallelBM@debug_gpu/models/cntkSpeech.dnn.3'
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:48:34: Starting Epoch 4: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:48:34: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 07/13/2016 16:48:34:  Epoch[ 4 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.89976988 * 1926; EvalErrorPrediction = 0.52128764 * 1926; time = 0.1640s; samplesPerSecond = 11744.1
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     0.27 seconds since last report (0.00 seconds on comm.); 4905 samples processed by 2 workers (2581 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 18.37k samplesPerSecond , throughputPerWorker = 9.19k samplesPerSecond
MPI Rank 0: 07/13/2016 16:48:34:  Epoch[ 4 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.79499440 * 1894; EvalErrorPrediction = 0.50844773 * 1894; time = 0.1664s; samplesPerSecond = 11382.4
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     0.22 seconds since last report (0.00 seconds on comm.); 4870 samples processed by 2 workers (2537 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 21.69k samplesPerSecond , throughputPerWorker = 10.85k samplesPerSecond
MPI Rank 0: 07/13/2016 16:48:34:  Epoch[ 4 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.84956803 * 1931; EvalErrorPrediction = 0.51475919 * 1931; time = 0.1670s; samplesPerSecond = 11561.7
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.02 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     0.24 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2513 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 20.67k samplesPerSecond , throughputPerWorker = 10.33k samplesPerSecond
MPI Rank 0: 07/13/2016 16:48:34:  Epoch[ 4 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.82336020 * 1880; EvalErrorPrediction = 0.50159574 * 1880; time = 0.1888s; samplesPerSecond = 9955.6
MPI Rank 0: 07/13/2016 16:48:35:  Epoch[ 4 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.79200574 * 1880; EvalErrorPrediction = 0.49627660 * 1880; time = 0.1452s; samplesPerSecond = 12952.1
MPI Rank 0: 07/13/2016 16:48:35:  Epoch[ 4 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.80502326 * 1861; EvalErrorPrediction = 0.50994089 * 1861; time = 0.1399s; samplesPerSecond = 13299.5
MPI Rank 0: 07/13/2016 16:48:35:  Epoch[ 4 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.81515951 * 1263; EvalErrorPrediction = 0.48851940 * 1263; time = 0.0561s; samplesPerSecond = 22522.6
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.02 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     0.35 seconds since last report (0.00 seconds on comm.); 5789 samples processed by 2 workers (5004 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 16.44k samplesPerSecond , throughputPerWorker = 8.22k samplesPerSecond
MPI Rank 0: 07/13/2016 16:48:35: Finished Epoch[ 4 of 5]: [Training] CrossEntropyWithSoftmax = 1.83787473 * 20480; EvalErrorPrediction = 0.51215820 * 20480; totalSamplesSeen = 81920; learningRatePerSample = 9.7656251e-05; epochTime=1.08171s
MPI Rank 0: 07/13/2016 16:48:35: SGD: Saving checkpoint model '/tmp/cntk-test-20160713164744.999927/Speech/DNN_ParallelBM@debug_gpu/models/cntkSpeech.dnn.4'
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:48:35: Starting Epoch 5: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:48:35: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 07/13/2016 16:48:35:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80055910 * 1897; EvalErrorPrediction = 0.49868213 * 1897; time = 0.1612s; samplesPerSecond = 11767.5
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     0.27 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 18.13k samplesPerSecond , throughputPerWorker = 9.07k samplesPerSecond
MPI Rank 0: 07/13/2016 16:48:35:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86746838 * 1821; EvalErrorPrediction = 0.51455244 * 1821; time = 0.1716s; samplesPerSecond = 10613.2
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.02 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     0.23 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 21.52k samplesPerSecond , throughputPerWorker = 10.76k samplesPerSecond
MPI Rank 0: 07/13/2016 16:48:36:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.89216516 * 1871; EvalErrorPrediction = 0.52057723 * 1871; time = 0.1714s; samplesPerSecond = 10915.8
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     0.23 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 21.39k samplesPerSecond , throughputPerWorker = 10.69k samplesPerSecond
MPI Rank 0: 07/13/2016 16:48:36:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.81968853 * 1870; EvalErrorPrediction = 0.49144385 * 1870; time = 0.1784s; samplesPerSecond = 10481.1
MPI Rank 0: 07/13/2016 16:48:36:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.89739279 * 1899; EvalErrorPrediction = 0.51711427 * 1899; time = 0.1513s; samplesPerSecond = 12550.7
MPI Rank 0: 07/13/2016 16:48:36:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.85833241 * 1878; EvalErrorPrediction = 0.52236422 * 1878; time = 0.1395s; samplesPerSecond = 13465.6
MPI Rank 0: 07/13/2016 16:48:36:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.86115648 * 1221; EvalErrorPrediction = 0.50696151 * 1221; time = 0.0541s; samplesPerSecond = 22556.4
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     0.36 seconds since last report (0.00 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 16.37k samplesPerSecond , throughputPerWorker = 8.18k samplesPerSecond
MPI Rank 0: 07/13/2016 16:48:36: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84363929 * 20480; EvalErrorPrediction = 0.51025391 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 9.7656251e-05; epochTime=1.08108s
MPI Rank 0: 07/13/2016 16:48:36: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160713164744.999927/Speech/DNN_ParallelBM@debug_gpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/13/2016 16:48:36: learnRatePerSample reduced to 4.8828126e-05
MPI Rank 0: 07/13/2016 16:48:36: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:48:36: Starting Epoch 5: learning rate per sample = 0.000049  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:48:36: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 07/13/2016 16:48:37:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80064927 * 1897; EvalErrorPrediction = 0.49815498 * 1897; time = 0.1594s; samplesPerSecond = 11897.5
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     0.26 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 19.23k samplesPerSecond , throughputPerWorker = 9.61k samplesPerSecond
MPI Rank 0: 07/13/2016 16:48:37:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86833563 * 1821; EvalErrorPrediction = 0.51510159 * 1821; time = 0.1696s; samplesPerSecond = 10735.8
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.02 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     0.23 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 21.68k samplesPerSecond , throughputPerWorker = 10.84k samplesPerSecond
MPI Rank 0: 07/13/2016 16:48:37:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.89383486 * 1871; EvalErrorPrediction = 0.52111170 * 1871; time = 0.1712s; samplesPerSecond = 10929.1
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     0.23 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 21.39k samplesPerSecond , throughputPerWorker = 10.69k samplesPerSecond
MPI Rank 0: 07/13/2016 16:48:37:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.82119679 * 1870; EvalErrorPrediction = 0.49251337 * 1870; time = 0.1788s; samplesPerSecond = 10460.5
MPI Rank 0: 07/13/2016 16:48:37:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.89901122 * 1899; EvalErrorPrediction = 0.51869405 * 1899; time = 0.1516s; samplesPerSecond = 12524.1
MPI Rank 0: 07/13/2016 16:48:37:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.86037327 * 1878; EvalErrorPrediction = 0.52342918 * 1878; time = 0.1388s; samplesPerSecond = 13533.2
MPI Rank 0: 07/13/2016 16:48:37:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.86390618 * 1221; EvalErrorPrediction = 0.50941851 * 1221; time = 0.0539s; samplesPerSecond = 22651.8
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     0.35 seconds since last report (0.00 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 16.41k samplesPerSecond , throughputPerWorker = 8.21k samplesPerSecond
MPI Rank 0: 07/13/2016 16:48:37: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84493298 * 20480; EvalErrorPrediction = 0.51040039 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 4.8828126e-05; epochTime=1.06312s
MPI Rank 0: 07/13/2016 16:48:37: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160713164744.999927/Speech/DNN_ParallelBM@debug_gpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/13/2016 16:48:38: learnRatePerSample reduced to 2.4414063e-05
MPI Rank 0: 07/13/2016 16:48:38: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:48:38: Starting Epoch 5: learning rate per sample = 0.000024  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:48:38: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 07/13/2016 16:48:38:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80069673 * 1897; EvalErrorPrediction = 0.49868213 * 1897; time = 0.1582s; samplesPerSecond = 11990.7
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     0.26 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 18.88k samplesPerSecond , throughputPerWorker = 9.44k samplesPerSecond
MPI Rank 0: 07/13/2016 16:48:38:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86881421 * 1821; EvalErrorPrediction = 0.51345415 * 1821; time = 0.1670s; samplesPerSecond = 10906.7
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.01 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     0.23 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 21.65k samplesPerSecond , throughputPerWorker = 10.82k samplesPerSecond
MPI Rank 0: 07/13/2016 16:48:38:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.89481082 * 1871; EvalErrorPrediction = 0.51897381 * 1871; time = 0.1731s; samplesPerSecond = 10810.7
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     0.23 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 21.38k samplesPerSecond , throughputPerWorker = 10.69k samplesPerSecond
MPI Rank 0: 07/13/2016 16:48:38:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.82214273 * 1870; EvalErrorPrediction = 0.49465241 * 1870; time = 0.1790s; samplesPerSecond = 10449.3
MPI Rank 0: 07/13/2016 16:48:39:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.90008573 * 1899; EvalErrorPrediction = 0.52185361 * 1899; time = 0.1517s; samplesPerSecond = 12520.4
MPI Rank 0: 07/13/2016 16:48:39:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.86165710 * 1878; EvalErrorPrediction = 0.52289670 * 1878; time = 0.1390s; samplesPerSecond = 13510.4
MPI Rank 0: 07/13/2016 16:48:39:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.86530783 * 1221; EvalErrorPrediction = 0.50941851 * 1221; time = 0.0538s; samplesPerSecond = 22714.2
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     0.36 seconds since last report (0.00 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 16.41k samplesPerSecond , throughputPerWorker = 8.20k samplesPerSecond
MPI Rank 0: 07/13/2016 16:48:39: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84568574 * 20480; EvalErrorPrediction = 0.51049805 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 2.4414063e-05; epochTime=1.06847s
MPI Rank 0: 07/13/2016 16:48:39: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160713164744.999927/Speech/DNN_ParallelBM@debug_gpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/13/2016 16:48:39: learnRatePerSample reduced to 1.2207031e-05
MPI Rank 0: 07/13/2016 16:48:39: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:48:39: Starting Epoch 5: learning rate per sample = 0.000012  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:48:39: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 07/13/2016 16:48:39:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80072106 * 1897; EvalErrorPrediction = 0.49762783 * 1897; time = 0.1668s; samplesPerSecond = 11372.1
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     0.27 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 18.19k samplesPerSecond , throughputPerWorker = 9.09k samplesPerSecond
MPI Rank 0: 07/13/2016 16:48:39:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86906602 * 1821; EvalErrorPrediction = 0.51345415 * 1821; time = 0.1638s; samplesPerSecond = 11114.4
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.01 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     0.23 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 21.66k samplesPerSecond , throughputPerWorker = 10.83k samplesPerSecond
MPI Rank 0: 07/13/2016 16:48:40:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.89534508 * 1871; EvalErrorPrediction = 0.51897381 * 1871; time = 0.1718s; samplesPerSecond = 10887.5
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     0.23 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 21.35k samplesPerSecond , throughputPerWorker = 10.68k samplesPerSecond
MPI Rank 0: 07/13/2016 16:48:40:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.82269026 * 1870; EvalErrorPrediction = 0.49465241 * 1870; time = 0.1786s; samplesPerSecond = 10469.6
MPI Rank 0: 07/13/2016 16:48:40:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.90075815 * 1899; EvalErrorPrediction = 0.52132701 * 1899; time = 0.1513s; samplesPerSecond = 12550.6
MPI Rank 0: 07/13/2016 16:48:40:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.86244120 * 1878; EvalErrorPrediction = 0.52342918 * 1878; time = 0.1395s; samplesPerSecond = 13464.7
MPI Rank 0: 07/13/2016 16:48:40:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.86601864 * 1221; EvalErrorPrediction = 0.51187551 * 1221; time = 0.0540s; samplesPerSecond = 22617.0
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     0.36 seconds since last report (0.00 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 16.39k samplesPerSecond , throughputPerWorker = 8.19k samplesPerSecond
MPI Rank 0: 07/13/2016 16:48:40: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84611027 * 20480; EvalErrorPrediction = 0.51083984 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 1.2207031e-05; epochTime=1.07887s
MPI Rank 0: 07/13/2016 16:48:40: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160713164744.999927/Speech/DNN_ParallelBM@debug_gpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/13/2016 16:48:40: learnRatePerSample reduced to 6.1035157e-06
MPI Rank 0: 07/13/2016 16:48:40: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:48:40: Starting Epoch 5: learning rate per sample = 0.000006  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:48:40: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 07/13/2016 16:48:41:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80073339 * 1897; EvalErrorPrediction = 0.49762783 * 1897; time = 0.1590s; samplesPerSecond = 11930.1
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     0.25 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 19.28k samplesPerSecond , throughputPerWorker = 9.64k samplesPerSecond
MPI Rank 0: 07/13/2016 16:48:41:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86919523 * 1821; EvalErrorPrediction = 0.51290500 * 1821; time = 0.1691s; samplesPerSecond = 10769.0
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.02 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     0.23 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 21.67k samplesPerSecond , throughputPerWorker = 10.83k samplesPerSecond
MPI Rank 0: 07/13/2016 16:48:41:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.89562551 * 1871; EvalErrorPrediction = 0.51950828 * 1871; time = 0.1712s; samplesPerSecond = 10928.7
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     0.23 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 21.44k samplesPerSecond , throughputPerWorker = 10.72k samplesPerSecond
MPI Rank 0: 07/13/2016 16:48:41:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.82298742 * 1870; EvalErrorPrediction = 0.49625668 * 1870; time = 0.1783s; samplesPerSecond = 10487.2
MPI Rank 0: 07/13/2016 16:48:41:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.90114315 * 1899; EvalErrorPrediction = 0.52238020 * 1899; time = 0.1524s; samplesPerSecond = 12460.0
MPI Rank 0: 07/13/2016 16:48:41:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.86288926 * 1878; EvalErrorPrediction = 0.52396166 * 1878; time = 0.1400s; samplesPerSecond = 13416.6
MPI Rank 0: 07/13/2016 16:48:41:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.86638702 * 1221; EvalErrorPrediction = 0.51187551 * 1221; time = 0.0544s; samplesPerSecond = 22447.7
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     0.36 seconds since last report (0.00 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 16.26k samplesPerSecond , throughputPerWorker = 8.13k samplesPerSecond
MPI Rank 0: 07/13/2016 16:48:41: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84633999 * 20480; EvalErrorPrediction = 0.51123047 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 6.1035157e-06; epochTime=1.06536s
MPI Rank 0: 07/13/2016 16:48:41: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160713164744.999927/Speech/DNN_ParallelBM@debug_gpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/13/2016 16:48:42: learnRatePerSample reduced to 3.0517579e-06
MPI Rank 0: 07/13/2016 16:48:42: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:48:42: Starting Epoch 5: learning rate per sample = 0.000003  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:48:42: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 07/13/2016 16:48:42:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80073959 * 1897; EvalErrorPrediction = 0.49762783 * 1897; time = 0.1592s; samplesPerSecond = 11913.6
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     0.25 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 19.29k samplesPerSecond , throughputPerWorker = 9.64k samplesPerSecond
MPI Rank 0: 07/13/2016 16:48:42:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86926069 * 1821; EvalErrorPrediction = 0.51345415 * 1821; time = 0.1691s; samplesPerSecond = 10766.6
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.02 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     0.23 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 21.58k samplesPerSecond , throughputPerWorker = 10.79k samplesPerSecond
MPI Rank 0: 07/13/2016 16:48:42:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.89576929 * 1871; EvalErrorPrediction = 0.51950828 * 1871; time = 0.1720s; samplesPerSecond = 10878.8
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     0.23 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 21.46k samplesPerSecond , throughputPerWorker = 10.73k samplesPerSecond
MPI Rank 0: 07/13/2016 16:48:42:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.82314256 * 1870; EvalErrorPrediction = 0.49679144 * 1870; time = 0.1780s; samplesPerSecond = 10506.9
MPI Rank 0: 07/13/2016 16:48:43:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.90135030 * 1899; EvalErrorPrediction = 0.52185361 * 1899; time = 0.1511s; samplesPerSecond = 12567.5
MPI Rank 0: 07/13/2016 16:48:43:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.86313105 * 1878; EvalErrorPrediction = 0.52449414 * 1878; time = 0.1390s; samplesPerSecond = 13512.8
MPI Rank 0: 07/13/2016 16:48:43:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.86657721 * 1221; EvalErrorPrediction = 0.51187551 * 1221; time = 0.0541s; samplesPerSecond = 22571.0
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     0.35 seconds since last report (0.00 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 16.43k samplesPerSecond , throughputPerWorker = 8.22k samplesPerSecond
MPI Rank 0: 07/13/2016 16:48:43: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84646018 * 20480; EvalErrorPrediction = 0.51127930 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 3.0517579e-06; epochTime=1.06215s
MPI Rank 0: 07/13/2016 16:48:43: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160713164744.999927/Speech/DNN_ParallelBM@debug_gpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/13/2016 16:48:43: learnRatePerSample reduced to 1.5258789e-06
MPI Rank 0: 07/13/2016 16:48:43: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:48:43: Starting Epoch 5: learning rate per sample = 0.000002  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:48:43: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 07/13/2016 16:48:43:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80074270 * 1897; EvalErrorPrediction = 0.49762783 * 1897; time = 0.1660s; samplesPerSecond = 11429.0
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     0.27 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 18.24k samplesPerSecond , throughputPerWorker = 9.12k samplesPerSecond
MPI Rank 0: 07/13/2016 16:48:43:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86929363 * 1821; EvalErrorPrediction = 0.51345415 * 1821; time = 0.1576s; samplesPerSecond = 11558.1
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.02 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     0.23 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 21.21k samplesPerSecond , throughputPerWorker = 10.61k samplesPerSecond
MPI Rank 0: 07/13/2016 16:48:44:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.89584210 * 1871; EvalErrorPrediction = 0.51897381 * 1871; time = 0.1826s; samplesPerSecond = 10249.2
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     0.23 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 21.44k samplesPerSecond , throughputPerWorker = 10.72k samplesPerSecond
MPI Rank 0: 07/13/2016 16:48:44:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.82322186 * 1870; EvalErrorPrediction = 0.49732620 * 1870; time = 0.1783s; samplesPerSecond = 10488.9
MPI Rank 0: 07/13/2016 16:48:44:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.90145790 * 1899; EvalErrorPrediction = 0.52185361 * 1899; time = 0.1516s; samplesPerSecond = 12530.2
MPI Rank 0: 07/13/2016 16:48:44:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.86325694 * 1878; EvalErrorPrediction = 0.52396166 * 1878; time = 0.1395s; samplesPerSecond = 13463.7
MPI Rank 0: 07/13/2016 16:48:44:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.86667428 * 1221; EvalErrorPrediction = 0.51187551 * 1221; time = 0.0544s; samplesPerSecond = 22456.4
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     0.36 seconds since last report (0.00 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 16.36k samplesPerSecond , throughputPerWorker = 8.18k samplesPerSecond
MPI Rank 0: 07/13/2016 16:48:44: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84652175 * 20480; EvalErrorPrediction = 0.51123047 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 1.5258789e-06; epochTime=1.0825s
MPI Rank 0: 07/13/2016 16:48:44: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160713164744.999927/Speech/DNN_ParallelBM@debug_gpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/13/2016 16:48:44: learnRatePerSample reduced to 7.6293946e-07
MPI Rank 0: 07/13/2016 16:48:44: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:48:44: Starting Epoch 5: learning rate per sample = 0.000001  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:48:44: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 07/13/2016 16:48:45:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80074425 * 1897; EvalErrorPrediction = 0.49762783 * 1897; time = 0.1587s; samplesPerSecond = 11953.1
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.01 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     0.26 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 19.27k samplesPerSecond , throughputPerWorker = 9.63k samplesPerSecond
MPI Rank 0: 07/13/2016 16:48:45:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86931015 * 1821; EvalErrorPrediction = 0.51345415 * 1821; time = 0.1700s; samplesPerSecond = 10712.6
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     0.22 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 21.75k samplesPerSecond , throughputPerWorker = 10.88k samplesPerSecond
MPI Rank 0: 07/13/2016 16:48:45:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.89587874 * 1871; EvalErrorPrediction = 0.51897381 * 1871; time = 0.1701s; samplesPerSecond = 11000.9
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.04 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     0.23 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 21.45k samplesPerSecond , throughputPerWorker = 10.72k samplesPerSecond
MPI Rank 0: 07/13/2016 16:48:45:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.82326196 * 1870; EvalErrorPrediction = 0.49732620 * 1870; time = 0.1784s; samplesPerSecond = 10480.8
MPI Rank 0: 07/13/2016 16:48:45:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.90151275 * 1899; EvalErrorPrediction = 0.52132701 * 1899; time = 0.1519s; samplesPerSecond = 12499.3
MPI Rank 0: 07/13/2016 16:48:45:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.86332122 * 1878; EvalErrorPrediction = 0.52396166 * 1878; time = 0.1413s; samplesPerSecond = 13288.7
MPI Rank 0: 07/13/2016 16:48:45:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.86672338 * 1221; EvalErrorPrediction = 0.51187551 * 1221; time = 0.0544s; samplesPerSecond = 22449.0
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.04 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     0.36 seconds since last report (0.00 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 16.25k samplesPerSecond , throughputPerWorker = 8.13k samplesPerSecond
MPI Rank 0: 07/13/2016 16:48:45: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84655293 * 20480; EvalErrorPrediction = 0.51118164 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 7.6293946e-07; epochTime=1.06471s
MPI Rank 0: 07/13/2016 16:48:45: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160713164744.999927/Speech/DNN_ParallelBM@debug_gpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/13/2016 16:48:46: learnRatePerSample reduced to 3.8146973e-07
MPI Rank 0: 07/13/2016 16:48:46: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:48:46: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:48:46: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 07/13/2016 16:48:46:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80074503 * 1897; EvalErrorPrediction = 0.49762783 * 1897; time = 0.1594s; samplesPerSecond = 11903.1
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.01 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     0.26 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 19.21k samplesPerSecond , throughputPerWorker = 9.61k samplesPerSecond
MPI Rank 0: 07/13/2016 16:48:46:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86931843 * 1821; EvalErrorPrediction = 0.51345415 * 1821; time = 0.1698s; samplesPerSecond = 10726.9
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.02 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     0.23 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 21.60k samplesPerSecond , throughputPerWorker = 10.80k samplesPerSecond
MPI Rank 0: 07/13/2016 16:48:46:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.89589712 * 1871; EvalErrorPrediction = 0.51897381 * 1871; time = 0.1720s; samplesPerSecond = 10878.8
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.04 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     0.23 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 21.37k samplesPerSecond , throughputPerWorker = 10.69k samplesPerSecond
MPI Rank 0: 07/13/2016 16:48:46:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.82328212 * 1870; EvalErrorPrediction = 0.49732620 * 1870; time = 0.1788s; samplesPerSecond = 10456.0
MPI Rank 0: 07/13/2016 16:48:47:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.90154044 * 1899; EvalErrorPrediction = 0.52132701 * 1899; time = 0.1506s; samplesPerSecond = 12609.5
MPI Rank 0: 07/13/2016 16:48:47:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.86335370 * 1878; EvalErrorPrediction = 0.52396166 * 1878; time = 0.1386s; samplesPerSecond = 13549.5
MPI Rank 0: 07/13/2016 16:48:47:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.86674809 * 1221; EvalErrorPrediction = 0.51187551 * 1221; time = 0.0539s; samplesPerSecond = 22656.0
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.04 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     0.35 seconds since last report (0.00 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 16.47k samplesPerSecond , throughputPerWorker = 8.23k samplesPerSecond
MPI Rank 0: 07/13/2016 16:48:47: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84656861 * 20480; EvalErrorPrediction = 0.51118164 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 3.8146973e-07; epochTime=1.06311s
MPI Rank 0: 07/13/2016 16:48:47: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160713164744.999927/Speech/DNN_ParallelBM@debug_gpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/13/2016 16:48:47: learnRatePerSample reduced to 1.9073487e-07
MPI Rank 0: 07/13/2016 16:48:47: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:48:47: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:48:47: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 07/13/2016 16:48:47:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80074542 * 1897; EvalErrorPrediction = 0.49762783 * 1897; time = 0.1666s; samplesPerSecond = 11387.8
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     0.27 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 18.16k samplesPerSecond , throughputPerWorker = 9.08k samplesPerSecond
MPI Rank 0: 07/13/2016 16:48:47:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86932257 * 1821; EvalErrorPrediction = 0.51345415 * 1821; time = 0.1657s; samplesPerSecond = 10991.1
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.01 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     0.23 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 21.67k samplesPerSecond , throughputPerWorker = 10.84k samplesPerSecond
MPI Rank 0: 07/13/2016 16:48:48:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.89590632 * 1871; EvalErrorPrediction = 0.51897381 * 1871; time = 0.1698s; samplesPerSecond = 11017.0
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     0.23 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 21.44k samplesPerSecond , throughputPerWorker = 10.72k samplesPerSecond
MPI Rank 0: 07/13/2016 16:48:48:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.82329223 * 1870; EvalErrorPrediction = 0.49786096 * 1870; time = 0.1784s; samplesPerSecond = 10480.5
MPI Rank 0: 07/13/2016 16:48:48:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.90155435 * 1899; EvalErrorPrediction = 0.52132701 * 1899; time = 0.1523s; samplesPerSecond = 12468.2
MPI Rank 0: 07/13/2016 16:48:48:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.86337003 * 1878; EvalErrorPrediction = 0.52396166 * 1878; time = 0.1396s; samplesPerSecond = 13455.9
MPI Rank 0: 07/13/2016 16:48:48:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.86676047 * 1221; EvalErrorPrediction = 0.51187551 * 1221; time = 0.0545s; samplesPerSecond = 22388.1
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     0.36 seconds since last report (0.00 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 16.31k samplesPerSecond , throughputPerWorker = 8.15k samplesPerSecond
MPI Rank 0: 07/13/2016 16:48:48: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84657648 * 20480; EvalErrorPrediction = 0.51118164 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 1.9073487e-07; epochTime=1.0801s
MPI Rank 0: 07/13/2016 16:48:48: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160713164744.999927/Speech/DNN_ParallelBM@debug_gpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/13/2016 16:48:48: learnRatePerSample reduced to 9.5367433e-08
MPI Rank 0: 07/13/2016 16:48:48: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:48:48: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:48:48: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 07/13/2016 16:48:49:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80074562 * 1897; EvalErrorPrediction = 0.49762783 * 1897; time = 0.1586s; samplesPerSecond = 11958.3
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     0.26 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 19.28k samplesPerSecond , throughputPerWorker = 9.64k samplesPerSecond
MPI Rank 0: 07/13/2016 16:48:49:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86932464 * 1821; EvalErrorPrediction = 0.51345415 * 1821; time = 0.1694s; samplesPerSecond = 10749.6
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.02 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     0.23 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 21.71k samplesPerSecond , throughputPerWorker = 10.85k samplesPerSecond
MPI Rank 0: 07/13/2016 16:48:49:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.89591093 * 1871; EvalErrorPrediction = 0.51950828 * 1871; time = 0.1709s; samplesPerSecond = 10948.3
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     0.23 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 21.42k samplesPerSecond , throughputPerWorker = 10.71k samplesPerSecond
MPI Rank 0: 07/13/2016 16:48:49:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.82329729 * 1870; EvalErrorPrediction = 0.49786096 * 1870; time = 0.1786s; samplesPerSecond = 10468.7
MPI Rank 0: 07/13/2016 16:48:49:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.90156133 * 1899; EvalErrorPrediction = 0.52132701 * 1899; time = 0.1516s; samplesPerSecond = 12526.1
MPI Rank 0: 07/13/2016 16:48:49:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.86337821 * 1878; EvalErrorPrediction = 0.52396166 * 1878; time = 0.1401s; samplesPerSecond = 13404.3
MPI Rank 0: 07/13/2016 16:48:49:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.86676668 * 1221; EvalErrorPrediction = 0.51187551 * 1221; time = 0.0545s; samplesPerSecond = 22421.4
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     0.36 seconds since last report (0.00 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 16.31k samplesPerSecond , throughputPerWorker = 8.16k samplesPerSecond
MPI Rank 0: 07/13/2016 16:48:49: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84658042 * 20480; EvalErrorPrediction = 0.51123047 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 9.5367433e-08; epochTime=1.06401s
MPI Rank 0: 07/13/2016 16:48:49: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160713164744.999927/Speech/DNN_ParallelBM@debug_gpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/13/2016 16:48:50: learnRatePerSample reduced to 4.7683717e-08
MPI Rank 0: 07/13/2016 16:48:50: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:48:50: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:48:50: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 07/13/2016 16:48:50:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80074571 * 1897; EvalErrorPrediction = 0.49762783 * 1897; time = 0.1588s; samplesPerSecond = 11947.0
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.01 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     0.26 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 19.18k samplesPerSecond , throughputPerWorker = 9.59k samplesPerSecond
MPI Rank 0: 07/13/2016 16:48:50:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86932568 * 1821; EvalErrorPrediction = 0.51345415 * 1821; time = 0.1768s; samplesPerSecond = 10302.5
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.01 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     0.22 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 21.75k samplesPerSecond , throughputPerWorker = 10.87k samplesPerSecond
MPI Rank 0: 07/13/2016 16:48:51:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.89591323 * 1871; EvalErrorPrediction = 0.51950828 * 1871; time = 0.1643s; samplesPerSecond = 11387.2
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     0.23 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 21.38k samplesPerSecond , throughputPerWorker = 10.69k samplesPerSecond
MPI Rank 0: 07/13/2016 16:48:51:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.82329983 * 1870; EvalErrorPrediction = 0.49786096 * 1870; time = 0.1788s; samplesPerSecond = 10459.2
MPI Rank 0: 07/13/2016 16:48:51:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.90156482 * 1899; EvalErrorPrediction = 0.52132701 * 1899; time = 0.1517s; samplesPerSecond = 12521.4
MPI Rank 0: 07/13/2016 16:48:51:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.86338231 * 1878; EvalErrorPrediction = 0.52396166 * 1878; time = 0.1393s; samplesPerSecond = 13478.2
MPI Rank 0: 07/13/2016 16:48:51:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.86676978 * 1221; EvalErrorPrediction = 0.51187551 * 1221; time = 0.0546s; samplesPerSecond = 22345.9
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     0.36 seconds since last report (0.00 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 16.34k samplesPerSecond , throughputPerWorker = 8.17k samplesPerSecond
MPI Rank 0: 07/13/2016 16:48:51: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84658239 * 20480; EvalErrorPrediction = 0.51123047 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 4.7683717e-08; epochTime=1.06475s
MPI Rank 0: 07/13/2016 16:48:51: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160713164744.999927/Speech/DNN_ParallelBM@debug_gpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/13/2016 16:48:51: learnRatePerSample reduced to 2.3841858e-08
MPI Rank 0: 07/13/2016 16:48:51: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:48:51: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:48:51: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 07/13/2016 16:48:52:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80074576 * 1897; EvalErrorPrediction = 0.49762783 * 1897; time = 0.1584s; samplesPerSecond = 11977.4
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     0.25 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 19.35k samplesPerSecond , throughputPerWorker = 9.68k samplesPerSecond
MPI Rank 0: 07/13/2016 16:48:52:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86932620 * 1821; EvalErrorPrediction = 0.51345415 * 1821; time = 0.1690s; samplesPerSecond = 10773.2
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.02 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     0.23 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 21.62k samplesPerSecond , throughputPerWorker = 10.81k samplesPerSecond
MPI Rank 0: 07/13/2016 16:48:52:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.89591438 * 1871; EvalErrorPrediction = 0.51950828 * 1871; time = 0.1717s; samplesPerSecond = 10896.3
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     0.22 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 21.65k samplesPerSecond , throughputPerWorker = 10.83k samplesPerSecond
MPI Rank 0: 07/13/2016 16:48:52:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.82330109 * 1870; EvalErrorPrediction = 0.49786096 * 1870; time = 0.1760s; samplesPerSecond = 10623.9
MPI Rank 0: 07/13/2016 16:48:52:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.90156657 * 1899; EvalErrorPrediction = 0.52132701 * 1899; time = 0.1518s; samplesPerSecond = 12512.8
MPI Rank 0: 07/13/2016 16:48:52:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.86338436 * 1878; EvalErrorPrediction = 0.52449414 * 1878; time = 0.1391s; samplesPerSecond = 13504.3
MPI Rank 0: 07/13/2016 16:48:52:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.86677134 * 1221; EvalErrorPrediction = 0.51187551 * 1221; time = 0.0538s; samplesPerSecond = 22696.9
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     0.36 seconds since last report (0.00 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 16.40k samplesPerSecond , throughputPerWorker = 8.20k samplesPerSecond
MPI Rank 0: 07/13/2016 16:48:52: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84658338 * 20480; EvalErrorPrediction = 0.51127930 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 2.3841858e-08; epochTime=1.0597s
MPI Rank 0: 07/13/2016 16:48:52: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160713164744.999927/Speech/DNN_ParallelBM@debug_gpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/13/2016 16:48:53: learnRatePerSample reduced to 1.1920929e-08
MPI Rank 0: 07/13/2016 16:48:53: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:48:53: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:48:53: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 07/13/2016 16:48:53:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80074579 * 1897; EvalErrorPrediction = 0.49762783 * 1897; time = 0.1637s; samplesPerSecond = 11588.5
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     0.27 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 18.20k samplesPerSecond , throughputPerWorker = 9.10k samplesPerSecond
MPI Rank 0: 07/13/2016 16:48:53:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86932646 * 1821; EvalErrorPrediction = 0.51345415 * 1821; time = 0.1676s; samplesPerSecond = 10864.4
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.01 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     0.23 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 21.68k samplesPerSecond , throughputPerWorker = 10.84k samplesPerSecond
MPI Rank 0: 07/13/2016 16:48:53:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.89591496 * 1871; EvalErrorPrediction = 0.51950828 * 1871; time = 0.1710s; samplesPerSecond = 10940.9
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     0.23 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 21.44k samplesPerSecond , throughputPerWorker = 10.72k samplesPerSecond
MPI Rank 0: 07/13/2016 16:48:53:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.82330173 * 1870; EvalErrorPrediction = 0.49786096 * 1870; time = 0.1784s; samplesPerSecond = 10482.8
MPI Rank 0: 07/13/2016 16:48:54:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.90156744 * 1899; EvalErrorPrediction = 0.52132701 * 1899; time = 0.1511s; samplesPerSecond = 12568.2
MPI Rank 0: 07/13/2016 16:48:54:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.86338539 * 1878; EvalErrorPrediction = 0.52449414 * 1878; time = 0.1387s; samplesPerSecond = 13542.8
MPI Rank 0: 07/13/2016 16:48:54:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.86677211 * 1221; EvalErrorPrediction = 0.51187551 * 1221; time = 0.0539s; samplesPerSecond = 22673.3
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     0.35 seconds since last report (0.00 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 16.44k samplesPerSecond , throughputPerWorker = 8.22k samplesPerSecond
MPI Rank 0: 07/13/2016 16:48:54: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84658387 * 20480; EvalErrorPrediction = 0.51127930 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 1.1920929e-08; epochTime=1.07633s
MPI Rank 0: 07/13/2016 16:48:54: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160713164744.999927/Speech/DNN_ParallelBM@debug_gpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/13/2016 16:48:54: learnRatePerSample reduced to 5.9604646e-09
MPI Rank 0: 07/13/2016 16:48:54: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:48:54: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:48:54: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 07/13/2016 16:48:54:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80074580 * 1897; EvalErrorPrediction = 0.49762783 * 1897; time = 0.1669s; samplesPerSecond = 11365.8
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     0.27 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 18.18k samplesPerSecond , throughputPerWorker = 9.09k samplesPerSecond
MPI Rank 0: 07/13/2016 16:48:54:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86932659 * 1821; EvalErrorPrediction = 0.51345415 * 1821; time = 0.1638s; samplesPerSecond = 11114.9
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.01 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     0.23 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 21.67k samplesPerSecond , throughputPerWorker = 10.84k samplesPerSecond
MPI Rank 0: 07/13/2016 16:48:55:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.89591525 * 1871; EvalErrorPrediction = 0.51950828 * 1871; time = 0.1712s; samplesPerSecond = 10931.2
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     0.23 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 21.45k samplesPerSecond , throughputPerWorker = 10.72k samplesPerSecond
MPI Rank 0: 07/13/2016 16:48:55:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.82330204 * 1870; EvalErrorPrediction = 0.49786096 * 1870; time = 0.1783s; samplesPerSecond = 10490.7
MPI Rank 0: 07/13/2016 16:48:55:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.90156788 * 1899; EvalErrorPrediction = 0.52132701 * 1899; time = 0.1520s; samplesPerSecond = 12490.0
MPI Rank 0: 07/13/2016 16:48:55:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.86338590 * 1878; EvalErrorPrediction = 0.52449414 * 1878; time = 0.1400s; samplesPerSecond = 13412.3
MPI Rank 0: 07/13/2016 16:48:55:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.86677250 * 1221; EvalErrorPrediction = 0.51187551 * 1221; time = 0.0542s; samplesPerSecond = 22523.9
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     0.36 seconds since last report (0.00 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 16.31k samplesPerSecond , throughputPerWorker = 8.16k samplesPerSecond
MPI Rank 0: 07/13/2016 16:48:55: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84658412 * 20480; EvalErrorPrediction = 0.51127930 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 5.9604646e-09; epochTime=1.07957s
MPI Rank 0: 07/13/2016 16:48:55: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160713164744.999927/Speech/DNN_ParallelBM@debug_gpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/13/2016 16:48:55: learnRatePerSample reduced to 2.9802323e-09
MPI Rank 0: 07/13/2016 16:48:55: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:48:55: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:48:55: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 07/13/2016 16:48:56:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80074581 * 1897; EvalErrorPrediction = 0.49762783 * 1897; time = 0.1595s; samplesPerSecond = 11895.5
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.01 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     0.26 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 19.17k samplesPerSecond , throughputPerWorker = 9.58k samplesPerSecond
MPI Rank 0: 07/13/2016 16:48:56:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86932665 * 1821; EvalErrorPrediction = 0.51345415 * 1821; time = 0.1718s; samplesPerSecond = 10600.3
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.02 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     0.22 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 21.95k samplesPerSecond , throughputPerWorker = 10.98k samplesPerSecond
MPI Rank 0: 07/13/2016 16:48:56:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.89591539 * 1871; EvalErrorPrediction = 0.51950828 * 1871; time = 0.1658s; samplesPerSecond = 11286.0
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.04 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     0.23 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 21.38k samplesPerSecond , throughputPerWorker = 10.69k samplesPerSecond
MPI Rank 0: 07/13/2016 16:48:56:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.82330220 * 1870; EvalErrorPrediction = 0.49786096 * 1870; time = 0.1790s; samplesPerSecond = 10448.4
MPI Rank 0: 07/13/2016 16:48:56:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.90156809 * 1899; EvalErrorPrediction = 0.52132701 * 1899; time = 0.1512s; samplesPerSecond = 12563.4
MPI Rank 0: 07/13/2016 16:48:56:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.86338616 * 1878; EvalErrorPrediction = 0.52449414 * 1878; time = 0.1394s; samplesPerSecond = 13471.8
MPI Rank 0: 07/13/2016 16:48:56:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.86677270 * 1221; EvalErrorPrediction = 0.51187551 * 1221; time = 0.0542s; samplesPerSecond = 22521.4
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.04 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     0.36 seconds since last report (0.00 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 16.38k samplesPerSecond , throughputPerWorker = 8.19k samplesPerSecond
MPI Rank 0: 07/13/2016 16:48:56: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84658424 * 20480; EvalErrorPrediction = 0.51127930 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 2.9802323e-09; epochTime=1.06199s
MPI Rank 0: 07/13/2016 16:48:56: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160713164744.999927/Speech/DNN_ParallelBM@debug_gpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/13/2016 16:48:57: learnRatePerSample reduced to 1.4901161e-09
MPI Rank 0: 07/13/2016 16:48:57: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:48:57: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:48:57: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 07/13/2016 16:48:57:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80074581 * 1897; EvalErrorPrediction = 0.49762783 * 1897; time = 0.1584s; samplesPerSecond = 11977.0
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     0.26 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 19.25k samplesPerSecond , throughputPerWorker = 9.63k samplesPerSecond
MPI Rank 0: 07/13/2016 16:48:57:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86932668 * 1821; EvalErrorPrediction = 0.51345415 * 1821; time = 0.1701s; samplesPerSecond = 10705.5
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.02 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     0.23 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 21.58k samplesPerSecond , throughputPerWorker = 10.79k samplesPerSecond
MPI Rank 0: 07/13/2016 16:48:57:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.89591546 * 1871; EvalErrorPrediction = 0.51950828 * 1871; time = 0.1711s; samplesPerSecond = 10936.7
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     0.23 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 21.34k samplesPerSecond , throughputPerWorker = 10.67k samplesPerSecond
MPI Rank 0: 07/13/2016 16:48:57:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.82330228 * 1870; EvalErrorPrediction = 0.49786096 * 1870; time = 0.1791s; samplesPerSecond = 10439.6
MPI Rank 0: 07/13/2016 16:48:58:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.90156820 * 1899; EvalErrorPrediction = 0.52132701 * 1899; time = 0.1512s; samplesPerSecond = 12557.2
MPI Rank 0: 07/13/2016 16:48:58:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.86338629 * 1878; EvalErrorPrediction = 0.52449414 * 1878; time = 0.1392s; samplesPerSecond = 13486.8
MPI Rank 0: 07/13/2016 16:48:58:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.86677279 * 1221; EvalErrorPrediction = 0.51187551 * 1221; time = 0.0547s; samplesPerSecond = 22334.8
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     0.36 seconds since last report (0.00 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 16.37k samplesPerSecond , throughputPerWorker = 8.19k samplesPerSecond
MPI Rank 0: 07/13/2016 16:48:58: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84658431 * 20480; EvalErrorPrediction = 0.51127930 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 1.4901161e-09; epochTime=1.06512s
MPI Rank 0: 07/13/2016 16:48:58: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160713164744.999927/Speech/DNN_ParallelBM@debug_gpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/13/2016 16:48:58: learnRatePerSample reduced to 7.4505807e-10
MPI Rank 0: 07/13/2016 16:48:58: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 07/13/2016 16:48:58: Learn Rate Per Sample for Epoch[5] = 7.4505807e-10 is less than minLearnRate 9.9999997e-10. Training complete.
MPI Rank 0: 07/13/2016 16:48:58: CNTKCommandTrainEnd: speechTrain
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:48:58: Action "train" complete.
MPI Rank 0: 
MPI Rank 0: 07/13/2016 16:48:58: __COMPLETED__
MPI Rank 0: ~MPIWrapper
MPI Rank 1: 07/13/2016 16:48:11: -------------------------------------------------------------------
MPI Rank 1: 07/13/2016 16:48:11: Build info: 
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:48:11: 		Built time: Jul 13 2016 15:56:58
MPI Rank 1: 07/13/2016 16:48:11: 		Last modified date: Tue Jul 12 10:36:36 2016
MPI Rank 1: 07/13/2016 16:48:11: 		Build type: debug
MPI Rank 1: 07/13/2016 16:48:11: 		Build target: GPU
MPI Rank 1: 07/13/2016 16:48:11: 		With 1bit-SGD: yes
MPI Rank 1: 07/13/2016 16:48:11: 		Math lib: mkl
MPI Rank 1: 07/13/2016 16:48:11: 		CUDA_PATH: /usr/local/cuda-7.5
MPI Rank 1: 07/13/2016 16:48:11: 		CUB_PATH: /usr/local/cub-1.4.1
MPI Rank 1: 07/13/2016 16:48:11: 		CUDNN_PATH: /usr/local/cudnn-4.0
MPI Rank 1: 07/13/2016 16:48:11: 		Build Branch: HEAD
MPI Rank 1: 07/13/2016 16:48:11: 		Build SHA1: 539ab7467b022b4ffa087721bcf20d18485c8d0d
MPI Rank 1: 07/13/2016 16:48:11: 		Built by philly on a77bf6d98305
MPI Rank 1: 07/13/2016 16:48:11: 		Build Path: /home/philly/jenkins/workspace/CNTK-Build-Linux
MPI Rank 1: 07/13/2016 16:48:11: -------------------------------------------------------------------
MPI Rank 1: 07/13/2016 16:48:13: -------------------------------------------------------------------
MPI Rank 1: 07/13/2016 16:48:13: GPU info:
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:48:13: 		Device[0]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3071 MB
MPI Rank 1: 07/13/2016 16:48:13: 		Device[1]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3071 MB
MPI Rank 1: 07/13/2016 16:48:13: 		Device[2]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3071 MB
MPI Rank 1: 07/13/2016 16:48:13: 		Device[3]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3071 MB
MPI Rank 1: 07/13/2016 16:48:13: -------------------------------------------------------------------
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:48:13: Running on localhost at 2016/07/13 16:48:13
MPI Rank 1: 07/13/2016 16:48:13: Command line: 
MPI Rank 1: /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/build/1bitsgd/debug/bin/cntk  configFile=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/ParallelBM/../ParallelBM/cntk.cntk  currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data  RunDir=/tmp/cntk-test-20160713164744.999927/Speech/DNN_ParallelBM@debug_gpu  DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data  ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/ParallelBM/..  OutputDir=/tmp/cntk-test-20160713164744.999927/Speech/DNN_ParallelBM@debug_gpu  DeviceId=0  timestamping=true  numCPUThreads=12  precision=double  speechTrain=[SGD=[ParallelTrain=[parallelizationStartEpoch=2]]]  stderr=/tmp/cntk-test-20160713164744.999927/Speech/DNN_ParallelBM@debug_gpu/stderr
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:48:13: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
MPI Rank 1: 07/13/2016 16:48:13: precision = "float"
MPI Rank 1: command = speechTrain
MPI Rank 1: deviceId = $DeviceId$
MPI Rank 1: parallelTrain = true
MPI Rank 1: speechTrain = [
MPI Rank 1:     action = "train"
MPI Rank 1:     modelPath = "$RunDir$/models/cntkSpeech.dnn"
MPI Rank 1:     deviceId = $DeviceId$
MPI Rank 1:     traceLevel = 1
MPI Rank 1:     SimpleNetworkBuilder = [
MPI Rank 1:         layerSizes = 363:512:512:132
MPI Rank 1:         trainingCriterion = "CrossEntropyWithSoftmax"
MPI Rank 1:         evalCriterion = "ErrorPrediction"
MPI Rank 1:         layerTypes = "Sigmoid"
MPI Rank 1:         initValueScale = 1.0
MPI Rank 1:         applyMeanVarNorm = true
MPI Rank 1:         uniformInit = true
MPI Rank 1:         needPrior = true
MPI Rank 1:     ]
MPI Rank 1:     ExperimentalNetworkBuilder = [    // the same as above but with BS. Not active; activate by commenting out the SimpleNetworkBuilder entry above
MPI Rank 1:         layerSizes = 363:512:512:132
MPI Rank 1:         trainingCriterion = 'CE'
MPI Rank 1:         evalCriterion = 'Err'
MPI Rank 1:         applyMeanVarNorm = true
MPI Rank 1:         L = Length(layerSizes)-1    // number of model layers
MPI Rank 1:         features = Input(layerSizes[0], 1, tag='feature') ; labels = Input(layerSizes[Length(layerSizes)-1], 1, tag='label')
MPI Rank 1:         featNorm = if applyMeanVarNorm
MPI Rank 1:                    then MeanVarNorm(features)
MPI Rank 1:                    else features
MPI Rank 1:         layers[layer:1..L-1] = if layer > 1
MPI Rank 1:                                then SBFF(layers[layer-1].Eh, layerSizes[layer], layerSizes[layer-1])
MPI Rank 1:                                else SBFF(featNorm, layerSizes[layer], layerSizes[layer-1])
MPI Rank 1:         outLayer = BFF(layers[L-1].Eh, layerSizes[L], layerSizes[L-1])
MPI Rank 1:         outZ = outLayer.z        // + PastValue(layerSizes[L], 1, outLayer.z)
MPI Rank 1:         CE = if trainingCriterion == 'CE'
MPI Rank 1:              then CrossEntropyWithSoftmax(labels, outZ, tag='criterion')
MPI Rank 1:              else Fail('unknown trainingCriterion ' + trainingCriterion)
MPI Rank 1:         Err = if evalCriterion == 'Err' then
MPI Rank 1:               ErrorPrediction(labels, outZ, tag='evaluation')
MPI Rank 1:               else Fail('unknown evalCriterion ' + evalCriterion)
MPI Rank 1:         logPrior = LogPrior(labels)
MPI Rank 1:         // TODO: how to add a tag to an infix operation?
MPI Rank 1:         ScaledLogLikelihood = Minus (outZ, logPrior, tag='output')
MPI Rank 1:     ]
MPI Rank 1:     SGD = [
MPI Rank 1:         epochSize = 20480
MPI Rank 1:         minibatchSize = 64:256:1024
MPI Rank 1:         learningRatesPerMB = 1.0:0.5:0.1
MPI Rank 1:         numMBsToShowResult = 3
MPI Rank 1:         momentumPerMB = 0.9:0.656119
MPI Rank 1:         dropoutRate = 0.0
MPI Rank 1:         maxEpochs = 5
MPI Rank 1:         keepCheckPointFiles = true
MPI Rank 1:         clippingThresholdPerSample = 1#INF
MPI Rank 1:         ParallelTrain = [
MPI Rank 1:             parallelizationMethod = "BlockMomentumSGD"
MPI Rank 1:             distributedMBReading = true
MPI Rank 1:             syncPerfStats=1
MPI Rank 1:             BlockMomentumSGD = [
MPI Rank 1:                 blockSizePerWorker=2048
MPI Rank 1:                 resetSGDMomentum=true
MPI Rank 1:                 useNesterovMomentum=true
MPI Rank 1:             ]
MPI Rank 1:         ]
MPI Rank 1:         AutoAdjust = [
MPI Rank 1:             reduceLearnRateIfImproveLessThan = 0
MPI Rank 1:             loadBestModel = true
MPI Rank 1:             increaseLearnRateIfImproveMoreThan = 1000000000
MPI Rank 1:             learnRateDecreaseFactor = 0.5
MPI Rank 1:             learnRateIncreaseFactor = 1.382
MPI Rank 1:             autoAdjustLR = "adjustAfterEpoch"
MPI Rank 1:         ]
MPI Rank 1:     ]
MPI Rank 1:     reader = [
MPI Rank 1:         readerType = "HTKMLFReader"
MPI Rank 1:         readMethod = "blockRandomize"
MPI Rank 1:         miniBatchMode = "partial"
MPI Rank 1:         randomize = "auto"
MPI Rank 1:         verbosity = 0
MPI Rank 1:         features = [
MPI Rank 1:             dim = 363
MPI Rank 1:             type = "real"
MPI Rank 1:             scpFile = "glob_0000.scp"
MPI Rank 1:         ]
MPI Rank 1:         labels = [
MPI Rank 1:             mlfFile = "$DataDir$/glob_0000.mlf"
MPI Rank 1:             labelMappingFile = "$DataDir$/state.list"
MPI Rank 1:             labelDim = 132
MPI Rank 1:             labelType = "category"
MPI Rank 1:         ]
MPI Rank 1:     ]
MPI Rank 1: ]
MPI Rank 1: currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
MPI Rank 1: RunDir=/tmp/cntk-test-20160713164744.999927/Speech/DNN_ParallelBM@debug_gpu
MPI Rank 1: DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
MPI Rank 1: ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/ParallelBM/..
MPI Rank 1: OutputDir=/tmp/cntk-test-20160713164744.999927/Speech/DNN_ParallelBM@debug_gpu
MPI Rank 1: DeviceId=0
MPI Rank 1: timestamping=true
MPI Rank 1: numCPUThreads=12
MPI Rank 1: precision=double
MPI Rank 1: speechTrain=[SGD=[ParallelTrain=[parallelizationStartEpoch=2]]]
MPI Rank 1: stderr=/tmp/cntk-test-20160713164744.999927/Speech/DNN_ParallelBM@debug_gpu/stderr
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:48:13: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:48:13: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 1: 07/13/2016 16:48:13: precision = "float"
MPI Rank 1: command = speechTrain
MPI Rank 1: deviceId = 0
MPI Rank 1: parallelTrain = true
MPI Rank 1: speechTrain = [
MPI Rank 1:     action = "train"
MPI Rank 1:     modelPath = "/tmp/cntk-test-20160713164744.999927/Speech/DNN_ParallelBM@debug_gpu/models/cntkSpeech.dnn"
MPI Rank 1:     deviceId = 0
MPI Rank 1:     traceLevel = 1
MPI Rank 1:     SimpleNetworkBuilder = [
MPI Rank 1:         layerSizes = 363:512:512:132
MPI Rank 1:         trainingCriterion = "CrossEntropyWithSoftmax"
MPI Rank 1:         evalCriterion = "ErrorPrediction"
MPI Rank 1:         layerTypes = "Sigmoid"
MPI Rank 1:         initValueScale = 1.0
MPI Rank 1:         applyMeanVarNorm = true
MPI Rank 1:         uniformInit = true
MPI Rank 1:         needPrior = true
MPI Rank 1:     ]
MPI Rank 1:     ExperimentalNetworkBuilder = [    // the same as above but with BS. Not active; activate by commenting out the SimpleNetworkBuilder entry above
MPI Rank 1:         layerSizes = 363:512:512:132
MPI Rank 1:         trainingCriterion = 'CE'
MPI Rank 1:         evalCriterion = 'Err'
MPI Rank 1:         applyMeanVarNorm = true
MPI Rank 1:         L = Length(layerSizes)-1    // number of model layers
MPI Rank 1:         features = Input(layerSizes[0], 1, tag='feature') ; labels = Input(layerSizes[Length(layerSizes)-1], 1, tag='label')
MPI Rank 1:         featNorm = if applyMeanVarNorm
MPI Rank 1:                    then MeanVarNorm(features)
MPI Rank 1:                    else features
MPI Rank 1:         layers[layer:1..L-1] = if layer > 1
MPI Rank 1:                                then SBFF(layers[layer-1].Eh, layerSizes[layer], layerSizes[layer-1])
MPI Rank 1:                                else SBFF(featNorm, layerSizes[layer], layerSizes[layer-1])
MPI Rank 1:         outLayer = BFF(layers[L-1].Eh, layerSizes[L], layerSizes[L-1])
MPI Rank 1:         outZ = outLayer.z        // + PastValue(layerSizes[L], 1, outLayer.z)
MPI Rank 1:         CE = if trainingCriterion == 'CE'
MPI Rank 1:              then CrossEntropyWithSoftmax(labels, outZ, tag='criterion')
MPI Rank 1:              else Fail('unknown trainingCriterion ' + trainingCriterion)
MPI Rank 1:         Err = if evalCriterion == 'Err' then
MPI Rank 1:               ErrorPrediction(labels, outZ, tag='evaluation')
MPI Rank 1:               else Fail('unknown evalCriterion ' + evalCriterion)
MPI Rank 1:         logPrior = LogPrior(labels)
MPI Rank 1:         // TODO: how to add a tag to an infix operation?
MPI Rank 1:         ScaledLogLikelihood = Minus (outZ, logPrior, tag='output')
MPI Rank 1:     ]
MPI Rank 1:     SGD = [
MPI Rank 1:         epochSize = 20480
MPI Rank 1:         minibatchSize = 64:256:1024
MPI Rank 1:         learningRatesPerMB = 1.0:0.5:0.1
MPI Rank 1:         numMBsToShowResult = 3
MPI Rank 1:         momentumPerMB = 0.9:0.656119
MPI Rank 1:         dropoutRate = 0.0
MPI Rank 1:         maxEpochs = 5
MPI Rank 1:         keepCheckPointFiles = true
MPI Rank 1:         clippingThresholdPerSample = 1#INF
MPI Rank 1:         ParallelTrain = [
MPI Rank 1:             parallelizationMethod = "BlockMomentumSGD"
MPI Rank 1:             distributedMBReading = true
MPI Rank 1:             syncPerfStats=1
MPI Rank 1:             BlockMomentumSGD = [
MPI Rank 1:                 blockSizePerWorker=2048
MPI Rank 1:                 resetSGDMomentum=true
MPI Rank 1:                 useNesterovMomentum=true
MPI Rank 1:             ]
MPI Rank 1:         ]
MPI Rank 1:         AutoAdjust = [
MPI Rank 1:             reduceLearnRateIfImproveLessThan = 0
MPI Rank 1:             loadBestModel = true
MPI Rank 1:             increaseLearnRateIfImproveMoreThan = 1000000000
MPI Rank 1:             learnRateDecreaseFactor = 0.5
MPI Rank 1:             learnRateIncreaseFactor = 1.382
MPI Rank 1:             autoAdjustLR = "adjustAfterEpoch"
MPI Rank 1:         ]
MPI Rank 1:     ]
MPI Rank 1:     reader = [
MPI Rank 1:         readerType = "HTKMLFReader"
MPI Rank 1:         readMethod = "blockRandomize"
MPI Rank 1:         miniBatchMode = "partial"
MPI Rank 1:         randomize = "auto"
MPI Rank 1:         verbosity = 0
MPI Rank 1:         features = [
MPI Rank 1:             dim = 363
MPI Rank 1:             type = "real"
MPI Rank 1:             scpFile = "glob_0000.scp"
MPI Rank 1:         ]
MPI Rank 1:         labels = [
MPI Rank 1:             mlfFile = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/glob_0000.mlf"
MPI Rank 1:             labelMappingFile = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/state.list"
MPI Rank 1:             labelDim = 132
MPI Rank 1:             labelType = "category"
MPI Rank 1:         ]
MPI Rank 1:     ]
MPI Rank 1: ]
MPI Rank 1: currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
MPI Rank 1: RunDir=/tmp/cntk-test-20160713164744.999927/Speech/DNN_ParallelBM@debug_gpu
MPI Rank 1: DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
MPI Rank 1: ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/ParallelBM/..
MPI Rank 1: OutputDir=/tmp/cntk-test-20160713164744.999927/Speech/DNN_ParallelBM@debug_gpu
MPI Rank 1: DeviceId=0
MPI Rank 1: timestamping=true
MPI Rank 1: numCPUThreads=12
MPI Rank 1: precision=double
MPI Rank 1: speechTrain=[SGD=[ParallelTrain=[parallelizationStartEpoch=2]]]
MPI Rank 1: stderr=/tmp/cntk-test-20160713164744.999927/Speech/DNN_ParallelBM@debug_gpu/stderr
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:48:13: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:48:13: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 1: configparameters: cntk.cntk:command=speechTrain
MPI Rank 1: configparameters: cntk.cntk:ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/ParallelBM/..
MPI Rank 1: configparameters: cntk.cntk:currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
MPI Rank 1: configparameters: cntk.cntk:DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
MPI Rank 1: configparameters: cntk.cntk:deviceId=0
MPI Rank 1: configparameters: cntk.cntk:numCPUThreads=12
MPI Rank 1: configparameters: cntk.cntk:OutputDir=/tmp/cntk-test-20160713164744.999927/Speech/DNN_ParallelBM@debug_gpu
MPI Rank 1: configparameters: cntk.cntk:parallelTrain=true
MPI Rank 1: configparameters: cntk.cntk:precision=double
MPI Rank 1: configparameters: cntk.cntk:RunDir=/tmp/cntk-test-20160713164744.999927/Speech/DNN_ParallelBM@debug_gpu
MPI Rank 1: configparameters: cntk.cntk:speechTrain=[
MPI Rank 1:     action = "train"
MPI Rank 1:     modelPath = "/tmp/cntk-test-20160713164744.999927/Speech/DNN_ParallelBM@debug_gpu/models/cntkSpeech.dnn"
MPI Rank 1:     deviceId = 0
MPI Rank 1:     traceLevel = 1
MPI Rank 1:     SimpleNetworkBuilder = [
MPI Rank 1:         layerSizes = 363:512:512:132
MPI Rank 1:         trainingCriterion = "CrossEntropyWithSoftmax"
MPI Rank 1:         evalCriterion = "ErrorPrediction"
MPI Rank 1:         layerTypes = "Sigmoid"
MPI Rank 1:         initValueScale = 1.0
MPI Rank 1:         applyMeanVarNorm = true
MPI Rank 1:         uniformInit = true
MPI Rank 1:         needPrior = true
MPI Rank 1:     ]
MPI Rank 1:     ExperimentalNetworkBuilder = [    // the same as above but with BS. Not active; activate by commenting out the SimpleNetworkBuilder entry above
MPI Rank 1:         layerSizes = 363:512:512:132
MPI Rank 1:         trainingCriterion = 'CE'
MPI Rank 1:         evalCriterion = 'Err'
MPI Rank 1:         applyMeanVarNorm = true
MPI Rank 1:         L = Length(layerSizes)-1    // number of model layers
MPI Rank 1:         features = Input(layerSizes[0], 1, tag='feature') ; labels = Input(layerSizes[Length(layerSizes)-1], 1, tag='label')
MPI Rank 1:         featNorm = if applyMeanVarNorm
MPI Rank 1:                    then MeanVarNorm(features)
MPI Rank 1:                    else features
MPI Rank 1:         layers[layer:1..L-1] = if layer > 1
MPI Rank 1:                                then SBFF(layers[layer-1].Eh, layerSizes[layer], layerSizes[layer-1])
MPI Rank 1:                                else SBFF(featNorm, layerSizes[layer], layerSizes[layer-1])
MPI Rank 1:         outLayer = BFF(layers[L-1].Eh, layerSizes[L], layerSizes[L-1])
MPI Rank 1:         outZ = outLayer.z        // + PastValue(layerSizes[L], 1, outLayer.z)
MPI Rank 1:         CE = if trainingCriterion == 'CE'
MPI Rank 1:              then CrossEntropyWithSoftmax(labels, outZ, tag='criterion')
MPI Rank 1:              else Fail('unknown trainingCriterion ' + trainingCriterion)
MPI Rank 1:         Err = if evalCriterion == 'Err' then
MPI Rank 1:               ErrorPrediction(labels, outZ, tag='evaluation')
MPI Rank 1:               else Fail('unknown evalCriterion ' + evalCriterion)
MPI Rank 1:         logPrior = LogPrior(labels)
MPI Rank 1:         // TODO: how to add a tag to an infix operation?
MPI Rank 1:         ScaledLogLikelihood = Minus (outZ, logPrior, tag='output')
MPI Rank 1:     ]
MPI Rank 1:     SGD = [
MPI Rank 1:         epochSize = 20480
MPI Rank 1:         minibatchSize = 64:256:1024
MPI Rank 1:         learningRatesPerMB = 1.0:0.5:0.1
MPI Rank 1:         numMBsToShowResult = 3
MPI Rank 1:         momentumPerMB = 0.9:0.656119
MPI Rank 1:         dropoutRate = 0.0
MPI Rank 1:         maxEpochs = 5
MPI Rank 1:         keepCheckPointFiles = true
MPI Rank 1:         clippingThresholdPerSample = 1#INF
MPI Rank 1:         ParallelTrain = [
MPI Rank 1:             parallelizationMethod = "BlockMomentumSGD"
MPI Rank 1:             distributedMBReading = true
MPI Rank 1:             syncPerfStats=1
MPI Rank 1:             BlockMomentumSGD = [
MPI Rank 1:                 blockSizePerWorker=2048
MPI Rank 1:                 resetSGDMomentum=true
MPI Rank 1:                 useNesterovMomentum=true
MPI Rank 1:             ]
MPI Rank 1:         ]
MPI Rank 1:         AutoAdjust = [
MPI Rank 1:             reduceLearnRateIfImproveLessThan = 0
MPI Rank 1:             loadBestModel = true
MPI Rank 1:             increaseLearnRateIfImproveMoreThan = 1000000000
MPI Rank 1:             learnRateDecreaseFactor = 0.5
MPI Rank 1:             learnRateIncreaseFactor = 1.382
MPI Rank 1:             autoAdjustLR = "adjustAfterEpoch"
MPI Rank 1:         ]
MPI Rank 1:     ]
MPI Rank 1:     reader = [
MPI Rank 1:         readerType = "HTKMLFReader"
MPI Rank 1:         readMethod = "blockRandomize"
MPI Rank 1:         miniBatchMode = "partial"
MPI Rank 1:         randomize = "auto"
MPI Rank 1:         verbosity = 0
MPI Rank 1:         features = [
MPI Rank 1:             dim = 363
MPI Rank 1:             type = "real"
MPI Rank 1:             scpFile = "glob_0000.scp"
MPI Rank 1:         ]
MPI Rank 1:         labels = [
MPI Rank 1:             mlfFile = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/glob_0000.mlf"
MPI Rank 1:             labelMappingFile = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/state.list"
MPI Rank 1:             labelDim = 132
MPI Rank 1:             labelType = "category"
MPI Rank 1:         ]
MPI Rank 1:     ]
MPI Rank 1: ] [SGD=[ParallelTrain=[parallelizationStartEpoch=2]]]
MPI Rank 1: 
MPI Rank 1: configparameters: cntk.cntk:stderr=/tmp/cntk-test-20160713164744.999927/Speech/DNN_ParallelBM@debug_gpu/stderr
MPI Rank 1: configparameters: cntk.cntk:timestamping=true
MPI Rank 1: 07/13/2016 16:48:13: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 1: 07/13/2016 16:48:13: Commands: speechTrain
MPI Rank 1: 07/13/2016 16:48:13: Precision = "double"
MPI Rank 1: 07/13/2016 16:48:13: Using 12 CPU threads.
MPI Rank 1: 07/13/2016 16:48:13: CNTKModelPath: /tmp/cntk-test-20160713164744.999927/Speech/DNN_ParallelBM@debug_gpu/models/cntkSpeech.dnn
MPI Rank 1: 07/13/2016 16:48:13: CNTKCommandTrainInfo: speechTrain : 5
MPI Rank 1: 07/13/2016 16:48:13: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 5
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:48:13: ##############################################################################
MPI Rank 1: 07/13/2016 16:48:13: #                                                                            #
MPI Rank 1: 07/13/2016 16:48:13: # Action "train"                                                             #
MPI Rank 1: 07/13/2016 16:48:13: #                                                                            #
MPI Rank 1: 07/13/2016 16:48:13: ##############################################################################
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:48:13: CNTKCommandTrainBegin: speechTrain
MPI Rank 1: SimpleNetworkBuilder Using GPU 0
MPI Rank 1: reading script file glob_0000.scp ... 948 entries
MPI Rank 1: total 132 state names in state list /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/state.list
MPI Rank 1: htkmlfreader: reading MLF file /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/glob_0000.mlf ... total 948 entries
MPI Rank 1: ...............................................................................................feature set 0: 252734 frames in 948 out of 948 utterances
MPI Rank 1: label set 0: 129 classes
MPI Rank 1: minibatchutterancesource: 948 utterances grouped into 3 chunks, av. chunk size: 316.0 utterances, 84244.7 frames
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:48:13: Creating virgin network.
MPI Rank 1: SetUniformRandomValue (GPU): creating curand object with seed 1, sizeof(ElemType)==8
MPI Rank 1: 
MPI Rank 1: Post-processing network...
MPI Rank 1: 
MPI Rank 1: 7 roots:
MPI Rank 1: 	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
MPI Rank 1: 	EvalErrorPrediction = ErrorPrediction()
MPI Rank 1: 	InvStdOfFeatures = InvStdDev()
MPI Rank 1: 	MeanOfFeatures = Mean()
MPI Rank 1: 	PosteriorProb = Softmax()
MPI Rank 1: 	Prior = Mean()
MPI Rank 1: 	ScaledLogLikelihood = Minus()
MPI Rank 1: 
MPI Rank 1: Validating network. 25 nodes to process in pass 1.
MPI Rank 1: 
MPI Rank 1: Validating --> labels = InputValue() :  -> [132 x *]
MPI Rank 1: Validating --> W2 = LearnableParameter() :  -> [132 x 512]
MPI Rank 1: Validating --> W1 = LearnableParameter() :  -> [512 x 512]
MPI Rank 1: Validating --> W0 = LearnableParameter() :  -> [512 x 363]
MPI Rank 1: Validating --> features = InputValue() :  -> [363 x *]
MPI Rank 1: Validating --> MeanOfFeatures = Mean (features) : [363 x *] -> [363]
MPI Rank 1: Validating --> InvStdOfFeatures = InvStdDev (features) : [363 x *] -> [363]
MPI Rank 1: Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [363 x *], [363], [363] -> [363 x *]
MPI Rank 1: Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [512 x 363], [363 x *] -> [512 x *]
MPI Rank 1: Validating --> B0 = LearnableParameter() :  -> [512 x 1]
MPI Rank 1: Validating --> W0*features+B0 = Plus (W0*features, B0) : [512 x *], [512 x 1] -> [512 x 1 x *]
MPI Rank 1: Validating --> H1 = Sigmoid (W0*features+B0) : [512 x 1 x *] -> [512 x 1 x *]
MPI Rank 1: Validating --> W1*H1 = Times (W1, H1) : [512 x 512], [512 x 1 x *] -> [512 x 1 x *]
MPI Rank 1: Validating --> B1 = LearnableParameter() :  -> [512 x 1]
MPI Rank 1: Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [512 x 1 x *], [512 x 1] -> [512 x 1 x *]
MPI Rank 1: Validating --> H2 = Sigmoid (W1*H1+B1) : [512 x 1 x *] -> [512 x 1 x *]
MPI Rank 1: Validating --> W2*H1 = Times (W2, H2) : [132 x 512], [512 x 1 x *] -> [132 x 1 x *]
MPI Rank 1: Validating --> B2 = LearnableParameter() :  -> [132 x 1]
MPI Rank 1: Validating --> HLast = Plus (W2*H1, B2) : [132 x 1 x *], [132 x 1] -> [132 x 1 x *]
MPI Rank 1: Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [132 x *], [132 x 1 x *] -> [1]
MPI Rank 1: Validating --> EvalErrorPrediction = ErrorPrediction (labels, HLast) : [132 x *], [132 x 1 x *] -> [1]
MPI Rank 1: Validating --> PosteriorProb = Softmax (HLast) : [132 x 1 x *] -> [132 x 1 x *]
MPI Rank 1: Validating --> Prior = Mean (labels) : [132 x *] -> [132]
MPI Rank 1: Validating --> LogOfPrior = Log (Prior) : [132] -> [132]
MPI Rank 1: Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [132 x 1 x *], [132] -> [132 x 1 x *]
MPI Rank 1: 
MPI Rank 1: Validating network. 17 nodes to process in pass 2.
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: Validating network, final pass.
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: 12 out of 25 nodes do not share the minibatch layout with the input data.
MPI Rank 1: 
MPI Rank 1: Post-processing network complete.
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:48:13: Created model with 25 nodes on GPU 0.
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:48:13: Training criterion node(s):
MPI Rank 1: 07/13/2016 16:48:13: 	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:48:13: Evaluation criterion node(s):
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:48:13: 	EvalErrorPrediction = ErrorPrediction
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: Allocating matrices for forward and/or backward propagation.
MPI Rank 1: 
MPI Rank 1: Memory Sharing Structure:
MPI Rank 1: 
MPI Rank 1: (nil): {[EvalErrorPrediction Gradient[1]] [InvStdOfFeatures Gradient[363]] [LogOfPrior Gradient[132]] [MVNormalizedFeatures Gradient[363 x *]] [MeanOfFeatures Gradient[363]] [PosteriorProb Gradient[132 x 1 x *]] [PosteriorProb Value[132 x 1 x *]] [Prior Gradient[132]] [ScaledLogLikelihood Gradient[132 x 1 x *]] [features Gradient[363 x *]] [labels Gradient[132 x *]] }
MPI Rank 1: 0x25f4228: {[features Value[363 x *]] }
MPI Rank 1: 0x2eca2c8: {[MeanOfFeatures Value[363]] }
MPI Rank 1: 0x2ed6a28: {[InvStdOfFeatures Value[363]] }
MPI Rank 1: 0x2ed7758: {[W0 Value[512 x 363]] }
MPI Rank 1: 0x2fc3f98: {[B0 Value[512 x 1]] }
MPI Rank 1: 0x2fc6088: {[W1 Value[512 x 512]] }
MPI Rank 1: 0x337b338: {[B1 Value[512 x 1]] }
MPI Rank 1: 0x337c4b8: {[W2 Value[132 x 512]] }
MPI Rank 1: 0x337d168: {[B2 Value[132 x 1]] }
MPI Rank 1: 0x337df98: {[labels Value[132 x *]] }
MPI Rank 1: 0x337f1f8: {[Prior Value[132]] }
MPI Rank 1: 0x3384c28: {[EvalErrorPrediction Value[1]] }
MPI Rank 1: 0x3384d88: {[ScaledLogLikelihood Value[132 x 1 x *]] }
MPI Rank 1: 0x3384f48: {[CrossEntropyWithSoftmax Value[1]] }
MPI Rank 1: 0x33853d8: {[W0 Gradient[512 x 363]] [W0*features+B0 Value[512 x 1 x *]] }
MPI Rank 1: 0x3385508: {[LogOfPrior Value[132]] }
MPI Rank 1: 0x3386c68: {[MVNormalizedFeatures Value[363 x *]] }
MPI Rank 1: 0x3387428: {[W0*features Value[512 x *]] }
MPI Rank 1: 0x3387638: {[H1 Value[512 x 1 x *]] [W0*features Gradient[512 x *]] }
MPI Rank 1: 0x3387798: {[W0*features+B0 Gradient[512 x 1 x *]] [W1*H1 Value[512 x 1 x *]] }
MPI Rank 1: 0x3387958: {[W1 Gradient[512 x 512]] [W1*H1+B1 Value[512 x 1 x *]] }
MPI Rank 1: 0x3387b18: {[H2 Value[512 x 1 x *]] [W1*H1 Gradient[512 x 1 x *]] }
MPI Rank 1: 0x3387cd8: {[B0 Gradient[512 x 1]] [H1 Gradient[512 x 1 x *]] [W1*H1+B1 Gradient[512 x 1 x *]] [W2*H1 Value[132 x 1 x *]] }
MPI Rank 1: 0x3387e98: {[HLast Value[132 x 1 x *]] [W2 Gradient[132 x 512]] }
MPI Rank 1: 0x33889f8: {[CrossEntropyWithSoftmax Gradient[1]] }
MPI Rank 1: 0x3388bb8: {[B1 Gradient[512 x 1]] [H2 Gradient[512 x 1 x *]] [HLast Gradient[132 x 1 x *]] }
MPI Rank 1: 0x3388d78: {[W2*H1 Gradient[132 x 1 x *]] }
MPI Rank 1: 0x3388f38: {[B2 Gradient[132 x 1]] }
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:48:13: Precomputing --> 3 PreCompute nodes found.
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:48:13: 	MeanOfFeatures = Mean()
MPI Rank 1: 07/13/2016 16:48:13: 	InvStdOfFeatures = InvStdDev()
MPI Rank 1: 07/13/2016 16:48:13: 	Prior = Mean()
MPI Rank 1: minibatchiterator: epoch 0: frames [0..252734] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
MPI Rank 1: requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:48:26: Precomputing --> Completed.
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:48:26: Starting Epoch 1: learning rate per sample = 0.015625  effective momentum = 0.900000  momentum as time constant = 607.4 samples
MPI Rank 1: minibatchiterator: epoch 0: frames [0..20480] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:48:26: Starting minibatch loop.
MPI Rank 1: 07/13/2016 16:48:26:  Epoch[ 1 of 5]-Minibatch[   1-   3, 0.94%]: CrossEntropyWithSoftmax = 4.57947979 * 192; EvalErrorPrediction = 0.96354167 * 192; time = 0.0476s; samplesPerSecond = 4033.7
MPI Rank 1: 07/13/2016 16:48:26:  Epoch[ 1 of 5]-Minibatch[   4-   6, 1.88%]: CrossEntropyWithSoftmax = 4.45832105 * 192; EvalErrorPrediction = 0.90104167 * 192; time = 0.0466s; samplesPerSecond = 4116.7
MPI Rank 1: 07/13/2016 16:48:26:  Epoch[ 1 of 5]-Minibatch[   7-   9, 2.81%]: CrossEntropyWithSoftmax = 4.29176856 * 192; EvalErrorPrediction = 0.85416667 * 192; time = 0.0468s; samplesPerSecond = 4098.4
MPI Rank 1: 07/13/2016 16:48:26:  Epoch[ 1 of 5]-Minibatch[  10-  12, 3.75%]: CrossEntropyWithSoftmax = 4.15840784 * 192; EvalErrorPrediction = 0.86979167 * 192; time = 0.0457s; samplesPerSecond = 4205.2
MPI Rank 1: 07/13/2016 16:48:26:  Epoch[ 1 of 5]-Minibatch[  13-  15, 4.69%]: CrossEntropyWithSoftmax = 4.21435783 * 192; EvalErrorPrediction = 0.86979167 * 192; time = 0.0443s; samplesPerSecond = 4335.9
MPI Rank 1: 07/13/2016 16:48:26:  Epoch[ 1 of 5]-Minibatch[  16-  18, 5.62%]: CrossEntropyWithSoftmax = 4.14020622 * 192; EvalErrorPrediction = 0.89583333 * 192; time = 0.0451s; samplesPerSecond = 4255.9
MPI Rank 1: 07/13/2016 16:48:26:  Epoch[ 1 of 5]-Minibatch[  19-  21, 6.56%]: CrossEntropyWithSoftmax = 4.04069876 * 192; EvalErrorPrediction = 0.85416667 * 192; time = 0.0446s; samplesPerSecond = 4304.0
MPI Rank 1: 07/13/2016 16:48:26:  Epoch[ 1 of 5]-Minibatch[  22-  24, 7.50%]: CrossEntropyWithSoftmax = 4.04991414 * 192; EvalErrorPrediction = 0.91666667 * 192; time = 0.0456s; samplesPerSecond = 4207.6
MPI Rank 1: 07/13/2016 16:48:26:  Epoch[ 1 of 5]-Minibatch[  25-  27, 8.44%]: CrossEntropyWithSoftmax = 3.88626656 * 192; EvalErrorPrediction = 0.84375000 * 192; time = 0.0433s; samplesPerSecond = 4430.9
MPI Rank 1: 07/13/2016 16:48:26:  Epoch[ 1 of 5]-Minibatch[  28-  30, 9.38%]: CrossEntropyWithSoftmax = 4.00467833 * 192; EvalErrorPrediction = 0.88020833 * 192; time = 0.0431s; samplesPerSecond = 4458.1
MPI Rank 1: 07/13/2016 16:48:26:  Epoch[ 1 of 5]-Minibatch[  31-  33, 10.31%]: CrossEntropyWithSoftmax = 3.94077029 * 192; EvalErrorPrediction = 0.86458333 * 192; time = 0.0421s; samplesPerSecond = 4560.9
MPI Rank 1: 07/13/2016 16:48:26:  Epoch[ 1 of 5]-Minibatch[  34-  36, 11.25%]: CrossEntropyWithSoftmax = 3.78326806 * 192; EvalErrorPrediction = 0.89062500 * 192; time = 0.0421s; samplesPerSecond = 4563.9
MPI Rank 1: 07/13/2016 16:48:26:  Epoch[ 1 of 5]-Minibatch[  37-  39, 12.19%]: CrossEntropyWithSoftmax = 3.94698521 * 192; EvalErrorPrediction = 0.89062500 * 192; time = 0.0421s; samplesPerSecond = 4565.5
MPI Rank 1: 07/13/2016 16:48:27:  Epoch[ 1 of 5]-Minibatch[  40-  42, 13.12%]: CrossEntropyWithSoftmax = 3.66011602 * 192; EvalErrorPrediction = 0.84895833 * 192; time = 0.0421s; samplesPerSecond = 4557.5
MPI Rank 1: 07/13/2016 16:48:27:  Epoch[ 1 of 5]-Minibatch[  43-  45, 14.06%]: CrossEntropyWithSoftmax = 3.98797978 * 192; EvalErrorPrediction = 0.91666667 * 192; time = 0.0421s; samplesPerSecond = 4556.6
MPI Rank 1: 07/13/2016 16:48:27:  Epoch[ 1 of 5]-Minibatch[  46-  48, 15.00%]: CrossEntropyWithSoftmax = 3.76297655 * 192; EvalErrorPrediction = 0.87500000 * 192; time = 0.0421s; samplesPerSecond = 4556.3
MPI Rank 1: 07/13/2016 16:48:27:  Epoch[ 1 of 5]-Minibatch[  49-  51, 15.94%]: CrossEntropyWithSoftmax = 3.69909670 * 192; EvalErrorPrediction = 0.89062500 * 192; time = 0.0420s; samplesPerSecond = 4574.8
MPI Rank 1: 07/13/2016 16:48:27:  Epoch[ 1 of 5]-Minibatch[  52-  54, 16.88%]: CrossEntropyWithSoftmax = 3.83747989 * 192; EvalErrorPrediction = 0.90104167 * 192; time = 0.0421s; samplesPerSecond = 4563.2
MPI Rank 1: 07/13/2016 16:48:27:  Epoch[ 1 of 5]-Minibatch[  55-  57, 17.81%]: CrossEntropyWithSoftmax = 3.82672791 * 192; EvalErrorPrediction = 0.89062500 * 192; time = 0.0419s; samplesPerSecond = 4580.5
MPI Rank 1: 07/13/2016 16:48:27:  Epoch[ 1 of 5]-Minibatch[  58-  60, 18.75%]: CrossEntropyWithSoftmax = 3.56520696 * 192; EvalErrorPrediction = 0.83333333 * 192; time = 0.0420s; samplesPerSecond = 4575.7
MPI Rank 1: 07/13/2016 16:48:27:  Epoch[ 1 of 5]-Minibatch[  61-  63, 19.69%]: CrossEntropyWithSoftmax = 3.40098566 * 192; EvalErrorPrediction = 0.80208333 * 192; time = 0.0415s; samplesPerSecond = 4630.2
MPI Rank 1: 07/13/2016 16:48:27:  Epoch[ 1 of 5]-Minibatch[  64-  66, 20.62%]: CrossEntropyWithSoftmax = 3.50668803 * 192; EvalErrorPrediction = 0.77604167 * 192; time = 0.0420s; samplesPerSecond = 4569.4
MPI Rank 1: 07/13/2016 16:48:27:  Epoch[ 1 of 5]-Minibatch[  67-  69, 21.56%]: CrossEntropyWithSoftmax = 3.82314351 * 192; EvalErrorPrediction = 0.86979167 * 192; time = 0.0421s; samplesPerSecond = 4565.6
MPI Rank 1: 07/13/2016 16:48:27:  Epoch[ 1 of 5]-Minibatch[  70-  72, 22.50%]: CrossEntropyWithSoftmax = 3.51780740 * 192; EvalErrorPrediction = 0.83854167 * 192; time = 0.0421s; samplesPerSecond = 4565.9
MPI Rank 1: 07/13/2016 16:48:27:  Epoch[ 1 of 5]-Minibatch[  73-  75, 23.44%]: CrossEntropyWithSoftmax = 3.32189431 * 192; EvalErrorPrediction = 0.79687500 * 192; time = 0.0420s; samplesPerSecond = 4569.3
MPI Rank 1: 07/13/2016 16:48:27:  Epoch[ 1 of 5]-Minibatch[  76-  78, 24.38%]: CrossEntropyWithSoftmax = 3.42533640 * 192; EvalErrorPrediction = 0.77604167 * 192; time = 0.0421s; samplesPerSecond = 4559.5
MPI Rank 1: 07/13/2016 16:48:27:  Epoch[ 1 of 5]-Minibatch[  79-  81, 25.31%]: CrossEntropyWithSoftmax = 3.42902377 * 192; EvalErrorPrediction = 0.81770833 * 192; time = 0.0421s; samplesPerSecond = 4556.9
MPI Rank 1: 07/13/2016 16:48:27:  Epoch[ 1 of 5]-Minibatch[  82-  84, 26.25%]: CrossEntropyWithSoftmax = 3.42017745 * 192; EvalErrorPrediction = 0.76041667 * 192; time = 0.0421s; samplesPerSecond = 4559.3
MPI Rank 1: 07/13/2016 16:48:27:  Epoch[ 1 of 5]-Minibatch[  85-  87, 27.19%]: CrossEntropyWithSoftmax = 3.30346679 * 192; EvalErrorPrediction = 0.73437500 * 192; time = 0.0421s; samplesPerSecond = 4557.1
MPI Rank 1: 07/13/2016 16:48:27:  Epoch[ 1 of 5]-Minibatch[  88-  90, 28.12%]: CrossEntropyWithSoftmax = 3.31343403 * 192; EvalErrorPrediction = 0.79687500 * 192; time = 0.0421s; samplesPerSecond = 4563.8
MPI Rank 1: 07/13/2016 16:48:27:  Epoch[ 1 of 5]-Minibatch[  91-  93, 29.06%]: CrossEntropyWithSoftmax = 3.22956709 * 192; EvalErrorPrediction = 0.83854167 * 192; time = 0.0416s; samplesPerSecond = 4613.9
MPI Rank 1: 07/13/2016 16:48:27:  Epoch[ 1 of 5]-Minibatch[  94-  96, 30.00%]: CrossEntropyWithSoftmax = 3.54894307 * 192; EvalErrorPrediction = 0.84895833 * 192; time = 0.0421s; samplesPerSecond = 4558.1
MPI Rank 1: 07/13/2016 16:48:27:  Epoch[ 1 of 5]-Minibatch[  97-  99, 30.94%]: CrossEntropyWithSoftmax = 3.33751842 * 192; EvalErrorPrediction = 0.85416667 * 192; time = 0.0420s; samplesPerSecond = 4568.7
MPI Rank 1: 07/13/2016 16:48:27:  Epoch[ 1 of 5]-Minibatch[ 100- 102, 31.87%]: CrossEntropyWithSoftmax = 3.25951347 * 192; EvalErrorPrediction = 0.80729167 * 192; time = 0.0420s; samplesPerSecond = 4566.2
MPI Rank 1: 07/13/2016 16:48:27:  Epoch[ 1 of 5]-Minibatch[ 103- 105, 32.81%]: CrossEntropyWithSoftmax = 3.24586699 * 192; EvalErrorPrediction = 0.78125000 * 192; time = 0.0421s; samplesPerSecond = 4560.7
MPI Rank 1: 07/13/2016 16:48:27:  Epoch[ 1 of 5]-Minibatch[ 106- 108, 33.75%]: CrossEntropyWithSoftmax = 3.06725828 * 192; EvalErrorPrediction = 0.71875000 * 192; time = 0.0421s; samplesPerSecond = 4561.3
MPI Rank 1: 07/13/2016 16:48:28:  Epoch[ 1 of 5]-Minibatch[ 109- 111, 34.69%]: CrossEntropyWithSoftmax = 3.39973653 * 192; EvalErrorPrediction = 0.77083333 * 192; time = 0.0421s; samplesPerSecond = 4566.0
MPI Rank 1: 07/13/2016 16:48:28:  Epoch[ 1 of 5]-Minibatch[ 112- 114, 35.62%]: CrossEntropyWithSoftmax = 3.34798378 * 192; EvalErrorPrediction = 0.78645833 * 192; time = 0.0421s; samplesPerSecond = 4561.0
MPI Rank 1: 07/13/2016 16:48:28:  Epoch[ 1 of 5]-Minibatch[ 115- 117, 36.56%]: CrossEntropyWithSoftmax = 3.38133778 * 192; EvalErrorPrediction = 0.82291667 * 192; time = 0.0421s; samplesPerSecond = 4558.4
MPI Rank 1: 07/13/2016 16:48:28:  Epoch[ 1 of 5]-Minibatch[ 118- 120, 37.50%]: CrossEntropyWithSoftmax = 3.19074044 * 192; EvalErrorPrediction = 0.74479167 * 192; time = 0.0422s; samplesPerSecond = 4554.0
MPI Rank 1: 07/13/2016 16:48:28:  Epoch[ 1 of 5]-Minibatch[ 121- 123, 38.44%]: CrossEntropyWithSoftmax = 3.14306337 * 192; EvalErrorPrediction = 0.74479167 * 192; time = 0.0421s; samplesPerSecond = 4559.3
MPI Rank 1: 07/13/2016 16:48:28:  Epoch[ 1 of 5]-Minibatch[ 124- 126, 39.38%]: CrossEntropyWithSoftmax = 3.10036521 * 192; EvalErrorPrediction = 0.72916667 * 192; time = 0.0420s; samplesPerSecond = 4569.1
MPI Rank 1: 07/13/2016 16:48:28:  Epoch[ 1 of 5]-Minibatch[ 127- 129, 40.31%]: CrossEntropyWithSoftmax = 3.17040971 * 192; EvalErrorPrediction = 0.76562500 * 192; time = 0.0438s; samplesPerSecond = 4386.5
MPI Rank 1: 07/13/2016 16:48:28:  Epoch[ 1 of 5]-Minibatch[ 130- 132, 41.25%]: CrossEntropyWithSoftmax = 3.19888148 * 192; EvalErrorPrediction = 0.75520833 * 192; time = 0.0420s; samplesPerSecond = 4569.1
MPI Rank 1: 07/13/2016 16:48:28:  Epoch[ 1 of 5]-Minibatch[ 133- 135, 42.19%]: CrossEntropyWithSoftmax = 2.91247084 * 192; EvalErrorPrediction = 0.66145833 * 192; time = 0.0425s; samplesPerSecond = 4513.9
MPI Rank 1: 07/13/2016 16:48:28:  Epoch[ 1 of 5]-Minibatch[ 136- 138, 43.12%]: CrossEntropyWithSoftmax = 2.96972038 * 192; EvalErrorPrediction = 0.70833333 * 192; time = 0.0421s; samplesPerSecond = 4559.1
MPI Rank 1: 07/13/2016 16:48:28:  Epoch[ 1 of 5]-Minibatch[ 139- 141, 44.06%]: CrossEntropyWithSoftmax = 3.15632232 * 192; EvalErrorPrediction = 0.76041667 * 192; time = 0.0421s; samplesPerSecond = 4558.0
MPI Rank 1: 07/13/2016 16:48:28:  Epoch[ 1 of 5]-Minibatch[ 142- 144, 45.00%]: CrossEntropyWithSoftmax = 2.98075176 * 192; EvalErrorPrediction = 0.71354167 * 192; time = 0.0421s; samplesPerSecond = 4557.4
MPI Rank 1: 07/13/2016 16:48:28:  Epoch[ 1 of 5]-Minibatch[ 145- 147, 45.94%]: CrossEntropyWithSoftmax = 3.03076846 * 192; EvalErrorPrediction = 0.77604167 * 192; time = 0.0422s; samplesPerSecond = 4553.5
MPI Rank 1: 07/13/2016 16:48:28:  Epoch[ 1 of 5]-Minibatch[ 148- 150, 46.88%]: CrossEntropyWithSoftmax = 2.91480722 * 192; EvalErrorPrediction = 0.71354167 * 192; time = 0.0421s; samplesPerSecond = 4556.0
MPI Rank 1: 07/13/2016 16:48:28:  Epoch[ 1 of 5]-Minibatch[ 151- 153, 47.81%]: CrossEntropyWithSoftmax = 3.16155322 * 192; EvalErrorPrediction = 0.75520833 * 192; time = 0.0421s; samplesPerSecond = 4559.5
MPI Rank 1: 07/13/2016 16:48:28:  Epoch[ 1 of 5]-Minibatch[ 154- 156, 48.75%]: CrossEntropyWithSoftmax = 2.76157172 * 192; EvalErrorPrediction = 0.69791667 * 192; time = 0.0422s; samplesPerSecond = 4554.1
MPI Rank 1: 07/13/2016 16:48:28:  Epoch[ 1 of 5]-Minibatch[ 157- 159, 49.69%]: CrossEntropyWithSoftmax = 3.06347679 * 192; EvalErrorPrediction = 0.75520833 * 192; time = 0.0421s; samplesPerSecond = 4559.4
MPI Rank 1: 07/13/2016 16:48:28:  Epoch[ 1 of 5]-Minibatch[ 160- 162, 50.62%]: CrossEntropyWithSoftmax = 2.84053583 * 192; EvalErrorPrediction = 0.69791667 * 192; time = 0.0427s; samplesPerSecond = 4492.6
MPI Rank 1: 07/13/2016 16:48:28:  Epoch[ 1 of 5]-Minibatch[ 163- 165, 51.56%]: CrossEntropyWithSoftmax = 2.87795860 * 192; EvalErrorPrediction = 0.75000000 * 192; time = 0.0421s; samplesPerSecond = 4556.9
MPI Rank 1: 07/13/2016 16:48:28:  Epoch[ 1 of 5]-Minibatch[ 166- 168, 52.50%]: CrossEntropyWithSoftmax = 2.92198252 * 192; EvalErrorPrediction = 0.70833333 * 192; time = 0.0427s; samplesPerSecond = 4501.5
MPI Rank 1: 07/13/2016 16:48:28:  Epoch[ 1 of 5]-Minibatch[ 169- 171, 53.44%]: CrossEntropyWithSoftmax = 2.81241750 * 192; EvalErrorPrediction = 0.66145833 * 192; time = 0.0425s; samplesPerSecond = 4516.8
MPI Rank 1: 07/13/2016 16:48:28:  Epoch[ 1 of 5]-Minibatch[ 172- 174, 54.37%]: CrossEntropyWithSoftmax = 2.62682593 * 192; EvalErrorPrediction = 0.64062500 * 192; time = 0.0421s; samplesPerSecond = 4561.3
MPI Rank 1: 07/13/2016 16:48:28:  Epoch[ 1 of 5]-Minibatch[ 175- 177, 55.31%]: CrossEntropyWithSoftmax = 2.75758644 * 192; EvalErrorPrediction = 0.73437500 * 192; time = 0.0421s; samplesPerSecond = 4559.5
MPI Rank 1: 07/13/2016 16:48:28:  Epoch[ 1 of 5]-Minibatch[ 178- 180, 56.25%]: CrossEntropyWithSoftmax = 2.74763961 * 192; EvalErrorPrediction = 0.67187500 * 192; time = 0.0421s; samplesPerSecond = 4560.4
MPI Rank 1: 07/13/2016 16:48:29:  Epoch[ 1 of 5]-Minibatch[ 181- 183, 57.19%]: CrossEntropyWithSoftmax = 2.90905834 * 192; EvalErrorPrediction = 0.68229167 * 192; time = 0.0421s; samplesPerSecond = 4564.9
MPI Rank 1: 07/13/2016 16:48:29:  Epoch[ 1 of 5]-Minibatch[ 184- 186, 58.13%]: CrossEntropyWithSoftmax = 2.76756973 * 192; EvalErrorPrediction = 0.70833333 * 192; time = 0.0421s; samplesPerSecond = 4558.5
MPI Rank 1: 07/13/2016 16:48:29:  Epoch[ 1 of 5]-Minibatch[ 187- 189, 59.06%]: CrossEntropyWithSoftmax = 2.76599748 * 192; EvalErrorPrediction = 0.75520833 * 192; time = 0.0421s; samplesPerSecond = 4560.4
MPI Rank 1: 07/13/2016 16:48:29:  Epoch[ 1 of 5]-Minibatch[ 190- 192, 60.00%]: CrossEntropyWithSoftmax = 2.83171014 * 192; EvalErrorPrediction = 0.70833333 * 192; time = 0.0421s; samplesPerSecond = 4557.9
MPI Rank 1: 07/13/2016 16:48:29:  Epoch[ 1 of 5]-Minibatch[ 193- 195, 60.94%]: CrossEntropyWithSoftmax = 2.59593490 * 192; EvalErrorPrediction = 0.61458333 * 192; time = 0.0421s; samplesPerSecond = 4563.5
MPI Rank 1: 07/13/2016 16:48:29:  Epoch[ 1 of 5]-Minibatch[ 196- 198, 61.88%]: CrossEntropyWithSoftmax = 2.64965270 * 192; EvalErrorPrediction = 0.66666667 * 192; time = 0.0420s; samplesPerSecond = 4568.1
MPI Rank 1: 07/13/2016 16:48:29:  Epoch[ 1 of 5]-Minibatch[ 199- 201, 62.81%]: CrossEntropyWithSoftmax = 2.33442260 * 192; EvalErrorPrediction = 0.60937500 * 192; time = 0.0421s; samplesPerSecond = 4562.6
MPI Rank 1: 07/13/2016 16:48:29:  Epoch[ 1 of 5]-Minibatch[ 202- 204, 63.75%]: CrossEntropyWithSoftmax = 2.67195863 * 192; EvalErrorPrediction = 0.67187500 * 192; time = 0.0421s; samplesPerSecond = 4562.7
MPI Rank 1: 07/13/2016 16:48:29:  Epoch[ 1 of 5]-Minibatch[ 205- 207, 64.69%]: CrossEntropyWithSoftmax = 2.72367540 * 192; EvalErrorPrediction = 0.66145833 * 192; time = 0.0421s; samplesPerSecond = 4565.2
MPI Rank 1: 07/13/2016 16:48:29:  Epoch[ 1 of 5]-Minibatch[ 208- 210, 65.62%]: CrossEntropyWithSoftmax = 2.59572337 * 192; EvalErrorPrediction = 0.68229167 * 192; time = 0.0421s; samplesPerSecond = 4562.4
MPI Rank 1: 07/13/2016 16:48:29:  Epoch[ 1 of 5]-Minibatch[ 211- 213, 66.56%]: CrossEntropyWithSoftmax = 2.53202795 * 192; EvalErrorPrediction = 0.63541667 * 192; time = 0.0434s; samplesPerSecond = 4426.0
MPI Rank 1: 07/13/2016 16:48:29:  Epoch[ 1 of 5]-Minibatch[ 214- 216, 67.50%]: CrossEntropyWithSoftmax = 2.50336278 * 192; EvalErrorPrediction = 0.67187500 * 192; time = 0.0434s; samplesPerSecond = 4425.9
MPI Rank 1: 07/13/2016 16:48:29:  Epoch[ 1 of 5]-Minibatch[ 217- 219, 68.44%]: CrossEntropyWithSoftmax = 2.77076318 * 192; EvalErrorPrediction = 0.68750000 * 192; time = 0.0434s; samplesPerSecond = 4428.8
MPI Rank 1: 07/13/2016 16:48:29:  Epoch[ 1 of 5]-Minibatch[ 220- 222, 69.38%]: CrossEntropyWithSoftmax = 2.45308521 * 192; EvalErrorPrediction = 0.59895833 * 192; time = 0.0440s; samplesPerSecond = 4365.0
MPI Rank 1: 07/13/2016 16:48:29:  Epoch[ 1 of 5]-Minibatch[ 223- 225, 70.31%]: CrossEntropyWithSoftmax = 2.54598920 * 192; EvalErrorPrediction = 0.60937500 * 192; time = 0.0428s; samplesPerSecond = 4481.8
MPI Rank 1: 07/13/2016 16:48:29:  Epoch[ 1 of 5]-Minibatch[ 226- 228, 71.25%]: CrossEntropyWithSoftmax = 2.58558089 * 192; EvalErrorPrediction = 0.65625000 * 192; time = 0.0420s; samplesPerSecond = 4567.3
MPI Rank 1: 07/13/2016 16:48:29:  Epoch[ 1 of 5]-Minibatch[ 229- 231, 72.19%]: CrossEntropyWithSoftmax = 2.41075660 * 192; EvalErrorPrediction = 0.61458333 * 192; time = 0.0420s; samplesPerSecond = 4567.7
MPI Rank 1: 07/13/2016 16:48:29:  Epoch[ 1 of 5]-Minibatch[ 232- 234, 73.12%]: CrossEntropyWithSoftmax = 2.52012028 * 192; EvalErrorPrediction = 0.66145833 * 192; time = 0.0420s; samplesPerSecond = 4571.3
MPI Rank 1: 07/13/2016 16:48:29:  Epoch[ 1 of 5]-Minibatch[ 235- 237, 74.06%]: CrossEntropyWithSoftmax = 2.30719546 * 192; EvalErrorPrediction = 0.62500000 * 192; time = 0.0420s; samplesPerSecond = 4576.1
MPI Rank 1: 07/13/2016 16:48:29:  Epoch[ 1 of 5]-Minibatch[ 238- 240, 75.00%]: CrossEntropyWithSoftmax = 2.42100657 * 192; EvalErrorPrediction = 0.59895833 * 192; time = 0.0419s; samplesPerSecond = 4581.0
MPI Rank 1: 07/13/2016 16:48:29:  Epoch[ 1 of 5]-Minibatch[ 241- 243, 75.94%]: CrossEntropyWithSoftmax = 2.39894546 * 192; EvalErrorPrediction = 0.63541667 * 192; time = 0.0420s; samplesPerSecond = 4574.4
MPI Rank 1: 07/13/2016 16:48:29:  Epoch[ 1 of 5]-Minibatch[ 244- 246, 76.88%]: CrossEntropyWithSoftmax = 2.44970724 * 192; EvalErrorPrediction = 0.67187500 * 192; time = 0.0419s; samplesPerSecond = 4582.0
MPI Rank 1: 07/13/2016 16:48:29:  Epoch[ 1 of 5]-Minibatch[ 247- 249, 77.81%]: CrossEntropyWithSoftmax = 2.33418475 * 192; EvalErrorPrediction = 0.63541667 * 192; time = 0.0419s; samplesPerSecond = 4580.5
MPI Rank 1: 07/13/2016 16:48:29:  Epoch[ 1 of 5]-Minibatch[ 250- 252, 78.75%]: CrossEntropyWithSoftmax = 2.37997032 * 192; EvalErrorPrediction = 0.61458333 * 192; time = 0.0419s; samplesPerSecond = 4577.1
MPI Rank 1: 07/13/2016 16:48:30:  Epoch[ 1 of 5]-Minibatch[ 253- 255, 79.69%]: CrossEntropyWithSoftmax = 2.47517097 * 192; EvalErrorPrediction = 0.59895833 * 192; time = 0.0420s; samplesPerSecond = 4576.3
MPI Rank 1: 07/13/2016 16:48:30:  Epoch[ 1 of 5]-Minibatch[ 256- 258, 80.62%]: CrossEntropyWithSoftmax = 2.60900086 * 192; EvalErrorPrediction = 0.69270833 * 192; time = 0.0424s; samplesPerSecond = 4525.5
MPI Rank 1: 07/13/2016 16:48:30:  Epoch[ 1 of 5]-Minibatch[ 259- 261, 81.56%]: CrossEntropyWithSoftmax = 2.43300244 * 192; EvalErrorPrediction = 0.65104167 * 192; time = 0.0420s; samplesPerSecond = 4566.8
MPI Rank 1: 07/13/2016 16:48:30:  Epoch[ 1 of 5]-Minibatch[ 262- 264, 82.50%]: CrossEntropyWithSoftmax = 2.12996515 * 192; EvalErrorPrediction = 0.56250000 * 192; time = 0.0421s; samplesPerSecond = 4564.7
MPI Rank 1: 07/13/2016 16:48:30:  Epoch[ 1 of 5]-Minibatch[ 265- 267, 83.44%]: CrossEntropyWithSoftmax = 2.51181403 * 192; EvalErrorPrediction = 0.62500000 * 192; time = 0.0420s; samplesPerSecond = 4570.9
MPI Rank 1: 07/13/2016 16:48:30:  Epoch[ 1 of 5]-Minibatch[ 268- 270, 84.38%]: CrossEntropyWithSoftmax = 2.29330120 * 192; EvalErrorPrediction = 0.60416667 * 192; time = 0.0420s; samplesPerSecond = 4576.0
MPI Rank 1: 07/13/2016 16:48:30:  Epoch[ 1 of 5]-Minibatch[ 271- 273, 85.31%]: CrossEntropyWithSoftmax = 2.33352411 * 192; EvalErrorPrediction = 0.60416667 * 192; time = 0.0429s; samplesPerSecond = 4474.5
MPI Rank 1: 07/13/2016 16:48:30:  Epoch[ 1 of 5]-Minibatch[ 274- 276, 86.25%]: CrossEntropyWithSoftmax = 2.17790026 * 192; EvalErrorPrediction = 0.57812500 * 192; time = 0.0428s; samplesPerSecond = 4486.2
MPI Rank 1: 07/13/2016 16:48:30:  Epoch[ 1 of 5]-Minibatch[ 277- 279, 87.19%]: CrossEntropyWithSoftmax = 2.18521155 * 192; EvalErrorPrediction = 0.54166667 * 192; time = 0.0420s; samplesPerSecond = 4576.0
MPI Rank 1: 07/13/2016 16:48:30:  Epoch[ 1 of 5]-Minibatch[ 280- 282, 88.12%]: CrossEntropyWithSoftmax = 2.29833071 * 192; EvalErrorPrediction = 0.58854167 * 192; time = 0.0430s; samplesPerSecond = 4466.8
MPI Rank 1: 07/13/2016 16:48:30:  Epoch[ 1 of 5]-Minibatch[ 283- 285, 89.06%]: CrossEntropyWithSoftmax = 2.21483298 * 192; EvalErrorPrediction = 0.61458333 * 192; time = 0.0421s; samplesPerSecond = 4565.8
MPI Rank 1: 07/13/2016 16:48:30:  Epoch[ 1 of 5]-Minibatch[ 286- 288, 90.00%]: CrossEntropyWithSoftmax = 2.37232627 * 192; EvalErrorPrediction = 0.61979167 * 192; time = 0.0427s; samplesPerSecond = 4498.7
MPI Rank 1: 07/13/2016 16:48:30:  Epoch[ 1 of 5]-Minibatch[ 289- 291, 90.94%]: CrossEntropyWithSoftmax = 2.34396058 * 192; EvalErrorPrediction = 0.60416667 * 192; time = 0.0435s; samplesPerSecond = 4417.8
MPI Rank 1: 07/13/2016 16:48:30:  Epoch[ 1 of 5]-Minibatch[ 292- 294, 91.88%]: CrossEntropyWithSoftmax = 2.18334302 * 192; EvalErrorPrediction = 0.63020833 * 192; time = 0.0434s; samplesPerSecond = 4428.5
MPI Rank 1: 07/13/2016 16:48:30:  Epoch[ 1 of 5]-Minibatch[ 295- 297, 92.81%]: CrossEntropyWithSoftmax = 2.07753101 * 192; EvalErrorPrediction = 0.57812500 * 192; time = 0.0429s; samplesPerSecond = 4472.0
MPI Rank 1: 07/13/2016 16:48:30:  Epoch[ 1 of 5]-Minibatch[ 298- 300, 93.75%]: CrossEntropyWithSoftmax = 2.26265833 * 192; EvalErrorPrediction = 0.63020833 * 192; time = 0.0421s; samplesPerSecond = 4565.6
MPI Rank 1: 07/13/2016 16:48:30:  Epoch[ 1 of 5]-Minibatch[ 301- 303, 94.69%]: CrossEntropyWithSoftmax = 2.21675905 * 192; EvalErrorPrediction = 0.58333333 * 192; time = 0.0421s; samplesPerSecond = 4558.4
MPI Rank 1: 07/13/2016 16:48:30:  Epoch[ 1 of 5]-Minibatch[ 304- 306, 95.62%]: CrossEntropyWithSoftmax = 2.18990385 * 192; EvalErrorPrediction = 0.58333333 * 192; time = 0.0421s; samplesPerSecond = 4564.3
MPI Rank 1: 07/13/2016 16:48:30:  Epoch[ 1 of 5]-Minibatch[ 307- 309, 96.56%]: CrossEntropyWithSoftmax = 2.48513433 * 192; EvalErrorPrediction = 0.64583333 * 192; time = 0.0421s; samplesPerSecond = 4558.3
MPI Rank 1: 07/13/2016 16:48:30:  Epoch[ 1 of 5]-Minibatch[ 310- 312, 97.50%]: CrossEntropyWithSoftmax = 2.25336704 * 192; EvalErrorPrediction = 0.59895833 * 192; time = 0.0427s; samplesPerSecond = 4501.5
MPI Rank 1: 07/13/2016 16:48:30:  Epoch[ 1 of 5]-Minibatch[ 313- 315, 98.44%]: CrossEntropyWithSoftmax = 2.13039619 * 192; EvalErrorPrediction = 0.55729167 * 192; time = 0.0424s; samplesPerSecond = 4523.3
MPI Rank 1: 07/13/2016 16:48:30:  Epoch[ 1 of 5]-Minibatch[ 316- 318, 99.38%]: CrossEntropyWithSoftmax = 2.27299748 * 192; EvalErrorPrediction = 0.60416667 * 192; time = 0.0421s; samplesPerSecond = 4558.2
MPI Rank 1: 07/13/2016 16:48:30: Finished Epoch[ 1 of 5]: [Training] CrossEntropyWithSoftmax = 2.99723568 * 20480; EvalErrorPrediction = 0.72426758 * 20480; totalSamplesSeen = 20480; learningRatePerSample = 0.015625; epochTime=4.54778s
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:48:31: Starting Epoch 2: learning rate per sample = 0.001953  effective momentum = 0.656119  momentum as time constant = 607.5 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 1: frames [20480..40960] (first utterance at frame 20480), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:48:31: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 07/13/2016 16:48:31:  Epoch[ 2 of 5]-Minibatch[   1-   3, 3.75%]: CrossEntropyWithSoftmax = 2.06713643 * 249; EvalErrorPrediction = 0.52208835 * 249; time = 0.0430s; samplesPerSecond = 5796.6
MPI Rank 1: 07/13/2016 16:48:31:  Epoch[ 2 of 5]-Minibatch[   4-   6, 7.50%]: CrossEntropyWithSoftmax = 2.16835808 * 239; EvalErrorPrediction = 0.57740586 * 239; time = 0.0473s; samplesPerSecond = 5053.5
MPI Rank 1: 07/13/2016 16:48:31:  Epoch[ 2 of 5]-Minibatch[   7-   9, 11.25%]: CrossEntropyWithSoftmax = 2.07984091 * 274; EvalErrorPrediction = 0.55109489 * 274; time = 0.0500s; samplesPerSecond = 5484.7
MPI Rank 1: 07/13/2016 16:48:31:  Epoch[ 2 of 5]-Minibatch[  10-  12, 15.00%]: CrossEntropyWithSoftmax = 2.16277557 * 277; EvalErrorPrediction = 0.60288809 * 277; time = 0.0467s; samplesPerSecond = 5932.6
MPI Rank 1: 07/13/2016 16:48:31:  Epoch[ 2 of 5]-Minibatch[  13-  15, 18.75%]: CrossEntropyWithSoftmax = 2.02360967 * 280; EvalErrorPrediction = 0.54642857 * 280; time = 0.0432s; samplesPerSecond = 6487.0
MPI Rank 1: 07/13/2016 16:48:31:  Epoch[ 2 of 5]-Minibatch[  16-  18, 22.50%]: CrossEntropyWithSoftmax = 2.11391771 * 283; EvalErrorPrediction = 0.59717314 * 283; time = 0.0461s; samplesPerSecond = 6143.1
MPI Rank 1: 07/13/2016 16:48:31:  Epoch[ 2 of 5]-Minibatch[  19-  21, 26.25%]: CrossEntropyWithSoftmax = 2.06691231 * 239; EvalErrorPrediction = 0.57322176 * 239; time = 0.0385s; samplesPerSecond = 6204.9
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     0.38 seconds since last report (0.00 seconds on comm.); 4331 samples processed by 2 workers (2141 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 11.55k samplesPerSecond , throughputPerWorker = 5.77k samplesPerSecond
MPI Rank 1: 07/13/2016 16:48:31:  Epoch[ 2 of 5]-Minibatch[  22-  24, 30.00%]: CrossEntropyWithSoftmax = 2.00607609 * 300; EvalErrorPrediction = 0.53666667 * 300; time = 0.0506s; samplesPerSecond = 5926.9
MPI Rank 1: 07/13/2016 16:48:31:  Epoch[ 2 of 5]-Minibatch[  25-  27, 33.75%]: CrossEntropyWithSoftmax = 1.99849291 * 269; EvalErrorPrediction = 0.53159851 * 269; time = 0.0441s; samplesPerSecond = 6101.2
MPI Rank 1: 07/13/2016 16:48:31:  Epoch[ 2 of 5]-Minibatch[  28-  30, 37.50%]: CrossEntropyWithSoftmax = 2.14699482 * 274; EvalErrorPrediction = 0.57299270 * 274; time = 0.0489s; samplesPerSecond = 5604.1
MPI Rank 1: 07/13/2016 16:48:31:  Epoch[ 2 of 5]-Minibatch[  31-  33, 41.25%]: CrossEntropyWithSoftmax = 2.04126317 * 289; EvalErrorPrediction = 0.58477509 * 289; time = 0.0481s; samplesPerSecond = 6013.9
MPI Rank 1: 07/13/2016 16:48:31:  Epoch[ 2 of 5]-Minibatch[  34-  36, 45.00%]: CrossEntropyWithSoftmax = 2.06113963 * 280; EvalErrorPrediction = 0.61785714 * 280; time = 0.0427s; samplesPerSecond = 6553.5
MPI Rank 1: 07/13/2016 16:48:31:  Epoch[ 2 of 5]-Minibatch[  37-  39, 48.75%]: CrossEntropyWithSoftmax = 2.05149355 * 262; EvalErrorPrediction = 0.53435115 * 262; time = 0.0457s; samplesPerSecond = 5727.5
MPI Rank 1: 07/13/2016 16:48:31:  Epoch[ 2 of 5]-Minibatch[  40-  42, 52.50%]: CrossEntropyWithSoftmax = 2.07615796 * 256; EvalErrorPrediction = 0.56640625 * 256; time = 0.0444s; samplesPerSecond = 5762.1
MPI Rank 1: 07/13/2016 16:48:31:  Epoch[ 2 of 5]-Minibatch[  43-  45, 56.25%]: CrossEntropyWithSoftmax = 1.93205618 * 271; EvalErrorPrediction = 0.53874539 * 271; time = 0.0361s; samplesPerSecond = 7512.8
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     0.34 seconds since last report (0.00 seconds on comm.); 4232 samples processed by 2 workers (2078 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 12.27k samplesPerSecond , throughputPerWorker = 6.14k samplesPerSecond
MPI Rank 1: 07/13/2016 16:48:31:  Epoch[ 2 of 5]-Minibatch[  46-  48, 60.00%]: CrossEntropyWithSoftmax = 2.05205732 * 266; EvalErrorPrediction = 0.58270677 * 266; time = 0.0515s; samplesPerSecond = 5166.9
MPI Rank 1: 07/13/2016 16:48:31:  Epoch[ 2 of 5]-Minibatch[  49-  51, 63.75%]: CrossEntropyWithSoftmax = 2.14681400 * 292; EvalErrorPrediction = 0.60616438 * 292; time = 0.0434s; samplesPerSecond = 6721.1
MPI Rank 1: 07/13/2016 16:48:31:  Epoch[ 2 of 5]-Minibatch[  52-  54, 67.50%]: CrossEntropyWithSoftmax = 2.06088333 * 281; EvalErrorPrediction = 0.56583630 * 281; time = 0.0504s; samplesPerSecond = 5579.6
MPI Rank 1: 07/13/2016 16:48:31:  Epoch[ 2 of 5]-Minibatch[  55-  57, 71.25%]: CrossEntropyWithSoftmax = 1.96455898 * 269; EvalErrorPrediction = 0.51672862 * 269; time = 0.0445s; samplesPerSecond = 6047.9
MPI Rank 1: 07/13/2016 16:48:31:  Epoch[ 2 of 5]-Minibatch[  58-  60, 75.00%]: CrossEntropyWithSoftmax = 1.95106467 * 293; EvalErrorPrediction = 0.52559727 * 293; time = 0.0433s; samplesPerSecond = 6774.4
MPI Rank 1: 07/13/2016 16:48:32:  Epoch[ 2 of 5]-Minibatch[  61-  63, 78.75%]: CrossEntropyWithSoftmax = 1.95943138 * 262; EvalErrorPrediction = 0.51145038 * 262; time = 0.0458s; samplesPerSecond = 5722.6
MPI Rank 1: 07/13/2016 16:48:32:  Epoch[ 2 of 5]-Minibatch[  64-  66, 82.50%]: CrossEntropyWithSoftmax = 2.07155768 * 296; EvalErrorPrediction = 0.54729730 * 296; time = 0.0389s; samplesPerSecond = 7604.0
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     0.33 seconds since last report (0.00 seconds on comm.); 4185 samples processed by 2 workers (2060 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 12.64k samplesPerSecond , throughputPerWorker = 6.32k samplesPerSecond
MPI Rank 1: 07/13/2016 16:48:32:  Epoch[ 2 of 5]-Minibatch[  67-  69, 86.25%]: CrossEntropyWithSoftmax = 1.95713212 * 278; EvalErrorPrediction = 0.50719424 * 278; time = 0.0468s; samplesPerSecond = 5944.7
MPI Rank 1: 07/13/2016 16:48:32:  Epoch[ 2 of 5]-Minibatch[  70-  72, 90.00%]: CrossEntropyWithSoftmax = 2.03053119 * 291; EvalErrorPrediction = 0.53608247 * 291; time = 0.0450s; samplesPerSecond = 6468.4
MPI Rank 1: 07/13/2016 16:48:32:  Epoch[ 2 of 5]-Minibatch[  73-  75, 93.75%]: CrossEntropyWithSoftmax = 2.09969286 * 299; EvalErrorPrediction = 0.55852843 * 299; time = 0.0513s; samplesPerSecond = 5833.1
MPI Rank 1: 07/13/2016 16:48:32:  Epoch[ 2 of 5]-Minibatch[  76-  78, 97.50%]: CrossEntropyWithSoftmax = 1.85965889 * 273; EvalErrorPrediction = 0.50183150 * 273; time = 0.0430s; samplesPerSecond = 6346.0
MPI Rank 1: 07/13/2016 16:48:32:  Epoch[ 2 of 5]-Minibatch[  79-  81, 101.25%]: CrossEntropyWithSoftmax = 1.89805579 * 190; EvalErrorPrediction = 0.51578947 * 190; time = 0.0240s; samplesPerSecond = 7920.0
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.08-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.02 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     0.70 seconds since last report (0.45 seconds on comm.); 7732 samples processed by 2 workers (1053 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 11.02k samplesPerSecond , throughputPerWorker = 5.51k samplesPerSecond
MPI Rank 1: 07/13/2016 16:48:32: Finished Epoch[ 2 of 5]: [Training] CrossEntropyWithSoftmax = 1.99875653 * 20480; EvalErrorPrediction = 0.54526367 * 20480; totalSamplesSeen = 40960; learningRatePerSample = 0.001953125; epochTime=1.75273s
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:48:32: Starting Epoch 3: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 2: frames [40960..61440] (first utterance at frame 40960), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:48:32: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 07/13/2016 16:48:33:  Epoch[ 3 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.92990384 * 1133; EvalErrorPrediction = 0.54368932 * 1133; time = 0.1133s; samplesPerSecond = 10002.5
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.03 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     0.27 seconds since last report (0.00 seconds on comm.); 4844 samples processed by 2 workers (2261 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 17.77k samplesPerSecond , throughputPerWorker = 8.89k samplesPerSecond
MPI Rank 1: 07/13/2016 16:48:33:  Epoch[ 3 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.93806210 * 1128; EvalErrorPrediction = 0.52659574 * 1128; time = 0.1400s; samplesPerSecond = 8054.8
MPI Rank 1: 07/13/2016 16:48:33:  Epoch[ 3 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.84931024 * 1154; EvalErrorPrediction = 0.51473137 * 1154; time = 0.1080s; samplesPerSecond = 10690.0
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.02 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     0.23 seconds since last report (0.00 seconds on comm.); 4849 samples processed by 2 workers (2269 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 21.54k samplesPerSecond , throughputPerWorker = 10.77k samplesPerSecond
MPI Rank 1: 07/13/2016 16:48:33:  Epoch[ 3 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.88039762 * 1115; EvalErrorPrediction = 0.51748879 * 1115; time = 0.1170s; samplesPerSecond = 9532.6
MPI Rank 1: 07/13/2016 16:48:33:  Epoch[ 3 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.89689671 * 1130; EvalErrorPrediction = 0.54336283 * 1130; time = 0.1002s; samplesPerSecond = 11277.3
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.05 seconds , average latency = 0.02 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     0.24 seconds since last report (0.00 seconds on comm.); 4868 samples processed by 2 workers (2273 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 20.57k samplesPerSecond , throughputPerWorker = 10.28k samplesPerSecond
MPI Rank 1: 07/13/2016 16:48:33:  Epoch[ 3 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.88822901 * 1143; EvalErrorPrediction = 0.53893263 * 1143; time = 0.1362s; samplesPerSecond = 8391.0
MPI Rank 1: 07/13/2016 16:48:33:  Epoch[ 3 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.92708667 * 758; EvalErrorPrediction = 0.53693931 * 758; time = 0.0537s; samplesPerSecond = 14119.9
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.15-seconds latency this time; accumulated time on sync point = 0.19 seconds , average latency = 0.05 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     0.37 seconds since last report (0.16 seconds on comm.); 5919 samples processed by 2 workers (758 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 16.01k samplesPerSecond , throughputPerWorker = 8.01k samplesPerSecond
MPI Rank 1: 07/13/2016 16:48:34: Finished Epoch[ 3 of 5]: [Training] CrossEntropyWithSoftmax = 1.88572700 * 20480; EvalErrorPrediction = 0.52416992 * 20480; totalSamplesSeen = 61440; learningRatePerSample = 9.7656251e-05; epochTime=1.10437s
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:48:34: Starting Epoch 4: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:48:34: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 07/13/2016 16:48:34:  Epoch[ 4 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.83907230 * 1146; EvalErrorPrediction = 0.51308901 * 1146; time = 0.1105s; samplesPerSecond = 10371.0
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.01 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     0.27 seconds since last report (0.00 seconds on comm.); 4905 samples processed by 2 workers (2324 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 18.37k samplesPerSecond , throughputPerWorker = 9.19k samplesPerSecond
MPI Rank 1: 07/13/2016 16:48:34:  Epoch[ 4 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.83174615 * 1178; EvalErrorPrediction = 0.50509338 * 1178; time = 0.1370s; samplesPerSecond = 8600.7
MPI Rank 1: 07/13/2016 16:48:34:  Epoch[ 4 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.89682396 * 1141; EvalErrorPrediction = 0.53812445 * 1141; time = 0.1063s; samplesPerSecond = 10733.7
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.01 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     0.22 seconds since last report (0.00 seconds on comm.); 4870 samples processed by 2 workers (2333 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 21.69k samplesPerSecond , throughputPerWorker = 10.85k samplesPerSecond
MPI Rank 1: 07/13/2016 16:48:34:  Epoch[ 4 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.88667869 * 1192; EvalErrorPrediction = 0.53271812 * 1192; time = 0.1180s; samplesPerSecond = 10101.4
MPI Rank 1: 07/13/2016 16:48:34:  Epoch[ 4 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.80769004 * 1192; EvalErrorPrediction = 0.52265101 * 1192; time = 0.1067s; samplesPerSecond = 11172.0
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.01 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     0.24 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 20.67k samplesPerSecond , throughputPerWorker = 10.33k samplesPerSecond
MPI Rank 1: 07/13/2016 16:48:34:  Epoch[ 4 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.82030293 * 1211; EvalErrorPrediction = 0.49958712 * 1211; time = 0.1309s; samplesPerSecond = 9250.1
MPI Rank 1: 07/13/2016 16:48:35:  Epoch[ 4 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.94035074 * 785; EvalErrorPrediction = 0.54267516 * 785; time = 0.0496s; samplesPerSecond = 15838.4
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.14-seconds latency this time; accumulated time on sync point = 0.15 seconds , average latency = 0.04 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     0.35 seconds since last report (0.15 seconds on comm.); 5789 samples processed by 2 workers (785 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 16.44k samplesPerSecond , throughputPerWorker = 8.22k samplesPerSecond
MPI Rank 1: 07/13/2016 16:48:35: Finished Epoch[ 4 of 5]: [Training] CrossEntropyWithSoftmax = 1.83787473 * 20480; EvalErrorPrediction = 0.51215820 * 20480; totalSamplesSeen = 81920; learningRatePerSample = 9.7656251e-05; epochTime=1.08171s
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:48:35: Starting Epoch 5: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:48:35: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 07/13/2016 16:48:35:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.78955055 * 1175; EvalErrorPrediction = 0.49021277 * 1175; time = 0.1179s; samplesPerSecond = 9968.4
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     0.27 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 18.14k samplesPerSecond , throughputPerWorker = 9.07k samplesPerSecond
MPI Rank 1: 07/13/2016 16:48:35:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.83857800 * 1251; EvalErrorPrediction = 0.51239009 * 1251; time = 0.1329s; samplesPerSecond = 9414.7
MPI Rank 1: 07/13/2016 16:48:35:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.78033156 * 1201; EvalErrorPrediction = 0.50374688 * 1201; time = 0.1079s; samplesPerSecond = 11134.8
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     0.23 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 21.52k samplesPerSecond , throughputPerWorker = 10.76k samplesPerSecond
MPI Rank 1: 07/13/2016 16:48:36:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.85251684 * 1202; EvalErrorPrediction = 0.51331115 * 1202; time = 0.1188s; samplesPerSecond = 10115.2
MPI Rank 1: 07/13/2016 16:48:36:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.83755982 * 1173; EvalErrorPrediction = 0.50809889 * 1173; time = 0.1055s; samplesPerSecond = 11118.8
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     0.23 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 21.39k samplesPerSecond , throughputPerWorker = 10.69k samplesPerSecond
MPI Rank 1: 07/13/2016 16:48:36:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.86874300 * 1194; EvalErrorPrediction = 0.52680067 * 1194; time = 0.1212s; samplesPerSecond = 9849.4
MPI Rank 1: 07/13/2016 16:48:36:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.78761926 * 827; EvalErrorPrediction = 0.51753325 * 827; time = 0.0518s; samplesPerSecond = 15950.8
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.15-seconds latency this time; accumulated time on sync point = 0.15 seconds , average latency = 0.04 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     0.36 seconds since last report (0.15 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 16.37k samplesPerSecond , throughputPerWorker = 8.19k samplesPerSecond
MPI Rank 1: 07/13/2016 16:48:36: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84363929 * 20480; EvalErrorPrediction = 0.51025391 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 9.7656251e-05; epochTime=1.08107s
MPI Rank 1: 07/13/2016 16:48:36: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160713164744.999927/Speech/DNN_ParallelBM@debug_gpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/13/2016 16:48:36: learnRatePerSample reduced to 4.8828126e-05
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:48:36: Starting Epoch 5: learning rate per sample = 0.000049  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:48:36: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 07/13/2016 16:48:36:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.78962087 * 1175; EvalErrorPrediction = 0.49021277 * 1175; time = 0.1157s; samplesPerSecond = 10158.8
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     0.26 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 19.23k samplesPerSecond , throughputPerWorker = 9.62k samplesPerSecond
MPI Rank 1: 07/13/2016 16:48:37:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.83882454 * 1251; EvalErrorPrediction = 0.50759392 * 1251; time = 0.1198s; samplesPerSecond = 10440.7
MPI Rank 1: 07/13/2016 16:48:37:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.78134486 * 1201; EvalErrorPrediction = 0.50208160 * 1201; time = 0.1067s; samplesPerSecond = 11260.2
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     0.23 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 21.68k samplesPerSecond , throughputPerWorker = 10.84k samplesPerSecond
MPI Rank 1: 07/13/2016 16:48:37:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.85328151 * 1202; EvalErrorPrediction = 0.51247920 * 1202; time = 0.1184s; samplesPerSecond = 10148.2
MPI Rank 1: 07/13/2016 16:48:37:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.84014759 * 1173; EvalErrorPrediction = 0.50895141 * 1173; time = 0.1055s; samplesPerSecond = 11116.6
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     0.23 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 21.39k samplesPerSecond , throughputPerWorker = 10.69k samplesPerSecond
MPI Rank 1: 07/13/2016 16:48:37:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.86995428 * 1194; EvalErrorPrediction = 0.52847571 * 1194; time = 0.1212s; samplesPerSecond = 9849.2
MPI Rank 1: 07/13/2016 16:48:37:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.78946637 * 827; EvalErrorPrediction = 0.51511487 * 827; time = 0.0520s; samplesPerSecond = 15905.4
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.15-seconds latency this time; accumulated time on sync point = 0.15 seconds , average latency = 0.04 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     0.35 seconds since last report (0.15 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 16.42k samplesPerSecond , throughputPerWorker = 8.21k samplesPerSecond
MPI Rank 1: 07/13/2016 16:48:37: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84493298 * 20480; EvalErrorPrediction = 0.51040039 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 4.8828126e-05; epochTime=1.06311s
MPI Rank 1: 07/13/2016 16:48:37: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160713164744.999927/Speech/DNN_ParallelBM@debug_gpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/13/2016 16:48:37: learnRatePerSample reduced to 2.4414063e-05
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:48:38: Starting Epoch 5: learning rate per sample = 0.000024  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:48:38: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 07/13/2016 16:48:38:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.78965640 * 1175; EvalErrorPrediction = 0.49021277 * 1175; time = 0.1155s; samplesPerSecond = 10169.5
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     0.26 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 18.88k samplesPerSecond , throughputPerWorker = 9.44k samplesPerSecond
MPI Rank 1: 07/13/2016 16:48:38:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.83895707 * 1251; EvalErrorPrediction = 0.50839329 * 1251; time = 0.1246s; samplesPerSecond = 10038.9
MPI Rank 1: 07/13/2016 16:48:38:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.78192244 * 1201; EvalErrorPrediction = 0.50208160 * 1201; time = 0.1064s; samplesPerSecond = 11290.9
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     0.23 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 21.65k samplesPerSecond , throughputPerWorker = 10.83k samplesPerSecond
MPI Rank 1: 07/13/2016 16:48:38:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.85367784 * 1202; EvalErrorPrediction = 0.51497504 * 1202; time = 0.1190s; samplesPerSecond = 10100.1
MPI Rank 1: 07/13/2016 16:48:38:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.84169854 * 1173; EvalErrorPrediction = 0.50809889 * 1173; time = 0.1055s; samplesPerSecond = 11116.2
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     0.23 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 21.38k samplesPerSecond , throughputPerWorker = 10.69k samplesPerSecond
MPI Rank 1: 07/13/2016 16:48:38:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87059172 * 1194; EvalErrorPrediction = 0.52680067 * 1194; time = 0.1213s; samplesPerSecond = 9840.0
MPI Rank 1: 07/13/2016 16:48:38:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.79036013 * 827; EvalErrorPrediction = 0.51269649 * 827; time = 0.0524s; samplesPerSecond = 15774.0
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.15-seconds latency this time; accumulated time on sync point = 0.15 seconds , average latency = 0.04 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     0.35 seconds since last report (0.15 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 16.41k samplesPerSecond , throughputPerWorker = 8.21k samplesPerSecond
MPI Rank 1: 07/13/2016 16:48:39: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84568574 * 20480; EvalErrorPrediction = 0.51049805 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 2.4414063e-05; epochTime=1.06845s
MPI Rank 1: 07/13/2016 16:48:39: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160713164744.999927/Speech/DNN_ParallelBM@debug_gpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/13/2016 16:48:39: learnRatePerSample reduced to 1.2207031e-05
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:48:39: Starting Epoch 5: learning rate per sample = 0.000012  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:48:39: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 07/13/2016 16:48:39:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.78967425 * 1175; EvalErrorPrediction = 0.49021277 * 1175; time = 0.1166s; samplesPerSecond = 10073.3
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     0.27 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 18.19k samplesPerSecond , throughputPerWorker = 9.10k samplesPerSecond
MPI Rank 1: 07/13/2016 16:48:39:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.83902575 * 1251; EvalErrorPrediction = 0.50839329 * 1251; time = 0.1333s; samplesPerSecond = 9382.9
MPI Rank 1: 07/13/2016 16:48:39:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.78223129 * 1201; EvalErrorPrediction = 0.50291424 * 1201; time = 0.1066s; samplesPerSecond = 11261.9
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     0.23 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 21.66k samplesPerSecond , throughputPerWorker = 10.83k samplesPerSecond
MPI Rank 1: 07/13/2016 16:48:40:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.85388363 * 1202; EvalErrorPrediction = 0.51580699 * 1202; time = 0.1186s; samplesPerSecond = 10133.0
MPI Rank 1: 07/13/2016 16:48:40:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.84256302 * 1173; EvalErrorPrediction = 0.51065644 * 1173; time = 0.1060s; samplesPerSecond = 11063.2
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     0.23 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 21.35k samplesPerSecond , throughputPerWorker = 10.68k samplesPerSecond
MPI Rank 1: 07/13/2016 16:48:40:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87093833 * 1194; EvalErrorPrediction = 0.52763819 * 1194; time = 0.1211s; samplesPerSecond = 9860.1
MPI Rank 1: 07/13/2016 16:48:40:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.79083879 * 827; EvalErrorPrediction = 0.51269649 * 827; time = 0.0520s; samplesPerSecond = 15916.4
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.15-seconds latency this time; accumulated time on sync point = 0.15 seconds , average latency = 0.04 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     0.36 seconds since last report (0.15 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 16.39k samplesPerSecond , throughputPerWorker = 8.20k samplesPerSecond
MPI Rank 1: 07/13/2016 16:48:40: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84611027 * 20480; EvalErrorPrediction = 0.51083984 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 1.2207031e-05; epochTime=1.07886s
MPI Rank 1: 07/13/2016 16:48:40: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160713164744.999927/Speech/DNN_ParallelBM@debug_gpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/13/2016 16:48:40: learnRatePerSample reduced to 6.1035157e-06
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:48:40: Starting Epoch 5: learning rate per sample = 0.000006  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:48:40: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 07/13/2016 16:48:40:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.78968320 * 1175; EvalErrorPrediction = 0.49021277 * 1175; time = 0.1150s; samplesPerSecond = 10220.1
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     0.25 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 19.28k samplesPerSecond , throughputPerWorker = 9.64k samplesPerSecond
MPI Rank 1: 07/13/2016 16:48:41:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.83906070 * 1251; EvalErrorPrediction = 0.50839329 * 1251; time = 0.1198s; samplesPerSecond = 10442.7
MPI Rank 1: 07/13/2016 16:48:41:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.78239105 * 1201; EvalErrorPrediction = 0.50291424 * 1201; time = 0.1066s; samplesPerSecond = 11268.1
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     0.23 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 21.67k samplesPerSecond , throughputPerWorker = 10.83k samplesPerSecond
MPI Rank 1: 07/13/2016 16:48:41:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.85398908 * 1202; EvalErrorPrediction = 0.51663894 * 1202; time = 0.1186s; samplesPerSecond = 10135.5
MPI Rank 1: 07/13/2016 16:48:41:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.84302155 * 1173; EvalErrorPrediction = 0.51150895 * 1173; time = 0.1055s; samplesPerSecond = 11114.1
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     0.23 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 21.44k samplesPerSecond , throughputPerWorker = 10.72k samplesPerSecond
MPI Rank 1: 07/13/2016 16:48:41:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87112259 * 1194; EvalErrorPrediction = 0.52763819 * 1194; time = 0.1207s; samplesPerSecond = 9893.8
MPI Rank 1: 07/13/2016 16:48:41:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.79109571 * 827; EvalErrorPrediction = 0.51269649 * 827; time = 0.0526s; samplesPerSecond = 15717.1
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.15-seconds latency this time; accumulated time on sync point = 0.15 seconds , average latency = 0.04 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     0.36 seconds since last report (0.15 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 16.26k samplesPerSecond , throughputPerWorker = 8.13k samplesPerSecond
MPI Rank 1: 07/13/2016 16:48:41: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84633999 * 20480; EvalErrorPrediction = 0.51123047 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 6.1035157e-06; epochTime=1.06537s
MPI Rank 1: 07/13/2016 16:48:41: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160713164744.999927/Speech/DNN_ParallelBM@debug_gpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/13/2016 16:48:42: learnRatePerSample reduced to 3.0517579e-06
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:48:42: Starting Epoch 5: learning rate per sample = 0.000003  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:48:42: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 07/13/2016 16:48:42:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.78968768 * 1175; EvalErrorPrediction = 0.49021277 * 1175; time = 0.1151s; samplesPerSecond = 10211.0
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     0.25 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 19.29k samplesPerSecond , throughputPerWorker = 9.64k samplesPerSecond
MPI Rank 1: 07/13/2016 16:48:42:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.83907833 * 1251; EvalErrorPrediction = 0.50839329 * 1251; time = 0.1194s; samplesPerSecond = 10473.6
MPI Rank 1: 07/13/2016 16:48:42:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.78247230 * 1201; EvalErrorPrediction = 0.50291424 * 1201; time = 0.1069s; samplesPerSecond = 11238.1
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     0.23 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 21.58k samplesPerSecond , throughputPerWorker = 10.79k samplesPerSecond
MPI Rank 1: 07/13/2016 16:48:42:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.85404253 * 1202; EvalErrorPrediction = 0.51663894 * 1202; time = 0.1192s; samplesPerSecond = 10083.3
MPI Rank 1: 07/13/2016 16:48:42:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.84325796 * 1173; EvalErrorPrediction = 0.51236147 * 1173; time = 0.1055s; samplesPerSecond = 11114.1
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     0.23 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 21.46k samplesPerSecond , throughputPerWorker = 10.73k samplesPerSecond
MPI Rank 1: 07/13/2016 16:48:42:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87121808 * 1194; EvalErrorPrediction = 0.52763819 * 1194; time = 0.1205s; samplesPerSecond = 9911.7
MPI Rank 1: 07/13/2016 16:48:42:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.79123019 * 827; EvalErrorPrediction = 0.51027811 * 827; time = 0.0520s; samplesPerSecond = 15905.1
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.15-seconds latency this time; accumulated time on sync point = 0.15 seconds , average latency = 0.04 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     0.35 seconds since last report (0.15 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 16.44k samplesPerSecond , throughputPerWorker = 8.22k samplesPerSecond
MPI Rank 1: 07/13/2016 16:48:43: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84646018 * 20480; EvalErrorPrediction = 0.51127930 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 3.0517579e-06; epochTime=1.06214s
MPI Rank 1: 07/13/2016 16:48:43: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160713164744.999927/Speech/DNN_ParallelBM@debug_gpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/13/2016 16:48:43: learnRatePerSample reduced to 1.5258789e-06
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:48:43: Starting Epoch 5: learning rate per sample = 0.000002  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:48:43: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 07/13/2016 16:48:43:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.78968993 * 1175; EvalErrorPrediction = 0.49021277 * 1175; time = 0.1176s; samplesPerSecond = 9992.7
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     0.27 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 18.24k samplesPerSecond , throughputPerWorker = 9.12k samplesPerSecond
MPI Rank 1: 07/13/2016 16:48:43:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.83908718 * 1251; EvalErrorPrediction = 0.50839329 * 1251; time = 0.1319s; samplesPerSecond = 9488.0
MPI Rank 1: 07/13/2016 16:48:43:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.78251328 * 1201; EvalErrorPrediction = 0.50291424 * 1201; time = 0.1081s; samplesPerSecond = 11114.0
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     0.23 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 21.21k samplesPerSecond , throughputPerWorker = 10.61k samplesPerSecond
MPI Rank 1: 07/13/2016 16:48:44:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.85406946 * 1202; EvalErrorPrediction = 0.51663894 * 1202; time = 0.1220s; samplesPerSecond = 9855.9
MPI Rank 1: 07/13/2016 16:48:44:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.84337803 * 1173; EvalErrorPrediction = 0.51236147 * 1173; time = 0.1054s; samplesPerSecond = 11124.1
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     0.23 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 21.44k samplesPerSecond , throughputPerWorker = 10.72k samplesPerSecond
MPI Rank 1: 07/13/2016 16:48:44:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87126675 * 1194; EvalErrorPrediction = 0.52763819 * 1194; time = 0.1208s; samplesPerSecond = 9888.0
MPI Rank 1: 07/13/2016 16:48:44:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.79129918 * 827; EvalErrorPrediction = 0.51027811 * 827; time = 0.0518s; samplesPerSecond = 15980.4
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.15-seconds latency this time; accumulated time on sync point = 0.15 seconds , average latency = 0.04 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     0.36 seconds since last report (0.15 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 16.37k samplesPerSecond , throughputPerWorker = 8.18k samplesPerSecond
MPI Rank 1: 07/13/2016 16:48:44: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84652175 * 20480; EvalErrorPrediction = 0.51123047 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 1.5258789e-06; epochTime=1.0825s
MPI Rank 1: 07/13/2016 16:48:44: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160713164744.999927/Speech/DNN_ParallelBM@debug_gpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/13/2016 16:48:44: learnRatePerSample reduced to 7.6293946e-07
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:48:44: Starting Epoch 5: learning rate per sample = 0.000001  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:48:44: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 07/13/2016 16:48:45:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.78969105 * 1175; EvalErrorPrediction = 0.49021277 * 1175; time = 0.1146s; samplesPerSecond = 10254.6
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     0.26 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 19.27k samplesPerSecond , throughputPerWorker = 9.64k samplesPerSecond
MPI Rank 1: 07/13/2016 16:48:45:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.83909162 * 1251; EvalErrorPrediction = 0.50839329 * 1251; time = 0.1205s; samplesPerSecond = 10378.6
MPI Rank 1: 07/13/2016 16:48:45:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.78253385 * 1201; EvalErrorPrediction = 0.50291424 * 1201; time = 0.1066s; samplesPerSecond = 11264.0
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     0.22 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 21.76k samplesPerSecond , throughputPerWorker = 10.88k samplesPerSecond
MPI Rank 1: 07/13/2016 16:48:45:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.85408297 * 1202; EvalErrorPrediction = 0.51663894 * 1202; time = 0.1177s; samplesPerSecond = 10215.4
MPI Rank 1: 07/13/2016 16:48:45:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.84343854 * 1173; EvalErrorPrediction = 0.51236147 * 1173; time = 0.1053s; samplesPerSecond = 11138.9
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     0.23 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 21.45k samplesPerSecond , throughputPerWorker = 10.72k samplesPerSecond
MPI Rank 1: 07/13/2016 16:48:45:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87129133 * 1194; EvalErrorPrediction = 0.52763819 * 1194; time = 0.1208s; samplesPerSecond = 9881.8
MPI Rank 1: 07/13/2016 16:48:45:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.79133413 * 827; EvalErrorPrediction = 0.51027811 * 827; time = 0.0520s; samplesPerSecond = 15895.9
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.15-seconds latency this time; accumulated time on sync point = 0.15 seconds , average latency = 0.04 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     0.36 seconds since last report (0.15 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 16.25k samplesPerSecond , throughputPerWorker = 8.13k samplesPerSecond
MPI Rank 1: 07/13/2016 16:48:45: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84655293 * 20480; EvalErrorPrediction = 0.51118164 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 7.6293946e-07; epochTime=1.06471s
MPI Rank 1: 07/13/2016 16:48:45: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160713164744.999927/Speech/DNN_ParallelBM@debug_gpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/13/2016 16:48:46: learnRatePerSample reduced to 3.8146973e-07
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:48:46: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:48:46: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 07/13/2016 16:48:46:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.78969161 * 1175; EvalErrorPrediction = 0.49021277 * 1175; time = 0.1155s; samplesPerSecond = 10170.4
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     0.26 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 19.22k samplesPerSecond , throughputPerWorker = 9.61k samplesPerSecond
MPI Rank 1: 07/13/2016 16:48:46:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.83909384 * 1251; EvalErrorPrediction = 0.50839329 * 1251; time = 0.1200s; samplesPerSecond = 10422.1
MPI Rank 1: 07/13/2016 16:48:46:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.78254416 * 1201; EvalErrorPrediction = 0.50291424 * 1201; time = 0.1068s; samplesPerSecond = 11249.8
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     0.23 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 21.60k samplesPerSecond , throughputPerWorker = 10.80k samplesPerSecond
MPI Rank 1: 07/13/2016 16:48:46:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.85408974 * 1202; EvalErrorPrediction = 0.51663894 * 1202; time = 0.1191s; samplesPerSecond = 10091.5
MPI Rank 1: 07/13/2016 16:48:46:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.84346892 * 1173; EvalErrorPrediction = 0.51236147 * 1173; time = 0.1056s; samplesPerSecond = 11109.5
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     0.23 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 21.37k samplesPerSecond , throughputPerWorker = 10.69k samplesPerSecond
MPI Rank 1: 07/13/2016 16:48:46:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87130368 * 1194; EvalErrorPrediction = 0.52763819 * 1194; time = 0.1213s; samplesPerSecond = 9840.8
MPI Rank 1: 07/13/2016 16:48:46:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.79135174 * 827; EvalErrorPrediction = 0.51027811 * 827; time = 0.0517s; samplesPerSecond = 15990.6
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.15-seconds latency this time; accumulated time on sync point = 0.15 seconds , average latency = 0.04 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     0.35 seconds since last report (0.15 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 16.47k samplesPerSecond , throughputPerWorker = 8.24k samplesPerSecond
MPI Rank 1: 07/13/2016 16:48:47: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84656861 * 20480; EvalErrorPrediction = 0.51118164 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 3.8146973e-07; epochTime=1.0631s
MPI Rank 1: 07/13/2016 16:48:47: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160713164744.999927/Speech/DNN_ParallelBM@debug_gpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/13/2016 16:48:47: learnRatePerSample reduced to 1.9073487e-07
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:48:47: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:48:47: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 07/13/2016 16:48:47:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.78969189 * 1175; EvalErrorPrediction = 0.49021277 * 1175; time = 0.1182s; samplesPerSecond = 9937.1
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     0.27 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 18.16k samplesPerSecond , throughputPerWorker = 9.08k samplesPerSecond
MPI Rank 1: 07/13/2016 16:48:47:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.83909495 * 1251; EvalErrorPrediction = 0.50839329 * 1251; time = 0.1322s; samplesPerSecond = 9460.3
MPI Rank 1: 07/13/2016 16:48:47:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.78254932 * 1201; EvalErrorPrediction = 0.50291424 * 1201; time = 0.1067s; samplesPerSecond = 11260.3
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     0.23 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 21.67k samplesPerSecond , throughputPerWorker = 10.84k samplesPerSecond
MPI Rank 1: 07/13/2016 16:48:48:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.85409313 * 1202; EvalErrorPrediction = 0.51663894 * 1202; time = 0.1185s; samplesPerSecond = 10145.0
MPI Rank 1: 07/13/2016 16:48:48:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.84348413 * 1173; EvalErrorPrediction = 0.51236147 * 1173; time = 0.1055s; samplesPerSecond = 11120.4
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     0.23 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 21.44k samplesPerSecond , throughputPerWorker = 10.72k samplesPerSecond
MPI Rank 1: 07/13/2016 16:48:48:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87130987 * 1194; EvalErrorPrediction = 0.52680067 * 1194; time = 0.1207s; samplesPerSecond = 9888.8
MPI Rank 1: 07/13/2016 16:48:48:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.79136057 * 827; EvalErrorPrediction = 0.51027811 * 827; time = 0.0524s; samplesPerSecond = 15789.7
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.15-seconds latency this time; accumulated time on sync point = 0.15 seconds , average latency = 0.04 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     0.36 seconds since last report (0.15 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 16.31k samplesPerSecond , throughputPerWorker = 8.16k samplesPerSecond
MPI Rank 1: 07/13/2016 16:48:48: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84657648 * 20480; EvalErrorPrediction = 0.51118164 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 1.9073487e-07; epochTime=1.08009s
MPI Rank 1: 07/13/2016 16:48:48: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160713164744.999927/Speech/DNN_ParallelBM@debug_gpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/13/2016 16:48:48: learnRatePerSample reduced to 9.5367433e-08
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:48:48: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:48:48: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 07/13/2016 16:48:49:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.78969203 * 1175; EvalErrorPrediction = 0.49021277 * 1175; time = 0.1147s; samplesPerSecond = 10245.2
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     0.25 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 19.28k samplesPerSecond , throughputPerWorker = 9.64k samplesPerSecond
MPI Rank 1: 07/13/2016 16:48:49:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.83909551 * 1251; EvalErrorPrediction = 0.50839329 * 1251; time = 0.1202s; samplesPerSecond = 10403.7
MPI Rank 1: 07/13/2016 16:48:49:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.78255190 * 1201; EvalErrorPrediction = 0.50291424 * 1201; time = 0.1064s; samplesPerSecond = 11283.8
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     0.23 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 21.71k samplesPerSecond , throughputPerWorker = 10.85k samplesPerSecond
MPI Rank 1: 07/13/2016 16:48:49:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.85409482 * 1202; EvalErrorPrediction = 0.51663894 * 1202; time = 0.1183s; samplesPerSecond = 10156.6
MPI Rank 1: 07/13/2016 16:48:49:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.84349175 * 1173; EvalErrorPrediction = 0.51236147 * 1173; time = 0.1054s; samplesPerSecond = 11130.0
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     0.23 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 21.42k samplesPerSecond , throughputPerWorker = 10.71k samplesPerSecond
MPI Rank 1: 07/13/2016 16:48:49:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87131297 * 1194; EvalErrorPrediction = 0.52680067 * 1194; time = 0.1210s; samplesPerSecond = 9865.5
MPI Rank 1: 07/13/2016 16:48:49:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.79136499 * 827; EvalErrorPrediction = 0.51027811 * 827; time = 0.0519s; samplesPerSecond = 15936.6
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.15-seconds latency this time; accumulated time on sync point = 0.15 seconds , average latency = 0.04 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     0.36 seconds since last report (0.15 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 16.31k samplesPerSecond , throughputPerWorker = 8.16k samplesPerSecond
MPI Rank 1: 07/13/2016 16:48:49: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84658042 * 20480; EvalErrorPrediction = 0.51123047 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 9.5367433e-08; epochTime=1.06401s
MPI Rank 1: 07/13/2016 16:48:49: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160713164744.999927/Speech/DNN_ParallelBM@debug_gpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/13/2016 16:48:50: learnRatePerSample reduced to 4.7683717e-08
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:48:50: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:48:50: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 07/13/2016 16:48:50:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.78969210 * 1175; EvalErrorPrediction = 0.49021277 * 1175; time = 0.1150s; samplesPerSecond = 10214.1
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     0.26 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 19.18k samplesPerSecond , throughputPerWorker = 9.59k samplesPerSecond
MPI Rank 1: 07/13/2016 16:48:50:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.83909579 * 1251; EvalErrorPrediction = 0.50839329 * 1251; time = 0.1209s; samplesPerSecond = 10350.2
MPI Rank 1: 07/13/2016 16:48:50:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.78255320 * 1201; EvalErrorPrediction = 0.50291424 * 1201; time = 0.1086s; samplesPerSecond = 11062.8
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     0.22 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 21.75k samplesPerSecond , throughputPerWorker = 10.87k samplesPerSecond
MPI Rank 1: 07/13/2016 16:48:50:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.85409567 * 1202; EvalErrorPrediction = 0.51663894 * 1202; time = 0.1158s; samplesPerSecond = 10382.3
MPI Rank 1: 07/13/2016 16:48:51:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.84349556 * 1173; EvalErrorPrediction = 0.51236147 * 1173; time = 0.1058s; samplesPerSecond = 11088.4
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     0.23 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 21.38k samplesPerSecond , throughputPerWorker = 10.69k samplesPerSecond
MPI Rank 1: 07/13/2016 16:48:51:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87131452 * 1194; EvalErrorPrediction = 0.52680067 * 1194; time = 0.1211s; samplesPerSecond = 9863.6
MPI Rank 1: 07/13/2016 16:48:51:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.79136720 * 827; EvalErrorPrediction = 0.51027811 * 827; time = 0.0519s; samplesPerSecond = 15934.8
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.15-seconds latency this time; accumulated time on sync point = 0.15 seconds , average latency = 0.04 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     0.36 seconds since last report (0.15 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 16.34k samplesPerSecond , throughputPerWorker = 8.17k samplesPerSecond
MPI Rank 1: 07/13/2016 16:48:51: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84658239 * 20480; EvalErrorPrediction = 0.51123047 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 4.7683717e-08; epochTime=1.06475s
MPI Rank 1: 07/13/2016 16:48:51: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160713164744.999927/Speech/DNN_ParallelBM@debug_gpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/13/2016 16:48:51: learnRatePerSample reduced to 2.3841858e-08
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:48:51: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:48:51: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 07/13/2016 16:48:51:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.78969213 * 1175; EvalErrorPrediction = 0.49021277 * 1175; time = 0.1144s; samplesPerSecond = 10270.5
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     0.25 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 19.36k samplesPerSecond , throughputPerWorker = 9.68k samplesPerSecond
MPI Rank 1: 07/13/2016 16:48:52:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.83909593 * 1251; EvalErrorPrediction = 0.50839329 * 1251; time = 0.1193s; samplesPerSecond = 10488.5
MPI Rank 1: 07/13/2016 16:48:52:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.78255384 * 1201; EvalErrorPrediction = 0.50291424 * 1201; time = 0.1068s; samplesPerSecond = 11248.6
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     0.23 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 21.62k samplesPerSecond , throughputPerWorker = 10.81k samplesPerSecond
MPI Rank 1: 07/13/2016 16:48:52:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.85409609 * 1202; EvalErrorPrediction = 0.51663894 * 1202; time = 0.1190s; samplesPerSecond = 10103.1
MPI Rank 1: 07/13/2016 16:48:52:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.84349747 * 1173; EvalErrorPrediction = 0.51236147 * 1173; time = 0.1059s; samplesPerSecond = 11078.3
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     0.22 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 21.66k samplesPerSecond , throughputPerWorker = 10.83k samplesPerSecond
MPI Rank 1: 07/13/2016 16:48:52:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87131530 * 1194; EvalErrorPrediction = 0.52680067 * 1194; time = 0.1181s; samplesPerSecond = 10112.9
MPI Rank 1: 07/13/2016 16:48:52:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.79136831 * 827; EvalErrorPrediction = 0.51027811 * 827; time = 0.0519s; samplesPerSecond = 15936.0
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.15-seconds latency this time; accumulated time on sync point = 0.15 seconds , average latency = 0.04 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     0.36 seconds since last report (0.15 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 16.40k samplesPerSecond , throughputPerWorker = 8.20k samplesPerSecond
MPI Rank 1: 07/13/2016 16:48:52: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84658338 * 20480; EvalErrorPrediction = 0.51127930 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 2.3841858e-08; epochTime=1.05969s
MPI Rank 1: 07/13/2016 16:48:52: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160713164744.999927/Speech/DNN_ParallelBM@debug_gpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/13/2016 16:48:52: learnRatePerSample reduced to 1.1920929e-08
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:48:53: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:48:53: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 07/13/2016 16:48:53:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.78969215 * 1175; EvalErrorPrediction = 0.49021277 * 1175; time = 0.1186s; samplesPerSecond = 9907.3
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     0.27 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 18.20k samplesPerSecond , throughputPerWorker = 9.10k samplesPerSecond
MPI Rank 1: 07/13/2016 16:48:53:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.83909600 * 1251; EvalErrorPrediction = 0.50839329 * 1251; time = 0.1313s; samplesPerSecond = 9529.0
MPI Rank 1: 07/13/2016 16:48:53:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.78255416 * 1201; EvalErrorPrediction = 0.50291424 * 1201; time = 0.1066s; samplesPerSecond = 11271.0
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     0.23 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 21.68k samplesPerSecond , throughputPerWorker = 10.84k samplesPerSecond
MPI Rank 1: 07/13/2016 16:48:53:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.85409630 * 1202; EvalErrorPrediction = 0.51663894 * 1202; time = 0.1185s; samplesPerSecond = 10143.3
MPI Rank 1: 07/13/2016 16:48:53:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.84349842 * 1173; EvalErrorPrediction = 0.51236147 * 1173; time = 0.1056s; samplesPerSecond = 11105.2
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     0.23 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 21.44k samplesPerSecond , throughputPerWorker = 10.72k samplesPerSecond
MPI Rank 1: 07/13/2016 16:48:53:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87131569 * 1194; EvalErrorPrediction = 0.52680067 * 1194; time = 0.1205s; samplesPerSecond = 9906.2
MPI Rank 1: 07/13/2016 16:48:53:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.79136886 * 827; EvalErrorPrediction = 0.51027811 * 827; time = 0.0520s; samplesPerSecond = 15901.7
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.15-seconds latency this time; accumulated time on sync point = 0.15 seconds , average latency = 0.04 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     0.35 seconds since last report (0.15 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 16.45k samplesPerSecond , throughputPerWorker = 8.22k samplesPerSecond
MPI Rank 1: 07/13/2016 16:48:54: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84658387 * 20480; EvalErrorPrediction = 0.51127930 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 1.1920929e-08; epochTime=1.07632s
MPI Rank 1: 07/13/2016 16:48:54: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160713164744.999927/Speech/DNN_ParallelBM@debug_gpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/13/2016 16:48:54: learnRatePerSample reduced to 5.9604646e-09
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:48:54: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:48:54: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 07/13/2016 16:48:54:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.78969216 * 1175; EvalErrorPrediction = 0.49021277 * 1175; time = 0.1168s; samplesPerSecond = 10056.0
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     0.27 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 18.18k samplesPerSecond , throughputPerWorker = 9.09k samplesPerSecond
MPI Rank 1: 07/13/2016 16:48:54:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.83909603 * 1251; EvalErrorPrediction = 0.50839329 * 1251; time = 0.1333s; samplesPerSecond = 9381.6
MPI Rank 1: 07/13/2016 16:48:54:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.78255433 * 1201; EvalErrorPrediction = 0.50291424 * 1201; time = 0.1066s; samplesPerSecond = 11271.3
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     0.23 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 21.67k samplesPerSecond , throughputPerWorker = 10.84k samplesPerSecond
MPI Rank 1: 07/13/2016 16:48:55:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.85409641 * 1202; EvalErrorPrediction = 0.51663894 * 1202; time = 0.1185s; samplesPerSecond = 10139.4
MPI Rank 1: 07/13/2016 16:48:55:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.84349890 * 1173; EvalErrorPrediction = 0.51236147 * 1173; time = 0.1053s; samplesPerSecond = 11137.9
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     0.23 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 21.45k samplesPerSecond , throughputPerWorker = 10.72k samplesPerSecond
MPI Rank 1: 07/13/2016 16:48:55:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87131588 * 1194; EvalErrorPrediction = 0.52680067 * 1194; time = 0.1208s; samplesPerSecond = 9883.6
MPI Rank 1: 07/13/2016 16:48:55:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.79136914 * 827; EvalErrorPrediction = 0.51027811 * 827; time = 0.0525s; samplesPerSecond = 15744.0
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.15-seconds latency this time; accumulated time on sync point = 0.15 seconds , average latency = 0.04 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     0.36 seconds since last report (0.15 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 16.32k samplesPerSecond , throughputPerWorker = 8.16k samplesPerSecond
MPI Rank 1: 07/13/2016 16:48:55: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84658412 * 20480; EvalErrorPrediction = 0.51127930 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 5.9604646e-09; epochTime=1.07956s
MPI Rank 1: 07/13/2016 16:48:55: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160713164744.999927/Speech/DNN_ParallelBM@debug_gpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/13/2016 16:48:55: learnRatePerSample reduced to 2.9802323e-09
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:48:55: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:48:55: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 07/13/2016 16:48:55:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.78969217 * 1175; EvalErrorPrediction = 0.49021277 * 1175; time = 0.1152s; samplesPerSecond = 10196.6
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     0.26 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 19.17k samplesPerSecond , throughputPerWorker = 9.59k samplesPerSecond
MPI Rank 1: 07/13/2016 16:48:56:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.83909605 * 1251; EvalErrorPrediction = 0.50839329 * 1251; time = 0.1206s; samplesPerSecond = 10377.2
MPI Rank 1: 07/13/2016 16:48:56:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.78255441 * 1201; EvalErrorPrediction = 0.50291424 * 1201; time = 0.1061s; samplesPerSecond = 11318.8
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     0.22 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 21.95k samplesPerSecond , throughputPerWorker = 10.98k samplesPerSecond
MPI Rank 1: 07/13/2016 16:48:56:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.85409646 * 1202; EvalErrorPrediction = 0.51663894 * 1202; time = 0.1161s; samplesPerSecond = 10350.3
MPI Rank 1: 07/13/2016 16:48:56:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.84349913 * 1173; EvalErrorPrediction = 0.51236147 * 1173; time = 0.1054s; samplesPerSecond = 11129.9
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     0.23 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 21.38k samplesPerSecond , throughputPerWorker = 10.69k samplesPerSecond
MPI Rank 1: 07/13/2016 16:48:56:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87131598 * 1194; EvalErrorPrediction = 0.52680067 * 1194; time = 0.1215s; samplesPerSecond = 9831.1
MPI Rank 1: 07/13/2016 16:48:56:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.79136928 * 827; EvalErrorPrediction = 0.51027811 * 827; time = 0.0520s; samplesPerSecond = 15891.3
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.15-seconds latency this time; accumulated time on sync point = 0.15 seconds , average latency = 0.04 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     0.36 seconds since last report (0.15 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 16.38k samplesPerSecond , throughputPerWorker = 8.19k samplesPerSecond
MPI Rank 1: 07/13/2016 16:48:56: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84658424 * 20480; EvalErrorPrediction = 0.51127930 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 2.9802323e-09; epochTime=1.06199s
MPI Rank 1: 07/13/2016 16:48:56: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160713164744.999927/Speech/DNN_ParallelBM@debug_gpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/13/2016 16:48:57: learnRatePerSample reduced to 1.4901161e-09
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:48:57: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:48:57: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 07/13/2016 16:48:57:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.78969217 * 1175; EvalErrorPrediction = 0.49021277 * 1175; time = 0.1147s; samplesPerSecond = 10243.0
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     0.26 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 19.26k samplesPerSecond , throughputPerWorker = 9.63k samplesPerSecond
MPI Rank 1: 07/13/2016 16:48:57:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.83909606 * 1251; EvalErrorPrediction = 0.50839329 * 1251; time = 0.1203s; samplesPerSecond = 10395.7
MPI Rank 1: 07/13/2016 16:48:57:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.78255445 * 1201; EvalErrorPrediction = 0.50291424 * 1201; time = 0.1067s; samplesPerSecond = 11255.8
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     0.23 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 21.58k samplesPerSecond , throughputPerWorker = 10.79k samplesPerSecond
MPI Rank 1: 07/13/2016 16:48:57:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.85409649 * 1202; EvalErrorPrediction = 0.51663894 * 1202; time = 0.1194s; samplesPerSecond = 10070.8
MPI Rank 1: 07/13/2016 16:48:57:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.84349925 * 1173; EvalErrorPrediction = 0.51236147 * 1173; time = 0.1060s; samplesPerSecond = 11069.4
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     0.23 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 21.34k samplesPerSecond , throughputPerWorker = 10.67k samplesPerSecond
MPI Rank 1: 07/13/2016 16:48:57:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87131603 * 1194; EvalErrorPrediction = 0.52680067 * 1194; time = 0.1213s; samplesPerSecond = 9847.2
MPI Rank 1: 07/13/2016 16:48:57:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.79136935 * 827; EvalErrorPrediction = 0.51027811 * 827; time = 0.0518s; samplesPerSecond = 15980.1
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.15-seconds latency this time; accumulated time on sync point = 0.15 seconds , average latency = 0.04 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     0.36 seconds since last report (0.15 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 16.38k samplesPerSecond , throughputPerWorker = 8.19k samplesPerSecond
MPI Rank 1: 07/13/2016 16:48:58: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84658431 * 20480; EvalErrorPrediction = 0.51127930 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 1.4901161e-09; epochTime=1.06511s
MPI Rank 1: 07/13/2016 16:48:58: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160713164744.999927/Speech/DNN_ParallelBM@debug_gpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/13/2016 16:48:58: learnRatePerSample reduced to 7.4505807e-10
MPI Rank 1: 07/13/2016 16:48:58: Learn Rate Per Sample for Epoch[5] = 7.4505807e-10 is less than minLearnRate 9.9999997e-10. Training complete.
MPI Rank 1: 07/13/2016 16:48:58: CNTKCommandTrainEnd: speechTrain
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:48:58: Action "train" complete.
MPI Rank 1: 
MPI Rank 1: 07/13/2016 16:48:58: __COMPLETED__
MPI Rank 1: ~MPIWrapper
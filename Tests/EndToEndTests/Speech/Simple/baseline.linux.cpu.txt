CPU info:
    CPU Model Name: Intel(R) Xeon(R) CPU E5-2630 v2 @ 2.60GHz
    Hardware threads: 24
    Total Memory: 264172964 kB
-------------------------------------------------------------------
=== Running /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/build/gpu/release/bin/cntk configFile=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Simple/cntk.cntk currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data RunDir=/tmp/cntk-test-20160713122635.123438/Speech_Simple@release_cpu DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Simple OutputDir=/tmp/cntk-test-20160713122635.123438/Speech_Simple@release_cpu DeviceId=-1 timestamping=true
-------------------------------------------------------------------
Build info: 

		Built time: Jul 13 2016 12:01:30
		Last modified date: Tue Jul 12 04:28:35 2016
		Build type: release
		Build target: GPU
		With 1bit-SGD: no
		Math lib: mkl
		CUDA_PATH: /usr/local/cuda-7.5
		CUB_PATH: /usr/local/cub-1.4.1
		CUDNN_PATH: /usr/local/cudnn-4.0
		Build Branch: HEAD
		Build SHA1: 50bb4c8afbc87c14548a5b5f315a064186a5cb5f
		Built by philly on 2bc22072e267
		Build Path: /home/philly/jenkins/workspace/CNTK-Build-Linux
-------------------------------------------------------------------
Changed current directory to /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
07/13/2016 12:28:20: -------------------------------------------------------------------
07/13/2016 12:28:20: Build info: 

07/13/2016 12:28:20: 		Built time: Jul 13 2016 12:01:30
07/13/2016 12:28:20: 		Last modified date: Tue Jul 12 04:28:35 2016
07/13/2016 12:28:20: 		Build type: release
07/13/2016 12:28:20: 		Build target: GPU
07/13/2016 12:28:20: 		With 1bit-SGD: no
07/13/2016 12:28:20: 		Math lib: mkl
07/13/2016 12:28:20: 		CUDA_PATH: /usr/local/cuda-7.5
07/13/2016 12:28:20: 		CUB_PATH: /usr/local/cub-1.4.1
07/13/2016 12:28:20: 		CUDNN_PATH: /usr/local/cudnn-4.0
07/13/2016 12:28:20: 		Build Branch: HEAD
07/13/2016 12:28:20: 		Build SHA1: 50bb4c8afbc87c14548a5b5f315a064186a5cb5f
07/13/2016 12:28:20: 		Built by philly on 2bc22072e267
07/13/2016 12:28:20: 		Build Path: /home/philly/jenkins/workspace/CNTK-Build-Linux
07/13/2016 12:28:20: -------------------------------------------------------------------
07/13/2016 12:28:21: -------------------------------------------------------------------
07/13/2016 12:28:21: GPU info:

07/13/2016 12:28:21: 		Device[0]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3071 MB
07/13/2016 12:28:21: 		Device[1]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3071 MB
07/13/2016 12:28:21: 		Device[2]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3071 MB
07/13/2016 12:28:21: 		Device[3]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3071 MB
07/13/2016 12:28:21: -------------------------------------------------------------------

07/13/2016 12:28:21: Running on localhost at 2016/07/13 12:28:21
07/13/2016 12:28:21: Command line: 
/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/build/gpu/release/bin/cntk  configFile=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Simple/cntk.cntk  currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data  RunDir=/tmp/cntk-test-20160713122635.123438/Speech_Simple@release_cpu  DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data  ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Simple  OutputDir=/tmp/cntk-test-20160713122635.123438/Speech_Simple@release_cpu  DeviceId=-1  timestamping=true



07/13/2016 12:28:21: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
07/13/2016 12:28:21: command=Simple_Demo:Simple_Demo_Output
DeviceNumber=-1
precision=float
modelPath=$RunDir$/models/simple.dnn
deviceId=$DeviceNumber$
outputNodeNames=ScaledLogLikelihood
traceLevel=1
Simple_Demo=[
    action=train
    SimpleNetworkBuilder=[
        layerSizes=2:50*2:2
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ErrorPrediction
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0 
        minibatchSize=128
        learningRatesPerSample=0.1
        momentumAsTimeConstant=2500
        dropoutRate=0.0
        maxEpochs=50
        keepCheckPointFiles = true
    ]
    reader=[
        readerType=CNTKTextFormatReader
        file=$DataDir$/SimpleDataTrain_cntk_text.txt
        input = [
            features=[
dim = 2      
                format = "dense"
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
]
Simple_Demo_Output=[
    action=write
    reader=[
        readerType=CNTKTextFormatReader
        file=$DataDir$/SimpleDataTest_cntk_text.txt
        input = [
            features=[
dim = 2 
                format = "dense" 
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
outputPath=$RunDir$/SimpleOutput    
]
currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
RunDir=/tmp/cntk-test-20160713122635.123438/Speech_Simple@release_cpu
DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Simple
OutputDir=/tmp/cntk-test-20160713122635.123438/Speech_Simple@release_cpu
DeviceId=-1
timestamping=true

07/13/2016 12:28:21: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<

07/13/2016 12:28:21: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
07/13/2016 12:28:21: command=Simple_Demo:Simple_Demo_Output
DeviceNumber=-1
precision=float
modelPath=/tmp/cntk-test-20160713122635.123438/Speech_Simple@release_cpu/models/simple.dnn
deviceId=-1
outputNodeNames=ScaledLogLikelihood
traceLevel=1
Simple_Demo=[
    action=train
    SimpleNetworkBuilder=[
        layerSizes=2:50*2:2
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ErrorPrediction
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0 
        minibatchSize=128
        learningRatesPerSample=0.1
        momentumAsTimeConstant=2500
        dropoutRate=0.0
        maxEpochs=50
        keepCheckPointFiles = true
    ]
    reader=[
        readerType=CNTKTextFormatReader
        file=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/SimpleDataTrain_cntk_text.txt
        input = [
            features=[
dim = 2      
                format = "dense"
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
]
Simple_Demo_Output=[
    action=write
    reader=[
        readerType=CNTKTextFormatReader
        file=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/SimpleDataTest_cntk_text.txt
        input = [
            features=[
dim = 2 
                format = "dense" 
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
outputPath=/tmp/cntk-test-20160713122635.123438/Speech_Simple@release_cpu/SimpleOutput    
]
currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
RunDir=/tmp/cntk-test-20160713122635.123438/Speech_Simple@release_cpu
DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Simple
OutputDir=/tmp/cntk-test-20160713122635.123438/Speech_Simple@release_cpu
DeviceId=-1
timestamping=true

07/13/2016 12:28:21: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<

07/13/2016 12:28:21: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
configparameters: cntk.cntk:command=Simple_Demo:Simple_Demo_Output
configparameters: cntk.cntk:ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Simple
configparameters: cntk.cntk:currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
configparameters: cntk.cntk:DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
configparameters: cntk.cntk:deviceId=-1
configparameters: cntk.cntk:DeviceNumber=-1
configparameters: cntk.cntk:modelPath=/tmp/cntk-test-20160713122635.123438/Speech_Simple@release_cpu/models/simple.dnn
configparameters: cntk.cntk:OutputDir=/tmp/cntk-test-20160713122635.123438/Speech_Simple@release_cpu
configparameters: cntk.cntk:outputNodeNames=ScaledLogLikelihood
configparameters: cntk.cntk:precision=float
configparameters: cntk.cntk:RunDir=/tmp/cntk-test-20160713122635.123438/Speech_Simple@release_cpu
configparameters: cntk.cntk:Simple_Demo=[
    action=train
    SimpleNetworkBuilder=[
        layerSizes=2:50*2:2
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ErrorPrediction
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0 
        minibatchSize=128
        learningRatesPerSample=0.1
        momentumAsTimeConstant=2500
        dropoutRate=0.0
        maxEpochs=50
        keepCheckPointFiles = true
    ]
    reader=[
        readerType=CNTKTextFormatReader
        file=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/SimpleDataTrain_cntk_text.txt
        input = [
            features=[
dim = 2      
                format = "dense"
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
]

configparameters: cntk.cntk:Simple_Demo_Output=[
    action=write
    reader=[
        readerType=CNTKTextFormatReader
        file=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/SimpleDataTest_cntk_text.txt
        input = [
            features=[
dim = 2 
                format = "dense" 
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
outputPath=/tmp/cntk-test-20160713122635.123438/Speech_Simple@release_cpu/SimpleOutput    
]

configparameters: cntk.cntk:timestamping=true
configparameters: cntk.cntk:traceLevel=1
07/13/2016 12:28:21: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
07/13/2016 12:28:21: Commands: Simple_Demo Simple_Demo_Output
07/13/2016 12:28:21: Precision = "float"
07/13/2016 12:28:21: CNTKModelPath: /tmp/cntk-test-20160713122635.123438/Speech_Simple@release_cpu/models/simple.dnn
07/13/2016 12:28:21: CNTKCommandTrainInfo: Simple_Demo : 50
07/13/2016 12:28:21: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 50

07/13/2016 12:28:21: ##############################################################################
07/13/2016 12:28:21: #                                                                            #
07/13/2016 12:28:21: # Action "train"                                                             #
07/13/2016 12:28:21: #                                                                            #
07/13/2016 12:28:21: ##############################################################################

07/13/2016 12:28:21: CNTKCommandTrainBegin: Simple_Demo
SimpleNetworkBuilder Using CPU

07/13/2016 12:28:21: Creating virgin network.

Post-processing network...

7 roots:
	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
	EvalErrorPrediction = ErrorPrediction()
	InvStdOfFeatures = InvStdDev()
	MeanOfFeatures = Mean()
	PosteriorProb = Softmax()
	Prior = Mean()
	ScaledLogLikelihood = Minus()

Validating network. 25 nodes to process in pass 1.

Validating --> labels = InputValue() :  -> [2 x *]
Validating --> W2 = LearnableParameter() :  -> [2 x 50]
Validating --> W1 = LearnableParameter() :  -> [50 x 50]
Validating --> W0 = LearnableParameter() :  -> [50 x 2]
Validating --> features = InputValue() :  -> [2 x *]
Validating --> MeanOfFeatures = Mean (features) : [2 x *] -> [2]
Validating --> InvStdOfFeatures = InvStdDev (features) : [2 x *] -> [2]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [2 x *], [2], [2] -> [2 x *]
Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [50 x 2], [2 x *] -> [50 x *]
Validating --> B0 = LearnableParameter() :  -> [50 x 1]
Validating --> W0*features+B0 = Plus (W0*features, B0) : [50 x *], [50 x 1] -> [50 x 1 x *]
Validating --> H1 = Sigmoid (W0*features+B0) : [50 x 1 x *] -> [50 x 1 x *]
Validating --> W1*H1 = Times (W1, H1) : [50 x 50], [50 x 1 x *] -> [50 x 1 x *]
Validating --> B1 = LearnableParameter() :  -> [50 x 1]
Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [50 x 1 x *], [50 x 1] -> [50 x 1 x *]
Validating --> H2 = Sigmoid (W1*H1+B1) : [50 x 1 x *] -> [50 x 1 x *]
Validating --> W2*H1 = Times (W2, H2) : [2 x 50], [50 x 1 x *] -> [2 x 1 x *]
Validating --> B2 = LearnableParameter() :  -> [2 x 1]
Validating --> HLast = Plus (W2*H1, B2) : [2 x 1 x *], [2 x 1] -> [2 x 1 x *]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [2 x *], [2 x 1 x *] -> [1]
Validating --> EvalErrorPrediction = ErrorPrediction (labels, HLast) : [2 x *], [2 x 1 x *] -> [1]
Validating --> PosteriorProb = Softmax (HLast) : [2 x 1 x *] -> [2 x 1 x *]
Validating --> Prior = Mean (labels) : [2 x *] -> [2]
Validating --> LogOfPrior = Log (Prior) : [2] -> [2]
Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [2 x 1 x *], [2] -> [2 x 1 x *]

Validating network. 17 nodes to process in pass 2.


Validating network, final pass.



12 out of 25 nodes do not share the minibatch layout with the input data.

Post-processing network complete.

07/13/2016 12:28:21: Created model with 25 nodes on CPU.

07/13/2016 12:28:21: Training criterion node(s):
07/13/2016 12:28:21: 	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax

07/13/2016 12:28:21: Evaluation criterion node(s):

07/13/2016 12:28:21: 	EvalErrorPrediction = ErrorPrediction


Allocating matrices for forward and/or backward propagation.

Memory Sharing Structure:

(nil): {[EvalErrorPrediction Gradient[1]] [InvStdOfFeatures Gradient[2]] [LogOfPrior Gradient[2]] [MVNormalizedFeatures Gradient[2 x *]] [MeanOfFeatures Gradient[2]] [PosteriorProb Gradient[2 x 1 x *]] [PosteriorProb Value[2 x 1 x *]] [Prior Gradient[2]] [ScaledLogLikelihood Gradient[2 x 1 x *]] [features Gradient[2 x *]] [labels Gradient[2 x *]] }
0x7fd056e3ee58: {[features Value[2 x *]] }
0x7fd056e3ef58: {[MeanOfFeatures Value[2]] }
0x7fd056e3f728: {[InvStdOfFeatures Value[2]] }
0x7fd056e40348: {[W0 Value[50 x 2]] }
0x7fd056e40908: {[B0 Value[50 x 1]] }
0x7fd056e418b8: {[W1 Value[50 x 50]] }
0x7fd056e443f8: {[B1 Value[50 x 1]] }
0x7fd056e452e8: {[W2 Value[2 x 50]] }
0x7fd056e458a8: {[B2 Value[2 x 1]] }
0x7fd056e46378: {[labels Value[2 x *]] }
0x7fd056e470e8: {[Prior Value[2]] }
0x7fd056e4c9f8: {[EvalErrorPrediction Value[1]] }
0x7fd056e4cb98: {[ScaledLogLikelihood Value[2 x 1 x *]] }
0x7fd056e4cd58: {[CrossEntropyWithSoftmax Value[1]] }
0x7fd056e4d2a8: {[W0 Gradient[50 x 2]] [W0*features+B0 Value[50 x 1 x *]] }
0x7fd056e4d418: {[LogOfPrior Value[2]] }
0x7fd056e4eb78: {[MVNormalizedFeatures Value[2 x *]] }
0x7fd056e4f338: {[W0*features Value[50 x *]] }
0x7fd056e4f548: {[H1 Value[50 x 1 x *]] [W0*features Gradient[50 x *]] }
0x7fd056e4f708: {[W0*features+B0 Gradient[50 x 1 x *]] [W1*H1 Value[50 x 1 x *]] }
0x7fd056e4f8c8: {[W1 Gradient[50 x 50]] [W1*H1+B1 Value[50 x 1 x *]] }
0x7fd056e4fa88: {[H2 Value[50 x 1 x *]] [W1*H1 Gradient[50 x 1 x *]] }
0x7fd056e4fc48: {[B0 Gradient[50 x 1]] [H1 Gradient[50 x 1 x *]] [W1*H1+B1 Gradient[50 x 1 x *]] [W2*H1 Value[2 x 1 x *]] }
0x7fd056e4fe08: {[HLast Value[2 x 1 x *]] [W2 Gradient[2 x 50]] }
0x7fd056ec6ac8: {[CrossEntropyWithSoftmax Gradient[1]] }
0x7fd056ec6c88: {[B1 Gradient[50 x 1]] [H2 Gradient[50 x 1 x *]] [HLast Gradient[2 x 1 x *]] }
0x7fd056ec6e48: {[W2*H1 Gradient[2 x 1 x *]] }
0x7fd056ec7008: {[B2 Gradient[2 x 1]] }


07/13/2016 12:28:21: Precomputing --> 3 PreCompute nodes found.

07/13/2016 12:28:21: 	MeanOfFeatures = Mean()
07/13/2016 12:28:21: 	InvStdOfFeatures = InvStdDev()
07/13/2016 12:28:21: 	Prior = Mean()
BlockRandomizer::StartEpoch: epoch 0: frames [0..10000] (first sequence at sample 0), data subset 0 of 1

07/13/2016 12:28:21: Precomputing --> Completed.


07/13/2016 12:28:21: Starting Epoch 1: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 0: frames [0..10000] (first sequence at sample 0), data subset 0 of 1

07/13/2016 12:28:21: Starting minibatch loop.
07/13/2016 12:28:22:  Epoch[ 1 of 50]-Minibatch[   1-  10]: CrossEntropyWithSoftmax = 0.73933568 * 1280; EvalErrorPrediction = 0.49140625 * 1280; time = 0.0712s; samplesPerSecond = 17985.6
07/13/2016 12:28:22:  Epoch[ 1 of 50]-Minibatch[  11-  20]: CrossEntropyWithSoftmax = 0.77136855 * 1280; EvalErrorPrediction = 0.48828125 * 1280; time = 0.0383s; samplesPerSecond = 33437.0
07/13/2016 12:28:22:  Epoch[ 1 of 50]-Minibatch[  21-  30]: CrossEntropyWithSoftmax = 0.70157547 * 1280; EvalErrorPrediction = 0.49531250 * 1280; time = 0.0431s; samplesPerSecond = 29670.8
07/13/2016 12:28:22:  Epoch[ 1 of 50]-Minibatch[  31-  40]: CrossEntropyWithSoftmax = 0.69864731 * 1280; EvalErrorPrediction = 0.49453125 * 1280; time = 0.0382s; samplesPerSecond = 33464.1
07/13/2016 12:28:22:  Epoch[ 1 of 50]-Minibatch[  41-  50]: CrossEntropyWithSoftmax = 0.71645107 * 1280; EvalErrorPrediction = 0.51562500 * 1280; time = 0.0390s; samplesPerSecond = 32786.9
07/13/2016 12:28:22:  Epoch[ 1 of 50]-Minibatch[  51-  60]: CrossEntropyWithSoftmax = 0.62874603 * 1280; EvalErrorPrediction = 0.41796875 * 1280; time = 0.0910s; samplesPerSecond = 14069.5
07/13/2016 12:28:22:  Epoch[ 1 of 50]-Minibatch[  61-  70]: CrossEntropyWithSoftmax = 0.27024193 * 1280; EvalErrorPrediction = 0.11328125 * 1280; time = 0.0483s; samplesPerSecond = 26499.9
07/13/2016 12:28:22: Finished Epoch[ 1 of 50]: [Training] CrossEntropyWithSoftmax = 0.60246250 * 10000; EvalErrorPrediction = 0.39590000 * 10000; totalSamplesSeen = 10000; learningRatePerSample = 0.1; epochTime=0.40898s
07/13/2016 12:28:22: SGD: Saving checkpoint model '/tmp/cntk-test-20160713122635.123438/Speech_Simple@release_cpu/models/simple.dnn.1'

07/13/2016 12:28:22: Starting Epoch 2: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 1: frames [10000..20000] (first sequence at sample 10000), data subset 0 of 1

07/13/2016 12:28:22: Starting minibatch loop.
07/13/2016 12:28:22:  Epoch[ 2 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.23306043 * 1280; EvalErrorPrediction = 0.06875000 * 1280; time = 0.0356s; samplesPerSecond = 35968.2
07/13/2016 12:28:22:  Epoch[ 2 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.24780281 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0421s; samplesPerSecond = 30416.1
07/13/2016 12:28:22:  Epoch[ 2 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.21934290 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0345s; samplesPerSecond = 37143.4
07/13/2016 12:28:22:  Epoch[ 2 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.20664573 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0562s; samplesPerSecond = 22781.5
07/13/2016 12:28:22:  Epoch[ 2 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.17843266 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0906s; samplesPerSecond = 14124.8
07/13/2016 12:28:22:  Epoch[ 2 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.22236977 * 1280; EvalErrorPrediction = 0.10312500 * 1280; time = 0.0701s; samplesPerSecond = 18256.0
07/13/2016 12:28:22:  Epoch[ 2 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16909218 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0328s; samplesPerSecond = 39014.9
07/13/2016 12:28:22: Finished Epoch[ 2 of 50]: [Training] CrossEntropyWithSoftmax = 0.20652896 * 10000; EvalErrorPrediction = 0.07970000 * 10000; totalSamplesSeen = 20000; learningRatePerSample = 0.1; epochTime=0.403596s
07/13/2016 12:28:22: SGD: Saving checkpoint model '/tmp/cntk-test-20160713122635.123438/Speech_Simple@release_cpu/models/simple.dnn.2'

07/13/2016 12:28:22: Starting Epoch 3: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 2: frames [20000..30000] (first sequence at sample 20000), data subset 0 of 1

07/13/2016 12:28:22: Starting minibatch loop.
07/13/2016 12:28:22:  Epoch[ 3 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15952392 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.0677s; samplesPerSecond = 18900.0
07/13/2016 12:28:22:  Epoch[ 3 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16969237 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0413s; samplesPerSecond = 30974.0
07/13/2016 12:28:22:  Epoch[ 3 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17790327 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0429s; samplesPerSecond = 29825.0
07/13/2016 12:28:22:  Epoch[ 3 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14991803 * 1280; EvalErrorPrediction = 0.06796875 * 1280; time = 0.0534s; samplesPerSecond = 23980.8
07/13/2016 12:28:23:  Epoch[ 3 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.19979520 * 1280; EvalErrorPrediction = 0.10468750 * 1280; time = 0.0606s; samplesPerSecond = 21121.4
07/13/2016 12:28:23:  Epoch[ 3 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15364428 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 0.0852s; samplesPerSecond = 15030.5
07/13/2016 12:28:23:  Epoch[ 3 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15614738 * 1280; EvalErrorPrediction = 0.06640625 * 1280; time = 0.0894s; samplesPerSecond = 14320.2
07/13/2016 12:28:23: Finished Epoch[ 3 of 50]: [Training] CrossEntropyWithSoftmax = 0.16649585 * 10000; EvalErrorPrediction = 0.07670000 * 10000; totalSamplesSeen = 30000; learningRatePerSample = 0.1; epochTime=0.47995s
07/13/2016 12:28:23: SGD: Saving checkpoint model '/tmp/cntk-test-20160713122635.123438/Speech_Simple@release_cpu/models/simple.dnn.3'

07/13/2016 12:28:23: Starting Epoch 4: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 3: frames [30000..40000] (first sequence at sample 30000), data subset 0 of 1

07/13/2016 12:28:23: Starting minibatch loop.
07/13/2016 12:28:23:  Epoch[ 4 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.19889363 * 1280; EvalErrorPrediction = 0.08750000 * 1280; time = 0.0704s; samplesPerSecond = 18177.2
07/13/2016 12:28:23:  Epoch[ 4 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17116731 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 0.0585s; samplesPerSecond = 21872.1
07/13/2016 12:28:23:  Epoch[ 4 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14583795 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0433s; samplesPerSecond = 29531.2
07/13/2016 12:28:23:  Epoch[ 4 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16399431 * 1280; EvalErrorPrediction = 0.06796875 * 1280; time = 0.0432s; samplesPerSecond = 29654.3
07/13/2016 12:28:23:  Epoch[ 4 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15278168 * 1280; EvalErrorPrediction = 0.06562500 * 1280; time = 0.0444s; samplesPerSecond = 28796.4
07/13/2016 12:28:23:  Epoch[ 4 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.18967047 * 1280; EvalErrorPrediction = 0.09140625 * 1280; time = 0.0477s; samplesPerSecond = 26829.3
07/13/2016 12:28:23:  Epoch[ 4 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16619186 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0550s; samplesPerSecond = 23282.9
07/13/2016 12:28:23: Finished Epoch[ 4 of 50]: [Training] CrossEntropyWithSoftmax = 0.16990123 * 10000; EvalErrorPrediction = 0.07600000 * 10000; totalSamplesSeen = 40000; learningRatePerSample = 0.1; epochTime=0.400206s
07/13/2016 12:28:23: SGD: Saving checkpoint model '/tmp/cntk-test-20160713122635.123438/Speech_Simple@release_cpu/models/simple.dnn.4'

07/13/2016 12:28:23: Starting Epoch 5: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 4: frames [40000..50000] (first sequence at sample 40000), data subset 0 of 1

07/13/2016 12:28:23: Starting minibatch loop.
07/13/2016 12:28:23:  Epoch[ 5 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.14866041 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0392s; samplesPerSecond = 32661.4
07/13/2016 12:28:23:  Epoch[ 5 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.19050208 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 0.0445s; samplesPerSecond = 28776.3
07/13/2016 12:28:23:  Epoch[ 5 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.19228487 * 1280; EvalErrorPrediction = 0.08437500 * 1280; time = 0.0350s; samplesPerSecond = 36604.9
07/13/2016 12:28:23:  Epoch[ 5 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16221976 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.1062s; samplesPerSecond = 12049.6
07/13/2016 12:28:23:  Epoch[ 5 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15045481 * 1280; EvalErrorPrediction = 0.06875000 * 1280; time = 0.0349s; samplesPerSecond = 36713.0
07/13/2016 12:28:23:  Epoch[ 5 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17695665 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 0.0499s; samplesPerSecond = 25644.6
07/13/2016 12:28:24:  Epoch[ 5 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.18600817 * 1280; EvalErrorPrediction = 0.08593750 * 1280; time = 0.0863s; samplesPerSecond = 14828.4
07/13/2016 12:28:24: Finished Epoch[ 5 of 50]: [Training] CrossEntropyWithSoftmax = 0.16876268 * 10000; EvalErrorPrediction = 0.07630000 * 10000; totalSamplesSeen = 50000; learningRatePerSample = 0.1; epochTime=0.447718s
07/13/2016 12:28:24: SGD: Saving checkpoint model '/tmp/cntk-test-20160713122635.123438/Speech_Simple@release_cpu/models/simple.dnn.5'

07/13/2016 12:28:24: Starting Epoch 6: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 5: frames [50000..60000] (first sequence at sample 50000), data subset 0 of 1

07/13/2016 12:28:24: Starting minibatch loop.
07/13/2016 12:28:24:  Epoch[ 6 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16541485 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0483s; samplesPerSecond = 26473.6
07/13/2016 12:28:24:  Epoch[ 6 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15799195 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 0.0465s; samplesPerSecond = 27520.4
07/13/2016 12:28:24:  Epoch[ 6 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15418167 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 0.0393s; samplesPerSecond = 32567.5
07/13/2016 12:28:24:  Epoch[ 6 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.17027073 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0484s; samplesPerSecond = 26463.2
07/13/2016 12:28:24:  Epoch[ 6 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16654892 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0444s; samplesPerSecond = 28848.3
07/13/2016 12:28:24:  Epoch[ 6 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16848326 * 1280; EvalErrorPrediction = 0.08671875 * 1280; time = 0.0849s; samplesPerSecond = 15068.9
07/13/2016 12:28:24:  Epoch[ 6 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15642786 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 0.0435s; samplesPerSecond = 29451.0
07/13/2016 12:28:24: Finished Epoch[ 6 of 50]: [Training] CrossEntropyWithSoftmax = 0.16224381 * 10000; EvalErrorPrediction = 0.07640000 * 10000; totalSamplesSeen = 60000; learningRatePerSample = 0.1; epochTime=0.565534s
07/13/2016 12:28:24: SGD: Saving checkpoint model '/tmp/cntk-test-20160713122635.123438/Speech_Simple@release_cpu/models/simple.dnn.6'

07/13/2016 12:28:24: Starting Epoch 7: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 6: frames [60000..70000] (first sequence at sample 60000), data subset 0 of 1

07/13/2016 12:28:24: Starting minibatch loop.
07/13/2016 12:28:24:  Epoch[ 7 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17808088 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.2731s; samplesPerSecond = 4686.3
07/13/2016 12:28:25:  Epoch[ 7 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.19384567 * 1280; EvalErrorPrediction = 0.08671875 * 1280; time = 0.2454s; samplesPerSecond = 5215.7
07/13/2016 12:28:25:  Epoch[ 7 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17011890 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0773s; samplesPerSecond = 16564.9
07/13/2016 12:28:25:  Epoch[ 7 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16028070 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0425s; samplesPerSecond = 30148.9
07/13/2016 12:28:25:  Epoch[ 7 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14625764 * 1280; EvalErrorPrediction = 0.06796875 * 1280; time = 0.0477s; samplesPerSecond = 26845.6
07/13/2016 12:28:25:  Epoch[ 7 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17853184 * 1280; EvalErrorPrediction = 0.08671875 * 1280; time = 0.0377s; samplesPerSecond = 33988.3
07/13/2016 12:28:25:  Epoch[ 7 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15227604 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0384s; samplesPerSecond = 33344.6
07/13/2016 12:28:25: Finished Epoch[ 7 of 50]: [Training] CrossEntropyWithSoftmax = 0.16922106 * 10000; EvalErrorPrediction = 0.07780000 * 10000; totalSamplesSeen = 70000; learningRatePerSample = 0.1; epochTime=0.804476s
07/13/2016 12:28:25: SGD: Saving checkpoint model '/tmp/cntk-test-20160713122635.123438/Speech_Simple@release_cpu/models/simple.dnn.7'

07/13/2016 12:28:25: Starting Epoch 8: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 7: frames [70000..80000] (first sequence at sample 70000), data subset 0 of 1

07/13/2016 12:28:25: Starting minibatch loop.
07/13/2016 12:28:25:  Epoch[ 8 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.19132322 * 1280; EvalErrorPrediction = 0.08671875 * 1280; time = 0.0441s; samplesPerSecond = 29009.2
07/13/2016 12:28:25:  Epoch[ 8 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15938927 * 1280; EvalErrorPrediction = 0.06875000 * 1280; time = 0.0420s; samplesPerSecond = 30481.3
07/13/2016 12:28:25:  Epoch[ 8 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16188369 * 1280; EvalErrorPrediction = 0.06875000 * 1280; time = 0.0437s; samplesPerSecond = 29312.8
07/13/2016 12:28:25:  Epoch[ 8 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15345082 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0422s; samplesPerSecond = 30303.0
07/13/2016 12:28:25:  Epoch[ 8 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16822319 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0685s; samplesPerSecond = 18697.6
07/13/2016 12:28:25:  Epoch[ 8 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.18607426 * 1280; EvalErrorPrediction = 0.08750000 * 1280; time = 0.0399s; samplesPerSecond = 32073.8
07/13/2016 12:28:25:  Epoch[ 8 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14823380 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 0.0544s; samplesPerSecond = 23510.8
07/13/2016 12:28:25: Finished Epoch[ 8 of 50]: [Training] CrossEntropyWithSoftmax = 0.16762673 * 10000; EvalErrorPrediction = 0.07680000 * 10000; totalSamplesSeen = 80000; learningRatePerSample = 0.1; epochTime=0.451144s
07/13/2016 12:28:25: SGD: Saving checkpoint model '/tmp/cntk-test-20160713122635.123438/Speech_Simple@release_cpu/models/simple.dnn.8'

07/13/2016 12:28:25: Starting Epoch 9: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 8: frames [80000..90000] (first sequence at sample 80000), data subset 0 of 1

07/13/2016 12:28:25: Starting minibatch loop.
07/13/2016 12:28:25:  Epoch[ 9 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16914328 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0674s; samplesPerSecond = 18997.0
07/13/2016 12:28:26:  Epoch[ 9 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17302328 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0384s; samplesPerSecond = 33295.2
07/13/2016 12:28:26:  Epoch[ 9 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16006942 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0556s; samplesPerSecond = 23023.7
07/13/2016 12:28:26:  Epoch[ 9 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15442376 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 0.0386s; samplesPerSecond = 33166.6
07/13/2016 12:28:26:  Epoch[ 9 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.13864594 * 1280; EvalErrorPrediction = 0.05703125 * 1280; time = 0.0400s; samplesPerSecond = 31988.8
07/13/2016 12:28:26:  Epoch[ 9 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17193160 * 1280; EvalErrorPrediction = 0.08359375 * 1280; time = 0.0411s; samplesPerSecond = 31154.2
07/13/2016 12:28:26:  Epoch[ 9 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14883986 * 1280; EvalErrorPrediction = 0.06484375 * 1280; time = 0.0507s; samplesPerSecond = 25237.6
07/13/2016 12:28:26: Finished Epoch[ 9 of 50]: [Training] CrossEntropyWithSoftmax = 0.16019153 * 10000; EvalErrorPrediction = 0.07470000 * 10000; totalSamplesSeen = 90000; learningRatePerSample = 0.1; epochTime=0.376237s
07/13/2016 12:28:26: SGD: Saving checkpoint model '/tmp/cntk-test-20160713122635.123438/Speech_Simple@release_cpu/models/simple.dnn.9'

07/13/2016 12:28:26: Starting Epoch 10: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 9: frames [90000..100000] (first sequence at sample 90000), data subset 0 of 1

07/13/2016 12:28:26: Starting minibatch loop.
07/13/2016 12:28:26:  Epoch[10 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15938257 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 0.0562s; samplesPerSecond = 22770.5
07/13/2016 12:28:26:  Epoch[10 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16747583 * 1280; EvalErrorPrediction = 0.08593750 * 1280; time = 0.0460s; samplesPerSecond = 27837.6
07/13/2016 12:28:26:  Epoch[10 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14229605 * 1280; EvalErrorPrediction = 0.06484375 * 1280; time = 0.0426s; samplesPerSecond = 30070.9
07/13/2016 12:28:26:  Epoch[10 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.17674642 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0398s; samplesPerSecond = 32143.8
07/13/2016 12:28:26:  Epoch[10 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16552539 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0468s; samplesPerSecond = 27360.4
07/13/2016 12:28:26:  Epoch[10 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16121101 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 0.0386s; samplesPerSecond = 33154.6
07/13/2016 12:28:26:  Epoch[10 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14450760 * 1280; EvalErrorPrediction = 0.06718750 * 1280; time = 0.0491s; samplesPerSecond = 26053.3
07/13/2016 12:28:26: Finished Epoch[10 of 50]: [Training] CrossEntropyWithSoftmax = 0.15833496 * 10000; EvalErrorPrediction = 0.07500000 * 10000; totalSamplesSeen = 100000; learningRatePerSample = 0.1; epochTime=0.35328s
07/13/2016 12:28:26: SGD: Saving checkpoint model '/tmp/cntk-test-20160713122635.123438/Speech_Simple@release_cpu/models/simple.dnn.10'

07/13/2016 12:28:26: Starting Epoch 11: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 10: frames [100000..110000] (first sequence at sample 100000), data subset 0 of 1

07/13/2016 12:28:26: Starting minibatch loop.
07/13/2016 12:28:26:  Epoch[11 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15803064 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0335s; samplesPerSecond = 38174.8
07/13/2016 12:28:26:  Epoch[11 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15592762 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0465s; samplesPerSecond = 27554.1
07/13/2016 12:28:26:  Epoch[11 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15867376 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0402s; samplesPerSecond = 31868.5
07/13/2016 12:28:26:  Epoch[11 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.18355393 * 1280; EvalErrorPrediction = 0.09140625 * 1280; time = 0.0710s; samplesPerSecond = 18035.0
07/13/2016 12:28:26:  Epoch[11 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16960340 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0664s; samplesPerSecond = 19277.1
07/13/2016 12:28:26:  Epoch[11 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16026030 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0389s; samplesPerSecond = 32905.7
07/13/2016 12:28:26:  Epoch[11 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15526876 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0511s; samplesPerSecond = 25047.9
07/13/2016 12:28:27: Finished Epoch[11 of 50]: [Training] CrossEntropyWithSoftmax = 0.16184227 * 10000; EvalErrorPrediction = 0.07630000 * 10000; totalSamplesSeen = 110000; learningRatePerSample = 0.1; epochTime=0.387039s
07/13/2016 12:28:27: SGD: Saving checkpoint model '/tmp/cntk-test-20160713122635.123438/Speech_Simple@release_cpu/models/simple.dnn.11'

07/13/2016 12:28:27: Starting Epoch 12: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 11: frames [110000..120000] (first sequence at sample 110000), data subset 0 of 1

07/13/2016 12:28:27: Starting minibatch loop.
07/13/2016 12:28:27:  Epoch[12 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.14852281 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.1756s; samplesPerSecond = 7289.5
07/13/2016 12:28:27:  Epoch[12 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16825688 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.1502s; samplesPerSecond = 8523.6
07/13/2016 12:28:27:  Epoch[12 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17481744 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0474s; samplesPerSecond = 26984.9
07/13/2016 12:28:27:  Epoch[12 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16886683 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0350s; samplesPerSecond = 36541.2
07/13/2016 12:28:27:  Epoch[12 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.19157701 * 1280; EvalErrorPrediction = 0.08828125 * 1280; time = 0.0385s; samplesPerSecond = 33227.8
07/13/2016 12:28:27:  Epoch[12 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14872885 * 1280; EvalErrorPrediction = 0.06718750 * 1280; time = 0.0735s; samplesPerSecond = 17419.9
07/13/2016 12:28:27:  Epoch[12 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16920624 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0918s; samplesPerSecond = 13942.9
07/13/2016 12:28:27: Finished Epoch[12 of 50]: [Training] CrossEntropyWithSoftmax = 0.16686217 * 10000; EvalErrorPrediction = 0.07710000 * 10000; totalSamplesSeen = 120000; learningRatePerSample = 0.1; epochTime=0.670552s
07/13/2016 12:28:27: SGD: Saving checkpoint model '/tmp/cntk-test-20160713122635.123438/Speech_Simple@release_cpu/models/simple.dnn.12'

07/13/2016 12:28:27: Starting Epoch 13: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 12: frames [120000..130000] (first sequence at sample 120000), data subset 0 of 1

07/13/2016 12:28:27: Starting minibatch loop.
07/13/2016 12:28:27:  Epoch[13 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15746654 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0880s; samplesPerSecond = 14543.6
07/13/2016 12:28:27:  Epoch[13 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15095075 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0290s; samplesPerSecond = 44128.8
07/13/2016 12:28:27:  Epoch[13 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16232102 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0534s; samplesPerSecond = 23975.4
07/13/2016 12:28:27:  Epoch[13 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16141205 * 1280; EvalErrorPrediction = 0.06875000 * 1280; time = 0.0477s; samplesPerSecond = 26823.1
07/13/2016 12:28:27:  Epoch[13 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.18838768 * 1280; EvalErrorPrediction = 0.09218750 * 1280; time = 0.0440s; samplesPerSecond = 29122.7
07/13/2016 12:28:27:  Epoch[13 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16033878 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.0370s; samplesPerSecond = 34614.2
07/13/2016 12:28:28:  Epoch[13 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.18104076 * 1280; EvalErrorPrediction = 0.08828125 * 1280; time = 0.0425s; samplesPerSecond = 30094.3
07/13/2016 12:28:28: Finished Epoch[13 of 50]: [Training] CrossEntropyWithSoftmax = 0.16538600 * 10000; EvalErrorPrediction = 0.07720000 * 10000; totalSamplesSeen = 130000; learningRatePerSample = 0.1; epochTime=0.377058s
07/13/2016 12:28:28: SGD: Saving checkpoint model '/tmp/cntk-test-20160713122635.123438/Speech_Simple@release_cpu/models/simple.dnn.13'

07/13/2016 12:28:28: Starting Epoch 14: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 13: frames [130000..140000] (first sequence at sample 130000), data subset 0 of 1

07/13/2016 12:28:28: Starting minibatch loop.
07/13/2016 12:28:28:  Epoch[14 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16673622 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0413s; samplesPerSecond = 31007.0
07/13/2016 12:28:28:  Epoch[14 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16026027 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0410s; samplesPerSecond = 31205.1
07/13/2016 12:28:28:  Epoch[14 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16508815 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 0.0408s; samplesPerSecond = 31357.2
07/13/2016 12:28:28:  Epoch[14 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14741759 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0343s; samplesPerSecond = 37353.7
07/13/2016 12:28:28:  Epoch[14 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15339546 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0419s; samplesPerSecond = 30538.7
07/13/2016 12:28:28:  Epoch[14 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16566677 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0342s; samplesPerSecond = 37451.0
07/13/2016 12:28:28:  Epoch[14 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16757851 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 0.0476s; samplesPerSecond = 26877.8
07/13/2016 12:28:28: Finished Epoch[14 of 50]: [Training] CrossEntropyWithSoftmax = 0.16044894 * 10000; EvalErrorPrediction = 0.07510000 * 10000; totalSamplesSeen = 140000; learningRatePerSample = 0.1; epochTime=0.318109s
07/13/2016 12:28:28: SGD: Saving checkpoint model '/tmp/cntk-test-20160713122635.123438/Speech_Simple@release_cpu/models/simple.dnn.14'

07/13/2016 12:28:28: Starting Epoch 15: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 14: frames [140000..150000] (first sequence at sample 140000), data subset 0 of 1

07/13/2016 12:28:28: Starting minibatch loop.
07/13/2016 12:28:28:  Epoch[15 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17496848 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0454s; samplesPerSecond = 28200.0
07/13/2016 12:28:28:  Epoch[15 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17374127 * 1280; EvalErrorPrediction = 0.08359375 * 1280; time = 0.0456s; samplesPerSecond = 28066.5
07/13/2016 12:28:28:  Epoch[15 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16181233 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0429s; samplesPerSecond = 29827.8
07/13/2016 12:28:28:  Epoch[15 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.17213588 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0469s; samplesPerSecond = 27303.8
07/13/2016 12:28:28:  Epoch[15 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.17390571 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0424s; samplesPerSecond = 30203.6
07/13/2016 12:28:28:  Epoch[15 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17115316 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0432s; samplesPerSecond = 29605.6
07/13/2016 12:28:28:  Epoch[15 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17045021 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0452s; samplesPerSecond = 28333.6
07/13/2016 12:28:28: Finished Epoch[15 of 50]: [Training] CrossEntropyWithSoftmax = 0.17080642 * 10000; EvalErrorPrediction = 0.07850000 * 10000; totalSamplesSeen = 150000; learningRatePerSample = 0.1; epochTime=0.351028s
07/13/2016 12:28:28: SGD: Saving checkpoint model '/tmp/cntk-test-20160713122635.123438/Speech_Simple@release_cpu/models/simple.dnn.15'

07/13/2016 12:28:28: Starting Epoch 16: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 15: frames [150000..160000] (first sequence at sample 150000), data subset 0 of 1

07/13/2016 12:28:28: Starting minibatch loop.
07/13/2016 12:28:28:  Epoch[16 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.14492916 * 1280; EvalErrorPrediction = 0.06875000 * 1280; time = 0.0649s; samplesPerSecond = 19731.2
07/13/2016 12:28:28:  Epoch[16 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17128218 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0576s; samplesPerSecond = 22217.6
07/13/2016 12:28:28:  Epoch[16 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16674979 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0420s; samplesPerSecond = 30498.0
07/13/2016 12:28:28:  Epoch[16 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14410810 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0397s; samplesPerSecond = 32235.3
07/13/2016 12:28:28:  Epoch[16 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15073400 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0411s; samplesPerSecond = 31125.4
07/13/2016 12:28:29:  Epoch[16 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15495987 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0381s; samplesPerSecond = 33552.6
07/13/2016 12:28:29:  Epoch[16 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15633564 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.0422s; samplesPerSecond = 30336.8
07/13/2016 12:28:29: Finished Epoch[16 of 50]: [Training] CrossEntropyWithSoftmax = 0.15949218 * 10000; EvalErrorPrediction = 0.07560000 * 10000; totalSamplesSeen = 160000; learningRatePerSample = 0.1; epochTime=0.363785s
07/13/2016 12:28:29: SGD: Saving checkpoint model '/tmp/cntk-test-20160713122635.123438/Speech_Simple@release_cpu/models/simple.dnn.16'

07/13/2016 12:28:29: Starting Epoch 17: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 16: frames [160000..170000] (first sequence at sample 160000), data subset 0 of 1

07/13/2016 12:28:29: Starting minibatch loop.
07/13/2016 12:28:29:  Epoch[17 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17188196 * 1280; EvalErrorPrediction = 0.08359375 * 1280; time = 0.0406s; samplesPerSecond = 31505.4
07/13/2016 12:28:29:  Epoch[17 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16207507 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 0.0440s; samplesPerSecond = 29059.9
07/13/2016 12:28:29:  Epoch[17 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16776812 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 0.0399s; samplesPerSecond = 32051.3
07/13/2016 12:28:29:  Epoch[17 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15647526 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 0.0400s; samplesPerSecond = 32014.4
07/13/2016 12:28:29:  Epoch[17 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15843949 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0419s; samplesPerSecond = 30573.0
07/13/2016 12:28:29:  Epoch[17 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14911509 * 1280; EvalErrorPrediction = 0.06406250 * 1280; time = 0.0381s; samplesPerSecond = 33627.6
07/13/2016 12:28:29:  Epoch[17 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15323792 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0442s; samplesPerSecond = 28973.7
07/13/2016 12:28:29: Finished Epoch[17 of 50]: [Training] CrossEntropyWithSoftmax = 0.15964144 * 10000; EvalErrorPrediction = 0.07370000 * 10000; totalSamplesSeen = 170000; learningRatePerSample = 0.1; epochTime=0.328491s
07/13/2016 12:28:29: SGD: Saving checkpoint model '/tmp/cntk-test-20160713122635.123438/Speech_Simple@release_cpu/models/simple.dnn.17'

07/13/2016 12:28:29: Starting Epoch 18: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 17: frames [170000..180000] (first sequence at sample 170000), data subset 0 of 1

07/13/2016 12:28:29: Starting minibatch loop.
07/13/2016 12:28:29:  Epoch[18 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15964607 * 1280; EvalErrorPrediction = 0.06718750 * 1280; time = 0.0427s; samplesPerSecond = 29986.4
07/13/2016 12:28:29:  Epoch[18 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15260020 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 0.0379s; samplesPerSecond = 33800.7
07/13/2016 12:28:29:  Epoch[18 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17087312 * 1280; EvalErrorPrediction = 0.08359375 * 1280; time = 0.0421s; samplesPerSecond = 30408.9
07/13/2016 12:28:29:  Epoch[18 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15228090 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 0.0381s; samplesPerSecond = 33574.7
07/13/2016 12:28:29:  Epoch[18 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.18577013 * 1280; EvalErrorPrediction = 0.08437500 * 1280; time = 0.0520s; samplesPerSecond = 24628.2
07/13/2016 12:28:29:  Epoch[18 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16892061 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0380s; samplesPerSecond = 33701.1
07/13/2016 12:28:29:  Epoch[18 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15040522 * 1280; EvalErrorPrediction = 0.06875000 * 1280; time = 0.0439s; samplesPerSecond = 29181.1
07/13/2016 12:28:29: Finished Epoch[18 of 50]: [Training] CrossEntropyWithSoftmax = 0.16220587 * 10000; EvalErrorPrediction = 0.07510000 * 10000; totalSamplesSeen = 180000; learningRatePerSample = 0.1; epochTime=0.342408s
07/13/2016 12:28:29: SGD: Saving checkpoint model '/tmp/cntk-test-20160713122635.123438/Speech_Simple@release_cpu/models/simple.dnn.18'

07/13/2016 12:28:29: Starting Epoch 19: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 18: frames [180000..190000] (first sequence at sample 180000), data subset 0 of 1

07/13/2016 12:28:29: Starting minibatch loop.
07/13/2016 12:28:29:  Epoch[19 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.14636862 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0287s; samplesPerSecond = 44616.4
07/13/2016 12:28:29:  Epoch[19 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15948336 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0328s; samplesPerSecond = 39082.8
07/13/2016 12:28:29:  Epoch[19 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16777477 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0579s; samplesPerSecond = 22094.1
07/13/2016 12:28:29:  Epoch[19 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.17910833 * 1280; EvalErrorPrediction = 0.08671875 * 1280; time = 0.0390s; samplesPerSecond = 32834.0
07/13/2016 12:28:29:  Epoch[19 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.18129115 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0424s; samplesPerSecond = 30170.2
07/13/2016 12:28:30:  Epoch[19 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.19801235 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0546s; samplesPerSecond = 23423.5
07/13/2016 12:28:30:  Epoch[19 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15825043 * 1280; EvalErrorPrediction = 0.06875000 * 1280; time = 0.0439s; samplesPerSecond = 29155.8
07/13/2016 12:28:30: Finished Epoch[19 of 50]: [Training] CrossEntropyWithSoftmax = 0.16814883 * 10000; EvalErrorPrediction = 0.07810000 * 10000; totalSamplesSeen = 190000; learningRatePerSample = 0.1; epochTime=0.337315s
07/13/2016 12:28:30: SGD: Saving checkpoint model '/tmp/cntk-test-20160713122635.123438/Speech_Simple@release_cpu/models/simple.dnn.19'

07/13/2016 12:28:30: Starting Epoch 20: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 19: frames [190000..200000] (first sequence at sample 190000), data subset 0 of 1

07/13/2016 12:28:30: Starting minibatch loop.
07/13/2016 12:28:30:  Epoch[20 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16492792 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0352s; samplesPerSecond = 36379.1
07/13/2016 12:28:30:  Epoch[20 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.18700212 * 1280; EvalErrorPrediction = 0.09531250 * 1280; time = 0.0418s; samplesPerSecond = 30646.2
07/13/2016 12:28:30:  Epoch[20 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17428069 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0433s; samplesPerSecond = 29561.2
07/13/2016 12:28:30:  Epoch[20 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15516224 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 0.0448s; samplesPerSecond = 28570.8
07/13/2016 12:28:30:  Epoch[20 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16162639 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 0.0381s; samplesPerSecond = 33584.3
07/13/2016 12:28:30:  Epoch[20 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.18605671 * 1280; EvalErrorPrediction = 0.08750000 * 1280; time = 0.0422s; samplesPerSecond = 30304.5
07/13/2016 12:28:30:  Epoch[20 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16932993 * 1280; EvalErrorPrediction = 0.06484375 * 1280; time = 0.0987s; samplesPerSecond = 12971.9
07/13/2016 12:28:30: Finished Epoch[20 of 50]: [Training] CrossEntropyWithSoftmax = 0.16857257 * 10000; EvalErrorPrediction = 0.07850000 * 10000; totalSamplesSeen = 200000; learningRatePerSample = 0.1; epochTime=0.384401s
07/13/2016 12:28:30: SGD: Saving checkpoint model '/tmp/cntk-test-20160713122635.123438/Speech_Simple@release_cpu/models/simple.dnn.20'

07/13/2016 12:28:30: Starting Epoch 21: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 20: frames [200000..210000] (first sequence at sample 200000), data subset 0 of 1

07/13/2016 12:28:30: Starting minibatch loop.
07/13/2016 12:28:30:  Epoch[21 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16475260 * 1280; EvalErrorPrediction = 0.08359375 * 1280; time = 0.0385s; samplesPerSecond = 33210.5
07/13/2016 12:28:30:  Epoch[21 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15382960 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.0475s; samplesPerSecond = 26944.0
07/13/2016 12:28:30:  Epoch[21 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15873981 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0486s; samplesPerSecond = 26325.0
07/13/2016 12:28:30:  Epoch[21 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16323705 * 1280; EvalErrorPrediction = 0.06640625 * 1280; time = 0.0460s; samplesPerSecond = 27852.1
07/13/2016 12:28:30:  Epoch[21 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.17472167 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0399s; samplesPerSecond = 32052.1
07/13/2016 12:28:30:  Epoch[21 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15822458 * 1280; EvalErrorPrediction = 0.06250000 * 1280; time = 0.0658s; samplesPerSecond = 19446.7
07/13/2016 12:28:30:  Epoch[21 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.18187141 * 1280; EvalErrorPrediction = 0.08750000 * 1280; time = 0.0866s; samplesPerSecond = 14776.0
07/13/2016 12:28:30: Finished Epoch[21 of 50]: [Training] CrossEntropyWithSoftmax = 0.16527875 * 10000; EvalErrorPrediction = 0.07540000 * 10000; totalSamplesSeen = 210000; learningRatePerSample = 0.1; epochTime=0.411032s
07/13/2016 12:28:30: SGD: Saving checkpoint model '/tmp/cntk-test-20160713122635.123438/Speech_Simple@release_cpu/models/simple.dnn.21'

07/13/2016 12:28:30: Starting Epoch 22: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 21: frames [210000..220000] (first sequence at sample 210000), data subset 0 of 1

07/13/2016 12:28:30: Starting minibatch loop.
07/13/2016 12:28:30:  Epoch[22 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.20337038 * 1280; EvalErrorPrediction = 0.09765625 * 1280; time = 0.0388s; samplesPerSecond = 33014.4
07/13/2016 12:28:31:  Epoch[22 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17333016 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0426s; samplesPerSecond = 30046.9
07/13/2016 12:28:31:  Epoch[22 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16090860 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0421s; samplesPerSecond = 30422.6
07/13/2016 12:28:31:  Epoch[22 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15491724 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0463s; samplesPerSecond = 27619.5
07/13/2016 12:28:31:  Epoch[22 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16119027 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 0.0431s; samplesPerSecond = 29699.1
07/13/2016 12:28:31:  Epoch[22 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16201906 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0391s; samplesPerSecond = 32752.5
07/13/2016 12:28:31:  Epoch[22 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17937288 * 1280; EvalErrorPrediction = 0.08671875 * 1280; time = 0.0427s; samplesPerSecond = 29968.2
07/13/2016 12:28:31: Finished Epoch[22 of 50]: [Training] CrossEntropyWithSoftmax = 0.16656190 * 10000; EvalErrorPrediction = 0.07760000 * 10000; totalSamplesSeen = 220000; learningRatePerSample = 0.1; epochTime=0.33861s
07/13/2016 12:28:31: SGD: Saving checkpoint model '/tmp/cntk-test-20160713122635.123438/Speech_Simple@release_cpu/models/simple.dnn.22'

07/13/2016 12:28:31: Starting Epoch 23: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 22: frames [220000..230000] (first sequence at sample 220000), data subset 0 of 1

07/13/2016 12:28:31: Starting minibatch loop.
07/13/2016 12:28:31:  Epoch[23 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17149630 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 0.0516s; samplesPerSecond = 24823.5
07/13/2016 12:28:31:  Epoch[23 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17126255 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0945s; samplesPerSecond = 13539.0
07/13/2016 12:28:31:  Epoch[23 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15208163 * 1280; EvalErrorPrediction = 0.06875000 * 1280; time = 0.0464s; samplesPerSecond = 27608.8
07/13/2016 12:28:31:  Epoch[23 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15624132 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0435s; samplesPerSecond = 29405.7
07/13/2016 12:28:31:  Epoch[23 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16128097 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0426s; samplesPerSecond = 30067.4
07/13/2016 12:28:31:  Epoch[23 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.13963528 * 1280; EvalErrorPrediction = 0.06875000 * 1280; time = 0.0387s; samplesPerSecond = 33109.2
07/13/2016 12:28:31:  Epoch[23 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16915150 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0402s; samplesPerSecond = 31807.6
07/13/2016 12:28:31: Finished Epoch[23 of 50]: [Training] CrossEntropyWithSoftmax = 0.15939630 * 10000; EvalErrorPrediction = 0.07480000 * 10000; totalSamplesSeen = 230000; learningRatePerSample = 0.1; epochTime=0.400854s
07/13/2016 12:28:31: SGD: Saving checkpoint model '/tmp/cntk-test-20160713122635.123438/Speech_Simple@release_cpu/models/simple.dnn.23'

07/13/2016 12:28:31: Starting Epoch 24: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 23: frames [230000..240000] (first sequence at sample 230000), data subset 0 of 1

07/13/2016 12:28:31: Starting minibatch loop.
07/13/2016 12:28:31:  Epoch[24 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17135580 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0344s; samplesPerSecond = 37247.2
07/13/2016 12:28:31:  Epoch[24 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15298202 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 0.0443s; samplesPerSecond = 28923.9
07/13/2016 12:28:31:  Epoch[24 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16153097 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.1038s; samplesPerSecond = 12326.9
07/13/2016 12:28:31:  Epoch[24 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16532121 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0691s; samplesPerSecond = 18519.1
07/13/2016 12:28:31:  Epoch[24 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16722107 * 1280; EvalErrorPrediction = 0.06796875 * 1280; time = 0.0418s; samplesPerSecond = 30641.8
07/13/2016 12:28:31:  Epoch[24 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17550230 * 1280; EvalErrorPrediction = 0.08671875 * 1280; time = 0.0425s; samplesPerSecond = 30112.0
07/13/2016 12:28:32:  Epoch[24 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16362991 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0429s; samplesPerSecond = 29803.5
07/13/2016 12:28:32: Finished Epoch[24 of 50]: [Training] CrossEntropyWithSoftmax = 0.16683051 * 10000; EvalErrorPrediction = 0.07720000 * 10000; totalSamplesSeen = 240000; learningRatePerSample = 0.1; epochTime=0.42086s
07/13/2016 12:28:32: SGD: Saving checkpoint model '/tmp/cntk-test-20160713122635.123438/Speech_Simple@release_cpu/models/simple.dnn.24'

07/13/2016 12:28:32: Starting Epoch 25: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 24: frames [240000..250000] (first sequence at sample 240000), data subset 0 of 1

07/13/2016 12:28:32: Starting minibatch loop.
07/13/2016 12:28:32:  Epoch[25 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.18008139 * 1280; EvalErrorPrediction = 0.08437500 * 1280; time = 0.0928s; samplesPerSecond = 13797.3
07/13/2016 12:28:32:  Epoch[25 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.18820145 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0374s; samplesPerSecond = 34235.6
07/13/2016 12:28:32:  Epoch[25 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16654949 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0915s; samplesPerSecond = 13986.2
07/13/2016 12:28:32:  Epoch[25 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.17137508 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0526s; samplesPerSecond = 24356.4
07/13/2016 12:28:32:  Epoch[25 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15490355 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0444s; samplesPerSecond = 28845.7
07/13/2016 12:28:32:  Epoch[25 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14499702 * 1280; EvalErrorPrediction = 0.06484375 * 1280; time = 0.0355s; samplesPerSecond = 36045.2
07/13/2016 12:28:32:  Epoch[25 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16295919 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0408s; samplesPerSecond = 31380.2
07/13/2016 12:28:32: Finished Epoch[25 of 50]: [Training] CrossEntropyWithSoftmax = 0.16751575 * 10000; EvalErrorPrediction = 0.07780000 * 10000; totalSamplesSeen = 250000; learningRatePerSample = 0.1; epochTime=0.468271s
07/13/2016 12:28:32: SGD: Saving checkpoint model '/tmp/cntk-test-20160713122635.123438/Speech_Simple@release_cpu/models/simple.dnn.25'

07/13/2016 12:28:32: Starting Epoch 26: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 25: frames [250000..260000] (first sequence at sample 250000), data subset 0 of 1

07/13/2016 12:28:32: Starting minibatch loop.
07/13/2016 12:28:32:  Epoch[26 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16835831 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0739s; samplesPerSecond = 17309.2
07/13/2016 12:28:32:  Epoch[26 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15105823 * 1280; EvalErrorPrediction = 0.06718750 * 1280; time = 0.0569s; samplesPerSecond = 22487.3
07/13/2016 12:28:32:  Epoch[26 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15089962 * 1280; EvalErrorPrediction = 0.06875000 * 1280; time = 0.0430s; samplesPerSecond = 29741.2
07/13/2016 12:28:32:  Epoch[26 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15928082 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0964s; samplesPerSecond = 13283.7
07/13/2016 12:28:32:  Epoch[26 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.17029176 * 1280; EvalErrorPrediction = 0.08593750 * 1280; time = 0.0517s; samplesPerSecond = 24761.6
07/13/2016 12:28:32:  Epoch[26 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14526391 * 1280; EvalErrorPrediction = 0.06484375 * 1280; time = 0.0863s; samplesPerSecond = 14831.1
07/13/2016 12:28:33:  Epoch[26 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17606630 * 1280; EvalErrorPrediction = 0.08593750 * 1280; time = 0.0553s; samplesPerSecond = 23153.6
07/13/2016 12:28:33: Finished Epoch[26 of 50]: [Training] CrossEntropyWithSoftmax = 0.15908248 * 10000; EvalErrorPrediction = 0.07440000 * 10000; totalSamplesSeen = 260000; learningRatePerSample = 0.1; epochTime=0.504439s
07/13/2016 12:28:33: SGD: Saving checkpoint model '/tmp/cntk-test-20160713122635.123438/Speech_Simple@release_cpu/models/simple.dnn.26'

07/13/2016 12:28:33: Starting Epoch 27: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 26: frames [260000..270000] (first sequence at sample 260000), data subset 0 of 1

07/13/2016 12:28:33: Starting minibatch loop.
07/13/2016 12:28:33:  Epoch[27 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15696132 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0698s; samplesPerSecond = 18341.3
07/13/2016 12:28:33:  Epoch[27 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16518061 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0481s; samplesPerSecond = 26600.2
07/13/2016 12:28:33:  Epoch[27 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15267425 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0467s; samplesPerSecond = 27410.2
07/13/2016 12:28:33:  Epoch[27 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16557865 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0630s; samplesPerSecond = 20313.3
07/13/2016 12:28:33:  Epoch[27 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15200953 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0994s; samplesPerSecond = 12882.3
07/13/2016 12:28:33:  Epoch[27 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15047340 * 1280; EvalErrorPrediction = 0.06640625 * 1280; time = 0.0372s; samplesPerSecond = 34399.4
07/13/2016 12:28:33:  Epoch[27 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.18083782 * 1280; EvalErrorPrediction = 0.08906250 * 1280; time = 0.0414s; samplesPerSecond = 30911.9
07/13/2016 12:28:33: Finished Epoch[27 of 50]: [Training] CrossEntropyWithSoftmax = 0.15806140 * 10000; EvalErrorPrediction = 0.07550000 * 10000; totalSamplesSeen = 270000; learningRatePerSample = 0.1; epochTime=0.447787s
07/13/2016 12:28:33: SGD: Saving checkpoint model '/tmp/cntk-test-20160713122635.123438/Speech_Simple@release_cpu/models/simple.dnn.27'

07/13/2016 12:28:33: Starting Epoch 28: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 27: frames [270000..280000] (first sequence at sample 270000), data subset 0 of 1

07/13/2016 12:28:33: Starting minibatch loop.
07/13/2016 12:28:33:  Epoch[28 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16852876 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0431s; samplesPerSecond = 29688.7
07/13/2016 12:28:33:  Epoch[28 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14662155 * 1280; EvalErrorPrediction = 0.06328125 * 1280; time = 0.0427s; samplesPerSecond = 29950.6
07/13/2016 12:28:33:  Epoch[28 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14875860 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 0.0439s; samplesPerSecond = 29183.1
07/13/2016 12:28:33:  Epoch[28 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16199880 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0578s; samplesPerSecond = 22148.4
07/13/2016 12:28:33:  Epoch[28 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.18050461 * 1280; EvalErrorPrediction = 0.08906250 * 1280; time = 0.0427s; samplesPerSecond = 29959.7
07/13/2016 12:28:33:  Epoch[28 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15580540 * 1280; EvalErrorPrediction = 0.06875000 * 1280; time = 0.0553s; samplesPerSecond = 23147.3
07/13/2016 12:28:33:  Epoch[28 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16533012 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0631s; samplesPerSecond = 20270.5
07/13/2016 12:28:33: Finished Epoch[28 of 50]: [Training] CrossEntropyWithSoftmax = 0.16206692 * 10000; EvalErrorPrediction = 0.07590000 * 10000; totalSamplesSeen = 280000; learningRatePerSample = 0.1; epochTime=0.394978s
07/13/2016 12:28:33: SGD: Saving checkpoint model '/tmp/cntk-test-20160713122635.123438/Speech_Simple@release_cpu/models/simple.dnn.28'

07/13/2016 12:28:33: Starting Epoch 29: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 28: frames [280000..290000] (first sequence at sample 280000), data subset 0 of 1

07/13/2016 12:28:33: Starting minibatch loop.
07/13/2016 12:28:33:  Epoch[29 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16519994 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0445s; samplesPerSecond = 28782.8
07/13/2016 12:28:33:  Epoch[29 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15904771 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0386s; samplesPerSecond = 33202.8
07/13/2016 12:28:34:  Epoch[29 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16316509 * 1280; EvalErrorPrediction = 0.06875000 * 1280; time = 0.0426s; samplesPerSecond = 30023.0
07/13/2016 12:28:34:  Epoch[29 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15609016 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0410s; samplesPerSecond = 31199.0
07/13/2016 12:28:34:  Epoch[29 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14817915 * 1280; EvalErrorPrediction = 0.06796875 * 1280; time = 0.0405s; samplesPerSecond = 31595.6
07/13/2016 12:28:34:  Epoch[29 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15711107 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0395s; samplesPerSecond = 32378.8
07/13/2016 12:28:34:  Epoch[29 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15871382 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0427s; samplesPerSecond = 29980.8
07/13/2016 12:28:34: Finished Epoch[29 of 50]: [Training] CrossEntropyWithSoftmax = 0.15744955 * 10000; EvalErrorPrediction = 0.07340000 * 10000; totalSamplesSeen = 290000; learningRatePerSample = 0.1; epochTime=0.338222s
07/13/2016 12:28:34: SGD: Saving checkpoint model '/tmp/cntk-test-20160713122635.123438/Speech_Simple@release_cpu/models/simple.dnn.29'

07/13/2016 12:28:34: Starting Epoch 30: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 29: frames [290000..300000] (first sequence at sample 290000), data subset 0 of 1

07/13/2016 12:28:34: Starting minibatch loop.
07/13/2016 12:28:34:  Epoch[30 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.14856814 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0425s; samplesPerSecond = 30145.3
07/13/2016 12:28:34:  Epoch[30 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15614189 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0374s; samplesPerSecond = 34237.4
07/13/2016 12:28:34:  Epoch[30 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.18894193 * 1280; EvalErrorPrediction = 0.08593750 * 1280; time = 0.0494s; samplesPerSecond = 25917.2
07/13/2016 12:28:34:  Epoch[30 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14171619 * 1280; EvalErrorPrediction = 0.06484375 * 1280; time = 0.0425s; samplesPerSecond = 30105.6
07/13/2016 12:28:34:  Epoch[30 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14764414 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 0.0395s; samplesPerSecond = 32394.4
07/13/2016 12:28:34:  Epoch[30 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16566000 * 1280; EvalErrorPrediction = 0.08593750 * 1280; time = 0.0388s; samplesPerSecond = 32955.7
07/13/2016 12:28:34:  Epoch[30 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16000910 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0437s; samplesPerSecond = 29273.9
07/13/2016 12:28:34: Finished Epoch[30 of 50]: [Training] CrossEntropyWithSoftmax = 0.15872233 * 10000; EvalErrorPrediction = 0.07530000 * 10000; totalSamplesSeen = 300000; learningRatePerSample = 0.1; epochTime=0.329102s
07/13/2016 12:28:34: SGD: Saving checkpoint model '/tmp/cntk-test-20160713122635.123438/Speech_Simple@release_cpu/models/simple.dnn.30'

07/13/2016 12:28:34: Starting Epoch 31: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 30: frames [300000..310000] (first sequence at sample 300000), data subset 0 of 1

07/13/2016 12:28:34: Starting minibatch loop.
07/13/2016 12:28:34:  Epoch[31 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16231698 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0431s; samplesPerSecond = 29677.7
07/13/2016 12:28:34:  Epoch[31 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17015637 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0388s; samplesPerSecond = 33028.8
07/13/2016 12:28:34:  Epoch[31 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14309304 * 1280; EvalErrorPrediction = 0.06171875 * 1280; time = 0.0828s; samplesPerSecond = 15461.0
07/13/2016 12:28:34:  Epoch[31 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15054049 * 1280; EvalErrorPrediction = 0.06640625 * 1280; time = 0.0567s; samplesPerSecond = 22575.4
07/13/2016 12:28:34:  Epoch[31 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15275049 * 1280; EvalErrorPrediction = 0.06875000 * 1280; time = 0.0475s; samplesPerSecond = 26959.3
07/13/2016 12:28:34:  Epoch[31 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.13504786 * 1280; EvalErrorPrediction = 0.06562500 * 1280; time = 0.0510s; samplesPerSecond = 25103.9
07/13/2016 12:28:34:  Epoch[31 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17576618 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0380s; samplesPerSecond = 33663.8
07/13/2016 12:28:34: Finished Epoch[31 of 50]: [Training] CrossEntropyWithSoftmax = 0.15947744 * 10000; EvalErrorPrediction = 0.07340000 * 10000; totalSamplesSeen = 310000; learningRatePerSample = 0.1; epochTime=0.399441s
07/13/2016 12:28:34: SGD: Saving checkpoint model '/tmp/cntk-test-20160713122635.123438/Speech_Simple@release_cpu/models/simple.dnn.31'

07/13/2016 12:28:34: Starting Epoch 32: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 31: frames [310000..320000] (first sequence at sample 310000), data subset 0 of 1

07/13/2016 12:28:34: Starting minibatch loop.
07/13/2016 12:28:35:  Epoch[32 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16154064 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0577s; samplesPerSecond = 22184.9
07/13/2016 12:28:35:  Epoch[32 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16160506 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0502s; samplesPerSecond = 25503.1
07/13/2016 12:28:35:  Epoch[32 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.13378718 * 1280; EvalErrorPrediction = 0.06640625 * 1280; time = 0.0538s; samplesPerSecond = 23812.6
07/13/2016 12:28:35:  Epoch[32 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16373558 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0547s; samplesPerSecond = 23412.4
07/13/2016 12:28:35:  Epoch[32 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16839790 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0522s; samplesPerSecond = 24540.3
07/13/2016 12:28:35:  Epoch[32 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16848178 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0472s; samplesPerSecond = 27145.7
07/13/2016 12:28:35:  Epoch[32 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14901552 * 1280; EvalErrorPrediction = 0.06250000 * 1280; time = 0.0388s; samplesPerSecond = 32949.8
07/13/2016 12:28:35: Finished Epoch[32 of 50]: [Training] CrossEntropyWithSoftmax = 0.16197542 * 10000; EvalErrorPrediction = 0.07480000 * 10000; totalSamplesSeen = 320000; learningRatePerSample = 0.1; epochTime=0.393106s
07/13/2016 12:28:35: SGD: Saving checkpoint model '/tmp/cntk-test-20160713122635.123438/Speech_Simple@release_cpu/models/simple.dnn.32'

07/13/2016 12:28:35: Starting Epoch 33: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 32: frames [320000..330000] (first sequence at sample 320000), data subset 0 of 1

07/13/2016 12:28:35: Starting minibatch loop.
07/13/2016 12:28:35:  Epoch[33 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17129622 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0437s; samplesPerSecond = 29314.1
07/13/2016 12:28:35:  Epoch[33 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15054884 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0438s; samplesPerSecond = 29205.7
07/13/2016 12:28:35:  Epoch[33 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14387212 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 0.0721s; samplesPerSecond = 17745.2
07/13/2016 12:28:35:  Epoch[33 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16222110 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0373s; samplesPerSecond = 34285.1
07/13/2016 12:28:35:  Epoch[33 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16773157 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0426s; samplesPerSecond = 30066.7
07/13/2016 12:28:35:  Epoch[33 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15197811 * 1280; EvalErrorPrediction = 0.06875000 * 1280; time = 0.0660s; samplesPerSecond = 19403.3
07/13/2016 12:28:35:  Epoch[33 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17714443 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 0.0562s; samplesPerSecond = 22774.6
07/13/2016 12:28:35: Finished Epoch[33 of 50]: [Training] CrossEntropyWithSoftmax = 0.16108008 * 10000; EvalErrorPrediction = 0.07560000 * 10000; totalSamplesSeen = 330000; learningRatePerSample = 0.1; epochTime=0.414348s
07/13/2016 12:28:35: SGD: Saving checkpoint model '/tmp/cntk-test-20160713122635.123438/Speech_Simple@release_cpu/models/simple.dnn.33'

07/13/2016 12:28:35: Starting Epoch 34: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 33: frames [330000..340000] (first sequence at sample 330000), data subset 0 of 1

07/13/2016 12:28:35: Starting minibatch loop.
07/13/2016 12:28:35:  Epoch[34 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17145665 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0469s; samplesPerSecond = 27278.7
07/13/2016 12:28:35:  Epoch[34 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16205611 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0425s; samplesPerSecond = 30137.5
07/13/2016 12:28:35:  Epoch[34 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16336939 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0648s; samplesPerSecond = 19762.5
07/13/2016 12:28:35:  Epoch[34 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15191164 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.0481s; samplesPerSecond = 26586.9
07/13/2016 12:28:36:  Epoch[34 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14747019 * 1280; EvalErrorPrediction = 0.06562500 * 1280; time = 0.0426s; samplesPerSecond = 30046.2
07/13/2016 12:28:36:  Epoch[34 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15344009 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0426s; samplesPerSecond = 30044.1
07/13/2016 12:28:36:  Epoch[34 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15842562 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0440s; samplesPerSecond = 29109.4
07/13/2016 12:28:36: Finished Epoch[34 of 50]: [Training] CrossEntropyWithSoftmax = 0.15948165 * 10000; EvalErrorPrediction = 0.07500000 * 10000; totalSamplesSeen = 340000; learningRatePerSample = 0.1; epochTime=0.376963s
07/13/2016 12:28:36: SGD: Saving checkpoint model '/tmp/cntk-test-20160713122635.123438/Speech_Simple@release_cpu/models/simple.dnn.34'

07/13/2016 12:28:36: Starting Epoch 35: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 34: frames [340000..350000] (first sequence at sample 340000), data subset 0 of 1

07/13/2016 12:28:36: Starting minibatch loop.
07/13/2016 12:28:36:  Epoch[35 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16640428 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0428s; samplesPerSecond = 29918.4
07/13/2016 12:28:36:  Epoch[35 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15777577 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0429s; samplesPerSecond = 29838.2
07/13/2016 12:28:36:  Epoch[35 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16434128 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0662s; samplesPerSecond = 19339.1
07/13/2016 12:28:36:  Epoch[35 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15438242 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0518s; samplesPerSecond = 24728.6
07/13/2016 12:28:36:  Epoch[35 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14508672 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 0.0387s; samplesPerSecond = 33095.5
07/13/2016 12:28:36:  Epoch[35 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14978857 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0388s; samplesPerSecond = 33022.0
07/13/2016 12:28:36:  Epoch[35 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.18113050 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0710s; samplesPerSecond = 18031.0
07/13/2016 12:28:36: Finished Epoch[35 of 50]: [Training] CrossEntropyWithSoftmax = 0.15992622 * 10000; EvalErrorPrediction = 0.07590000 * 10000; totalSamplesSeen = 350000; learningRatePerSample = 0.1; epochTime=0.392257s
07/13/2016 12:28:36: SGD: Saving checkpoint model '/tmp/cntk-test-20160713122635.123438/Speech_Simple@release_cpu/models/simple.dnn.35'

07/13/2016 12:28:36: Starting Epoch 36: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 35: frames [350000..360000] (first sequence at sample 350000), data subset 0 of 1

07/13/2016 12:28:36: Starting minibatch loop.
07/13/2016 12:28:36:  Epoch[36 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17041572 * 1280; EvalErrorPrediction = 0.08437500 * 1280; time = 0.0445s; samplesPerSecond = 28777.6
07/13/2016 12:28:36:  Epoch[36 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15814389 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0431s; samplesPerSecond = 29690.8
07/13/2016 12:28:36:  Epoch[36 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16349227 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 0.0426s; samplesPerSecond = 30050.5
07/13/2016 12:28:36:  Epoch[36 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16010098 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0399s; samplesPerSecond = 32101.1
07/13/2016 12:28:36:  Epoch[36 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15182309 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 0.0578s; samplesPerSecond = 22153.8
07/13/2016 12:28:36:  Epoch[36 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15396490 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0514s; samplesPerSecond = 24914.4
07/13/2016 12:28:36:  Epoch[36 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.18009357 * 1280; EvalErrorPrediction = 0.08593750 * 1280; time = 0.0577s; samplesPerSecond = 22178.7
07/13/2016 12:28:36: Finished Epoch[36 of 50]: [Training] CrossEntropyWithSoftmax = 0.16226083 * 10000; EvalErrorPrediction = 0.07700000 * 10000; totalSamplesSeen = 360000; learningRatePerSample = 0.1; epochTime=0.440456s
07/13/2016 12:28:36: SGD: Saving checkpoint model '/tmp/cntk-test-20160713122635.123438/Speech_Simple@release_cpu/models/simple.dnn.36'

07/13/2016 12:28:36: Starting Epoch 37: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 36: frames [360000..370000] (first sequence at sample 360000), data subset 0 of 1

07/13/2016 12:28:36: Starting minibatch loop.
07/13/2016 12:28:37:  Epoch[37 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15044581 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0378s; samplesPerSecond = 33845.4
07/13/2016 12:28:37:  Epoch[37 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15727519 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0404s; samplesPerSecond = 31678.5
07/13/2016 12:28:37:  Epoch[37 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17658706 * 1280; EvalErrorPrediction = 0.08750000 * 1280; time = 0.0512s; samplesPerSecond = 24977.1
07/13/2016 12:28:37:  Epoch[37 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15197978 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0376s; samplesPerSecond = 34038.9
07/13/2016 12:28:37:  Epoch[37 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15390072 * 1280; EvalErrorPrediction = 0.06718750 * 1280; time = 0.0527s; samplesPerSecond = 24271.4
07/13/2016 12:28:37:  Epoch[37 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14358773 * 1280; EvalErrorPrediction = 0.06718750 * 1280; time = 0.0480s; samplesPerSecond = 26652.2
07/13/2016 12:28:37:  Epoch[37 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16217842 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0580s; samplesPerSecond = 22081.1
07/13/2016 12:28:37: Finished Epoch[37 of 50]: [Training] CrossEntropyWithSoftmax = 0.15740476 * 10000; EvalErrorPrediction = 0.07510000 * 10000; totalSamplesSeen = 370000; learningRatePerSample = 0.1; epochTime=0.38183s
07/13/2016 12:28:37: SGD: Saving checkpoint model '/tmp/cntk-test-20160713122635.123438/Speech_Simple@release_cpu/models/simple.dnn.37'

07/13/2016 12:28:37: Starting Epoch 38: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 37: frames [370000..380000] (first sequence at sample 370000), data subset 0 of 1

07/13/2016 12:28:37: Starting minibatch loop.
07/13/2016 12:28:37:  Epoch[38 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16619613 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 0.0383s; samplesPerSecond = 33384.6
07/13/2016 12:28:37:  Epoch[38 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15460262 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 0.0435s; samplesPerSecond = 29453.7
07/13/2016 12:28:37:  Epoch[38 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15720551 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0502s; samplesPerSecond = 25506.1
07/13/2016 12:28:37:  Epoch[38 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.17886009 * 1280; EvalErrorPrediction = 0.08437500 * 1280; time = 0.0961s; samplesPerSecond = 13319.2
07/13/2016 12:28:37:  Epoch[38 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16477385 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0421s; samplesPerSecond = 30403.1
07/13/2016 12:28:37:  Epoch[38 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16247454 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0382s; samplesPerSecond = 33504.3
07/13/2016 12:28:37:  Epoch[38 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14554272 * 1280; EvalErrorPrediction = 0.06875000 * 1280; time = 0.0465s; samplesPerSecond = 27509.7
07/13/2016 12:28:37: Finished Epoch[38 of 50]: [Training] CrossEntropyWithSoftmax = 0.16285479 * 10000; EvalErrorPrediction = 0.07760000 * 10000; totalSamplesSeen = 380000; learningRatePerSample = 0.1; epochTime=0.427915s
07/13/2016 12:28:37: SGD: Saving checkpoint model '/tmp/cntk-test-20160713122635.123438/Speech_Simple@release_cpu/models/simple.dnn.38'

07/13/2016 12:28:37: Starting Epoch 39: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 38: frames [380000..390000] (first sequence at sample 380000), data subset 0 of 1

07/13/2016 12:28:37: Starting minibatch loop.
07/13/2016 12:28:37:  Epoch[39 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15448341 * 1280; EvalErrorPrediction = 0.06484375 * 1280; time = 0.0847s; samplesPerSecond = 15104.0
07/13/2016 12:28:37:  Epoch[39 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17907648 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0692s; samplesPerSecond = 18489.9
07/13/2016 12:28:38:  Epoch[39 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16982002 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 0.0404s; samplesPerSecond = 31709.1
07/13/2016 12:28:38:  Epoch[39 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16798797 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0426s; samplesPerSecond = 30056.8
07/13/2016 12:28:38:  Epoch[39 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14459414 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0403s; samplesPerSecond = 31792.6
07/13/2016 12:28:38:  Epoch[39 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.13847246 * 1280; EvalErrorPrediction = 0.06171875 * 1280; time = 0.0429s; samplesPerSecond = 29863.3
07/13/2016 12:28:38:  Epoch[39 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15802555 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.0422s; samplesPerSecond = 30321.7
07/13/2016 12:28:38: Finished Epoch[39 of 50]: [Training] CrossEntropyWithSoftmax = 0.16279224 * 10000; EvalErrorPrediction = 0.07570000 * 10000; totalSamplesSeen = 390000; learningRatePerSample = 0.1; epochTime=0.402188s
07/13/2016 12:28:38: SGD: Saving checkpoint model '/tmp/cntk-test-20160713122635.123438/Speech_Simple@release_cpu/models/simple.dnn.39'

07/13/2016 12:28:38: Starting Epoch 40: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 39: frames [390000..400000] (first sequence at sample 390000), data subset 0 of 1

07/13/2016 12:28:38: Starting minibatch loop.
07/13/2016 12:28:38:  Epoch[40 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16840934 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0647s; samplesPerSecond = 19790.0
07/13/2016 12:28:38:  Epoch[40 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15842315 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0411s; samplesPerSecond = 31143.6
07/13/2016 12:28:38:  Epoch[40 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15689163 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0439s; samplesPerSecond = 29153.2
07/13/2016 12:28:38:  Epoch[40 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15319600 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0576s; samplesPerSecond = 22235.3
07/13/2016 12:28:38:  Epoch[40 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15504360 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0425s; samplesPerSecond = 30139.6
07/13/2016 12:28:38:  Epoch[40 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16077409 * 1280; EvalErrorPrediction = 0.06875000 * 1280; time = 0.0460s; samplesPerSecond = 27840.0
07/13/2016 12:28:38:  Epoch[40 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.18390646 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 0.0398s; samplesPerSecond = 32140.6
07/13/2016 12:28:38: Finished Epoch[40 of 50]: [Training] CrossEntropyWithSoftmax = 0.16319042 * 10000; EvalErrorPrediction = 0.07580000 * 10000; totalSamplesSeen = 400000; learningRatePerSample = 0.1; epochTime=0.373785s
07/13/2016 12:28:38: SGD: Saving checkpoint model '/tmp/cntk-test-20160713122635.123438/Speech_Simple@release_cpu/models/simple.dnn.40'

07/13/2016 12:28:38: Starting Epoch 41: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 40: frames [400000..410000] (first sequence at sample 400000), data subset 0 of 1

07/13/2016 12:28:38: Starting minibatch loop.
07/13/2016 12:28:38:  Epoch[41 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17165155 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0391s; samplesPerSecond = 32729.0
07/13/2016 12:28:38:  Epoch[41 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15057638 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0425s; samplesPerSecond = 30135.4
07/13/2016 12:28:38:  Epoch[41 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16082604 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0361s; samplesPerSecond = 35469.8
07/13/2016 12:28:38:  Epoch[41 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15875053 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0440s; samplesPerSecond = 29097.5
07/13/2016 12:28:38:  Epoch[41 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15556507 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0527s; samplesPerSecond = 24275.1
07/13/2016 12:28:38:  Epoch[41 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14324150 * 1280; EvalErrorPrediction = 0.05859375 * 1280; time = 0.0384s; samplesPerSecond = 33327.3
07/13/2016 12:28:38:  Epoch[41 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15218315 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.0396s; samplesPerSecond = 32337.1
07/13/2016 12:28:38: Finished Epoch[41 of 50]: [Training] CrossEntropyWithSoftmax = 0.15675808 * 10000; EvalErrorPrediction = 0.07280000 * 10000; totalSamplesSeen = 410000; learningRatePerSample = 0.1; epochTime=0.333735s
07/13/2016 12:28:38: SGD: Saving checkpoint model '/tmp/cntk-test-20160713122635.123438/Speech_Simple@release_cpu/models/simple.dnn.41'

07/13/2016 12:28:38: Starting Epoch 42: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 41: frames [410000..420000] (first sequence at sample 410000), data subset 0 of 1

07/13/2016 12:28:38: Starting minibatch loop.
07/13/2016 12:28:38:  Epoch[42 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17523915 * 1280; EvalErrorPrediction = 0.08906250 * 1280; time = 0.0424s; samplesPerSecond = 30188.7
07/13/2016 12:28:39:  Epoch[42 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15212477 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 0.0434s; samplesPerSecond = 29522.3
07/13/2016 12:28:39:  Epoch[42 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15521283 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 0.0326s; samplesPerSecond = 39318.1
07/13/2016 12:28:39:  Epoch[42 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15564127 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0431s; samplesPerSecond = 29687.4
07/13/2016 12:28:39:  Epoch[42 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16578217 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0485s; samplesPerSecond = 26370.5
07/13/2016 12:28:39:  Epoch[42 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14213266 * 1280; EvalErrorPrediction = 0.06718750 * 1280; time = 0.0405s; samplesPerSecond = 31604.2
07/13/2016 12:28:39:  Epoch[42 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15324860 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 0.0719s; samplesPerSecond = 17808.9
07/13/2016 12:28:39: Finished Epoch[42 of 50]: [Training] CrossEntropyWithSoftmax = 0.15690872 * 10000; EvalErrorPrediction = 0.07570000 * 10000; totalSamplesSeen = 420000; learningRatePerSample = 0.1; epochTime=0.361071s
07/13/2016 12:28:39: SGD: Saving checkpoint model '/tmp/cntk-test-20160713122635.123438/Speech_Simple@release_cpu/models/simple.dnn.42'

07/13/2016 12:28:39: Starting Epoch 43: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 42: frames [420000..430000] (first sequence at sample 420000), data subset 0 of 1

07/13/2016 12:28:39: Starting minibatch loop.
07/13/2016 12:28:39:  Epoch[43 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15386535 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0430s; samplesPerSecond = 29799.3
07/13/2016 12:28:39:  Epoch[43 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15090064 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0462s; samplesPerSecond = 27713.4
07/13/2016 12:28:39:  Epoch[43 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.13803682 * 1280; EvalErrorPrediction = 0.06171875 * 1280; time = 0.0408s; samplesPerSecond = 31357.9
07/13/2016 12:28:39:  Epoch[43 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15230093 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0471s; samplesPerSecond = 27178.0
07/13/2016 12:28:39:  Epoch[43 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14417667 * 1280; EvalErrorPrediction = 0.06640625 * 1280; time = 0.0479s; samplesPerSecond = 26738.5
07/13/2016 12:28:39:  Epoch[43 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17858133 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0481s; samplesPerSecond = 26587.5
07/13/2016 12:28:39:  Epoch[43 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17021179 * 1280; EvalErrorPrediction = 0.08437500 * 1280; time = 0.0468s; samplesPerSecond = 27354.5
07/13/2016 12:28:39: Finished Epoch[43 of 50]: [Training] CrossEntropyWithSoftmax = 0.15581418 * 10000; EvalErrorPrediction = 0.07420000 * 10000; totalSamplesSeen = 430000; learningRatePerSample = 0.1; epochTime=0.356736s
07/13/2016 12:28:39: SGD: Saving checkpoint model '/tmp/cntk-test-20160713122635.123438/Speech_Simple@release_cpu/models/simple.dnn.43'

07/13/2016 12:28:39: Starting Epoch 44: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 43: frames [430000..440000] (first sequence at sample 430000), data subset 0 of 1

07/13/2016 12:28:39: Starting minibatch loop.
07/13/2016 12:28:39:  Epoch[44 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16945850 * 1280; EvalErrorPrediction = 0.08906250 * 1280; time = 0.0390s; samplesPerSecond = 32826.4
07/13/2016 12:28:39:  Epoch[44 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.13544406 * 1280; EvalErrorPrediction = 0.06093750 * 1280; time = 0.0425s; samplesPerSecond = 30112.0
07/13/2016 12:28:39:  Epoch[44 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16303706 * 1280; EvalErrorPrediction = 0.08359375 * 1280; time = 0.0393s; samplesPerSecond = 32546.0
07/13/2016 12:28:39:  Epoch[44 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.19170256 * 1280; EvalErrorPrediction = 0.08437500 * 1280; time = 0.0547s; samplesPerSecond = 23409.4
07/13/2016 12:28:39:  Epoch[44 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.17427287 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0595s; samplesPerSecond = 21526.4
07/13/2016 12:28:39:  Epoch[44 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.21128740 * 1280; EvalErrorPrediction = 0.09296875 * 1280; time = 0.0428s; samplesPerSecond = 29924.0
07/13/2016 12:28:39:  Epoch[44 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.18788481 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0389s; samplesPerSecond = 32943.0
07/13/2016 12:28:39: Finished Epoch[44 of 50]: [Training] CrossEntropyWithSoftmax = 0.17764906 * 10000; EvalErrorPrediction = 0.08200000 * 10000; totalSamplesSeen = 440000; learningRatePerSample = 0.1; epochTime=0.356598s
07/13/2016 12:28:39: SGD: Saving checkpoint model '/tmp/cntk-test-20160713122635.123438/Speech_Simple@release_cpu/models/simple.dnn.44'

07/13/2016 12:28:39: Starting Epoch 45: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 44: frames [440000..450000] (first sequence at sample 440000), data subset 0 of 1

07/13/2016 12:28:39: Starting minibatch loop.
07/13/2016 12:28:40:  Epoch[45 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.19548545 * 1280; EvalErrorPrediction = 0.08671875 * 1280; time = 0.0433s; samplesPerSecond = 29592.6
07/13/2016 12:28:40:  Epoch[45 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15311916 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.0865s; samplesPerSecond = 14795.5
07/13/2016 12:28:40:  Epoch[45 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15930483 * 1280; EvalErrorPrediction = 0.06875000 * 1280; time = 0.0438s; samplesPerSecond = 29237.1
07/13/2016 12:28:40:  Epoch[45 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.17239943 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0435s; samplesPerSecond = 29417.8
07/13/2016 12:28:40:  Epoch[45 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.12789493 * 1280; EvalErrorPrediction = 0.05703125 * 1280; time = 0.0361s; samplesPerSecond = 35453.1
07/13/2016 12:28:40:  Epoch[45 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.18878489 * 1280; EvalErrorPrediction = 0.09453125 * 1280; time = 0.0425s; samplesPerSecond = 30100.6
07/13/2016 12:28:40:  Epoch[45 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.18304195 * 1280; EvalErrorPrediction = 0.08750000 * 1280; time = 0.0445s; samplesPerSecond = 28773.1
07/13/2016 12:28:40: Finished Epoch[45 of 50]: [Training] CrossEntropyWithSoftmax = 0.16716315 * 10000; EvalErrorPrediction = 0.07740000 * 10000; totalSamplesSeen = 450000; learningRatePerSample = 0.1; epochTime=0.377801s
07/13/2016 12:28:40: SGD: Saving checkpoint model '/tmp/cntk-test-20160713122635.123438/Speech_Simple@release_cpu/models/simple.dnn.45'

07/13/2016 12:28:40: Starting Epoch 46: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 45: frames [450000..460000] (first sequence at sample 450000), data subset 0 of 1

07/13/2016 12:28:40: Starting minibatch loop.
07/13/2016 12:28:40:  Epoch[46 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17278781 * 1280; EvalErrorPrediction = 0.08437500 * 1280; time = 0.0426s; samplesPerSecond = 30019.5
07/13/2016 12:28:40:  Epoch[46 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15223329 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0486s; samplesPerSecond = 26340.7
07/13/2016 12:28:40:  Epoch[46 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16223400 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0438s; samplesPerSecond = 29253.8
07/13/2016 12:28:40:  Epoch[46 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.17466254 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 0.0433s; samplesPerSecond = 29542.1
07/13/2016 12:28:40:  Epoch[46 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.19236188 * 1280; EvalErrorPrediction = 0.09062500 * 1280; time = 0.0428s; samplesPerSecond = 29921.9
07/13/2016 12:28:40:  Epoch[46 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17003622 * 1280; EvalErrorPrediction = 0.08437500 * 1280; time = 0.0440s; samplesPerSecond = 29098.8
07/13/2016 12:28:40:  Epoch[46 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15896044 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0433s; samplesPerSecond = 29540.7
07/13/2016 12:28:40: Finished Epoch[46 of 50]: [Training] CrossEntropyWithSoftmax = 0.16901636 * 10000; EvalErrorPrediction = 0.08130000 * 10000; totalSamplesSeen = 460000; learningRatePerSample = 0.1; epochTime=0.344614s
07/13/2016 12:28:40: SGD: Saving checkpoint model '/tmp/cntk-test-20160713122635.123438/Speech_Simple@release_cpu/models/simple.dnn.46'

07/13/2016 12:28:40: Starting Epoch 47: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 46: frames [460000..470000] (first sequence at sample 460000), data subset 0 of 1

07/13/2016 12:28:40: Starting minibatch loop.
07/13/2016 12:28:40:  Epoch[47 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.19445362 * 1280; EvalErrorPrediction = 0.09062500 * 1280; time = 0.0623s; samplesPerSecond = 20543.8
07/13/2016 12:28:40:  Epoch[47 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17532339 * 1280; EvalErrorPrediction = 0.08671875 * 1280; time = 0.0372s; samplesPerSecond = 34368.9
07/13/2016 12:28:40:  Epoch[47 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15982275 * 1280; EvalErrorPrediction = 0.06718750 * 1280; time = 0.0490s; samplesPerSecond = 26103.3
07/13/2016 12:28:40:  Epoch[47 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.17681470 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 0.0907s; samplesPerSecond = 14118.8
07/13/2016 12:28:41:  Epoch[47 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.17092185 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0414s; samplesPerSecond = 30885.8
07/13/2016 12:28:41:  Epoch[47 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14961472 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0911s; samplesPerSecond = 14047.1
07/13/2016 12:28:41:  Epoch[47 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14567881 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 0.0928s; samplesPerSecond = 13786.7
07/13/2016 12:28:41: Finished Epoch[47 of 50]: [Training] CrossEntropyWithSoftmax = 0.16721079 * 10000; EvalErrorPrediction = 0.07690000 * 10000; totalSamplesSeen = 470000; learningRatePerSample = 0.1; epochTime=0.512708s
07/13/2016 12:28:41: SGD: Saving checkpoint model '/tmp/cntk-test-20160713122635.123438/Speech_Simple@release_cpu/models/simple.dnn.47'

07/13/2016 12:28:41: Starting Epoch 48: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 47: frames [470000..480000] (first sequence at sample 470000), data subset 0 of 1

07/13/2016 12:28:41: Starting minibatch loop.
07/13/2016 12:28:41:  Epoch[48 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.18766408 * 1280; EvalErrorPrediction = 0.08828125 * 1280; time = 0.0707s; samplesPerSecond = 18113.9
07/13/2016 12:28:41:  Epoch[48 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16356268 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 0.0377s; samplesPerSecond = 33946.9
07/13/2016 12:28:41:  Epoch[48 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16448779 * 1280; EvalErrorPrediction = 0.08593750 * 1280; time = 0.0459s; samplesPerSecond = 27901.9
07/13/2016 12:28:41:  Epoch[48 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15259590 * 1280; EvalErrorPrediction = 0.06328125 * 1280; time = 0.0442s; samplesPerSecond = 28967.8
07/13/2016 12:28:41:  Epoch[48 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.13187275 * 1280; EvalErrorPrediction = 0.05625000 * 1280; time = 0.0427s; samplesPerSecond = 29988.5
07/13/2016 12:28:41:  Epoch[48 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17249765 * 1280; EvalErrorPrediction = 0.08906250 * 1280; time = 0.0376s; samplesPerSecond = 34069.7
07/13/2016 12:28:41:  Epoch[48 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15977745 * 1280; EvalErrorPrediction = 0.08359375 * 1280; time = 0.0441s; samplesPerSecond = 29014.4
07/13/2016 12:28:41: Finished Epoch[48 of 50]: [Training] CrossEntropyWithSoftmax = 0.15953260 * 10000; EvalErrorPrediction = 0.07610000 * 10000; totalSamplesSeen = 480000; learningRatePerSample = 0.1; epochTime=0.363322s
07/13/2016 12:28:41: SGD: Saving checkpoint model '/tmp/cntk-test-20160713122635.123438/Speech_Simple@release_cpu/models/simple.dnn.48'

07/13/2016 12:28:41: Starting Epoch 49: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 48: frames [480000..490000] (first sequence at sample 480000), data subset 0 of 1

07/13/2016 12:28:41: Starting minibatch loop.
07/13/2016 12:28:41:  Epoch[49 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17180777 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 0.0495s; samplesPerSecond = 25834.1
07/13/2016 12:28:41:  Epoch[49 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16444919 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0418s; samplesPerSecond = 30638.1
07/13/2016 12:28:41:  Epoch[49 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17033641 * 1280; EvalErrorPrediction = 0.08828125 * 1280; time = 0.0650s; samplesPerSecond = 19701.7
07/13/2016 12:28:41:  Epoch[49 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15292215 * 1280; EvalErrorPrediction = 0.06484375 * 1280; time = 0.0588s; samplesPerSecond = 21771.7
07/13/2016 12:28:41:  Epoch[49 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.17955441 * 1280; EvalErrorPrediction = 0.08671875 * 1280; time = 0.0403s; samplesPerSecond = 31761.0
07/13/2016 12:28:41:  Epoch[49 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14437199 * 1280; EvalErrorPrediction = 0.06015625 * 1280; time = 0.0512s; samplesPerSecond = 24988.8
07/13/2016 12:28:41:  Epoch[49 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16817369 * 1280; EvalErrorPrediction = 0.08671875 * 1280; time = 0.0441s; samplesPerSecond = 29011.1
07/13/2016 12:28:41: Finished Epoch[49 of 50]: [Training] CrossEntropyWithSoftmax = 0.16283055 * 10000; EvalErrorPrediction = 0.07770000 * 10000; totalSamplesSeen = 490000; learningRatePerSample = 0.1; epochTime=0.388112s
07/13/2016 12:28:41: SGD: Saving checkpoint model '/tmp/cntk-test-20160713122635.123438/Speech_Simple@release_cpu/models/simple.dnn.49'

07/13/2016 12:28:41: Starting Epoch 50: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 49: frames [490000..500000] (first sequence at sample 490000), data subset 0 of 1

07/13/2016 12:28:41: Starting minibatch loop.
07/13/2016 12:28:42:  Epoch[50 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17482439 * 1280; EvalErrorPrediction = 0.08593750 * 1280; time = 0.0430s; samplesPerSecond = 29779.2
07/13/2016 12:28:42:  Epoch[50 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16347297 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0391s; samplesPerSecond = 32714.8
07/13/2016 12:28:42:  Epoch[50 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15064664 * 1280; EvalErrorPrediction = 0.06796875 * 1280; time = 0.0440s; samplesPerSecond = 29100.8
07/13/2016 12:28:42:  Epoch[50 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15297375 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0565s; samplesPerSecond = 22671.7
07/13/2016 12:28:42:  Epoch[50 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15320015 * 1280; EvalErrorPrediction = 0.06796875 * 1280; time = 0.0697s; samplesPerSecond = 18353.1
07/13/2016 12:28:42:  Epoch[50 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14706454 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 0.0975s; samplesPerSecond = 13134.9
07/13/2016 12:28:42:  Epoch[50 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14297619 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0358s; samplesPerSecond = 35726.2
07/13/2016 12:28:42: Finished Epoch[50 of 50]: [Training] CrossEntropyWithSoftmax = 0.15772699 * 10000; EvalErrorPrediction = 0.07490000 * 10000; totalSamplesSeen = 500000; learningRatePerSample = 0.1; epochTime=0.498677s
07/13/2016 12:28:42: SGD: Saving checkpoint model '/tmp/cntk-test-20160713122635.123438/Speech_Simple@release_cpu/models/simple.dnn'
07/13/2016 12:28:42: CNTKCommandTrainEnd: Simple_Demo

07/13/2016 12:28:42: Action "train" complete.


07/13/2016 12:28:42: ##############################################################################
07/13/2016 12:28:42: #                                                                            #
07/13/2016 12:28:42: # Action "write"                                                             #
07/13/2016 12:28:42: #                                                                            #
07/13/2016 12:28:42: ##############################################################################


Post-processing network...

7 roots:
	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
	EvalErrorPrediction = ErrorPrediction()
	InvStdOfFeatures = InvStdDev()
	MeanOfFeatures = Mean()
	PosteriorProb = Softmax()
	Prior = Mean()
	ScaledLogLikelihood = Minus()

Validating network. 25 nodes to process in pass 1.

Validating --> labels = InputValue() :  -> [2 x *1]
Validating --> W2 = LearnableParameter() :  -> [2 x 50]
Validating --> W1 = LearnableParameter() :  -> [50 x 50]
Validating --> W0 = LearnableParameter() :  -> [50 x 2]
Validating --> features = InputValue() :  -> [2 x *1]
Validating --> MeanOfFeatures = Mean (features) : [2 x *1] -> [2]
Validating --> InvStdOfFeatures = InvStdDev (features) : [2 x *1] -> [2]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [2 x *1], [2], [2] -> [2 x *1]
Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [50 x 2], [2 x *1] -> [50 x *1]
Validating --> B0 = LearnableParameter() :  -> [50 x 1]
Validating --> W0*features+B0 = Plus (W0*features, B0) : [50 x *1], [50 x 1] -> [50 x 1 x *1]
Validating --> H1 = Sigmoid (W0*features+B0) : [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> W1*H1 = Times (W1, H1) : [50 x 50], [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> B1 = LearnableParameter() :  -> [50 x 1]
Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [50 x 1 x *1], [50 x 1] -> [50 x 1 x *1]
Validating --> H2 = Sigmoid (W1*H1+B1) : [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> W2*H1 = Times (W2, H2) : [2 x 50], [50 x 1 x *1] -> [2 x 1 x *1]
Validating --> B2 = LearnableParameter() :  -> [2 x 1]
Validating --> HLast = Plus (W2*H1, B2) : [2 x 1 x *1], [2 x 1] -> [2 x 1 x *1]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [2 x *1], [2 x 1 x *1] -> [1]
Validating --> EvalErrorPrediction = ErrorPrediction (labels, HLast) : [2 x *1], [2 x 1 x *1] -> [1]
Validating --> PosteriorProb = Softmax (HLast) : [2 x 1 x *1] -> [2 x 1 x *1]
Validating --> Prior = Mean (labels) : [2 x *1] -> [2]
Validating --> LogOfPrior = Log (Prior) : [2] -> [2]
Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [2 x 1 x *1], [2] -> [2 x 1 x *1]

Validating network. 17 nodes to process in pass 2.


Validating network, final pass.



12 out of 25 nodes do not share the minibatch layout with the input data.

Post-processing network complete.



Allocating matrices for forward and/or backward propagation.

Memory Sharing Structure:

(nil): {[B0 Gradient[50 x 1]] [B1 Gradient[50 x 1]] [B2 Gradient[2 x 1]] [CrossEntropyWithSoftmax Gradient[1]] [CrossEntropyWithSoftmax Value[1]] [EvalErrorPrediction Gradient[1]] [EvalErrorPrediction Value[1]] [H1 Gradient[50 x 1 x *1]] [H2 Gradient[50 x 1 x *1]] [HLast Gradient[2 x 1 x *1]] [InvStdOfFeatures Gradient[2]] [LogOfPrior Gradient[2]] [MVNormalizedFeatures Gradient[2 x *1]] [MeanOfFeatures Gradient[2]] [PosteriorProb Gradient[2 x 1 x *1]] [PosteriorProb Value[2 x 1 x *1]] [Prior Gradient[2]] [ScaledLogLikelihood Gradient[2 x 1 x *1]] [W0 Gradient[50 x 2]] [W0*features Gradient[50 x *1]] [W0*features+B0 Gradient[50 x 1 x *1]] [W1 Gradient[50 x 50]] [W1*H1 Gradient[50 x 1 x *1]] [W1*H1+B1 Gradient[50 x 1 x *1]] [W2 Gradient[2 x 50]] [W2*H1 Gradient[2 x 1 x *1]] [features Gradient[2 x *1]] [labels Gradient[2 x *1]] }
0x7fd051018ac8: {[ScaledLogLikelihood Value[2 x 1 x *1]] }
0x7fd051018f08: {[MVNormalizedFeatures Value[2 x *1]] }
0x7fd051018fb8: {[LogOfPrior Value[2]] }
0x7fd05101a898: {[W0*features Value[50 x *1]] }
0x7fd05101af48: {[W0*features+B0 Value[50 x 1 x *1]] }
0x7fd05101b0a8: {[H1 Value[50 x 1 x *1]] }
0x7fd05101b268: {[W1*H1 Value[50 x 1 x *1]] }
0x7fd05101b428: {[W1*H1+B1 Value[50 x 1 x *1]] }
0x7fd05101b5e8: {[H2 Value[50 x 1 x *1]] }
0x7fd05101b7a8: {[W2*H1 Value[2 x 1 x *1]] }
0x7fd05101b968: {[HLast Value[2 x 1 x *1]] }
0x7fd056ee88b8: {[B0 Value[50 x 1]] }
0x7fd056ee9538: {[B1 Value[50 x 1]] }
0x7fd056eea158: {[B2 Value[2 x 1]] }
0x7fd056ef2488: {[features Value[2 x *1]] }
0x7fd056ef3b78: {[InvStdOfFeatures Value[2]] }
0x7fd056ef45c8: {[labels Value[2 x *1]] }
0x7fd056ef4dc8: {[MeanOfFeatures Value[2]] }
0x7fd056ef58f8: {[Prior Value[2]] }
0x7fd056ef5af8: {[W0 Value[50 x 2]] }
0x7fd056ef6458: {[W1 Value[50 x 50]] }
0x7fd056ef7508: {[W2 Value[2 x 50]] }

Minibatch[0]: ActualMBSize = 603
Written to /tmp/cntk-test-20160713122635.123438/Speech_Simple@release_cpu/SimpleOutput*
Total Samples Evaluated = 603

07/13/2016 12:28:42: Action "write" complete.

07/13/2016 12:28:42: __COMPLETED__
=== Deleting last epoch data
==== Re-running from checkpoint
=== Running /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/build/gpu/release/bin/cntk configFile=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Simple/cntk.cntk currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data RunDir=/tmp/cntk-test-20160713122635.123438/Speech_Simple@release_cpu DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Simple OutputDir=/tmp/cntk-test-20160713122635.123438/Speech_Simple@release_cpu DeviceId=-1 timestamping=true makeMode=true
-------------------------------------------------------------------
Build info: 

		Built time: Jul 13 2016 12:01:30
		Last modified date: Tue Jul 12 04:28:35 2016
		Build type: release
		Build target: GPU
		With 1bit-SGD: no
		Math lib: mkl
		CUDA_PATH: /usr/local/cuda-7.5
		CUB_PATH: /usr/local/cub-1.4.1
		CUDNN_PATH: /usr/local/cudnn-4.0
		Build Branch: HEAD
		Build SHA1: 50bb4c8afbc87c14548a5b5f315a064186a5cb5f
		Built by philly on 2bc22072e267
		Build Path: /home/philly/jenkins/workspace/CNTK-Build-Linux
-------------------------------------------------------------------
Changed current directory to /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
07/13/2016 12:28:42: -------------------------------------------------------------------
07/13/2016 12:28:42: Build info: 

07/13/2016 12:28:42: 		Built time: Jul 13 2016 12:01:30
07/13/2016 12:28:42: 		Last modified date: Tue Jul 12 04:28:35 2016
07/13/2016 12:28:42: 		Build type: release
07/13/2016 12:28:42: 		Build target: GPU
07/13/2016 12:28:42: 		With 1bit-SGD: no
07/13/2016 12:28:42: 		Math lib: mkl
07/13/2016 12:28:42: 		CUDA_PATH: /usr/local/cuda-7.5
07/13/2016 12:28:42: 		CUB_PATH: /usr/local/cub-1.4.1
07/13/2016 12:28:42: 		CUDNN_PATH: /usr/local/cudnn-4.0
07/13/2016 12:28:42: 		Build Branch: HEAD
07/13/2016 12:28:42: 		Build SHA1: 50bb4c8afbc87c14548a5b5f315a064186a5cb5f
07/13/2016 12:28:42: 		Built by philly on 2bc22072e267
07/13/2016 12:28:42: 		Build Path: /home/philly/jenkins/workspace/CNTK-Build-Linux
07/13/2016 12:28:42: -------------------------------------------------------------------
07/13/2016 12:28:43: -------------------------------------------------------------------
07/13/2016 12:28:43: GPU info:

07/13/2016 12:28:43: 		Device[0]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3071 MB
07/13/2016 12:28:43: 		Device[1]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3071 MB
07/13/2016 12:28:43: 		Device[2]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3071 MB
07/13/2016 12:28:43: 		Device[3]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3071 MB
07/13/2016 12:28:43: -------------------------------------------------------------------

07/13/2016 12:28:43: Running on localhost at 2016/07/13 12:28:43
07/13/2016 12:28:43: Command line: 
/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/build/gpu/release/bin/cntk  configFile=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Simple/cntk.cntk  currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data  RunDir=/tmp/cntk-test-20160713122635.123438/Speech_Simple@release_cpu  DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data  ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Simple  OutputDir=/tmp/cntk-test-20160713122635.123438/Speech_Simple@release_cpu  DeviceId=-1  timestamping=true  makeMode=true



07/13/2016 12:28:43: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
07/13/2016 12:28:43: command=Simple_Demo:Simple_Demo_Output
DeviceNumber=-1
precision=float
modelPath=$RunDir$/models/simple.dnn
deviceId=$DeviceNumber$
outputNodeNames=ScaledLogLikelihood
traceLevel=1
Simple_Demo=[
    action=train
    SimpleNetworkBuilder=[
        layerSizes=2:50*2:2
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ErrorPrediction
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0 
        minibatchSize=128
        learningRatesPerSample=0.1
        momentumAsTimeConstant=2500
        dropoutRate=0.0
        maxEpochs=50
        keepCheckPointFiles = true
    ]
    reader=[
        readerType=CNTKTextFormatReader
        file=$DataDir$/SimpleDataTrain_cntk_text.txt
        input = [
            features=[
dim = 2      
                format = "dense"
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
]
Simple_Demo_Output=[
    action=write
    reader=[
        readerType=CNTKTextFormatReader
        file=$DataDir$/SimpleDataTest_cntk_text.txt
        input = [
            features=[
dim = 2 
                format = "dense" 
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
outputPath=$RunDir$/SimpleOutput    
]
currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
RunDir=/tmp/cntk-test-20160713122635.123438/Speech_Simple@release_cpu
DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Simple
OutputDir=/tmp/cntk-test-20160713122635.123438/Speech_Simple@release_cpu
DeviceId=-1
timestamping=true
makeMode=true

07/13/2016 12:28:43: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<

07/13/2016 12:28:43: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
07/13/2016 12:28:43: command=Simple_Demo:Simple_Demo_Output
DeviceNumber=-1
precision=float
modelPath=/tmp/cntk-test-20160713122635.123438/Speech_Simple@release_cpu/models/simple.dnn
deviceId=-1
outputNodeNames=ScaledLogLikelihood
traceLevel=1
Simple_Demo=[
    action=train
    SimpleNetworkBuilder=[
        layerSizes=2:50*2:2
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ErrorPrediction
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0 
        minibatchSize=128
        learningRatesPerSample=0.1
        momentumAsTimeConstant=2500
        dropoutRate=0.0
        maxEpochs=50
        keepCheckPointFiles = true
    ]
    reader=[
        readerType=CNTKTextFormatReader
        file=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/SimpleDataTrain_cntk_text.txt
        input = [
            features=[
dim = 2      
                format = "dense"
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
]
Simple_Demo_Output=[
    action=write
    reader=[
        readerType=CNTKTextFormatReader
        file=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/SimpleDataTest_cntk_text.txt
        input = [
            features=[
dim = 2 
                format = "dense" 
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
outputPath=/tmp/cntk-test-20160713122635.123438/Speech_Simple@release_cpu/SimpleOutput    
]
currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
RunDir=/tmp/cntk-test-20160713122635.123438/Speech_Simple@release_cpu
DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Simple
OutputDir=/tmp/cntk-test-20160713122635.123438/Speech_Simple@release_cpu
DeviceId=-1
timestamping=true
makeMode=true

07/13/2016 12:28:43: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<

07/13/2016 12:28:43: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
configparameters: cntk.cntk:command=Simple_Demo:Simple_Demo_Output
configparameters: cntk.cntk:ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Simple
configparameters: cntk.cntk:currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
configparameters: cntk.cntk:DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
configparameters: cntk.cntk:deviceId=-1
configparameters: cntk.cntk:DeviceNumber=-1
configparameters: cntk.cntk:makeMode=true
configparameters: cntk.cntk:modelPath=/tmp/cntk-test-20160713122635.123438/Speech_Simple@release_cpu/models/simple.dnn
configparameters: cntk.cntk:OutputDir=/tmp/cntk-test-20160713122635.123438/Speech_Simple@release_cpu
configparameters: cntk.cntk:outputNodeNames=ScaledLogLikelihood
configparameters: cntk.cntk:precision=float
configparameters: cntk.cntk:RunDir=/tmp/cntk-test-20160713122635.123438/Speech_Simple@release_cpu
configparameters: cntk.cntk:Simple_Demo=[
    action=train
    SimpleNetworkBuilder=[
        layerSizes=2:50*2:2
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ErrorPrediction
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0 
        minibatchSize=128
        learningRatesPerSample=0.1
        momentumAsTimeConstant=2500
        dropoutRate=0.0
        maxEpochs=50
        keepCheckPointFiles = true
    ]
    reader=[
        readerType=CNTKTextFormatReader
        file=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/SimpleDataTrain_cntk_text.txt
        input = [
            features=[
dim = 2      
                format = "dense"
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
]

configparameters: cntk.cntk:Simple_Demo_Output=[
    action=write
    reader=[
        readerType=CNTKTextFormatReader
        file=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/SimpleDataTest_cntk_text.txt
        input = [
            features=[
dim = 2 
                format = "dense" 
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
outputPath=/tmp/cntk-test-20160713122635.123438/Speech_Simple@release_cpu/SimpleOutput    
]

configparameters: cntk.cntk:timestamping=true
configparameters: cntk.cntk:traceLevel=1
07/13/2016 12:28:43: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
07/13/2016 12:28:43: Commands: Simple_Demo Simple_Demo_Output
07/13/2016 12:28:43: Precision = "float"
07/13/2016 12:28:43: CNTKModelPath: /tmp/cntk-test-20160713122635.123438/Speech_Simple@release_cpu/models/simple.dnn
07/13/2016 12:28:43: CNTKCommandTrainInfo: Simple_Demo : 50
07/13/2016 12:28:43: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 50

07/13/2016 12:28:43: ##############################################################################
07/13/2016 12:28:43: #                                                                            #
07/13/2016 12:28:43: # Action "train"                                                             #
07/13/2016 12:28:43: #                                                                            #
07/13/2016 12:28:43: ##############################################################################

07/13/2016 12:28:43: CNTKCommandTrainBegin: Simple_Demo
SimpleNetworkBuilder Using CPU

07/13/2016 12:28:43: Starting from checkpoint. Loading network from '/tmp/cntk-test-20160713122635.123438/Speech_Simple@release_cpu/models/simple.dnn.49'.

Post-processing network...

7 roots:
	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
	EvalErrorPrediction = ErrorPrediction()
	InvStdOfFeatures = InvStdDev()
	MeanOfFeatures = Mean()
	PosteriorProb = Softmax()
	Prior = Mean()
	ScaledLogLikelihood = Minus()

Validating network. 25 nodes to process in pass 1.

Validating --> labels = InputValue() :  -> [2 x *1]
Validating --> W2 = LearnableParameter() :  -> [2 x 50]
Validating --> W1 = LearnableParameter() :  -> [50 x 50]
Validating --> W0 = LearnableParameter() :  -> [50 x 2]
Validating --> features = InputValue() :  -> [2 x *1]
Validating --> MeanOfFeatures = Mean (features) : [2 x *1] -> [2]
Validating --> InvStdOfFeatures = InvStdDev (features) : [2 x *1] -> [2]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [2 x *1], [2], [2] -> [2 x *1]
Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [50 x 2], [2 x *1] -> [50 x *1]
Validating --> B0 = LearnableParameter() :  -> [50 x 1]
Validating --> W0*features+B0 = Plus (W0*features, B0) : [50 x *1], [50 x 1] -> [50 x 1 x *1]
Validating --> H1 = Sigmoid (W0*features+B0) : [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> W1*H1 = Times (W1, H1) : [50 x 50], [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> B1 = LearnableParameter() :  -> [50 x 1]
Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [50 x 1 x *1], [50 x 1] -> [50 x 1 x *1]
Validating --> H2 = Sigmoid (W1*H1+B1) : [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> W2*H1 = Times (W2, H2) : [2 x 50], [50 x 1 x *1] -> [2 x 1 x *1]
Validating --> B2 = LearnableParameter() :  -> [2 x 1]
Validating --> HLast = Plus (W2*H1, B2) : [2 x 1 x *1], [2 x 1] -> [2 x 1 x *1]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [2 x *1], [2 x 1 x *1] -> [1]
Validating --> EvalErrorPrediction = ErrorPrediction (labels, HLast) : [2 x *1], [2 x 1 x *1] -> [1]
Validating --> PosteriorProb = Softmax (HLast) : [2 x 1 x *1] -> [2 x 1 x *1]
Validating --> Prior = Mean (labels) : [2 x *1] -> [2]
Validating --> LogOfPrior = Log (Prior) : [2] -> [2]
Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [2 x 1 x *1], [2] -> [2 x 1 x *1]

Validating network. 17 nodes to process in pass 2.


Validating network, final pass.



12 out of 25 nodes do not share the minibatch layout with the input data.

Post-processing network complete.

07/13/2016 12:28:43: Loaded model with 25 nodes on CPU.

07/13/2016 12:28:43: Training criterion node(s):
07/13/2016 12:28:43: 	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax

07/13/2016 12:28:43: Evaluation criterion node(s):

07/13/2016 12:28:43: 	EvalErrorPrediction = ErrorPrediction


Allocating matrices for forward and/or backward propagation.

Memory Sharing Structure:

(nil): {[EvalErrorPrediction Gradient[1]] [InvStdOfFeatures Gradient[2]] [LogOfPrior Gradient[2]] [MVNormalizedFeatures Gradient[2 x *1]] [MeanOfFeatures Gradient[2]] [PosteriorProb Gradient[2 x 1 x *1]] [PosteriorProb Value[2 x 1 x *1]] [Prior Gradient[2]] [ScaledLogLikelihood Gradient[2 x 1 x *1]] [features Gradient[2 x *1]] [labels Gradient[2 x *1]] }
0x143e278: {[B2 Value[2 x 1]] }
0x143eeb8: {[features Value[2 x *1]] }
0x143fb58: {[InvStdOfFeatures Value[2]] }
0x14405d8: {[labels Value[2 x *1]] }
0x1440d18: {[MeanOfFeatures Value[2]] }
0x1441018: {[Prior Value[2]] }
0x1441a28: {[W0 Value[50 x 2]] }
0x1441e38: {[W1 Value[50 x 50]] }
0x1443418: {[W2 Value[2 x 50]] }
0x144a8c8: {[EvalErrorPrediction Value[1]] }
0x144a9c8: {[ScaledLogLikelihood Value[2 x 1 x *1]] }
0x144ae58: {[CrossEntropyWithSoftmax Value[1]] }
0x144b4c8: {[W0 Gradient[50 x 2]] [W0*features+B0 Value[50 x 1 x *1]] }
0x144b6b8: {[LogOfPrior Value[2]] }
0x144d198: {[MVNormalizedFeatures Value[2 x *1]] }
0x144d898: {[W0*features Value[50 x *1]] }
0x144daa8: {[H1 Value[50 x 1 x *1]] [W0*features Gradient[50 x *1]] }
0x144dc68: {[W0*features+B0 Gradient[50 x 1 x *1]] [W1*H1 Value[50 x 1 x *1]] }
0x144de28: {[W1 Gradient[50 x 50]] [W1*H1+B1 Value[50 x 1 x *1]] }
0x144dfe8: {[H2 Value[50 x 1 x *1]] [W1*H1 Gradient[50 x 1 x *1]] }
0x144e1a8: {[B0 Gradient[50 x 1]] [H1 Gradient[50 x 1 x *1]] [W1*H1+B1 Gradient[50 x 1 x *1]] [W2*H1 Value[2 x 1 x *1]] }
0x144e368: {[HLast Value[2 x 1 x *1]] [W2 Gradient[2 x 50]] }
0x144ee98: {[CrossEntropyWithSoftmax Gradient[1]] }
0x144f058: {[B1 Gradient[50 x 1]] [H2 Gradient[50 x 1 x *1]] [HLast Gradient[2 x 1 x *1]] }
0x144f218: {[W2*H1 Gradient[2 x 1 x *1]] }
0x144f3d8: {[B2 Gradient[2 x 1]] }
0x18266c8: {[B1 Value[50 x 1]] }
0x1827318: {[B0 Value[50 x 1]] }

07/13/2016 12:28:43: No PreCompute nodes found, skipping PreCompute step.

07/13/2016 12:28:43: Starting Epoch 50: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 49: frames [490000..500000] (first sequence at sample 490000), data subset 0 of 1

07/13/2016 12:28:43: Starting minibatch loop.
07/13/2016 12:28:43:  Epoch[50 of 50]-Minibatch[   1-  10, 0.00000000000003%]: CrossEntropyWithSoftmax = 0.17482439 * 1280; EvalErrorPrediction = 0.08593750 * 1280; time = 0.2136s; samplesPerSecond = 5991.7
07/13/2016 12:28:43:  Epoch[50 of 50]-Minibatch[  11-  20, 0.00000000000006%]: CrossEntropyWithSoftmax = 0.16347297 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0459s; samplesPerSecond = 27879.4
07/13/2016 12:28:43:  Epoch[50 of 50]-Minibatch[  21-  30, 0.00000000000008%]: CrossEntropyWithSoftmax = 0.15064664 * 1280; EvalErrorPrediction = 0.06796875 * 1280; time = 0.0443s; samplesPerSecond = 28882.2
07/13/2016 12:28:43:  Epoch[50 of 50]-Minibatch[  31-  40, 0.00000000000011%]: CrossEntropyWithSoftmax = 0.15297375 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0400s; samplesPerSecond = 31997.6
07/13/2016 12:28:43:  Epoch[50 of 50]-Minibatch[  41-  50, 0.00000000000014%]: CrossEntropyWithSoftmax = 0.15320015 * 1280; EvalErrorPrediction = 0.06796875 * 1280; time = 0.0412s; samplesPerSecond = 31096.6
07/13/2016 12:28:44:  Epoch[50 of 50]-Minibatch[  51-  60, 0.00000000000017%]: CrossEntropyWithSoftmax = 0.14706454 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 0.0490s; samplesPerSecond = 26097.4
07/13/2016 12:28:44:  Epoch[50 of 50]-Minibatch[  61-  70, 0.00000000000019%]: CrossEntropyWithSoftmax = 0.14297619 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0360s; samplesPerSecond = 35602.0
07/13/2016 12:28:44: Finished Epoch[50 of 50]: [Training] CrossEntropyWithSoftmax = 0.15772699 * 10000; EvalErrorPrediction = 0.07490000 * 10000; totalSamplesSeen = 500000; learningRatePerSample = 0.1; epochTime=0.52085s
07/13/2016 12:28:44: SGD: Saving checkpoint model '/tmp/cntk-test-20160713122635.123438/Speech_Simple@release_cpu/models/simple.dnn'
07/13/2016 12:28:44: CNTKCommandTrainEnd: Simple_Demo

07/13/2016 12:28:44: Action "train" complete.


07/13/2016 12:28:44: ##############################################################################
07/13/2016 12:28:44: #                                                                            #
07/13/2016 12:28:44: # Action "write"                                                             #
07/13/2016 12:28:44: #                                                                            #
07/13/2016 12:28:44: ##############################################################################


Post-processing network...

7 roots:
	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
	EvalErrorPrediction = ErrorPrediction()
	InvStdOfFeatures = InvStdDev()
	MeanOfFeatures = Mean()
	PosteriorProb = Softmax()
	Prior = Mean()
	ScaledLogLikelihood = Minus()

Validating network. 25 nodes to process in pass 1.

Validating --> labels = InputValue() :  -> [2 x *2]
Validating --> W2 = LearnableParameter() :  -> [2 x 50]
Validating --> W1 = LearnableParameter() :  -> [50 x 50]
Validating --> W0 = LearnableParameter() :  -> [50 x 2]
Validating --> features = InputValue() :  -> [2 x *2]
Validating --> MeanOfFeatures = Mean (features) : [2 x *2] -> [2]
Validating --> InvStdOfFeatures = InvStdDev (features) : [2 x *2] -> [2]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [2 x *2], [2], [2] -> [2 x *2]
Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [50 x 2], [2 x *2] -> [50 x *2]
Validating --> B0 = LearnableParameter() :  -> [50 x 1]
Validating --> W0*features+B0 = Plus (W0*features, B0) : [50 x *2], [50 x 1] -> [50 x 1 x *2]
Validating --> H1 = Sigmoid (W0*features+B0) : [50 x 1 x *2] -> [50 x 1 x *2]
Validating --> W1*H1 = Times (W1, H1) : [50 x 50], [50 x 1 x *2] -> [50 x 1 x *2]
Validating --> B1 = LearnableParameter() :  -> [50 x 1]
Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [50 x 1 x *2], [50 x 1] -> [50 x 1 x *2]
Validating --> H2 = Sigmoid (W1*H1+B1) : [50 x 1 x *2] -> [50 x 1 x *2]
Validating --> W2*H1 = Times (W2, H2) : [2 x 50], [50 x 1 x *2] -> [2 x 1 x *2]
Validating --> B2 = LearnableParameter() :  -> [2 x 1]
Validating --> HLast = Plus (W2*H1, B2) : [2 x 1 x *2], [2 x 1] -> [2 x 1 x *2]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [2 x *2], [2 x 1 x *2] -> [1]
Validating --> EvalErrorPrediction = ErrorPrediction (labels, HLast) : [2 x *2], [2 x 1 x *2] -> [1]
Validating --> PosteriorProb = Softmax (HLast) : [2 x 1 x *2] -> [2 x 1 x *2]
Validating --> Prior = Mean (labels) : [2 x *2] -> [2]
Validating --> LogOfPrior = Log (Prior) : [2] -> [2]
Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [2 x 1 x *2], [2] -> [2 x 1 x *2]

Validating network. 17 nodes to process in pass 2.


Validating network, final pass.



12 out of 25 nodes do not share the minibatch layout with the input data.

Post-processing network complete.



Allocating matrices for forward and/or backward propagation.

Memory Sharing Structure:

(nil): {[B0 Gradient[50 x 1]] [B1 Gradient[50 x 1]] [B2 Gradient[2 x 1]] [CrossEntropyWithSoftmax Gradient[1]] [CrossEntropyWithSoftmax Value[1]] [EvalErrorPrediction Gradient[1]] [EvalErrorPrediction Value[1]] [H1 Gradient[50 x 1 x *2]] [H2 Gradient[50 x 1 x *2]] [HLast Gradient[2 x 1 x *2]] [InvStdOfFeatures Gradient[2]] [LogOfPrior Gradient[2]] [MVNormalizedFeatures Gradient[2 x *2]] [MeanOfFeatures Gradient[2]] [PosteriorProb Gradient[2 x 1 x *2]] [PosteriorProb Value[2 x 1 x *2]] [Prior Gradient[2]] [ScaledLogLikelihood Gradient[2 x 1 x *2]] [W0 Gradient[50 x 2]] [W0*features Gradient[50 x *2]] [W0*features+B0 Gradient[50 x 1 x *2]] [W1 Gradient[50 x 50]] [W1*H1 Gradient[50 x 1 x *2]] [W1*H1+B1 Gradient[50 x 1 x *2]] [W2 Gradient[2 x 50]] [W2*H1 Gradient[2 x 1 x *2]] [features Gradient[2 x *2]] [labels Gradient[2 x *2]] }
0x7fbf6ed0ebf8: {[B0 Value[50 x 1]] }
0x7fbf6ed0f898: {[B1 Value[50 x 1]] }
0x7fbf6ed104b8: {[B2 Value[2 x 1]] }
0x7fbf6ed3f778: {[features Value[2 x *2]] }
0x7fbf6ed40e68: {[InvStdOfFeatures Value[2]] }
0x7fbf6ed41878: {[labels Value[2 x *2]] }
0x7fbf6ed420a8: {[MeanOfFeatures Value[2]] }
0x7fbf6ed42c48: {[Prior Value[2]] }
0x7fbf6ed42e18: {[W0 Value[50 x 2]] }
0x7fbf6ed43788: {[W1 Value[50 x 50]] }
0x7fbf6ed44808: {[W2 Value[2 x 50]] }
0x7fbf6ed4c618: {[ScaledLogLikelihood Value[2 x 1 x *2]] }
0x7fbf6ed4c8a8: {[MVNormalizedFeatures Value[2 x *2]] }
0x7fbf6ed4c9a8: {[LogOfPrior Value[2]] }
0x7fbf6ed4e418: {[W0*features Value[50 x *2]] }
0x7fbf6ed4e828: {[W0*features+B0 Value[50 x 1 x *2]] }
0x7fbf6ed4e9e8: {[H1 Value[50 x 1 x *2]] }
0x7fbf6ed4eba8: {[W1*H1 Value[50 x 1 x *2]] }
0x7fbf6ed4ed68: {[W1*H1+B1 Value[50 x 1 x *2]] }
0x7fbf6ed4ef28: {[H2 Value[50 x 1 x *2]] }
0x7fbf6ed4f0e8: {[W2*H1 Value[2 x 1 x *2]] }
0x7fbf6ed4f2a8: {[HLast Value[2 x 1 x *2]] }

Minibatch[0]: ActualMBSize = 603
Written to /tmp/cntk-test-20160713122635.123438/Speech_Simple@release_cpu/SimpleOutput*
Total Samples Evaluated = 603

07/13/2016 12:28:44: Action "write" complete.

07/13/2016 12:28:44: __COMPLETED__
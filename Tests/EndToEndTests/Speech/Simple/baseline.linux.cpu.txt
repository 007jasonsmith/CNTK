CPU info:
    CPU Model Name: Intel(R) Xeon(R) CPU E5-2630 v2 @ 2.60GHz
    Hardware threads: 24
    Total Memory: 264172964 kB
-------------------------------------------------------------------
=== Running /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/build/gpu/release/bin/cntk configFile=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Simple/cntk.cntk currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data RunDir=/tmp/cntk-test-20160714122957.627315/Speech_Simple@release_cpu DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Simple OutputDir=/tmp/cntk-test-20160714122957.627315/Speech_Simple@release_cpu DeviceId=-1 timestamping=true
-------------------------------------------------------------------
Build info: 

		Built time: Jul 14 2016 12:04:41
		Last modified date: Tue Jul 12 04:28:35 2016
		Build type: release
		Build target: GPU
		With 1bit-SGD: no
		Math lib: mkl
		CUDA_PATH: /usr/local/cuda-7.5
		CUB_PATH: /usr/local/cub-1.4.1
		CUDNN_PATH: /usr/local/cudnn-4.0
		Build Branch: HEAD
		Build SHA1: 72bee394bf461e8f6f0feb593a8416c05f481957
		Built by philly on 34e58dd0283f
		Build Path: /home/philly/jenkins/workspace/CNTK-Build-Linux
-------------------------------------------------------------------
Changed current directory to /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
07/14/2016 12:33:34: -------------------------------------------------------------------
07/14/2016 12:33:34: Build info: 

07/14/2016 12:33:34: 		Built time: Jul 14 2016 12:04:41
07/14/2016 12:33:34: 		Last modified date: Tue Jul 12 04:28:35 2016
07/14/2016 12:33:34: 		Build type: release
07/14/2016 12:33:34: 		Build target: GPU
07/14/2016 12:33:34: 		With 1bit-SGD: no
07/14/2016 12:33:34: 		Math lib: mkl
07/14/2016 12:33:34: 		CUDA_PATH: /usr/local/cuda-7.5
07/14/2016 12:33:34: 		CUB_PATH: /usr/local/cub-1.4.1
07/14/2016 12:33:34: 		CUDNN_PATH: /usr/local/cudnn-4.0
07/14/2016 12:33:34: 		Build Branch: HEAD
07/14/2016 12:33:34: 		Build SHA1: 72bee394bf461e8f6f0feb593a8416c05f481957
07/14/2016 12:33:34: 		Built by philly on 34e58dd0283f
07/14/2016 12:33:34: 		Build Path: /home/philly/jenkins/workspace/CNTK-Build-Linux
07/14/2016 12:33:34: -------------------------------------------------------------------
07/14/2016 12:33:35: -------------------------------------------------------------------
07/14/2016 12:33:35: GPU info:

07/14/2016 12:33:35: 		Device[0]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3071 MB
07/14/2016 12:33:35: 		Device[1]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3071 MB
07/14/2016 12:33:35: 		Device[2]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3071 MB
07/14/2016 12:33:35: 		Device[3]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3071 MB
07/14/2016 12:33:35: -------------------------------------------------------------------

07/14/2016 12:33:35: Running on localhost at 2016/07/14 12:33:35
07/14/2016 12:33:35: Command line: 
/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/build/gpu/release/bin/cntk  configFile=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Simple/cntk.cntk  currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data  RunDir=/tmp/cntk-test-20160714122957.627315/Speech_Simple@release_cpu  DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data  ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Simple  OutputDir=/tmp/cntk-test-20160714122957.627315/Speech_Simple@release_cpu  DeviceId=-1  timestamping=true



07/14/2016 12:33:35: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
07/14/2016 12:33:35: command=Simple_Demo:Simple_Demo_Output
DeviceNumber=-1
precision=float
modelPath=$RunDir$/models/simple.dnn
deviceId=$DeviceNumber$
outputNodeNames=ScaledLogLikelihood
traceLevel=1
Simple_Demo=[
    action=train
    SimpleNetworkBuilder=[
        layerSizes=2:50*2:2
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ErrorPrediction
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0 
        minibatchSize=128
        learningRatesPerSample=0.1
        momentumAsTimeConstant=2500
        dropoutRate=0.0
        maxEpochs=50
        keepCheckPointFiles = true
    ]
    reader=[
        readerType=CNTKTextFormatReader
        file=$DataDir$/SimpleDataTrain_cntk_text.txt
        input = [
            features=[
dim = 2      
                format = "dense"
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
]
Simple_Demo_Output=[
    action=write
    reader=[
        readerType=CNTKTextFormatReader
        file=$DataDir$/SimpleDataTest_cntk_text.txt
        input = [
            features=[
dim = 2 
                format = "dense" 
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
outputPath=$RunDir$/SimpleOutput    
]
currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
RunDir=/tmp/cntk-test-20160714122957.627315/Speech_Simple@release_cpu
DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Simple
OutputDir=/tmp/cntk-test-20160714122957.627315/Speech_Simple@release_cpu
DeviceId=-1
timestamping=true

07/14/2016 12:33:35: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<

07/14/2016 12:33:35: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
07/14/2016 12:33:35: command=Simple_Demo:Simple_Demo_Output
DeviceNumber=-1
precision=float
modelPath=/tmp/cntk-test-20160714122957.627315/Speech_Simple@release_cpu/models/simple.dnn
deviceId=-1
outputNodeNames=ScaledLogLikelihood
traceLevel=1
Simple_Demo=[
    action=train
    SimpleNetworkBuilder=[
        layerSizes=2:50*2:2
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ErrorPrediction
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0 
        minibatchSize=128
        learningRatesPerSample=0.1
        momentumAsTimeConstant=2500
        dropoutRate=0.0
        maxEpochs=50
        keepCheckPointFiles = true
    ]
    reader=[
        readerType=CNTKTextFormatReader
        file=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/SimpleDataTrain_cntk_text.txt
        input = [
            features=[
dim = 2      
                format = "dense"
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
]
Simple_Demo_Output=[
    action=write
    reader=[
        readerType=CNTKTextFormatReader
        file=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/SimpleDataTest_cntk_text.txt
        input = [
            features=[
dim = 2 
                format = "dense" 
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
outputPath=/tmp/cntk-test-20160714122957.627315/Speech_Simple@release_cpu/SimpleOutput    
]
currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
RunDir=/tmp/cntk-test-20160714122957.627315/Speech_Simple@release_cpu
DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Simple
OutputDir=/tmp/cntk-test-20160714122957.627315/Speech_Simple@release_cpu
DeviceId=-1
timestamping=true

07/14/2016 12:33:35: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<

07/14/2016 12:33:35: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
configparameters: cntk.cntk:command=Simple_Demo:Simple_Demo_Output
configparameters: cntk.cntk:ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Simple
configparameters: cntk.cntk:currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
configparameters: cntk.cntk:DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
configparameters: cntk.cntk:deviceId=-1
configparameters: cntk.cntk:DeviceNumber=-1
configparameters: cntk.cntk:modelPath=/tmp/cntk-test-20160714122957.627315/Speech_Simple@release_cpu/models/simple.dnn
configparameters: cntk.cntk:OutputDir=/tmp/cntk-test-20160714122957.627315/Speech_Simple@release_cpu
configparameters: cntk.cntk:outputNodeNames=ScaledLogLikelihood
configparameters: cntk.cntk:precision=float
configparameters: cntk.cntk:RunDir=/tmp/cntk-test-20160714122957.627315/Speech_Simple@release_cpu
configparameters: cntk.cntk:Simple_Demo=[
    action=train
    SimpleNetworkBuilder=[
        layerSizes=2:50*2:2
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ErrorPrediction
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0 
        minibatchSize=128
        learningRatesPerSample=0.1
        momentumAsTimeConstant=2500
        dropoutRate=0.0
        maxEpochs=50
        keepCheckPointFiles = true
    ]
    reader=[
        readerType=CNTKTextFormatReader
        file=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/SimpleDataTrain_cntk_text.txt
        input = [
            features=[
dim = 2      
                format = "dense"
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
]

configparameters: cntk.cntk:Simple_Demo_Output=[
    action=write
    reader=[
        readerType=CNTKTextFormatReader
        file=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/SimpleDataTest_cntk_text.txt
        input = [
            features=[
dim = 2 
                format = "dense" 
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
outputPath=/tmp/cntk-test-20160714122957.627315/Speech_Simple@release_cpu/SimpleOutput    
]

configparameters: cntk.cntk:timestamping=true
configparameters: cntk.cntk:traceLevel=1
07/14/2016 12:33:35: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
07/14/2016 12:33:35: Commands: Simple_Demo Simple_Demo_Output
07/14/2016 12:33:35: Precision = "float"
07/14/2016 12:33:35: CNTKModelPath: /tmp/cntk-test-20160714122957.627315/Speech_Simple@release_cpu/models/simple.dnn
07/14/2016 12:33:35: CNTKCommandTrainInfo: Simple_Demo : 50
07/14/2016 12:33:35: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 50

07/14/2016 12:33:35: ##############################################################################
07/14/2016 12:33:35: #                                                                            #
07/14/2016 12:33:35: # Action "train"                                                             #
07/14/2016 12:33:35: #                                                                            #
07/14/2016 12:33:35: ##############################################################################

07/14/2016 12:33:35: CNTKCommandTrainBegin: Simple_Demo
SimpleNetworkBuilder Using CPU

07/14/2016 12:33:35: Creating virgin network.

Post-processing network...

7 roots:
	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
	EvalErrorPrediction = ErrorPrediction()
	InvStdOfFeatures = InvStdDev()
	MeanOfFeatures = Mean()
	PosteriorProb = Softmax()
	Prior = Mean()
	ScaledLogLikelihood = Minus()

Validating network. 25 nodes to process in pass 1.

Validating --> labels = InputValue() :  -> [2 x *]
Validating --> W2 = LearnableParameter() :  -> [2 x 50]
Validating --> W1 = LearnableParameter() :  -> [50 x 50]
Validating --> W0 = LearnableParameter() :  -> [50 x 2]
Validating --> features = InputValue() :  -> [2 x *]
Validating --> MeanOfFeatures = Mean (features) : [2 x *] -> [2]
Validating --> InvStdOfFeatures = InvStdDev (features) : [2 x *] -> [2]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [2 x *], [2], [2] -> [2 x *]
Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [50 x 2], [2 x *] -> [50 x *]
Validating --> B0 = LearnableParameter() :  -> [50 x 1]
Validating --> W0*features+B0 = Plus (W0*features, B0) : [50 x *], [50 x 1] -> [50 x 1 x *]
Validating --> H1 = Sigmoid (W0*features+B0) : [50 x 1 x *] -> [50 x 1 x *]
Validating --> W1*H1 = Times (W1, H1) : [50 x 50], [50 x 1 x *] -> [50 x 1 x *]
Validating --> B1 = LearnableParameter() :  -> [50 x 1]
Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [50 x 1 x *], [50 x 1] -> [50 x 1 x *]
Validating --> H2 = Sigmoid (W1*H1+B1) : [50 x 1 x *] -> [50 x 1 x *]
Validating --> W2*H1 = Times (W2, H2) : [2 x 50], [50 x 1 x *] -> [2 x 1 x *]
Validating --> B2 = LearnableParameter() :  -> [2 x 1]
Validating --> HLast = Plus (W2*H1, B2) : [2 x 1 x *], [2 x 1] -> [2 x 1 x *]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [2 x *], [2 x 1 x *] -> [1]
Validating --> EvalErrorPrediction = ErrorPrediction (labels, HLast) : [2 x *], [2 x 1 x *] -> [1]
Validating --> PosteriorProb = Softmax (HLast) : [2 x 1 x *] -> [2 x 1 x *]
Validating --> Prior = Mean (labels) : [2 x *] -> [2]
Validating --> LogOfPrior = Log (Prior) : [2] -> [2]
Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [2 x 1 x *], [2] -> [2 x 1 x *]

Validating network. 17 nodes to process in pass 2.


Validating network, final pass.



12 out of 25 nodes do not share the minibatch layout with the input data.

Post-processing network complete.

07/14/2016 12:33:35: Created model with 25 nodes on CPU.

07/14/2016 12:33:35: Training criterion node(s):
07/14/2016 12:33:35: 	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax

07/14/2016 12:33:35: Evaluation criterion node(s):

07/14/2016 12:33:35: 	EvalErrorPrediction = ErrorPrediction


Allocating matrices for forward and/or backward propagation.

Memory Sharing Structure:

(nil): {[EvalErrorPrediction Gradient[1]] [InvStdOfFeatures Gradient[2]] [LogOfPrior Gradient[2]] [MVNormalizedFeatures Gradient[2 x *]] [MeanOfFeatures Gradient[2]] [PosteriorProb Gradient[2 x 1 x *]] [PosteriorProb Value[2 x 1 x *]] [Prior Gradient[2]] [ScaledLogLikelihood Gradient[2 x 1 x *]] [features Gradient[2 x *]] [labels Gradient[2 x *]] }
0x7fa7392c69b8: {[CrossEntropyWithSoftmax Gradient[1]] }
0x7fa7392c6b78: {[B1 Gradient[50 x 1]] [H2 Gradient[50 x 1 x *]] [HLast Gradient[2 x 1 x *]] }
0x7fa7392c6d38: {[W2*H1 Gradient[2 x 1 x *]] }
0x7fa7392c6ef8: {[B2 Gradient[2 x 1]] }
0x7fa73a44f318: {[InvStdOfFeatures Value[2]] }
0x7fa73a450ba8: {[W0 Value[50 x 2]] }
0x7fa73a451168: {[B0 Value[50 x 1]] }
0x7fa73a452148: {[W1 Value[50 x 50]] }
0x7fa73a454c88: {[B1 Value[50 x 1]] }
0x7fa73a455b78: {[W2 Value[2 x 50]] }
0x7fa73a456138: {[B2 Value[2 x 1]] }
0x7fa73a456c08: {[labels Value[2 x *]] }
0x7fa73a457978: {[Prior Value[2]] }
0x7fa73a45d288: {[EvalErrorPrediction Value[1]] }
0x7fa73a45d428: {[ScaledLogLikelihood Value[2 x 1 x *]] }
0x7fa73a45d5e8: {[CrossEntropyWithSoftmax Value[1]] }
0x7fa73a45db38: {[W0 Gradient[50 x 2]] [W0*features+B0 Value[50 x 1 x *]] }
0x7fa73a45dca8: {[LogOfPrior Value[2]] }
0x7fa73a45f408: {[MVNormalizedFeatures Value[2 x *]] }
0x7fa73a45fbc8: {[W0*features Value[50 x *]] }
0x7fa73a45fdd8: {[H1 Value[50 x 1 x *]] [W0*features Gradient[50 x *]] }
0x7fa73a45ff98: {[W0*features+B0 Gradient[50 x 1 x *]] [W1*H1 Value[50 x 1 x *]] }
0x7fa73a460158: {[W1 Gradient[50 x 50]] [W1*H1+B1 Value[50 x 1 x *]] }
0x7fa73a460318: {[H2 Value[50 x 1 x *]] [W1*H1 Gradient[50 x 1 x *]] }
0x7fa73a4604d8: {[B0 Gradient[50 x 1]] [H1 Gradient[50 x 1 x *]] [W1*H1+B1 Gradient[50 x 1 x *]] [W2*H1 Value[2 x 1 x *]] }
0x7fa73a460698: {[HLast Value[2 x 1 x *]] [W2 Gradient[2 x 50]] }
0x7fa73a4bae18: {[MeanOfFeatures Value[2]] }
0x7fa73a4bc2b8: {[features Value[2 x *]] }


07/14/2016 12:33:35: Precomputing --> 3 PreCompute nodes found.

07/14/2016 12:33:35: 	MeanOfFeatures = Mean()
07/14/2016 12:33:35: 	InvStdOfFeatures = InvStdDev()
07/14/2016 12:33:35: 	Prior = Mean()
BlockRandomizer::StartEpoch: epoch 0: frames [0..10000] (first sequence at sample 0), data subset 0 of 1

07/14/2016 12:33:35: Precomputing --> Completed.


07/14/2016 12:33:35: Starting Epoch 1: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 0: frames [0..10000] (first sequence at sample 0), data subset 0 of 1

07/14/2016 12:33:35: Starting minibatch loop.
07/14/2016 12:33:35:  Epoch[ 1 of 50]-Minibatch[   1-  10]: CrossEntropyWithSoftmax = 0.73933568 * 1280; EvalErrorPrediction = 0.49140625 * 1280; time = 0.1665s; samplesPerSecond = 7688.7
07/14/2016 12:33:36:  Epoch[ 1 of 50]-Minibatch[  11-  20]: CrossEntropyWithSoftmax = 0.77136855 * 1280; EvalErrorPrediction = 0.48828125 * 1280; time = 0.1089s; samplesPerSecond = 11756.5
07/14/2016 12:33:36:  Epoch[ 1 of 50]-Minibatch[  21-  30]: CrossEntropyWithSoftmax = 0.70157547 * 1280; EvalErrorPrediction = 0.49531250 * 1280; time = 0.0608s; samplesPerSecond = 21055.1
07/14/2016 12:33:36:  Epoch[ 1 of 50]-Minibatch[  31-  40]: CrossEntropyWithSoftmax = 0.69864731 * 1280; EvalErrorPrediction = 0.49453125 * 1280; time = 0.0408s; samplesPerSecond = 31361.8
07/14/2016 12:33:36:  Epoch[ 1 of 50]-Minibatch[  41-  50]: CrossEntropyWithSoftmax = 0.71645107 * 1280; EvalErrorPrediction = 0.51562500 * 1280; time = 0.0500s; samplesPerSecond = 25605.1
07/14/2016 12:33:36:  Epoch[ 1 of 50]-Minibatch[  51-  60]: CrossEntropyWithSoftmax = 0.62874603 * 1280; EvalErrorPrediction = 0.41796875 * 1280; time = 0.0413s; samplesPerSecond = 31003.2
07/14/2016 12:33:36:  Epoch[ 1 of 50]-Minibatch[  61-  70]: CrossEntropyWithSoftmax = 0.27024193 * 1280; EvalErrorPrediction = 0.11328125 * 1280; time = 0.0364s; samplesPerSecond = 35124.3
07/14/2016 12:33:36: Finished Epoch[ 1 of 50]: [Training] CrossEntropyWithSoftmax = 0.60246250 * 10000; EvalErrorPrediction = 0.39590000 * 10000; totalSamplesSeen = 10000; learningRatePerSample = 0.1; epochTime=0.534765s
07/14/2016 12:33:36: SGD: Saving checkpoint model '/tmp/cntk-test-20160714122957.627315/Speech_Simple@release_cpu/models/simple.dnn.1'

07/14/2016 12:33:36: Starting Epoch 2: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 1: frames [10000..20000] (first sequence at sample 10000), data subset 0 of 1

07/14/2016 12:33:36: Starting minibatch loop.
07/14/2016 12:33:36:  Epoch[ 2 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.23306043 * 1280; EvalErrorPrediction = 0.06875000 * 1280; time = 0.0366s; samplesPerSecond = 34994.7
07/14/2016 12:33:36:  Epoch[ 2 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.24780281 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0523s; samplesPerSecond = 24466.2
07/14/2016 12:33:36:  Epoch[ 2 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.21934290 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0969s; samplesPerSecond = 13214.7
07/14/2016 12:33:36:  Epoch[ 2 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.20664573 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0683s; samplesPerSecond = 18741.4
07/14/2016 12:33:36:  Epoch[ 2 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.17843266 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0573s; samplesPerSecond = 22346.8
07/14/2016 12:33:36:  Epoch[ 2 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.22236977 * 1280; EvalErrorPrediction = 0.10312500 * 1280; time = 0.0628s; samplesPerSecond = 20394.8
07/14/2016 12:33:36:  Epoch[ 2 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16909218 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0429s; samplesPerSecond = 29841.7
07/14/2016 12:33:36: Finished Epoch[ 2 of 50]: [Training] CrossEntropyWithSoftmax = 0.20652896 * 10000; EvalErrorPrediction = 0.07970000 * 10000; totalSamplesSeen = 20000; learningRatePerSample = 0.1; epochTime=0.461968s
07/14/2016 12:33:36: SGD: Saving checkpoint model '/tmp/cntk-test-20160714122957.627315/Speech_Simple@release_cpu/models/simple.dnn.2'

07/14/2016 12:33:36: Starting Epoch 3: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 2: frames [20000..30000] (first sequence at sample 20000), data subset 0 of 1

07/14/2016 12:33:36: Starting minibatch loop.
07/14/2016 12:33:36:  Epoch[ 3 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15952392 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.0648s; samplesPerSecond = 19760.4
07/14/2016 12:33:36:  Epoch[ 3 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16969237 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.1025s; samplesPerSecond = 12488.9
07/14/2016 12:33:36:  Epoch[ 3 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17790327 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0379s; samplesPerSecond = 33815.0
07/14/2016 12:33:36:  Epoch[ 3 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14991803 * 1280; EvalErrorPrediction = 0.06796875 * 1280; time = 0.0560s; samplesPerSecond = 22840.8
07/14/2016 12:33:37:  Epoch[ 3 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.19979520 * 1280; EvalErrorPrediction = 0.10468750 * 1280; time = 0.0986s; samplesPerSecond = 12978.3
07/14/2016 12:33:37:  Epoch[ 3 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15364428 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 0.0955s; samplesPerSecond = 13405.0
07/14/2016 12:33:37:  Epoch[ 3 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15614738 * 1280; EvalErrorPrediction = 0.06640625 * 1280; time = 0.0500s; samplesPerSecond = 25598.0
07/14/2016 12:33:37: Finished Epoch[ 3 of 50]: [Training] CrossEntropyWithSoftmax = 0.16649585 * 10000; EvalErrorPrediction = 0.07670000 * 10000; totalSamplesSeen = 30000; learningRatePerSample = 0.1; epochTime=0.561437s
07/14/2016 12:33:37: SGD: Saving checkpoint model '/tmp/cntk-test-20160714122957.627315/Speech_Simple@release_cpu/models/simple.dnn.3'

07/14/2016 12:33:37: Starting Epoch 4: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 3: frames [30000..40000] (first sequence at sample 30000), data subset 0 of 1

07/14/2016 12:33:37: Starting minibatch loop.
07/14/2016 12:33:37:  Epoch[ 4 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.19889363 * 1280; EvalErrorPrediction = 0.08750000 * 1280; time = 0.0511s; samplesPerSecond = 25050.4
07/14/2016 12:33:37:  Epoch[ 4 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17116731 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 0.0691s; samplesPerSecond = 18515.6
07/14/2016 12:33:37:  Epoch[ 4 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14583795 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0379s; samplesPerSecond = 33731.3
07/14/2016 12:33:37:  Epoch[ 4 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16399431 * 1280; EvalErrorPrediction = 0.06796875 * 1280; time = 0.0557s; samplesPerSecond = 22981.9
07/14/2016 12:33:37:  Epoch[ 4 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15278168 * 1280; EvalErrorPrediction = 0.06562500 * 1280; time = 0.0522s; samplesPerSecond = 24515.0
07/14/2016 12:33:37:  Epoch[ 4 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.18967047 * 1280; EvalErrorPrediction = 0.09140625 * 1280; time = 0.0580s; samplesPerSecond = 22053.8
07/14/2016 12:33:37:  Epoch[ 4 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16619186 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0445s; samplesPerSecond = 28751.8
07/14/2016 12:33:37: Finished Epoch[ 4 of 50]: [Training] CrossEntropyWithSoftmax = 0.16990123 * 10000; EvalErrorPrediction = 0.07600000 * 10000; totalSamplesSeen = 40000; learningRatePerSample = 0.1; epochTime=0.41269s
07/14/2016 12:33:37: SGD: Saving checkpoint model '/tmp/cntk-test-20160714122957.627315/Speech_Simple@release_cpu/models/simple.dnn.4'

07/14/2016 12:33:37: Starting Epoch 5: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 4: frames [40000..50000] (first sequence at sample 40000), data subset 0 of 1

07/14/2016 12:33:37: Starting minibatch loop.
07/14/2016 12:33:37:  Epoch[ 5 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.14866041 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0700s; samplesPerSecond = 18284.7
07/14/2016 12:33:37:  Epoch[ 5 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.19050208 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 0.1191s; samplesPerSecond = 10747.8
07/14/2016 12:33:37:  Epoch[ 5 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.19228487 * 1280; EvalErrorPrediction = 0.08437500 * 1280; time = 0.0674s; samplesPerSecond = 18982.4
07/14/2016 12:33:38:  Epoch[ 5 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16221976 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0493s; samplesPerSecond = 25947.2
07/14/2016 12:33:38:  Epoch[ 5 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15045481 * 1280; EvalErrorPrediction = 0.06875000 * 1280; time = 0.0360s; samplesPerSecond = 35599.1
07/14/2016 12:33:38:  Epoch[ 5 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17695665 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 0.0399s; samplesPerSecond = 32078.6
07/14/2016 12:33:38:  Epoch[ 5 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.18600817 * 1280; EvalErrorPrediction = 0.08593750 * 1280; time = 0.0450s; samplesPerSecond = 28459.6
07/14/2016 12:33:38: Finished Epoch[ 5 of 50]: [Training] CrossEntropyWithSoftmax = 0.16876268 * 10000; EvalErrorPrediction = 0.07630000 * 10000; totalSamplesSeen = 50000; learningRatePerSample = 0.1; epochTime=0.492925s
07/14/2016 12:33:38: SGD: Saving checkpoint model '/tmp/cntk-test-20160714122957.627315/Speech_Simple@release_cpu/models/simple.dnn.5'

07/14/2016 12:33:38: Starting Epoch 6: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 5: frames [50000..60000] (first sequence at sample 50000), data subset 0 of 1

07/14/2016 12:33:38: Starting minibatch loop.
07/14/2016 12:33:38:  Epoch[ 6 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16541485 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0322s; samplesPerSecond = 39693.6
07/14/2016 12:33:38:  Epoch[ 6 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15799195 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 0.0624s; samplesPerSecond = 20515.1
07/14/2016 12:33:38:  Epoch[ 6 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15418167 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 0.0508s; samplesPerSecond = 25173.6
07/14/2016 12:33:38:  Epoch[ 6 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.17027073 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0903s; samplesPerSecond = 14169.3
07/14/2016 12:33:38:  Epoch[ 6 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16654892 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0525s; samplesPerSecond = 24375.4
07/14/2016 12:33:38:  Epoch[ 6 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16848326 * 1280; EvalErrorPrediction = 0.08671875 * 1280; time = 0.0689s; samplesPerSecond = 18588.7
07/14/2016 12:33:38:  Epoch[ 6 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15642786 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 0.0485s; samplesPerSecond = 26374.9
07/14/2016 12:33:38: Finished Epoch[ 6 of 50]: [Training] CrossEntropyWithSoftmax = 0.16224381 * 10000; EvalErrorPrediction = 0.07640000 * 10000; totalSamplesSeen = 60000; learningRatePerSample = 0.1; epochTime=0.460809s
07/14/2016 12:33:38: SGD: Saving checkpoint model '/tmp/cntk-test-20160714122957.627315/Speech_Simple@release_cpu/models/simple.dnn.6'

07/14/2016 12:33:38: Starting Epoch 7: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 6: frames [60000..70000] (first sequence at sample 60000), data subset 0 of 1

07/14/2016 12:33:38: Starting minibatch loop.
07/14/2016 12:33:38:  Epoch[ 7 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17808088 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0665s; samplesPerSecond = 19247.0
07/14/2016 12:33:38:  Epoch[ 7 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.19384567 * 1280; EvalErrorPrediction = 0.08671875 * 1280; time = 0.0440s; samplesPerSecond = 29093.6
07/14/2016 12:33:38:  Epoch[ 7 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17011890 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.1022s; samplesPerSecond = 12529.2
07/14/2016 12:33:38:  Epoch[ 7 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16028070 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0556s; samplesPerSecond = 23006.3
07/14/2016 12:33:38:  Epoch[ 7 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14625764 * 1280; EvalErrorPrediction = 0.06796875 * 1280; time = 0.0447s; samplesPerSecond = 28632.8
07/14/2016 12:33:39:  Epoch[ 7 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17853184 * 1280; EvalErrorPrediction = 0.08671875 * 1280; time = 0.0436s; samplesPerSecond = 29369.9
07/14/2016 12:33:39:  Epoch[ 7 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15227604 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0399s; samplesPerSecond = 32083.4
07/14/2016 12:33:39: Finished Epoch[ 7 of 50]: [Training] CrossEntropyWithSoftmax = 0.16922106 * 10000; EvalErrorPrediction = 0.07780000 * 10000; totalSamplesSeen = 70000; learningRatePerSample = 0.1; epochTime=0.438168s
07/14/2016 12:33:39: SGD: Saving checkpoint model '/tmp/cntk-test-20160714122957.627315/Speech_Simple@release_cpu/models/simple.dnn.7'

07/14/2016 12:33:39: Starting Epoch 8: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 7: frames [70000..80000] (first sequence at sample 70000), data subset 0 of 1

07/14/2016 12:33:39: Starting minibatch loop.
07/14/2016 12:33:39:  Epoch[ 8 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.19132322 * 1280; EvalErrorPrediction = 0.08671875 * 1280; time = 0.0307s; samplesPerSecond = 41650.4
07/14/2016 12:33:39:  Epoch[ 8 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15938927 * 1280; EvalErrorPrediction = 0.06875000 * 1280; time = 0.0423s; samplesPerSecond = 30286.5
07/14/2016 12:33:39:  Epoch[ 8 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16188369 * 1280; EvalErrorPrediction = 0.06875000 * 1280; time = 0.0966s; samplesPerSecond = 13245.7
07/14/2016 12:33:39:  Epoch[ 8 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15345082 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0523s; samplesPerSecond = 24490.6
07/14/2016 12:33:39:  Epoch[ 8 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16822319 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0753s; samplesPerSecond = 16992.8
07/14/2016 12:33:39:  Epoch[ 8 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.18607426 * 1280; EvalErrorPrediction = 0.08750000 * 1280; time = 0.0559s; samplesPerSecond = 22891.9
07/14/2016 12:33:39:  Epoch[ 8 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14823380 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 0.0431s; samplesPerSecond = 29697.0
07/14/2016 12:33:39: Finished Epoch[ 8 of 50]: [Training] CrossEntropyWithSoftmax = 0.16762673 * 10000; EvalErrorPrediction = 0.07680000 * 10000; totalSamplesSeen = 80000; learningRatePerSample = 0.1; epochTime=0.435126s
07/14/2016 12:33:39: SGD: Saving checkpoint model '/tmp/cntk-test-20160714122957.627315/Speech_Simple@release_cpu/models/simple.dnn.8'

07/14/2016 12:33:39: Starting Epoch 9: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 8: frames [80000..90000] (first sequence at sample 80000), data subset 0 of 1

07/14/2016 12:33:39: Starting minibatch loop.
07/14/2016 12:33:39:  Epoch[ 9 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16914328 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0434s; samplesPerSecond = 29499.2
07/14/2016 12:33:39:  Epoch[ 9 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17302328 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0423s; samplesPerSecond = 30288.7
07/14/2016 12:33:39:  Epoch[ 9 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16006942 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0303s; samplesPerSecond = 42281.9
07/14/2016 12:33:39:  Epoch[ 9 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15442376 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 0.1089s; samplesPerSecond = 11756.6
07/14/2016 12:33:39:  Epoch[ 9 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.13864594 * 1280; EvalErrorPrediction = 0.05703125 * 1280; time = 0.0863s; samplesPerSecond = 14835.1
07/14/2016 12:33:40:  Epoch[ 9 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17193160 * 1280; EvalErrorPrediction = 0.08359375 * 1280; time = 0.3376s; samplesPerSecond = 3792.0
07/14/2016 12:33:40:  Epoch[ 9 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14883986 * 1280; EvalErrorPrediction = 0.06484375 * 1280; time = 0.0895s; samplesPerSecond = 14300.4
07/14/2016 12:33:40: Finished Epoch[ 9 of 50]: [Training] CrossEntropyWithSoftmax = 0.16019153 * 10000; EvalErrorPrediction = 0.07470000 * 10000; totalSamplesSeen = 90000; learningRatePerSample = 0.1; epochTime=0.779534s
07/14/2016 12:33:40: SGD: Saving checkpoint model '/tmp/cntk-test-20160714122957.627315/Speech_Simple@release_cpu/models/simple.dnn.9'

07/14/2016 12:33:40: Starting Epoch 10: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 9: frames [90000..100000] (first sequence at sample 90000), data subset 0 of 1

07/14/2016 12:33:40: Starting minibatch loop.
07/14/2016 12:33:40:  Epoch[10 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15938257 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 0.0607s; samplesPerSecond = 21098.4
07/14/2016 12:33:40:  Epoch[10 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16747583 * 1280; EvalErrorPrediction = 0.08593750 * 1280; time = 0.0392s; samplesPerSecond = 32673.1
07/14/2016 12:33:40:  Epoch[10 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14229605 * 1280; EvalErrorPrediction = 0.06484375 * 1280; time = 0.0830s; samplesPerSecond = 15430.1
07/14/2016 12:33:40:  Epoch[10 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.17674642 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0434s; samplesPerSecond = 29514.8
07/14/2016 12:33:40:  Epoch[10 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16552539 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0381s; samplesPerSecond = 33578.2
07/14/2016 12:33:40:  Epoch[10 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16121101 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 0.0457s; samplesPerSecond = 27980.6
07/14/2016 12:33:40:  Epoch[10 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14450760 * 1280; EvalErrorPrediction = 0.06718750 * 1280; time = 0.0836s; samplesPerSecond = 15308.3
07/14/2016 12:33:40: Finished Epoch[10 of 50]: [Training] CrossEntropyWithSoftmax = 0.15833496 * 10000; EvalErrorPrediction = 0.07500000 * 10000; totalSamplesSeen = 100000; learningRatePerSample = 0.1; epochTime=0.52561s
07/14/2016 12:33:40: SGD: Saving checkpoint model '/tmp/cntk-test-20160714122957.627315/Speech_Simple@release_cpu/models/simple.dnn.10'

07/14/2016 12:33:40: Starting Epoch 11: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 10: frames [100000..110000] (first sequence at sample 100000), data subset 0 of 1

07/14/2016 12:33:40: Starting minibatch loop.
07/14/2016 12:33:40:  Epoch[11 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15803064 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0621s; samplesPerSecond = 20624.9
07/14/2016 12:33:40:  Epoch[11 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15592762 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0600s; samplesPerSecond = 21329.4
07/14/2016 12:33:41:  Epoch[11 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15867376 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0863s; samplesPerSecond = 14833.7
07/14/2016 12:33:41:  Epoch[11 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.18355393 * 1280; EvalErrorPrediction = 0.09140625 * 1280; time = 0.0923s; samplesPerSecond = 13864.8
07/14/2016 12:33:41:  Epoch[11 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16960340 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0395s; samplesPerSecond = 32413.3
07/14/2016 12:33:41:  Epoch[11 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16026030 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0485s; samplesPerSecond = 26411.9
07/14/2016 12:33:41:  Epoch[11 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15526876 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0487s; samplesPerSecond = 26259.6
07/14/2016 12:33:41: Finished Epoch[11 of 50]: [Training] CrossEntropyWithSoftmax = 0.16184227 * 10000; EvalErrorPrediction = 0.07630000 * 10000; totalSamplesSeen = 110000; learningRatePerSample = 0.1; epochTime=0.495959s
07/14/2016 12:33:41: SGD: Saving checkpoint model '/tmp/cntk-test-20160714122957.627315/Speech_Simple@release_cpu/models/simple.dnn.11'

07/14/2016 12:33:41: Starting Epoch 12: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 11: frames [110000..120000] (first sequence at sample 110000), data subset 0 of 1

07/14/2016 12:33:41: Starting minibatch loop.
07/14/2016 12:33:41:  Epoch[12 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.14852281 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0513s; samplesPerSecond = 24968.8
07/14/2016 12:33:41:  Epoch[12 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16825688 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0461s; samplesPerSecond = 27774.2
07/14/2016 12:33:41:  Epoch[12 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17481744 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0445s; samplesPerSecond = 28749.2
07/14/2016 12:33:41:  Epoch[12 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16886683 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0716s; samplesPerSecond = 17874.3
07/14/2016 12:33:41:  Epoch[12 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.19157701 * 1280; EvalErrorPrediction = 0.08828125 * 1280; time = 0.0482s; samplesPerSecond = 26554.4
07/14/2016 12:33:41:  Epoch[12 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14872885 * 1280; EvalErrorPrediction = 0.06718750 * 1280; time = 0.0441s; samplesPerSecond = 29020.3
07/14/2016 12:33:41:  Epoch[12 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16920624 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0754s; samplesPerSecond = 16979.3
07/14/2016 12:33:41: Finished Epoch[12 of 50]: [Training] CrossEntropyWithSoftmax = 0.16686217 * 10000; EvalErrorPrediction = 0.07710000 * 10000; totalSamplesSeen = 120000; learningRatePerSample = 0.1; epochTime=0.412521s
07/14/2016 12:33:41: SGD: Saving checkpoint model '/tmp/cntk-test-20160714122957.627315/Speech_Simple@release_cpu/models/simple.dnn.12'

07/14/2016 12:33:41: Starting Epoch 13: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 12: frames [120000..130000] (first sequence at sample 120000), data subset 0 of 1

07/14/2016 12:33:41: Starting minibatch loop.
07/14/2016 12:33:41:  Epoch[13 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15746654 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0622s; samplesPerSecond = 20570.2
07/14/2016 12:33:41:  Epoch[13 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15095075 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.1210s; samplesPerSecond = 10574.3
07/14/2016 12:33:41:  Epoch[13 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16232102 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0432s; samplesPerSecond = 29621.4
07/14/2016 12:33:42:  Epoch[13 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16141205 * 1280; EvalErrorPrediction = 0.06875000 * 1280; time = 0.1054s; samplesPerSecond = 12143.8
07/14/2016 12:33:42:  Epoch[13 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.18838768 * 1280; EvalErrorPrediction = 0.09218750 * 1280; time = 0.1232s; samplesPerSecond = 10388.0
07/14/2016 12:33:42:  Epoch[13 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16033878 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.0611s; samplesPerSecond = 20933.2
07/14/2016 12:33:42:  Epoch[13 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.18104076 * 1280; EvalErrorPrediction = 0.08828125 * 1280; time = 0.0581s; samplesPerSecond = 22034.0
07/14/2016 12:33:42: Finished Epoch[13 of 50]: [Training] CrossEntropyWithSoftmax = 0.16538600 * 10000; EvalErrorPrediction = 0.07720000 * 10000; totalSamplesSeen = 130000; learningRatePerSample = 0.1; epochTime=0.625331s
07/14/2016 12:33:42: SGD: Saving checkpoint model '/tmp/cntk-test-20160714122957.627315/Speech_Simple@release_cpu/models/simple.dnn.13'

07/14/2016 12:33:42: Starting Epoch 14: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 13: frames [130000..140000] (first sequence at sample 130000), data subset 0 of 1

07/14/2016 12:33:42: Starting minibatch loop.
07/14/2016 12:33:42:  Epoch[14 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16673622 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0435s; samplesPerSecond = 29407.0
07/14/2016 12:33:42:  Epoch[14 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16026027 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0434s; samplesPerSecond = 29506.7
07/14/2016 12:33:42:  Epoch[14 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16508815 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 0.0932s; samplesPerSecond = 13727.9
07/14/2016 12:33:42:  Epoch[14 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14741759 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0688s; samplesPerSecond = 18615.7
07/14/2016 12:33:42:  Epoch[14 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15339546 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0724s; samplesPerSecond = 17688.1
07/14/2016 12:33:42:  Epoch[14 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16566677 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0449s; samplesPerSecond = 28479.9
07/14/2016 12:33:42:  Epoch[14 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16757851 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 0.0680s; samplesPerSecond = 18814.4
07/14/2016 12:33:42: Finished Epoch[14 of 50]: [Training] CrossEntropyWithSoftmax = 0.16044894 * 10000; EvalErrorPrediction = 0.07510000 * 10000; totalSamplesSeen = 140000; learningRatePerSample = 0.1; epochTime=0.515831s
07/14/2016 12:33:42: SGD: Saving checkpoint model '/tmp/cntk-test-20160714122957.627315/Speech_Simple@release_cpu/models/simple.dnn.14'

07/14/2016 12:33:42: Starting Epoch 15: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 14: frames [140000..150000] (first sequence at sample 140000), data subset 0 of 1

07/14/2016 12:33:42: Starting minibatch loop.
07/14/2016 12:33:42:  Epoch[15 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17496848 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0526s; samplesPerSecond = 24353.1
07/14/2016 12:33:42:  Epoch[15 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17374127 * 1280; EvalErrorPrediction = 0.08359375 * 1280; time = 0.0420s; samplesPerSecond = 30493.6
07/14/2016 12:33:43:  Epoch[15 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16181233 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0715s; samplesPerSecond = 17895.1
07/14/2016 12:33:43:  Epoch[15 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.17213588 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0529s; samplesPerSecond = 24181.5
07/14/2016 12:33:43:  Epoch[15 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.17390571 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0419s; samplesPerSecond = 30514.0
07/14/2016 12:33:43:  Epoch[15 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17115316 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0439s; samplesPerSecond = 29163.2
07/14/2016 12:33:43:  Epoch[15 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17045021 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0409s; samplesPerSecond = 31296.6
07/14/2016 12:33:43: Finished Epoch[15 of 50]: [Training] CrossEntropyWithSoftmax = 0.17080642 * 10000; EvalErrorPrediction = 0.07850000 * 10000; totalSamplesSeen = 150000; learningRatePerSample = 0.1; epochTime=0.385199s
07/14/2016 12:33:43: SGD: Saving checkpoint model '/tmp/cntk-test-20160714122957.627315/Speech_Simple@release_cpu/models/simple.dnn.15'

07/14/2016 12:33:43: Starting Epoch 16: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 15: frames [150000..160000] (first sequence at sample 150000), data subset 0 of 1

07/14/2016 12:33:43: Starting minibatch loop.
07/14/2016 12:33:43:  Epoch[16 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.14492916 * 1280; EvalErrorPrediction = 0.06875000 * 1280; time = 0.0393s; samplesPerSecond = 32557.5
07/14/2016 12:33:43:  Epoch[16 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17128218 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0575s; samplesPerSecond = 22277.9
07/14/2016 12:33:43:  Epoch[16 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16674979 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0432s; samplesPerSecond = 29644.0
07/14/2016 12:33:43:  Epoch[16 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14410810 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0428s; samplesPerSecond = 29903.7
07/14/2016 12:33:43:  Epoch[16 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15073400 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0380s; samplesPerSecond = 33677.1
07/14/2016 12:33:43:  Epoch[16 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15495987 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0299s; samplesPerSecond = 42848.1
07/14/2016 12:33:43:  Epoch[16 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15633564 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.0377s; samplesPerSecond = 33950.5
07/14/2016 12:33:43: Finished Epoch[16 of 50]: [Training] CrossEntropyWithSoftmax = 0.15949218 * 10000; EvalErrorPrediction = 0.07560000 * 10000; totalSamplesSeen = 160000; learningRatePerSample = 0.1; epochTime=0.316226s
07/14/2016 12:33:43: SGD: Saving checkpoint model '/tmp/cntk-test-20160714122957.627315/Speech_Simple@release_cpu/models/simple.dnn.16'

07/14/2016 12:33:43: Starting Epoch 17: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 16: frames [160000..170000] (first sequence at sample 160000), data subset 0 of 1

07/14/2016 12:33:43: Starting minibatch loop.
07/14/2016 12:33:43:  Epoch[17 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17188196 * 1280; EvalErrorPrediction = 0.08359375 * 1280; time = 0.0295s; samplesPerSecond = 43403.1
07/14/2016 12:33:43:  Epoch[17 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16207507 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 0.0589s; samplesPerSecond = 21730.6
07/14/2016 12:33:43:  Epoch[17 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16776812 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 0.0593s; samplesPerSecond = 21572.1
07/14/2016 12:33:43:  Epoch[17 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15647526 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 0.0992s; samplesPerSecond = 12902.8
07/14/2016 12:33:43:  Epoch[17 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15843949 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.1429s; samplesPerSecond = 8955.9
07/14/2016 12:33:44:  Epoch[17 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14911509 * 1280; EvalErrorPrediction = 0.06406250 * 1280; time = 0.0752s; samplesPerSecond = 17015.8
07/14/2016 12:33:44:  Epoch[17 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15323792 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0407s; samplesPerSecond = 31465.1
07/14/2016 12:33:44: Finished Epoch[17 of 50]: [Training] CrossEntropyWithSoftmax = 0.15964144 * 10000; EvalErrorPrediction = 0.07370000 * 10000; totalSamplesSeen = 170000; learningRatePerSample = 0.1; epochTime=0.542653s
07/14/2016 12:33:44: SGD: Saving checkpoint model '/tmp/cntk-test-20160714122957.627315/Speech_Simple@release_cpu/models/simple.dnn.17'

07/14/2016 12:33:44: Starting Epoch 18: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 17: frames [170000..180000] (first sequence at sample 170000), data subset 0 of 1

07/14/2016 12:33:44: Starting minibatch loop.
07/14/2016 12:33:44:  Epoch[18 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15964607 * 1280; EvalErrorPrediction = 0.06718750 * 1280; time = 0.0501s; samplesPerSecond = 25561.1
07/14/2016 12:33:44:  Epoch[18 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15260020 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 0.0380s; samplesPerSecond = 33659.4
07/14/2016 12:33:44:  Epoch[18 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17087312 * 1280; EvalErrorPrediction = 0.08359375 * 1280; time = 0.0470s; samplesPerSecond = 27212.6
07/14/2016 12:33:44:  Epoch[18 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15228090 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 0.0616s; samplesPerSecond = 20785.0
07/14/2016 12:33:44:  Epoch[18 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.18577013 * 1280; EvalErrorPrediction = 0.08437500 * 1280; time = 0.0496s; samplesPerSecond = 25803.9
07/14/2016 12:33:44:  Epoch[18 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16892061 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0419s; samplesPerSecond = 30581.8
07/14/2016 12:33:44:  Epoch[18 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15040522 * 1280; EvalErrorPrediction = 0.06875000 * 1280; time = 0.0612s; samplesPerSecond = 20919.1
07/14/2016 12:33:44: Finished Epoch[18 of 50]: [Training] CrossEntropyWithSoftmax = 0.16220587 * 10000; EvalErrorPrediction = 0.07510000 * 10000; totalSamplesSeen = 180000; learningRatePerSample = 0.1; epochTime=0.395656s
07/14/2016 12:33:44: SGD: Saving checkpoint model '/tmp/cntk-test-20160714122957.627315/Speech_Simple@release_cpu/models/simple.dnn.18'

07/14/2016 12:33:44: Starting Epoch 19: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 18: frames [180000..190000] (first sequence at sample 180000), data subset 0 of 1

07/14/2016 12:33:44: Starting minibatch loop.
07/14/2016 12:33:44:  Epoch[19 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.14636862 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0618s; samplesPerSecond = 20717.7
07/14/2016 12:33:44:  Epoch[19 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15948336 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0395s; samplesPerSecond = 32443.7
07/14/2016 12:33:44:  Epoch[19 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16777477 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0640s; samplesPerSecond = 19994.7
07/14/2016 12:33:44:  Epoch[19 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.17910833 * 1280; EvalErrorPrediction = 0.08671875 * 1280; time = 0.0435s; samplesPerSecond = 29454.4
07/14/2016 12:33:44:  Epoch[19 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.18129115 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0379s; samplesPerSecond = 33757.9
07/14/2016 12:33:44:  Epoch[19 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.19801235 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.1001s; samplesPerSecond = 12788.9
07/14/2016 12:33:44:  Epoch[19 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15825043 * 1280; EvalErrorPrediction = 0.06875000 * 1280; time = 0.0438s; samplesPerSecond = 29208.4
07/14/2016 12:33:44: Finished Epoch[19 of 50]: [Training] CrossEntropyWithSoftmax = 0.16814883 * 10000; EvalErrorPrediction = 0.07810000 * 10000; totalSamplesSeen = 190000; learningRatePerSample = 0.1; epochTime=0.427713s
07/14/2016 12:33:44: SGD: Saving checkpoint model '/tmp/cntk-test-20160714122957.627315/Speech_Simple@release_cpu/models/simple.dnn.19'

07/14/2016 12:33:44: Starting Epoch 20: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 19: frames [190000..200000] (first sequence at sample 190000), data subset 0 of 1

07/14/2016 12:33:44: Starting minibatch loop.
07/14/2016 12:33:45:  Epoch[20 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16492792 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.1119s; samplesPerSecond = 11440.1
07/14/2016 12:33:45:  Epoch[20 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.18700212 * 1280; EvalErrorPrediction = 0.09531250 * 1280; time = 0.0467s; samplesPerSecond = 27405.5
07/14/2016 12:33:45:  Epoch[20 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17428069 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0426s; samplesPerSecond = 30015.9
07/14/2016 12:33:45:  Epoch[20 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15516224 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 0.0439s; samplesPerSecond = 29167.8
07/14/2016 12:33:45:  Epoch[20 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16162639 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 0.0918s; samplesPerSecond = 13948.7
07/14/2016 12:33:45:  Epoch[20 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.18605671 * 1280; EvalErrorPrediction = 0.08750000 * 1280; time = 0.0899s; samplesPerSecond = 14233.0
07/14/2016 12:33:45:  Epoch[20 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16932993 * 1280; EvalErrorPrediction = 0.06484375 * 1280; time = 0.0514s; samplesPerSecond = 24912.9
07/14/2016 12:33:45: Finished Epoch[20 of 50]: [Training] CrossEntropyWithSoftmax = 0.16857257 * 10000; EvalErrorPrediction = 0.07850000 * 10000; totalSamplesSeen = 200000; learningRatePerSample = 0.1; epochTime=0.538916s
07/14/2016 12:33:45: SGD: Saving checkpoint model '/tmp/cntk-test-20160714122957.627315/Speech_Simple@release_cpu/models/simple.dnn.20'

07/14/2016 12:33:45: Starting Epoch 21: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 20: frames [200000..210000] (first sequence at sample 200000), data subset 0 of 1

07/14/2016 12:33:45: Starting minibatch loop.
07/14/2016 12:33:45:  Epoch[21 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16475260 * 1280; EvalErrorPrediction = 0.08359375 * 1280; time = 0.0382s; samplesPerSecond = 33512.2
07/14/2016 12:33:45:  Epoch[21 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15382960 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.0390s; samplesPerSecond = 32779.3
07/14/2016 12:33:45:  Epoch[21 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15873981 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0365s; samplesPerSecond = 35068.5
07/14/2016 12:33:45:  Epoch[21 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16323705 * 1280; EvalErrorPrediction = 0.06640625 * 1280; time = 0.0489s; samplesPerSecond = 26199.4
07/14/2016 12:33:45:  Epoch[21 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.17472167 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0377s; samplesPerSecond = 33939.7
07/14/2016 12:33:45:  Epoch[21 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15822458 * 1280; EvalErrorPrediction = 0.06250000 * 1280; time = 0.0863s; samplesPerSecond = 14839.0
07/14/2016 12:33:45:  Epoch[21 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.18187141 * 1280; EvalErrorPrediction = 0.08750000 * 1280; time = 0.0578s; samplesPerSecond = 22158.0
07/14/2016 12:33:45: Finished Epoch[21 of 50]: [Training] CrossEntropyWithSoftmax = 0.16527875 * 10000; EvalErrorPrediction = 0.07540000 * 10000; totalSamplesSeen = 210000; learningRatePerSample = 0.1; epochTime=0.389322s
07/14/2016 12:33:45: SGD: Saving checkpoint model '/tmp/cntk-test-20160714122957.627315/Speech_Simple@release_cpu/models/simple.dnn.21'

07/14/2016 12:33:45: Starting Epoch 22: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 21: frames [210000..220000] (first sequence at sample 210000), data subset 0 of 1

07/14/2016 12:33:45: Starting minibatch loop.
07/14/2016 12:33:45:  Epoch[22 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.20337038 * 1280; EvalErrorPrediction = 0.09765625 * 1280; time = 0.0425s; samplesPerSecond = 30134.0
07/14/2016 12:33:45:  Epoch[22 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17333016 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0424s; samplesPerSecond = 30201.5
07/14/2016 12:33:46:  Epoch[22 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16090860 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0626s; samplesPerSecond = 20441.7
07/14/2016 12:33:46:  Epoch[22 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15491724 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0402s; samplesPerSecond = 31863.8
07/14/2016 12:33:46:  Epoch[22 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16119027 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 0.0423s; samplesPerSecond = 30225.7
07/14/2016 12:33:46:  Epoch[22 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16201906 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0388s; samplesPerSecond = 32980.3
07/14/2016 12:33:46:  Epoch[22 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17937288 * 1280; EvalErrorPrediction = 0.08671875 * 1280; time = 0.0784s; samplesPerSecond = 16328.4
07/14/2016 12:33:46: Finished Epoch[22 of 50]: [Training] CrossEntropyWithSoftmax = 0.16656190 * 10000; EvalErrorPrediction = 0.07760000 * 10000; totalSamplesSeen = 220000; learningRatePerSample = 0.1; epochTime=0.397084s
07/14/2016 12:33:46: SGD: Saving checkpoint model '/tmp/cntk-test-20160714122957.627315/Speech_Simple@release_cpu/models/simple.dnn.22'

07/14/2016 12:33:46: Starting Epoch 23: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 22: frames [220000..230000] (first sequence at sample 220000), data subset 0 of 1

07/14/2016 12:33:46: Starting minibatch loop.
07/14/2016 12:33:46:  Epoch[23 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17149630 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 0.0392s; samplesPerSecond = 32663.9
07/14/2016 12:33:46:  Epoch[23 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17126255 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0493s; samplesPerSecond = 25952.4
07/14/2016 12:33:46:  Epoch[23 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15208163 * 1280; EvalErrorPrediction = 0.06875000 * 1280; time = 0.0583s; samplesPerSecond = 21956.2
07/14/2016 12:33:46:  Epoch[23 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15624132 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0529s; samplesPerSecond = 24175.1
07/14/2016 12:33:46:  Epoch[23 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16128097 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0632s; samplesPerSecond = 20250.6
07/14/2016 12:33:46:  Epoch[23 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.13963528 * 1280; EvalErrorPrediction = 0.06875000 * 1280; time = 0.0827s; samplesPerSecond = 15471.8
07/14/2016 12:33:46:  Epoch[23 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16915150 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0627s; samplesPerSecond = 20430.0
07/14/2016 12:33:46: Finished Epoch[23 of 50]: [Training] CrossEntropyWithSoftmax = 0.15939630 * 10000; EvalErrorPrediction = 0.07480000 * 10000; totalSamplesSeen = 230000; learningRatePerSample = 0.1; epochTime=0.476649s
07/14/2016 12:33:46: SGD: Saving checkpoint model '/tmp/cntk-test-20160714122957.627315/Speech_Simple@release_cpu/models/simple.dnn.23'

07/14/2016 12:33:46: Starting Epoch 24: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 23: frames [230000..240000] (first sequence at sample 230000), data subset 0 of 1

07/14/2016 12:33:46: Starting minibatch loop.
07/14/2016 12:33:46:  Epoch[24 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17135580 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.1032s; samplesPerSecond = 12408.0
07/14/2016 12:33:46:  Epoch[24 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15298202 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 0.0660s; samplesPerSecond = 19379.3
07/14/2016 12:33:46:  Epoch[24 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16153097 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0427s; samplesPerSecond = 29960.4
07/14/2016 12:33:47:  Epoch[24 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16532121 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0929s; samplesPerSecond = 13772.8
07/14/2016 12:33:47:  Epoch[24 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16722107 * 1280; EvalErrorPrediction = 0.06796875 * 1280; time = 0.0911s; samplesPerSecond = 14054.8
07/14/2016 12:33:47:  Epoch[24 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17550230 * 1280; EvalErrorPrediction = 0.08671875 * 1280; time = 0.0570s; samplesPerSecond = 22461.7
07/14/2016 12:33:47:  Epoch[24 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16362991 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0808s; samplesPerSecond = 15843.7
07/14/2016 12:33:47: Finished Epoch[24 of 50]: [Training] CrossEntropyWithSoftmax = 0.16683051 * 10000; EvalErrorPrediction = 0.07720000 * 10000; totalSamplesSeen = 240000; learningRatePerSample = 0.1; epochTime=0.584933s
07/14/2016 12:33:47: SGD: Saving checkpoint model '/tmp/cntk-test-20160714122957.627315/Speech_Simple@release_cpu/models/simple.dnn.24'

07/14/2016 12:33:47: Starting Epoch 25: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 24: frames [240000..250000] (first sequence at sample 240000), data subset 0 of 1

07/14/2016 12:33:47: Starting minibatch loop.
07/14/2016 12:33:47:  Epoch[25 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.18008139 * 1280; EvalErrorPrediction = 0.08437500 * 1280; time = 0.0866s; samplesPerSecond = 14783.7
07/14/2016 12:33:47:  Epoch[25 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.18820145 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0405s; samplesPerSecond = 31590.9
07/14/2016 12:33:47:  Epoch[25 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16654949 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0416s; samplesPerSecond = 30767.0
07/14/2016 12:33:47:  Epoch[25 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.17137508 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0419s; samplesPerSecond = 30573.0
07/14/2016 12:33:47:  Epoch[25 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15490355 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0635s; samplesPerSecond = 20155.3
07/14/2016 12:33:47:  Epoch[25 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14499702 * 1280; EvalErrorPrediction = 0.06484375 * 1280; time = 0.0521s; samplesPerSecond = 24570.0
07/14/2016 12:33:47:  Epoch[25 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16295919 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0433s; samplesPerSecond = 29536.6
07/14/2016 12:33:47: Finished Epoch[25 of 50]: [Training] CrossEntropyWithSoftmax = 0.16751575 * 10000; EvalErrorPrediction = 0.07780000 * 10000; totalSamplesSeen = 250000; learningRatePerSample = 0.1; epochTime=0.485784s
07/14/2016 12:33:47: SGD: Saving checkpoint model '/tmp/cntk-test-20160714122957.627315/Speech_Simple@release_cpu/models/simple.dnn.25'

07/14/2016 12:33:47: Starting Epoch 26: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 25: frames [250000..260000] (first sequence at sample 250000), data subset 0 of 1

07/14/2016 12:33:47: Starting minibatch loop.
07/14/2016 12:33:47:  Epoch[26 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16835831 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0651s; samplesPerSecond = 19650.0
07/14/2016 12:33:47:  Epoch[26 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15105823 * 1280; EvalErrorPrediction = 0.06718750 * 1280; time = 0.0372s; samplesPerSecond = 34439.2
07/14/2016 12:33:47:  Epoch[26 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15089962 * 1280; EvalErrorPrediction = 0.06875000 * 1280; time = 0.0446s; samplesPerSecond = 28716.3
07/14/2016 12:33:48:  Epoch[26 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15928082 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0641s; samplesPerSecond = 19980.0
07/14/2016 12:33:48:  Epoch[26 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.17029176 * 1280; EvalErrorPrediction = 0.08593750 * 1280; time = 0.0444s; samplesPerSecond = 28800.3
07/14/2016 12:33:48:  Epoch[26 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14526391 * 1280; EvalErrorPrediction = 0.06484375 * 1280; time = 0.0711s; samplesPerSecond = 18011.9
07/14/2016 12:33:48:  Epoch[26 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17606630 * 1280; EvalErrorPrediction = 0.08593750 * 1280; time = 0.0407s; samplesPerSecond = 31449.6
07/14/2016 12:33:48: Finished Epoch[26 of 50]: [Training] CrossEntropyWithSoftmax = 0.15908248 * 10000; EvalErrorPrediction = 0.07440000 * 10000; totalSamplesSeen = 260000; learningRatePerSample = 0.1; epochTime=0.406862s
07/14/2016 12:33:48: SGD: Saving checkpoint model '/tmp/cntk-test-20160714122957.627315/Speech_Simple@release_cpu/models/simple.dnn.26'

07/14/2016 12:33:48: Starting Epoch 27: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 26: frames [260000..270000] (first sequence at sample 260000), data subset 0 of 1

07/14/2016 12:33:48: Starting minibatch loop.
07/14/2016 12:33:48:  Epoch[27 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15696132 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0663s; samplesPerSecond = 19318.1
07/14/2016 12:33:48:  Epoch[27 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16518061 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0375s; samplesPerSecond = 34170.7
07/14/2016 12:33:48:  Epoch[27 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15267425 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0449s; samplesPerSecond = 28514.8
07/14/2016 12:33:48:  Epoch[27 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16557865 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0649s; samplesPerSecond = 19709.6
07/14/2016 12:33:48:  Epoch[27 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15200953 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0769s; samplesPerSecond = 16642.0
07/14/2016 12:33:48:  Epoch[27 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15047340 * 1280; EvalErrorPrediction = 0.06640625 * 1280; time = 0.0493s; samplesPerSecond = 25962.4
07/14/2016 12:33:48:  Epoch[27 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.18083782 * 1280; EvalErrorPrediction = 0.08906250 * 1280; time = 0.0358s; samplesPerSecond = 35764.2
07/14/2016 12:33:48: Finished Epoch[27 of 50]: [Training] CrossEntropyWithSoftmax = 0.15806140 * 10000; EvalErrorPrediction = 0.07550000 * 10000; totalSamplesSeen = 270000; learningRatePerSample = 0.1; epochTime=0.415758s
07/14/2016 12:33:48: SGD: Saving checkpoint model '/tmp/cntk-test-20160714122957.627315/Speech_Simple@release_cpu/models/simple.dnn.27'

07/14/2016 12:33:48: Starting Epoch 28: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 27: frames [270000..280000] (first sequence at sample 270000), data subset 0 of 1

07/14/2016 12:33:48: Starting minibatch loop.
07/14/2016 12:33:48:  Epoch[28 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16852876 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0429s; samplesPerSecond = 29863.3
07/14/2016 12:33:48:  Epoch[28 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14662155 * 1280; EvalErrorPrediction = 0.06328125 * 1280; time = 0.0712s; samplesPerSecond = 17973.0
07/14/2016 12:33:48:  Epoch[28 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14875860 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 0.1041s; samplesPerSecond = 12292.9
07/14/2016 12:33:48:  Epoch[28 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16199880 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0416s; samplesPerSecond = 30803.3
07/14/2016 12:33:48:  Epoch[28 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.18050461 * 1280; EvalErrorPrediction = 0.08906250 * 1280; time = 0.0385s; samplesPerSecond = 33262.3
07/14/2016 12:33:49:  Epoch[28 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15580540 * 1280; EvalErrorPrediction = 0.06875000 * 1280; time = 0.0699s; samplesPerSecond = 18319.0
07/14/2016 12:33:49:  Epoch[28 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16533012 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0421s; samplesPerSecond = 30424.0
07/14/2016 12:33:49: Finished Epoch[28 of 50]: [Training] CrossEntropyWithSoftmax = 0.16206692 * 10000; EvalErrorPrediction = 0.07590000 * 10000; totalSamplesSeen = 280000; learningRatePerSample = 0.1; epochTime=0.459007s
07/14/2016 12:33:49: SGD: Saving checkpoint model '/tmp/cntk-test-20160714122957.627315/Speech_Simple@release_cpu/models/simple.dnn.28'

07/14/2016 12:33:49: Starting Epoch 29: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 28: frames [280000..290000] (first sequence at sample 280000), data subset 0 of 1

07/14/2016 12:33:49: Starting minibatch loop.
07/14/2016 12:33:49:  Epoch[29 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16519994 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0417s; samplesPerSecond = 30685.1
07/14/2016 12:33:49:  Epoch[29 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15904771 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0479s; samplesPerSecond = 26725.7
07/14/2016 12:33:49:  Epoch[29 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16316509 * 1280; EvalErrorPrediction = 0.06875000 * 1280; time = 0.0642s; samplesPerSecond = 19945.5
07/14/2016 12:33:49:  Epoch[29 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15609016 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0608s; samplesPerSecond = 21063.0
07/14/2016 12:33:49:  Epoch[29 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14817915 * 1280; EvalErrorPrediction = 0.06796875 * 1280; time = 0.0419s; samplesPerSecond = 30533.6
07/14/2016 12:33:49:  Epoch[29 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15711107 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0461s; samplesPerSecond = 27788.6
07/14/2016 12:33:49:  Epoch[29 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15871382 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0530s; samplesPerSecond = 24134.6
07/14/2016 12:33:49: Finished Epoch[29 of 50]: [Training] CrossEntropyWithSoftmax = 0.15744955 * 10000; EvalErrorPrediction = 0.07340000 * 10000; totalSamplesSeen = 290000; learningRatePerSample = 0.1; epochTime=0.390575s
07/14/2016 12:33:49: SGD: Saving checkpoint model '/tmp/cntk-test-20160714122957.627315/Speech_Simple@release_cpu/models/simple.dnn.29'

07/14/2016 12:33:49: Starting Epoch 30: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 29: frames [290000..300000] (first sequence at sample 290000), data subset 0 of 1

07/14/2016 12:33:49: Starting minibatch loop.
07/14/2016 12:33:49:  Epoch[30 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.14856814 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0594s; samplesPerSecond = 21554.3
07/14/2016 12:33:49:  Epoch[30 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15614189 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0361s; samplesPerSecond = 35489.5
07/14/2016 12:33:49:  Epoch[30 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.18894193 * 1280; EvalErrorPrediction = 0.08593750 * 1280; time = 0.0414s; samplesPerSecond = 30890.3
07/14/2016 12:33:49:  Epoch[30 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14171619 * 1280; EvalErrorPrediction = 0.06484375 * 1280; time = 0.0705s; samplesPerSecond = 18146.2
07/14/2016 12:33:49:  Epoch[30 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14764414 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 0.0379s; samplesPerSecond = 33800.7
07/14/2016 12:33:49:  Epoch[30 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16566000 * 1280; EvalErrorPrediction = 0.08593750 * 1280; time = 0.0700s; samplesPerSecond = 18280.2
07/14/2016 12:33:49:  Epoch[30 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16000910 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.1285s; samplesPerSecond = 9963.9
07/14/2016 12:33:50: Finished Epoch[30 of 50]: [Training] CrossEntropyWithSoftmax = 0.15872233 * 10000; EvalErrorPrediction = 0.07530000 * 10000; totalSamplesSeen = 300000; learningRatePerSample = 0.1; epochTime=0.486085s
07/14/2016 12:33:50: SGD: Saving checkpoint model '/tmp/cntk-test-20160714122957.627315/Speech_Simple@release_cpu/models/simple.dnn.30'

07/14/2016 12:33:50: Starting Epoch 31: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 30: frames [300000..310000] (first sequence at sample 300000), data subset 0 of 1

07/14/2016 12:33:50: Starting minibatch loop.
07/14/2016 12:33:50:  Epoch[31 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16231698 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0393s; samplesPerSecond = 32570.8
07/14/2016 12:33:50:  Epoch[31 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17015637 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0576s; samplesPerSecond = 22228.8
07/14/2016 12:33:50:  Epoch[31 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14309304 * 1280; EvalErrorPrediction = 0.06171875 * 1280; time = 0.0388s; samplesPerSecond = 33011.8
07/14/2016 12:33:50:  Epoch[31 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15054049 * 1280; EvalErrorPrediction = 0.06640625 * 1280; time = 0.0532s; samplesPerSecond = 24070.1
07/14/2016 12:33:50:  Epoch[31 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15275049 * 1280; EvalErrorPrediction = 0.06875000 * 1280; time = 0.0646s; samplesPerSecond = 19814.2
07/14/2016 12:33:50:  Epoch[31 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.13504786 * 1280; EvalErrorPrediction = 0.06562500 * 1280; time = 0.0421s; samplesPerSecond = 30385.8
07/14/2016 12:33:50:  Epoch[31 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17576618 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0424s; samplesPerSecond = 30205.1
07/14/2016 12:33:50: Finished Epoch[31 of 50]: [Training] CrossEntropyWithSoftmax = 0.15947744 * 10000; EvalErrorPrediction = 0.07340000 * 10000; totalSamplesSeen = 310000; learningRatePerSample = 0.1; epochTime=0.375297s
07/14/2016 12:33:50: SGD: Saving checkpoint model '/tmp/cntk-test-20160714122957.627315/Speech_Simple@release_cpu/models/simple.dnn.31'

07/14/2016 12:33:50: Starting Epoch 32: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 31: frames [310000..320000] (first sequence at sample 310000), data subset 0 of 1

07/14/2016 12:33:50: Starting minibatch loop.
07/14/2016 12:33:50:  Epoch[32 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16154064 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0412s; samplesPerSecond = 31102.7
07/14/2016 12:33:50:  Epoch[32 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16160506 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0283s; samplesPerSecond = 45308.1
07/14/2016 12:33:50:  Epoch[32 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.13378718 * 1280; EvalErrorPrediction = 0.06640625 * 1280; time = 0.0926s; samplesPerSecond = 13817.8
07/14/2016 12:33:50:  Epoch[32 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16373558 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0415s; samplesPerSecond = 30838.9
07/14/2016 12:33:50:  Epoch[32 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16839790 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0423s; samplesPerSecond = 30285.8
07/14/2016 12:33:50:  Epoch[32 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16848178 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0390s; samplesPerSecond = 32819.7
07/14/2016 12:33:50:  Epoch[32 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14901552 * 1280; EvalErrorPrediction = 0.06250000 * 1280; time = 0.0286s; samplesPerSecond = 44778.7
07/14/2016 12:33:50: Finished Epoch[32 of 50]: [Training] CrossEntropyWithSoftmax = 0.16197542 * 10000; EvalErrorPrediction = 0.07480000 * 10000; totalSamplesSeen = 320000; learningRatePerSample = 0.1; epochTime=0.34s
07/14/2016 12:33:50: SGD: Saving checkpoint model '/tmp/cntk-test-20160714122957.627315/Speech_Simple@release_cpu/models/simple.dnn.32'

07/14/2016 12:33:50: Starting Epoch 33: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 32: frames [320000..330000] (first sequence at sample 320000), data subset 0 of 1

07/14/2016 12:33:50: Starting minibatch loop.
07/14/2016 12:33:50:  Epoch[33 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17129622 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0413s; samplesPerSecond = 30986.0
07/14/2016 12:33:50:  Epoch[33 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15054884 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.1057s; samplesPerSecond = 12108.3
07/14/2016 12:33:50:  Epoch[33 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14387212 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 0.0410s; samplesPerSecond = 31237.8
07/14/2016 12:33:50:  Epoch[33 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16222110 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0567s; samplesPerSecond = 22572.6
07/14/2016 12:33:51:  Epoch[33 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16773157 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.1300s; samplesPerSecond = 9848.0
07/14/2016 12:33:51:  Epoch[33 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15197811 * 1280; EvalErrorPrediction = 0.06875000 * 1280; time = 0.0533s; samplesPerSecond = 24023.6
07/14/2016 12:33:51:  Epoch[33 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17714443 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 0.0477s; samplesPerSecond = 26809.1
07/14/2016 12:33:51: Finished Epoch[33 of 50]: [Training] CrossEntropyWithSoftmax = 0.16108008 * 10000; EvalErrorPrediction = 0.07560000 * 10000; totalSamplesSeen = 330000; learningRatePerSample = 0.1; epochTime=0.611185s
07/14/2016 12:33:51: SGD: Saving checkpoint model '/tmp/cntk-test-20160714122957.627315/Speech_Simple@release_cpu/models/simple.dnn.33'

07/14/2016 12:33:51: Starting Epoch 34: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 33: frames [330000..340000] (first sequence at sample 330000), data subset 0 of 1

07/14/2016 12:33:51: Starting minibatch loop.
07/14/2016 12:33:51:  Epoch[34 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17145665 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0847s; samplesPerSecond = 15113.2
07/14/2016 12:33:51:  Epoch[34 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16205611 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0478s; samplesPerSecond = 26771.0
07/14/2016 12:33:51:  Epoch[34 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16336939 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0425s; samplesPerSecond = 30148.1
07/14/2016 12:33:51:  Epoch[34 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15191164 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.0446s; samplesPerSecond = 28692.5
07/14/2016 12:33:51:  Epoch[34 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14747019 * 1280; EvalErrorPrediction = 0.06562500 * 1280; time = 0.0457s; samplesPerSecond = 28000.2
07/14/2016 12:33:51:  Epoch[34 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15344009 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0438s; samplesPerSecond = 29200.4
07/14/2016 12:33:51:  Epoch[34 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15842562 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0663s; samplesPerSecond = 19300.7
07/14/2016 12:33:51: Finished Epoch[34 of 50]: [Training] CrossEntropyWithSoftmax = 0.15948165 * 10000; EvalErrorPrediction = 0.07500000 * 10000; totalSamplesSeen = 340000; learningRatePerSample = 0.1; epochTime=0.421556s
07/14/2016 12:33:51: SGD: Saving checkpoint model '/tmp/cntk-test-20160714122957.627315/Speech_Simple@release_cpu/models/simple.dnn.34'

07/14/2016 12:33:51: Starting Epoch 35: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 34: frames [340000..350000] (first sequence at sample 340000), data subset 0 of 1

07/14/2016 12:33:51: Starting minibatch loop.
07/14/2016 12:33:51:  Epoch[35 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16640428 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0589s; samplesPerSecond = 21732.5
07/14/2016 12:33:51:  Epoch[35 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15777577 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0750s; samplesPerSecond = 17059.6
07/14/2016 12:33:51:  Epoch[35 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16434128 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0504s; samplesPerSecond = 25387.3
07/14/2016 12:33:52:  Epoch[35 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15438242 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0671s; samplesPerSecond = 19071.7
07/14/2016 12:33:52:  Epoch[35 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14508672 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 0.0815s; samplesPerSecond = 15700.1
07/14/2016 12:33:52:  Epoch[35 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14978857 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.1849s; samplesPerSecond = 6923.6
07/14/2016 12:33:52:  Epoch[35 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.18113050 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0605s; samplesPerSecond = 21139.6
07/14/2016 12:33:52: Finished Epoch[35 of 50]: [Training] CrossEntropyWithSoftmax = 0.15992622 * 10000; EvalErrorPrediction = 0.07590000 * 10000; totalSamplesSeen = 350000; learningRatePerSample = 0.1; epochTime=0.624825s
07/14/2016 12:33:52: SGD: Saving checkpoint model '/tmp/cntk-test-20160714122957.627315/Speech_Simple@release_cpu/models/simple.dnn.35'

07/14/2016 12:33:52: Starting Epoch 36: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 35: frames [350000..360000] (first sequence at sample 350000), data subset 0 of 1

07/14/2016 12:33:52: Starting minibatch loop.
07/14/2016 12:33:52:  Epoch[36 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17041572 * 1280; EvalErrorPrediction = 0.08437500 * 1280; time = 0.0380s; samplesPerSecond = 33723.3
07/14/2016 12:33:52:  Epoch[36 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15814389 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0589s; samplesPerSecond = 21734.3
07/14/2016 12:33:52:  Epoch[36 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16349227 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 0.0387s; samplesPerSecond = 33094.6
07/14/2016 12:33:52:  Epoch[36 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16010098 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0435s; samplesPerSecond = 29449.7
07/14/2016 12:33:52:  Epoch[36 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15182309 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 0.0393s; samplesPerSecond = 32537.7
07/14/2016 12:33:52:  Epoch[36 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15396490 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0944s; samplesPerSecond = 13559.2
07/14/2016 12:33:52:  Epoch[36 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.18009357 * 1280; EvalErrorPrediction = 0.08593750 * 1280; time = 0.0436s; samplesPerSecond = 29368.6
07/14/2016 12:33:52: Finished Epoch[36 of 50]: [Training] CrossEntropyWithSoftmax = 0.16226083 * 10000; EvalErrorPrediction = 0.07700000 * 10000; totalSamplesSeen = 360000; learningRatePerSample = 0.1; epochTime=0.392422s
07/14/2016 12:33:52: SGD: Saving checkpoint model '/tmp/cntk-test-20160714122957.627315/Speech_Simple@release_cpu/models/simple.dnn.36'

07/14/2016 12:33:52: Starting Epoch 37: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 36: frames [360000..370000] (first sequence at sample 360000), data subset 0 of 1

07/14/2016 12:33:52: Starting minibatch loop.
07/14/2016 12:33:52:  Epoch[37 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15044581 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0570s; samplesPerSecond = 22460.5
07/14/2016 12:33:52:  Epoch[37 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15727519 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0433s; samplesPerSecond = 29554.4
07/14/2016 12:33:52:  Epoch[37 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17658706 * 1280; EvalErrorPrediction = 0.08750000 * 1280; time = 0.0593s; samplesPerSecond = 21588.8
07/14/2016 12:33:52:  Epoch[37 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15197978 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0372s; samplesPerSecond = 34375.3
07/14/2016 12:33:53:  Epoch[37 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15390072 * 1280; EvalErrorPrediction = 0.06718750 * 1280; time = 0.0401s; samplesPerSecond = 31946.5
07/14/2016 12:33:53:  Epoch[37 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14358773 * 1280; EvalErrorPrediction = 0.06718750 * 1280; time = 0.0385s; samplesPerSecond = 33248.5
07/14/2016 12:33:53:  Epoch[37 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16217842 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0447s; samplesPerSecond = 28612.9
07/14/2016 12:33:53: Finished Epoch[37 of 50]: [Training] CrossEntropyWithSoftmax = 0.15740476 * 10000; EvalErrorPrediction = 0.07510000 * 10000; totalSamplesSeen = 370000; learningRatePerSample = 0.1; epochTime=0.359694s
07/14/2016 12:33:53: SGD: Saving checkpoint model '/tmp/cntk-test-20160714122957.627315/Speech_Simple@release_cpu/models/simple.dnn.37'

07/14/2016 12:33:53: Starting Epoch 38: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 37: frames [370000..380000] (first sequence at sample 370000), data subset 0 of 1

07/14/2016 12:33:53: Starting minibatch loop.
07/14/2016 12:33:53:  Epoch[38 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16619613 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 0.0420s; samplesPerSecond = 30471.1
07/14/2016 12:33:53:  Epoch[38 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15460262 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 0.0592s; samplesPerSecond = 21637.3
07/14/2016 12:33:53:  Epoch[38 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15720551 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0515s; samplesPerSecond = 24839.4
07/14/2016 12:33:53:  Epoch[38 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.17886009 * 1280; EvalErrorPrediction = 0.08437500 * 1280; time = 0.0468s; samplesPerSecond = 27371.5
07/14/2016 12:33:53:  Epoch[38 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16477385 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0439s; samplesPerSecond = 29166.5
07/14/2016 12:33:53:  Epoch[38 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16247454 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0436s; samplesPerSecond = 29350.4
07/14/2016 12:33:53:  Epoch[38 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14554272 * 1280; EvalErrorPrediction = 0.06875000 * 1280; time = 0.0398s; samplesPerSecond = 32126.9
07/14/2016 12:33:53: Finished Epoch[38 of 50]: [Training] CrossEntropyWithSoftmax = 0.16285479 * 10000; EvalErrorPrediction = 0.07760000 * 10000; totalSamplesSeen = 380000; learningRatePerSample = 0.1; epochTime=0.369336s
07/14/2016 12:33:53: SGD: Saving checkpoint model '/tmp/cntk-test-20160714122957.627315/Speech_Simple@release_cpu/models/simple.dnn.38'

07/14/2016 12:33:53: Starting Epoch 39: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 38: frames [380000..390000] (first sequence at sample 380000), data subset 0 of 1

07/14/2016 12:33:53: Starting minibatch loop.
07/14/2016 12:33:53:  Epoch[39 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15448341 * 1280; EvalErrorPrediction = 0.06484375 * 1280; time = 0.0443s; samplesPerSecond = 28880.9
07/14/2016 12:33:53:  Epoch[39 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17907648 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0735s; samplesPerSecond = 17413.1
07/14/2016 12:33:53:  Epoch[39 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16982002 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 0.0924s; samplesPerSecond = 13848.3
07/14/2016 12:33:53:  Epoch[39 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16798797 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.1435s; samplesPerSecond = 8919.9
07/14/2016 12:33:54:  Epoch[39 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14459414 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.1350s; samplesPerSecond = 9483.7
07/14/2016 12:33:54:  Epoch[39 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.13847246 * 1280; EvalErrorPrediction = 0.06171875 * 1280; time = 0.0937s; samplesPerSecond = 13659.5
07/14/2016 12:33:54:  Epoch[39 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15802555 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.0554s; samplesPerSecond = 23116.0
07/14/2016 12:33:54: Finished Epoch[39 of 50]: [Training] CrossEntropyWithSoftmax = 0.16279224 * 10000; EvalErrorPrediction = 0.07570000 * 10000; totalSamplesSeen = 390000; learningRatePerSample = 0.1; epochTime=0.681401s
07/14/2016 12:33:54: SGD: Saving checkpoint model '/tmp/cntk-test-20160714122957.627315/Speech_Simple@release_cpu/models/simple.dnn.39'

07/14/2016 12:33:54: Starting Epoch 40: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 39: frames [390000..400000] (first sequence at sample 390000), data subset 0 of 1

07/14/2016 12:33:54: Starting minibatch loop.
07/14/2016 12:33:54:  Epoch[40 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16840934 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0383s; samplesPerSecond = 33415.1
07/14/2016 12:33:54:  Epoch[40 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15842315 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.1267s; samplesPerSecond = 10100.1
07/14/2016 12:33:54:  Epoch[40 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15689163 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0603s; samplesPerSecond = 21236.7
07/14/2016 12:33:54:  Epoch[40 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15319600 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0546s; samplesPerSecond = 23450.1
07/14/2016 12:33:54:  Epoch[40 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15504360 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0468s; samplesPerSecond = 27330.6
07/14/2016 12:33:54:  Epoch[40 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16077409 * 1280; EvalErrorPrediction = 0.06875000 * 1280; time = 0.0594s; samplesPerSecond = 21532.1
07/14/2016 12:33:54:  Epoch[40 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.18390646 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 0.0432s; samplesPerSecond = 29643.4
07/14/2016 12:33:54: Finished Epoch[40 of 50]: [Training] CrossEntropyWithSoftmax = 0.16319042 * 10000; EvalErrorPrediction = 0.07580000 * 10000; totalSamplesSeen = 400000; learningRatePerSample = 0.1; epochTime=0.469686s
07/14/2016 12:33:54: SGD: Saving checkpoint model '/tmp/cntk-test-20160714122957.627315/Speech_Simple@release_cpu/models/simple.dnn.40'

07/14/2016 12:33:54: Starting Epoch 41: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 40: frames [400000..410000] (first sequence at sample 400000), data subset 0 of 1

07/14/2016 12:33:54: Starting minibatch loop.
07/14/2016 12:33:54:  Epoch[41 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17165155 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0390s; samplesPerSecond = 32859.3
07/14/2016 12:33:54:  Epoch[41 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15057638 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0462s; samplesPerSecond = 27708.0
07/14/2016 12:33:54:  Epoch[41 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16082604 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0303s; samplesPerSecond = 42287.5
07/14/2016 12:33:54:  Epoch[41 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15875053 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0583s; samplesPerSecond = 21957.7
07/14/2016 12:33:54:  Epoch[41 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15556507 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0533s; samplesPerSecond = 24034.9
07/14/2016 12:33:54:  Epoch[41 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14324150 * 1280; EvalErrorPrediction = 0.05859375 * 1280; time = 0.0441s; samplesPerSecond = 29019.0
07/14/2016 12:33:54:  Epoch[41 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15218315 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.0385s; samplesPerSecond = 33278.7
07/14/2016 12:33:55: Finished Epoch[41 of 50]: [Training] CrossEntropyWithSoftmax = 0.15675808 * 10000; EvalErrorPrediction = 0.07280000 * 10000; totalSamplesSeen = 410000; learningRatePerSample = 0.1; epochTime=0.368728s
07/14/2016 12:33:55: SGD: Saving checkpoint model '/tmp/cntk-test-20160714122957.627315/Speech_Simple@release_cpu/models/simple.dnn.41'

07/14/2016 12:33:55: Starting Epoch 42: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 41: frames [410000..420000] (first sequence at sample 410000), data subset 0 of 1

07/14/2016 12:33:55: Starting minibatch loop.
07/14/2016 12:33:55:  Epoch[42 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17523915 * 1280; EvalErrorPrediction = 0.08906250 * 1280; time = 0.0506s; samplesPerSecond = 25283.5
07/14/2016 12:33:55:  Epoch[42 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15212477 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 0.0388s; samplesPerSecond = 32956.6
07/14/2016 12:33:55:  Epoch[42 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15521283 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 0.0356s; samplesPerSecond = 35962.1
07/14/2016 12:33:55:  Epoch[42 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15564127 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0400s; samplesPerSecond = 32009.6
07/14/2016 12:33:55:  Epoch[42 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16578217 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0495s; samplesPerSecond = 25857.5
07/14/2016 12:33:55:  Epoch[42 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14213266 * 1280; EvalErrorPrediction = 0.06718750 * 1280; time = 0.0407s; samplesPerSecond = 31478.2
07/14/2016 12:33:55:  Epoch[42 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15324860 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 0.0615s; samplesPerSecond = 20807.9
07/14/2016 12:33:55: Finished Epoch[42 of 50]: [Training] CrossEntropyWithSoftmax = 0.15690872 * 10000; EvalErrorPrediction = 0.07570000 * 10000; totalSamplesSeen = 420000; learningRatePerSample = 0.1; epochTime=0.36122s
07/14/2016 12:33:55: SGD: Saving checkpoint model '/tmp/cntk-test-20160714122957.627315/Speech_Simple@release_cpu/models/simple.dnn.42'

07/14/2016 12:33:55: Starting Epoch 43: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 42: frames [420000..430000] (first sequence at sample 420000), data subset 0 of 1

07/14/2016 12:33:55: Starting minibatch loop.
07/14/2016 12:33:55:  Epoch[43 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15386535 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0485s; samplesPerSecond = 26408.1
07/14/2016 12:33:55:  Epoch[43 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15090064 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0751s; samplesPerSecond = 17042.6
07/14/2016 12:33:55:  Epoch[43 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.13803682 * 1280; EvalErrorPrediction = 0.06171875 * 1280; time = 0.0308s; samplesPerSecond = 41573.3
07/14/2016 12:33:55:  Epoch[43 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15230093 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0367s; samplesPerSecond = 34870.7
07/14/2016 12:33:55:  Epoch[43 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14417667 * 1280; EvalErrorPrediction = 0.06640625 * 1280; time = 0.0352s; samplesPerSecond = 36322.4
07/14/2016 12:33:55:  Epoch[43 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17858133 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0483s; samplesPerSecond = 26498.8
07/14/2016 12:33:55:  Epoch[43 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17021179 * 1280; EvalErrorPrediction = 0.08437500 * 1280; time = 0.0469s; samplesPerSecond = 27292.7
07/14/2016 12:33:55: Finished Epoch[43 of 50]: [Training] CrossEntropyWithSoftmax = 0.15581418 * 10000; EvalErrorPrediction = 0.07420000 * 10000; totalSamplesSeen = 430000; learningRatePerSample = 0.1; epochTime=0.362072s
07/14/2016 12:33:55: SGD: Saving checkpoint model '/tmp/cntk-test-20160714122957.627315/Speech_Simple@release_cpu/models/simple.dnn.43'

07/14/2016 12:33:55: Starting Epoch 44: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 43: frames [430000..440000] (first sequence at sample 430000), data subset 0 of 1

07/14/2016 12:33:55: Starting minibatch loop.
07/14/2016 12:33:55:  Epoch[44 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16945850 * 1280; EvalErrorPrediction = 0.08906250 * 1280; time = 0.0536s; samplesPerSecond = 23885.5
07/14/2016 12:33:55:  Epoch[44 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.13544406 * 1280; EvalErrorPrediction = 0.06093750 * 1280; time = 0.0522s; samplesPerSecond = 24513.6
07/14/2016 12:33:55:  Epoch[44 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16303706 * 1280; EvalErrorPrediction = 0.08359375 * 1280; time = 0.0717s; samplesPerSecond = 17846.4
07/14/2016 12:33:55:  Epoch[44 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.19170256 * 1280; EvalErrorPrediction = 0.08437500 * 1280; time = 0.0443s; samplesPerSecond = 28889.3
07/14/2016 12:33:56:  Epoch[44 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.17427287 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0531s; samplesPerSecond = 24087.8
07/14/2016 12:33:56:  Epoch[44 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.21128740 * 1280; EvalErrorPrediction = 0.09296875 * 1280; time = 0.0496s; samplesPerSecond = 25783.6
07/14/2016 12:33:56:  Epoch[44 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.18788481 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.1183s; samplesPerSecond = 10816.6
07/14/2016 12:33:56: Finished Epoch[44 of 50]: [Training] CrossEntropyWithSoftmax = 0.17764906 * 10000; EvalErrorPrediction = 0.08200000 * 10000; totalSamplesSeen = 440000; learningRatePerSample = 0.1; epochTime=0.47706s
07/14/2016 12:33:56: SGD: Saving checkpoint model '/tmp/cntk-test-20160714122957.627315/Speech_Simple@release_cpu/models/simple.dnn.44'

07/14/2016 12:33:56: Starting Epoch 45: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 44: frames [440000..450000] (first sequence at sample 440000), data subset 0 of 1

07/14/2016 12:33:56: Starting minibatch loop.
07/14/2016 12:33:56:  Epoch[45 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.19548545 * 1280; EvalErrorPrediction = 0.08671875 * 1280; time = 0.0433s; samplesPerSecond = 29580.3
07/14/2016 12:33:56:  Epoch[45 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15311916 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.0395s; samplesPerSecond = 32434.6
07/14/2016 12:33:56:  Epoch[45 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15930483 * 1280; EvalErrorPrediction = 0.06875000 * 1280; time = 0.0458s; samplesPerSecond = 27962.9
07/14/2016 12:33:56:  Epoch[45 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.17239943 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0582s; samplesPerSecond = 21990.1
07/14/2016 12:33:56:  Epoch[45 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.12789493 * 1280; EvalErrorPrediction = 0.05703125 * 1280; time = 0.0392s; samplesPerSecond = 32675.6
07/14/2016 12:33:56:  Epoch[45 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.18878489 * 1280; EvalErrorPrediction = 0.09453125 * 1280; time = 0.0445s; samplesPerSecond = 28778.3
07/14/2016 12:33:56:  Epoch[45 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.18304195 * 1280; EvalErrorPrediction = 0.08750000 * 1280; time = 0.0748s; samplesPerSecond = 17112.5
07/14/2016 12:33:56: Finished Epoch[45 of 50]: [Training] CrossEntropyWithSoftmax = 0.16716315 * 10000; EvalErrorPrediction = 0.07740000 * 10000; totalSamplesSeen = 450000; learningRatePerSample = 0.1; epochTime=0.386144s
07/14/2016 12:33:56: SGD: Saving checkpoint model '/tmp/cntk-test-20160714122957.627315/Speech_Simple@release_cpu/models/simple.dnn.45'

07/14/2016 12:33:56: Starting Epoch 46: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 45: frames [450000..460000] (first sequence at sample 450000), data subset 0 of 1

07/14/2016 12:33:56: Starting minibatch loop.
07/14/2016 12:33:56:  Epoch[46 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17278781 * 1280; EvalErrorPrediction = 0.08437500 * 1280; time = 0.0509s; samplesPerSecond = 25157.2
07/14/2016 12:33:56:  Epoch[46 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15223329 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0405s; samplesPerSecond = 31634.6
07/14/2016 12:33:56:  Epoch[46 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16223400 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0386s; samplesPerSecond = 33152.0
07/14/2016 12:33:56:  Epoch[46 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.17466254 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 0.0811s; samplesPerSecond = 15778.9
07/14/2016 12:33:56:  Epoch[46 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.19236188 * 1280; EvalErrorPrediction = 0.09062500 * 1280; time = 0.0637s; samplesPerSecond = 20107.8
07/14/2016 12:33:56:  Epoch[46 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17003622 * 1280; EvalErrorPrediction = 0.08437500 * 1280; time = 0.0441s; samplesPerSecond = 29022.3
07/14/2016 12:33:57:  Epoch[46 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15896044 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0499s; samplesPerSecond = 25676.0
07/14/2016 12:33:57: Finished Epoch[46 of 50]: [Training] CrossEntropyWithSoftmax = 0.16901636 * 10000; EvalErrorPrediction = 0.08130000 * 10000; totalSamplesSeen = 460000; learningRatePerSample = 0.1; epochTime=0.451911s
07/14/2016 12:33:57: SGD: Saving checkpoint model '/tmp/cntk-test-20160714122957.627315/Speech_Simple@release_cpu/models/simple.dnn.46'

07/14/2016 12:33:57: Starting Epoch 47: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 46: frames [460000..470000] (first sequence at sample 460000), data subset 0 of 1

07/14/2016 12:33:57: Starting minibatch loop.
07/14/2016 12:33:57:  Epoch[47 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.19445362 * 1280; EvalErrorPrediction = 0.09062500 * 1280; time = 0.0854s; samplesPerSecond = 14980.2
07/14/2016 12:33:57:  Epoch[47 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17532339 * 1280; EvalErrorPrediction = 0.08671875 * 1280; time = 0.0360s; samplesPerSecond = 35524.0
07/14/2016 12:33:57:  Epoch[47 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15982275 * 1280; EvalErrorPrediction = 0.06718750 * 1280; time = 0.0404s; samplesPerSecond = 31695.7
07/14/2016 12:33:57:  Epoch[47 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.17681470 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 0.0584s; samplesPerSecond = 21928.7
07/14/2016 12:33:57:  Epoch[47 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.17092185 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0452s; samplesPerSecond = 28318.6
07/14/2016 12:33:57:  Epoch[47 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14961472 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0701s; samplesPerSecond = 18272.1
07/14/2016 12:33:57:  Epoch[47 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14567881 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 0.0428s; samplesPerSecond = 29879.3
07/14/2016 12:33:57: Finished Epoch[47 of 50]: [Training] CrossEntropyWithSoftmax = 0.16721079 * 10000; EvalErrorPrediction = 0.07690000 * 10000; totalSamplesSeen = 470000; learningRatePerSample = 0.1; epochTime=0.420881s
07/14/2016 12:33:57: SGD: Saving checkpoint model '/tmp/cntk-test-20160714122957.627315/Speech_Simple@release_cpu/models/simple.dnn.47'

07/14/2016 12:33:57: Starting Epoch 48: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 47: frames [470000..480000] (first sequence at sample 470000), data subset 0 of 1

07/14/2016 12:33:57: Starting minibatch loop.
07/14/2016 12:33:57:  Epoch[48 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.18766408 * 1280; EvalErrorPrediction = 0.08828125 * 1280; time = 0.0710s; samplesPerSecond = 18022.6
07/14/2016 12:33:57:  Epoch[48 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16356268 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 0.0761s; samplesPerSecond = 16825.1
07/14/2016 12:33:57:  Epoch[48 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16448779 * 1280; EvalErrorPrediction = 0.08593750 * 1280; time = 0.0618s; samplesPerSecond = 20727.1
07/14/2016 12:33:57:  Epoch[48 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15259590 * 1280; EvalErrorPrediction = 0.06328125 * 1280; time = 0.0374s; samplesPerSecond = 34252.1
07/14/2016 12:33:57:  Epoch[48 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.13187275 * 1280; EvalErrorPrediction = 0.05625000 * 1280; time = 0.0301s; samplesPerSecond = 42485.4
07/14/2016 12:33:57:  Epoch[48 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17249765 * 1280; EvalErrorPrediction = 0.08906250 * 1280; time = 0.0583s; samplesPerSecond = 21953.1
07/14/2016 12:33:57:  Epoch[48 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15977745 * 1280; EvalErrorPrediction = 0.08359375 * 1280; time = 0.0811s; samplesPerSecond = 15779.3
07/14/2016 12:33:57: Finished Epoch[48 of 50]: [Training] CrossEntropyWithSoftmax = 0.15953260 * 10000; EvalErrorPrediction = 0.07610000 * 10000; totalSamplesSeen = 480000; learningRatePerSample = 0.1; epochTime=0.48342s
07/14/2016 12:33:57: SGD: Saving checkpoint model '/tmp/cntk-test-20160714122957.627315/Speech_Simple@release_cpu/models/simple.dnn.48'

07/14/2016 12:33:57: Starting Epoch 49: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 48: frames [480000..490000] (first sequence at sample 480000), data subset 0 of 1

07/14/2016 12:33:57: Starting minibatch loop.
07/14/2016 12:33:58:  Epoch[49 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17180777 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 0.0557s; samplesPerSecond = 22977.0
07/14/2016 12:33:58:  Epoch[49 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16444919 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0494s; samplesPerSecond = 25923.0
07/14/2016 12:33:58:  Epoch[49 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17033641 * 1280; EvalErrorPrediction = 0.08828125 * 1280; time = 0.0548s; samplesPerSecond = 23339.4
07/14/2016 12:33:58:  Epoch[49 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15292215 * 1280; EvalErrorPrediction = 0.06484375 * 1280; time = 0.0384s; samplesPerSecond = 33355.9
07/14/2016 12:33:58:  Epoch[49 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.17955441 * 1280; EvalErrorPrediction = 0.08671875 * 1280; time = 0.0437s; samplesPerSecond = 29282.6
07/14/2016 12:33:58:  Epoch[49 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14437199 * 1280; EvalErrorPrediction = 0.06015625 * 1280; time = 0.0401s; samplesPerSecond = 31912.2
07/14/2016 12:33:58:  Epoch[49 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16817369 * 1280; EvalErrorPrediction = 0.08671875 * 1280; time = 0.0296s; samplesPerSecond = 43222.8
07/14/2016 12:33:58: Finished Epoch[49 of 50]: [Training] CrossEntropyWithSoftmax = 0.16283055 * 10000; EvalErrorPrediction = 0.07770000 * 10000; totalSamplesSeen = 490000; learningRatePerSample = 0.1; epochTime=0.339521s
07/14/2016 12:33:58: SGD: Saving checkpoint model '/tmp/cntk-test-20160714122957.627315/Speech_Simple@release_cpu/models/simple.dnn.49'

07/14/2016 12:33:58: Starting Epoch 50: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 49: frames [490000..500000] (first sequence at sample 490000), data subset 0 of 1

07/14/2016 12:33:58: Starting minibatch loop.
07/14/2016 12:33:58:  Epoch[50 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17482439 * 1280; EvalErrorPrediction = 0.08593750 * 1280; time = 0.0463s; samplesPerSecond = 27617.2
07/14/2016 12:33:58:  Epoch[50 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16347297 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0563s; samplesPerSecond = 22720.8
07/14/2016 12:33:58:  Epoch[50 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15064664 * 1280; EvalErrorPrediction = 0.06796875 * 1280; time = 0.0395s; samplesPerSecond = 32409.2
07/14/2016 12:33:58:  Epoch[50 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15297375 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0598s; samplesPerSecond = 21401.5
07/14/2016 12:33:58:  Epoch[50 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15320015 * 1280; EvalErrorPrediction = 0.06796875 * 1280; time = 0.0496s; samplesPerSecond = 25791.9
07/14/2016 12:33:58:  Epoch[50 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14706454 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 0.0974s; samplesPerSecond = 13139.0
07/14/2016 12:33:58:  Epoch[50 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14297619 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0428s; samplesPerSecond = 29918.4
07/14/2016 12:33:58: Finished Epoch[50 of 50]: [Training] CrossEntropyWithSoftmax = 0.15772699 * 10000; EvalErrorPrediction = 0.07490000 * 10000; totalSamplesSeen = 500000; learningRatePerSample = 0.1; epochTime=0.438304s
07/14/2016 12:33:58: SGD: Saving checkpoint model '/tmp/cntk-test-20160714122957.627315/Speech_Simple@release_cpu/models/simple.dnn'
07/14/2016 12:33:58: CNTKCommandTrainEnd: Simple_Demo

07/14/2016 12:33:58: Action "train" complete.


07/14/2016 12:33:58: ##############################################################################
07/14/2016 12:33:58: #                                                                            #
07/14/2016 12:33:58: # Action "write"                                                             #
07/14/2016 12:33:58: #                                                                            #
07/14/2016 12:33:58: ##############################################################################


Post-processing network...

7 roots:
	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
	EvalErrorPrediction = ErrorPrediction()
	InvStdOfFeatures = InvStdDev()
	MeanOfFeatures = Mean()
	PosteriorProb = Softmax()
	Prior = Mean()
	ScaledLogLikelihood = Minus()

Validating network. 25 nodes to process in pass 1.

Validating --> labels = InputValue() :  -> [2 x *1]
Validating --> W2 = LearnableParameter() :  -> [2 x 50]
Validating --> W1 = LearnableParameter() :  -> [50 x 50]
Validating --> W0 = LearnableParameter() :  -> [50 x 2]
Validating --> features = InputValue() :  -> [2 x *1]
Validating --> MeanOfFeatures = Mean (features) : [2 x *1] -> [2]
Validating --> InvStdOfFeatures = InvStdDev (features) : [2 x *1] -> [2]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [2 x *1], [2], [2] -> [2 x *1]
Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [50 x 2], [2 x *1] -> [50 x *1]
Validating --> B0 = LearnableParameter() :  -> [50 x 1]
Validating --> W0*features+B0 = Plus (W0*features, B0) : [50 x *1], [50 x 1] -> [50 x 1 x *1]
Validating --> H1 = Sigmoid (W0*features+B0) : [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> W1*H1 = Times (W1, H1) : [50 x 50], [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> B1 = LearnableParameter() :  -> [50 x 1]
Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [50 x 1 x *1], [50 x 1] -> [50 x 1 x *1]
Validating --> H2 = Sigmoid (W1*H1+B1) : [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> W2*H1 = Times (W2, H2) : [2 x 50], [50 x 1 x *1] -> [2 x 1 x *1]
Validating --> B2 = LearnableParameter() :  -> [2 x 1]
Validating --> HLast = Plus (W2*H1, B2) : [2 x 1 x *1], [2 x 1] -> [2 x 1 x *1]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [2 x *1], [2 x 1 x *1] -> [1]
Validating --> EvalErrorPrediction = ErrorPrediction (labels, HLast) : [2 x *1], [2 x 1 x *1] -> [1]
Validating --> PosteriorProb = Softmax (HLast) : [2 x 1 x *1] -> [2 x 1 x *1]
Validating --> Prior = Mean (labels) : [2 x *1] -> [2]
Validating --> LogOfPrior = Log (Prior) : [2] -> [2]
Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [2 x 1 x *1], [2] -> [2 x 1 x *1]

Validating network. 17 nodes to process in pass 2.


Validating network, final pass.



12 out of 25 nodes do not share the minibatch layout with the input data.

Post-processing network complete.



Allocating matrices for forward and/or backward propagation.

Memory Sharing Structure:

(nil): {[B0 Gradient[50 x 1]] [B1 Gradient[50 x 1]] [B2 Gradient[2 x 1]] [CrossEntropyWithSoftmax Gradient[1]] [CrossEntropyWithSoftmax Value[1]] [EvalErrorPrediction Gradient[1]] [EvalErrorPrediction Value[1]] [H1 Gradient[50 x 1 x *1]] [H2 Gradient[50 x 1 x *1]] [HLast Gradient[2 x 1 x *1]] [InvStdOfFeatures Gradient[2]] [LogOfPrior Gradient[2]] [MVNormalizedFeatures Gradient[2 x *1]] [MeanOfFeatures Gradient[2]] [PosteriorProb Gradient[2 x 1 x *1]] [PosteriorProb Value[2 x 1 x *1]] [Prior Gradient[2]] [ScaledLogLikelihood Gradient[2 x 1 x *1]] [W0 Gradient[50 x 2]] [W0*features Gradient[50 x *1]] [W0*features+B0 Gradient[50 x 1 x *1]] [W1 Gradient[50 x 50]] [W1*H1 Gradient[50 x 1 x *1]] [W1*H1+B1 Gradient[50 x 1 x *1]] [W2 Gradient[2 x 50]] [W2*H1 Gradient[2 x 1 x *1]] [features Gradient[2 x *1]] [labels Gradient[2 x *1]] }
0x7fa732438818: {[B0 Value[50 x 1]] }
0x7fa732439498: {[B1 Value[50 x 1]] }
0x7fa732439b48: {[features Value[2 x *1]] }
0x7fa73243a0b8: {[B2 Value[2 x 1]] }
0x7fa73244fd88: {[InvStdOfFeatures Value[2]] }
0x7fa732450778: {[labels Value[2 x *1]] }
0x7fa732450fc8: {[MeanOfFeatures Value[2]] }
0x7fa732451298: {[Prior Value[2]] }
0x7fa732451d58: {[W0 Value[50 x 2]] }
0x7fa732452688: {[W1 Value[50 x 50]] }
0x7fa732453708: {[W2 Value[2 x 50]] }
0x7fa73245b488: {[ScaledLogLikelihood Value[2 x 1 x *1]] }
0x7fa73245b718: {[MVNormalizedFeatures Value[2 x *1]] }
0x7fa73245b918: {[LogOfPrior Value[2]] }
0x7fa73245d308: {[W0*features Value[50 x *1]] }
0x7fa73245d718: {[W0*features+B0 Value[50 x 1 x *1]] }
0x7fa73245d8d8: {[H1 Value[50 x 1 x *1]] }
0x7fa73245da98: {[W1*H1 Value[50 x 1 x *1]] }
0x7fa73245dc58: {[W1*H1+B1 Value[50 x 1 x *1]] }
0x7fa73245de18: {[H2 Value[50 x 1 x *1]] }
0x7fa73245dfd8: {[W2*H1 Value[2 x 1 x *1]] }
0x7fa73245e198: {[HLast Value[2 x 1 x *1]] }

Minibatch[0]: ActualMBSize = 603
Written to /tmp/cntk-test-20160714122957.627315/Speech_Simple@release_cpu/SimpleOutput*
Total Samples Evaluated = 603

07/14/2016 12:33:58: Action "write" complete.

07/14/2016 12:33:58: __COMPLETED__
=== Deleting last epoch data
==== Re-running from checkpoint
=== Running /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/build/gpu/release/bin/cntk configFile=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Simple/cntk.cntk currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data RunDir=/tmp/cntk-test-20160714122957.627315/Speech_Simple@release_cpu DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Simple OutputDir=/tmp/cntk-test-20160714122957.627315/Speech_Simple@release_cpu DeviceId=-1 timestamping=true makeMode=true
-------------------------------------------------------------------
Build info: 

		Built time: Jul 14 2016 12:04:41
		Last modified date: Tue Jul 12 04:28:35 2016
		Build type: release
		Build target: GPU
		With 1bit-SGD: no
		Math lib: mkl
		CUDA_PATH: /usr/local/cuda-7.5
		CUB_PATH: /usr/local/cub-1.4.1
		CUDNN_PATH: /usr/local/cudnn-4.0
		Build Branch: HEAD
		Build SHA1: 72bee394bf461e8f6f0feb593a8416c05f481957
		Built by philly on 34e58dd0283f
		Build Path: /home/philly/jenkins/workspace/CNTK-Build-Linux
-------------------------------------------------------------------
Changed current directory to /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
07/14/2016 12:33:58: -------------------------------------------------------------------
07/14/2016 12:33:58: Build info: 

07/14/2016 12:33:58: 		Built time: Jul 14 2016 12:04:41
07/14/2016 12:33:58: 		Last modified date: Tue Jul 12 04:28:35 2016
07/14/2016 12:33:58: 		Build type: release
07/14/2016 12:33:58: 		Build target: GPU
07/14/2016 12:33:58: 		With 1bit-SGD: no
07/14/2016 12:33:58: 		Math lib: mkl
07/14/2016 12:33:58: 		CUDA_PATH: /usr/local/cuda-7.5
07/14/2016 12:33:58: 		CUB_PATH: /usr/local/cub-1.4.1
07/14/2016 12:33:58: 		CUDNN_PATH: /usr/local/cudnn-4.0
07/14/2016 12:33:58: 		Build Branch: HEAD
07/14/2016 12:33:58: 		Build SHA1: 72bee394bf461e8f6f0feb593a8416c05f481957
07/14/2016 12:33:58: 		Built by philly on 34e58dd0283f
07/14/2016 12:33:58: 		Build Path: /home/philly/jenkins/workspace/CNTK-Build-Linux
07/14/2016 12:33:58: -------------------------------------------------------------------
07/14/2016 12:33:59: -------------------------------------------------------------------
07/14/2016 12:33:59: GPU info:

07/14/2016 12:33:59: 		Device[0]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3071 MB
07/14/2016 12:33:59: 		Device[1]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3071 MB
07/14/2016 12:33:59: 		Device[2]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3071 MB
07/14/2016 12:33:59: 		Device[3]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3071 MB
07/14/2016 12:33:59: -------------------------------------------------------------------

07/14/2016 12:33:59: Running on localhost at 2016/07/14 12:33:59
07/14/2016 12:33:59: Command line: 
/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/build/gpu/release/bin/cntk  configFile=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Simple/cntk.cntk  currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data  RunDir=/tmp/cntk-test-20160714122957.627315/Speech_Simple@release_cpu  DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data  ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Simple  OutputDir=/tmp/cntk-test-20160714122957.627315/Speech_Simple@release_cpu  DeviceId=-1  timestamping=true  makeMode=true



07/14/2016 12:33:59: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
07/14/2016 12:33:59: command=Simple_Demo:Simple_Demo_Output
DeviceNumber=-1
precision=float
modelPath=$RunDir$/models/simple.dnn
deviceId=$DeviceNumber$
outputNodeNames=ScaledLogLikelihood
traceLevel=1
Simple_Demo=[
    action=train
    SimpleNetworkBuilder=[
        layerSizes=2:50*2:2
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ErrorPrediction
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0 
        minibatchSize=128
        learningRatesPerSample=0.1
        momentumAsTimeConstant=2500
        dropoutRate=0.0
        maxEpochs=50
        keepCheckPointFiles = true
    ]
    reader=[
        readerType=CNTKTextFormatReader
        file=$DataDir$/SimpleDataTrain_cntk_text.txt
        input = [
            features=[
dim = 2      
                format = "dense"
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
]
Simple_Demo_Output=[
    action=write
    reader=[
        readerType=CNTKTextFormatReader
        file=$DataDir$/SimpleDataTest_cntk_text.txt
        input = [
            features=[
dim = 2 
                format = "dense" 
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
outputPath=$RunDir$/SimpleOutput    
]
currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
RunDir=/tmp/cntk-test-20160714122957.627315/Speech_Simple@release_cpu
DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Simple
OutputDir=/tmp/cntk-test-20160714122957.627315/Speech_Simple@release_cpu
DeviceId=-1
timestamping=true
makeMode=true

07/14/2016 12:33:59: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<

07/14/2016 12:33:59: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
07/14/2016 12:33:59: command=Simple_Demo:Simple_Demo_Output
DeviceNumber=-1
precision=float
modelPath=/tmp/cntk-test-20160714122957.627315/Speech_Simple@release_cpu/models/simple.dnn
deviceId=-1
outputNodeNames=ScaledLogLikelihood
traceLevel=1
Simple_Demo=[
    action=train
    SimpleNetworkBuilder=[
        layerSizes=2:50*2:2
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ErrorPrediction
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0 
        minibatchSize=128
        learningRatesPerSample=0.1
        momentumAsTimeConstant=2500
        dropoutRate=0.0
        maxEpochs=50
        keepCheckPointFiles = true
    ]
    reader=[
        readerType=CNTKTextFormatReader
        file=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/SimpleDataTrain_cntk_text.txt
        input = [
            features=[
dim = 2      
                format = "dense"
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
]
Simple_Demo_Output=[
    action=write
    reader=[
        readerType=CNTKTextFormatReader
        file=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/SimpleDataTest_cntk_text.txt
        input = [
            features=[
dim = 2 
                format = "dense" 
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
outputPath=/tmp/cntk-test-20160714122957.627315/Speech_Simple@release_cpu/SimpleOutput    
]
currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
RunDir=/tmp/cntk-test-20160714122957.627315/Speech_Simple@release_cpu
DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Simple
OutputDir=/tmp/cntk-test-20160714122957.627315/Speech_Simple@release_cpu
DeviceId=-1
timestamping=true
makeMode=true

07/14/2016 12:33:59: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<

07/14/2016 12:33:59: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
configparameters: cntk.cntk:command=Simple_Demo:Simple_Demo_Output
configparameters: cntk.cntk:ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Simple
configparameters: cntk.cntk:currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
configparameters: cntk.cntk:DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
configparameters: cntk.cntk:deviceId=-1
configparameters: cntk.cntk:DeviceNumber=-1
configparameters: cntk.cntk:makeMode=true
configparameters: cntk.cntk:modelPath=/tmp/cntk-test-20160714122957.627315/Speech_Simple@release_cpu/models/simple.dnn
configparameters: cntk.cntk:OutputDir=/tmp/cntk-test-20160714122957.627315/Speech_Simple@release_cpu
configparameters: cntk.cntk:outputNodeNames=ScaledLogLikelihood
configparameters: cntk.cntk:precision=float
configparameters: cntk.cntk:RunDir=/tmp/cntk-test-20160714122957.627315/Speech_Simple@release_cpu
configparameters: cntk.cntk:Simple_Demo=[
    action=train
    SimpleNetworkBuilder=[
        layerSizes=2:50*2:2
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ErrorPrediction
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0 
        minibatchSize=128
        learningRatesPerSample=0.1
        momentumAsTimeConstant=2500
        dropoutRate=0.0
        maxEpochs=50
        keepCheckPointFiles = true
    ]
    reader=[
        readerType=CNTKTextFormatReader
        file=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/SimpleDataTrain_cntk_text.txt
        input = [
            features=[
dim = 2      
                format = "dense"
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
]

configparameters: cntk.cntk:Simple_Demo_Output=[
    action=write
    reader=[
        readerType=CNTKTextFormatReader
        file=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/SimpleDataTest_cntk_text.txt
        input = [
            features=[
dim = 2 
                format = "dense" 
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
outputPath=/tmp/cntk-test-20160714122957.627315/Speech_Simple@release_cpu/SimpleOutput    
]

configparameters: cntk.cntk:timestamping=true
configparameters: cntk.cntk:traceLevel=1
07/14/2016 12:33:59: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
07/14/2016 12:33:59: Commands: Simple_Demo Simple_Demo_Output
07/14/2016 12:33:59: Precision = "float"
07/14/2016 12:33:59: CNTKModelPath: /tmp/cntk-test-20160714122957.627315/Speech_Simple@release_cpu/models/simple.dnn
07/14/2016 12:33:59: CNTKCommandTrainInfo: Simple_Demo : 50
07/14/2016 12:33:59: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 50

07/14/2016 12:33:59: ##############################################################################
07/14/2016 12:33:59: #                                                                            #
07/14/2016 12:33:59: # Action "train"                                                             #
07/14/2016 12:33:59: #                                                                            #
07/14/2016 12:33:59: ##############################################################################

07/14/2016 12:33:59: CNTKCommandTrainBegin: Simple_Demo
SimpleNetworkBuilder Using CPU

07/14/2016 12:33:59: Starting from checkpoint. Loading network from '/tmp/cntk-test-20160714122957.627315/Speech_Simple@release_cpu/models/simple.dnn.49'.

Post-processing network...

7 roots:
	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
	EvalErrorPrediction = ErrorPrediction()
	InvStdOfFeatures = InvStdDev()
	MeanOfFeatures = Mean()
	PosteriorProb = Softmax()
	Prior = Mean()
	ScaledLogLikelihood = Minus()

Validating network. 25 nodes to process in pass 1.

Validating --> labels = InputValue() :  -> [2 x *1]
Validating --> W2 = LearnableParameter() :  -> [2 x 50]
Validating --> W1 = LearnableParameter() :  -> [50 x 50]
Validating --> W0 = LearnableParameter() :  -> [50 x 2]
Validating --> features = InputValue() :  -> [2 x *1]
Validating --> MeanOfFeatures = Mean (features) : [2 x *1] -> [2]
Validating --> InvStdOfFeatures = InvStdDev (features) : [2 x *1] -> [2]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [2 x *1], [2], [2] -> [2 x *1]
Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [50 x 2], [2 x *1] -> [50 x *1]
Validating --> B0 = LearnableParameter() :  -> [50 x 1]
Validating --> W0*features+B0 = Plus (W0*features, B0) : [50 x *1], [50 x 1] -> [50 x 1 x *1]
Validating --> H1 = Sigmoid (W0*features+B0) : [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> W1*H1 = Times (W1, H1) : [50 x 50], [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> B1 = LearnableParameter() :  -> [50 x 1]
Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [50 x 1 x *1], [50 x 1] -> [50 x 1 x *1]
Validating --> H2 = Sigmoid (W1*H1+B1) : [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> W2*H1 = Times (W2, H2) : [2 x 50], [50 x 1 x *1] -> [2 x 1 x *1]
Validating --> B2 = LearnableParameter() :  -> [2 x 1]
Validating --> HLast = Plus (W2*H1, B2) : [2 x 1 x *1], [2 x 1] -> [2 x 1 x *1]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [2 x *1], [2 x 1 x *1] -> [1]
Validating --> EvalErrorPrediction = ErrorPrediction (labels, HLast) : [2 x *1], [2 x 1 x *1] -> [1]
Validating --> PosteriorProb = Softmax (HLast) : [2 x 1 x *1] -> [2 x 1 x *1]
Validating --> Prior = Mean (labels) : [2 x *1] -> [2]
Validating --> LogOfPrior = Log (Prior) : [2] -> [2]
Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [2 x 1 x *1], [2] -> [2 x 1 x *1]

Validating network. 17 nodes to process in pass 2.


Validating network, final pass.



12 out of 25 nodes do not share the minibatch layout with the input data.

Post-processing network complete.

07/14/2016 12:33:59: Loaded model with 25 nodes on CPU.

07/14/2016 12:33:59: Training criterion node(s):
07/14/2016 12:33:59: 	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax

07/14/2016 12:33:59: Evaluation criterion node(s):

07/14/2016 12:33:59: 	EvalErrorPrediction = ErrorPrediction


Allocating matrices for forward and/or backward propagation.

Memory Sharing Structure:

(nil): {[EvalErrorPrediction Gradient[1]] [InvStdOfFeatures Gradient[2]] [LogOfPrior Gradient[2]] [MVNormalizedFeatures Gradient[2 x *1]] [MeanOfFeatures Gradient[2]] [PosteriorProb Gradient[2 x 1 x *1]] [PosteriorProb Value[2 x 1 x *1]] [Prior Gradient[2]] [ScaledLogLikelihood Gradient[2 x 1 x *1]] [features Gradient[2 x *1]] [labels Gradient[2 x *1]] }
0x7fc1751b4d48: {[features Value[2 x *1]] }
0x7fc1751b5ad8: {[InvStdOfFeatures Value[2]] }
0x7fc1751b64e8: {[labels Value[2 x *1]] }
0x7fc1751b6d18: {[MeanOfFeatures Value[2]] }
0x7fc1751b78b8: {[Prior Value[2]] }
0x7fc1751b7a88: {[W0 Value[50 x 2]] }
0x7fc1751b83f8: {[W1 Value[50 x 50]] }
0x7fc1751b9478: {[W2 Value[2 x 50]] }
0x7fc1751c1138: {[EvalErrorPrediction Value[1]] }
0x7fc1751c12f8: {[ScaledLogLikelihood Value[2 x 1 x *1]] }
0x7fc1751c14b8: {[CrossEntropyWithSoftmax Value[1]] }
0x7fc1751c1a78: {[LogOfPrior Value[2]] }
0x7fc1751c2bd8: {[MVNormalizedFeatures Value[2 x *1]] }
0x7fc1751c32d8: {[W0*features Value[50 x *1]] }
0x7fc1751c3808: {[W0 Gradient[50 x 2]] [W0*features+B0 Value[50 x 1 x *1]] }
0x7fc1751c3968: {[H1 Value[50 x 1 x *1]] [W0*features Gradient[50 x *1]] }
0x7fc1751c3b28: {[W0*features+B0 Gradient[50 x 1 x *1]] [W1*H1 Value[50 x 1 x *1]] }
0x7fc1751c3ce8: {[W1 Gradient[50 x 50]] [W1*H1+B1 Value[50 x 1 x *1]] }
0x7fc1751c3ea8: {[H2 Value[50 x 1 x *1]] [W1*H1 Gradient[50 x 1 x *1]] }
0x7fc1751c4068: {[B0 Gradient[50 x 1]] [H1 Gradient[50 x 1 x *1]] [W1*H1+B1 Gradient[50 x 1 x *1]] [W2*H1 Value[2 x 1 x *1]] }
0x7fc1751c4228: {[HLast Value[2 x 1 x *1]] [W2 Gradient[2 x 50]] }
0x7fc1751c4d88: {[CrossEntropyWithSoftmax Gradient[1]] }
0x7fc1751c4f48: {[B1 Gradient[50 x 1]] [H2 Gradient[50 x 1 x *1]] [HLast Gradient[2 x 1 x *1]] }
0x7fc1751c5108: {[W2*H1 Gradient[2 x 1 x *1]] }
0x7fc1751c52c8: {[B2 Gradient[2 x 1]] }
0x7fc1759ba728: {[B1 Value[50 x 1]] }
0x7fc1759bad58: {[B0 Value[50 x 1]] }
0x7fc1759bb238: {[B2 Value[2 x 1]] }

07/14/2016 12:33:59: No PreCompute nodes found, skipping PreCompute step.

07/14/2016 12:33:59: Starting Epoch 50: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 49: frames [490000..500000] (first sequence at sample 490000), data subset 0 of 1

07/14/2016 12:33:59: Starting minibatch loop.
07/14/2016 12:34:00:  Epoch[50 of 50]-Minibatch[   1-  10, 0.00000000000003%]: CrossEntropyWithSoftmax = 0.17482439 * 1280; EvalErrorPrediction = 0.08593750 * 1280; time = 0.2199s; samplesPerSecond = 5821.6
07/14/2016 12:34:00:  Epoch[50 of 50]-Minibatch[  11-  20, 0.00000000000006%]: CrossEntropyWithSoftmax = 0.16347297 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0436s; samplesPerSecond = 29377.3
07/14/2016 12:34:00:  Epoch[50 of 50]-Minibatch[  21-  30, 0.00000000000008%]: CrossEntropyWithSoftmax = 0.15064664 * 1280; EvalErrorPrediction = 0.06796875 * 1280; time = 0.0509s; samplesPerSecond = 25153.3
07/14/2016 12:34:00:  Epoch[50 of 50]-Minibatch[  31-  40, 0.00000000000011%]: CrossEntropyWithSoftmax = 0.15297375 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0473s; samplesPerSecond = 27059.6
07/14/2016 12:34:00:  Epoch[50 of 50]-Minibatch[  41-  50, 0.00000000000014%]: CrossEntropyWithSoftmax = 0.15320015 * 1280; EvalErrorPrediction = 0.06796875 * 1280; time = 0.0682s; samplesPerSecond = 18762.8
07/14/2016 12:34:00:  Epoch[50 of 50]-Minibatch[  51-  60, 0.00000000000017%]: CrossEntropyWithSoftmax = 0.14706454 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 0.0467s; samplesPerSecond = 27383.2
07/14/2016 12:34:00:  Epoch[50 of 50]-Minibatch[  61-  70, 0.00000000000019%]: CrossEntropyWithSoftmax = 0.14297619 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0419s; samplesPerSecond = 30558.4
07/14/2016 12:34:00: Finished Epoch[50 of 50]: [Training] CrossEntropyWithSoftmax = 0.15772699 * 10000; EvalErrorPrediction = 0.07490000 * 10000; totalSamplesSeen = 500000; learningRatePerSample = 0.1; epochTime=0.564558s
07/14/2016 12:34:00: SGD: Saving checkpoint model '/tmp/cntk-test-20160714122957.627315/Speech_Simple@release_cpu/models/simple.dnn'
07/14/2016 12:34:00: CNTKCommandTrainEnd: Simple_Demo

07/14/2016 12:34:00: Action "train" complete.


07/14/2016 12:34:00: ##############################################################################
07/14/2016 12:34:00: #                                                                            #
07/14/2016 12:34:00: # Action "write"                                                             #
07/14/2016 12:34:00: #                                                                            #
07/14/2016 12:34:00: ##############################################################################


Post-processing network...

7 roots:
	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
	EvalErrorPrediction = ErrorPrediction()
	InvStdOfFeatures = InvStdDev()
	MeanOfFeatures = Mean()
	PosteriorProb = Softmax()
	Prior = Mean()
	ScaledLogLikelihood = Minus()

Validating network. 25 nodes to process in pass 1.

Validating --> labels = InputValue() :  -> [2 x *2]
Validating --> W2 = LearnableParameter() :  -> [2 x 50]
Validating --> W1 = LearnableParameter() :  -> [50 x 50]
Validating --> W0 = LearnableParameter() :  -> [50 x 2]
Validating --> features = InputValue() :  -> [2 x *2]
Validating --> MeanOfFeatures = Mean (features) : [2 x *2] -> [2]
Validating --> InvStdOfFeatures = InvStdDev (features) : [2 x *2] -> [2]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [2 x *2], [2], [2] -> [2 x *2]
Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [50 x 2], [2 x *2] -> [50 x *2]
Validating --> B0 = LearnableParameter() :  -> [50 x 1]
Validating --> W0*features+B0 = Plus (W0*features, B0) : [50 x *2], [50 x 1] -> [50 x 1 x *2]
Validating --> H1 = Sigmoid (W0*features+B0) : [50 x 1 x *2] -> [50 x 1 x *2]
Validating --> W1*H1 = Times (W1, H1) : [50 x 50], [50 x 1 x *2] -> [50 x 1 x *2]
Validating --> B1 = LearnableParameter() :  -> [50 x 1]
Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [50 x 1 x *2], [50 x 1] -> [50 x 1 x *2]
Validating --> H2 = Sigmoid (W1*H1+B1) : [50 x 1 x *2] -> [50 x 1 x *2]
Validating --> W2*H1 = Times (W2, H2) : [2 x 50], [50 x 1 x *2] -> [2 x 1 x *2]
Validating --> B2 = LearnableParameter() :  -> [2 x 1]
Validating --> HLast = Plus (W2*H1, B2) : [2 x 1 x *2], [2 x 1] -> [2 x 1 x *2]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [2 x *2], [2 x 1 x *2] -> [1]
Validating --> EvalErrorPrediction = ErrorPrediction (labels, HLast) : [2 x *2], [2 x 1 x *2] -> [1]
Validating --> PosteriorProb = Softmax (HLast) : [2 x 1 x *2] -> [2 x 1 x *2]
Validating --> Prior = Mean (labels) : [2 x *2] -> [2]
Validating --> LogOfPrior = Log (Prior) : [2] -> [2]
Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [2 x 1 x *2], [2] -> [2 x 1 x *2]

Validating network. 17 nodes to process in pass 2.


Validating network, final pass.



12 out of 25 nodes do not share the minibatch layout with the input data.

Post-processing network complete.



Allocating matrices for forward and/or backward propagation.

Memory Sharing Structure:

(nil): {[B0 Gradient[50 x 1]] [B1 Gradient[50 x 1]] [B2 Gradient[2 x 1]] [CrossEntropyWithSoftmax Gradient[1]] [CrossEntropyWithSoftmax Value[1]] [EvalErrorPrediction Gradient[1]] [EvalErrorPrediction Value[1]] [H1 Gradient[50 x 1 x *2]] [H2 Gradient[50 x 1 x *2]] [HLast Gradient[2 x 1 x *2]] [InvStdOfFeatures Gradient[2]] [LogOfPrior Gradient[2]] [MVNormalizedFeatures Gradient[2 x *2]] [MeanOfFeatures Gradient[2]] [PosteriorProb Gradient[2 x 1 x *2]] [PosteriorProb Value[2 x 1 x *2]] [Prior Gradient[2]] [ScaledLogLikelihood Gradient[2 x 1 x *2]] [W0 Gradient[50 x 2]] [W0*features Gradient[50 x *2]] [W0*features+B0 Gradient[50 x 1 x *2]] [W1 Gradient[50 x 50]] [W1*H1 Gradient[50 x 1 x *2]] [W1*H1+B1 Gradient[50 x 1 x *2]] [W2 Gradient[2 x 50]] [W2*H1 Gradient[2 x 1 x *2]] [features Gradient[2 x *2]] [labels Gradient[2 x *2]] }
0x7fc16e50ebf8: {[B0 Value[50 x 1]] }
0x7fc16e50f898: {[B1 Value[50 x 1]] }
0x7fc16e5104b8: {[B2 Value[2 x 1]] }
0x7fc16e53f778: {[features Value[2 x *2]] }
0x7fc16e540e68: {[InvStdOfFeatures Value[2]] }
0x7fc16e541878: {[labels Value[2 x *2]] }
0x7fc16e5420a8: {[MeanOfFeatures Value[2]] }
0x7fc16e542c48: {[Prior Value[2]] }
0x7fc16e542e18: {[W0 Value[50 x 2]] }
0x7fc16e543788: {[W1 Value[50 x 50]] }
0x7fc16e544808: {[W2 Value[2 x 50]] }
0x7fc16e54c618: {[ScaledLogLikelihood Value[2 x 1 x *2]] }
0x7fc16e54c8a8: {[MVNormalizedFeatures Value[2 x *2]] }
0x7fc16e54c9a8: {[LogOfPrior Value[2]] }
0x7fc16e54e418: {[W0*features Value[50 x *2]] }
0x7fc16e54e828: {[W0*features+B0 Value[50 x 1 x *2]] }
0x7fc16e54e9e8: {[H1 Value[50 x 1 x *2]] }
0x7fc16e54eba8: {[W1*H1 Value[50 x 1 x *2]] }
0x7fc16e54ed68: {[W1*H1+B1 Value[50 x 1 x *2]] }
0x7fc16e54ef28: {[H2 Value[50 x 1 x *2]] }
0x7fc16e54f0e8: {[W2*H1 Value[2 x 1 x *2]] }
0x7fc16e54f2a8: {[HLast Value[2 x 1 x *2]] }

Minibatch[0]: ActualMBSize = 603
Written to /tmp/cntk-test-20160714122957.627315/Speech_Simple@release_cpu/SimpleOutput*
Total Samples Evaluated = 603

07/14/2016 12:34:00: Action "write" complete.

07/14/2016 12:34:00: __COMPLETED__
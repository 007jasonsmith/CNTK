CPU info:
    CPU Model Name: Intel(R) Xeon(R) CPU E5-2630 v2 @ 2.60GHz
    Hardware threads: 24
    Total Memory: 264172964 kB
-------------------------------------------------------------------
=== Running /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/build/gpu/debug/bin/cntk configFile=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Simple/cntk.cntk currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data RunDir=/tmp/cntk-test-20160713121920.930131/Speech_Simple@debug_gpu DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Simple OutputDir=/tmp/cntk-test-20160713121920.930131/Speech_Simple@debug_gpu DeviceId=0 timestamping=true
-------------------------------------------------------------------
Build info: 

		Built time: Jul 13 2016 11:58:00
		Last modified date: Tue Jul 12 04:28:35 2016
		Build type: debug
		Build target: GPU
		With 1bit-SGD: no
		Math lib: mkl
		CUDA_PATH: /usr/local/cuda-7.5
		CUB_PATH: /usr/local/cub-1.4.1
		CUDNN_PATH: /usr/local/cudnn-4.0
		Build Branch: HEAD
		Build SHA1: 50bb4c8afbc87c14548a5b5f315a064186a5cb5f
		Built by philly on 2bc22072e267
		Build Path: /home/philly/jenkins/workspace/CNTK-Build-Linux
-------------------------------------------------------------------
Changed current directory to /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
07/13/2016 12:23:06: -------------------------------------------------------------------
07/13/2016 12:23:06: Build info: 

07/13/2016 12:23:06: 		Built time: Jul 13 2016 11:58:00
07/13/2016 12:23:06: 		Last modified date: Tue Jul 12 04:28:35 2016
07/13/2016 12:23:06: 		Build type: debug
07/13/2016 12:23:06: 		Build target: GPU
07/13/2016 12:23:06: 		With 1bit-SGD: no
07/13/2016 12:23:06: 		Math lib: mkl
07/13/2016 12:23:06: 		CUDA_PATH: /usr/local/cuda-7.5
07/13/2016 12:23:06: 		CUB_PATH: /usr/local/cub-1.4.1
07/13/2016 12:23:06: 		CUDNN_PATH: /usr/local/cudnn-4.0
07/13/2016 12:23:06: 		Build Branch: HEAD
07/13/2016 12:23:06: 		Build SHA1: 50bb4c8afbc87c14548a5b5f315a064186a5cb5f
07/13/2016 12:23:06: 		Built by philly on 2bc22072e267
07/13/2016 12:23:06: 		Build Path: /home/philly/jenkins/workspace/CNTK-Build-Linux
07/13/2016 12:23:06: -------------------------------------------------------------------
07/13/2016 12:23:07: -------------------------------------------------------------------
07/13/2016 12:23:07: GPU info:

07/13/2016 12:23:07: 		Device[0]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3071 MB
07/13/2016 12:23:07: 		Device[1]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3071 MB
07/13/2016 12:23:07: 		Device[2]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3071 MB
07/13/2016 12:23:07: 		Device[3]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3071 MB
07/13/2016 12:23:07: -------------------------------------------------------------------

07/13/2016 12:23:07: Running on localhost at 2016/07/13 12:23:07
07/13/2016 12:23:07: Command line: 
/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/build/gpu/debug/bin/cntk  configFile=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Simple/cntk.cntk  currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data  RunDir=/tmp/cntk-test-20160713121920.930131/Speech_Simple@debug_gpu  DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data  ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Simple  OutputDir=/tmp/cntk-test-20160713121920.930131/Speech_Simple@debug_gpu  DeviceId=0  timestamping=true



07/13/2016 12:23:07: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
07/13/2016 12:23:07: command=Simple_Demo:Simple_Demo_Output
DeviceNumber=-1
precision=float
modelPath=$RunDir$/models/simple.dnn
deviceId=$DeviceNumber$
outputNodeNames=ScaledLogLikelihood
traceLevel=1
Simple_Demo=[
    action=train
    SimpleNetworkBuilder=[
        layerSizes=2:50*2:2
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ErrorPrediction
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0 
        minibatchSize=128
        learningRatesPerSample=0.1
        momentumAsTimeConstant=2500
        dropoutRate=0.0
        maxEpochs=50
        keepCheckPointFiles = true
    ]
    reader=[
        readerType=CNTKTextFormatReader
        file=$DataDir$/SimpleDataTrain_cntk_text.txt
        input = [
            features=[
dim = 2      
                format = "dense"
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
]
Simple_Demo_Output=[
    action=write
    reader=[
        readerType=CNTKTextFormatReader
        file=$DataDir$/SimpleDataTest_cntk_text.txt
        input = [
            features=[
dim = 2 
                format = "dense" 
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
outputPath=$RunDir$/SimpleOutput    
]
currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
RunDir=/tmp/cntk-test-20160713121920.930131/Speech_Simple@debug_gpu
DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Simple
OutputDir=/tmp/cntk-test-20160713121920.930131/Speech_Simple@debug_gpu
DeviceId=0
timestamping=true

07/13/2016 12:23:07: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<

07/13/2016 12:23:07: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
07/13/2016 12:23:07: command=Simple_Demo:Simple_Demo_Output
DeviceNumber=-1
precision=float
modelPath=/tmp/cntk-test-20160713121920.930131/Speech_Simple@debug_gpu/models/simple.dnn
deviceId=-1
outputNodeNames=ScaledLogLikelihood
traceLevel=1
Simple_Demo=[
    action=train
    SimpleNetworkBuilder=[
        layerSizes=2:50*2:2
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ErrorPrediction
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0 
        minibatchSize=128
        learningRatesPerSample=0.1
        momentumAsTimeConstant=2500
        dropoutRate=0.0
        maxEpochs=50
        keepCheckPointFiles = true
    ]
    reader=[
        readerType=CNTKTextFormatReader
        file=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/SimpleDataTrain_cntk_text.txt
        input = [
            features=[
dim = 2      
                format = "dense"
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
]
Simple_Demo_Output=[
    action=write
    reader=[
        readerType=CNTKTextFormatReader
        file=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/SimpleDataTest_cntk_text.txt
        input = [
            features=[
dim = 2 
                format = "dense" 
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
outputPath=/tmp/cntk-test-20160713121920.930131/Speech_Simple@debug_gpu/SimpleOutput    
]
currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
RunDir=/tmp/cntk-test-20160713121920.930131/Speech_Simple@debug_gpu
DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Simple
OutputDir=/tmp/cntk-test-20160713121920.930131/Speech_Simple@debug_gpu
DeviceId=0
timestamping=true

07/13/2016 12:23:07: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<

07/13/2016 12:23:07: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
configparameters: cntk.cntk:command=Simple_Demo:Simple_Demo_Output
configparameters: cntk.cntk:ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Simple
configparameters: cntk.cntk:currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
configparameters: cntk.cntk:DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
configparameters: cntk.cntk:deviceId=0
configparameters: cntk.cntk:DeviceNumber=-1
configparameters: cntk.cntk:modelPath=/tmp/cntk-test-20160713121920.930131/Speech_Simple@debug_gpu/models/simple.dnn
configparameters: cntk.cntk:OutputDir=/tmp/cntk-test-20160713121920.930131/Speech_Simple@debug_gpu
configparameters: cntk.cntk:outputNodeNames=ScaledLogLikelihood
configparameters: cntk.cntk:precision=float
configparameters: cntk.cntk:RunDir=/tmp/cntk-test-20160713121920.930131/Speech_Simple@debug_gpu
configparameters: cntk.cntk:Simple_Demo=[
    action=train
    SimpleNetworkBuilder=[
        layerSizes=2:50*2:2
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ErrorPrediction
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0 
        minibatchSize=128
        learningRatesPerSample=0.1
        momentumAsTimeConstant=2500
        dropoutRate=0.0
        maxEpochs=50
        keepCheckPointFiles = true
    ]
    reader=[
        readerType=CNTKTextFormatReader
        file=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/SimpleDataTrain_cntk_text.txt
        input = [
            features=[
dim = 2      
                format = "dense"
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
]

configparameters: cntk.cntk:Simple_Demo_Output=[
    action=write
    reader=[
        readerType=CNTKTextFormatReader
        file=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/SimpleDataTest_cntk_text.txt
        input = [
            features=[
dim = 2 
                format = "dense" 
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
outputPath=/tmp/cntk-test-20160713121920.930131/Speech_Simple@debug_gpu/SimpleOutput    
]

configparameters: cntk.cntk:timestamping=true
configparameters: cntk.cntk:traceLevel=1
07/13/2016 12:23:07: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
07/13/2016 12:23:07: Commands: Simple_Demo Simple_Demo_Output
07/13/2016 12:23:07: Precision = "float"
07/13/2016 12:23:07: CNTKModelPath: /tmp/cntk-test-20160713121920.930131/Speech_Simple@debug_gpu/models/simple.dnn
07/13/2016 12:23:07: CNTKCommandTrainInfo: Simple_Demo : 50
07/13/2016 12:23:07: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 50

07/13/2016 12:23:07: ##############################################################################
07/13/2016 12:23:07: #                                                                            #
07/13/2016 12:23:07: # Action "train"                                                             #
07/13/2016 12:23:07: #                                                                            #
07/13/2016 12:23:07: ##############################################################################

07/13/2016 12:23:07: CNTKCommandTrainBegin: Simple_Demo
SimpleNetworkBuilder Using GPU 0

07/13/2016 12:23:07: Creating virgin network.
SetUniformRandomValue (GPU): creating curand object with seed 1, sizeof(ElemType)==4

Post-processing network...

7 roots:
	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
	EvalErrorPrediction = ErrorPrediction()
	InvStdOfFeatures = InvStdDev()
	MeanOfFeatures = Mean()
	PosteriorProb = Softmax()
	Prior = Mean()
	ScaledLogLikelihood = Minus()

Validating network. 25 nodes to process in pass 1.

Validating --> labels = InputValue() :  -> [2 x *]
Validating --> W2 = LearnableParameter() :  -> [2 x 50]
Validating --> W1 = LearnableParameter() :  -> [50 x 50]
Validating --> W0 = LearnableParameter() :  -> [50 x 2]
Validating --> features = InputValue() :  -> [2 x *]
Validating --> MeanOfFeatures = Mean (features) : [2 x *] -> [2]
Validating --> InvStdOfFeatures = InvStdDev (features) : [2 x *] -> [2]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [2 x *], [2], [2] -> [2 x *]
Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [50 x 2], [2 x *] -> [50 x *]
Validating --> B0 = LearnableParameter() :  -> [50 x 1]
Validating --> W0*features+B0 = Plus (W0*features, B0) : [50 x *], [50 x 1] -> [50 x 1 x *]
Validating --> H1 = Sigmoid (W0*features+B0) : [50 x 1 x *] -> [50 x 1 x *]
Validating --> W1*H1 = Times (W1, H1) : [50 x 50], [50 x 1 x *] -> [50 x 1 x *]
Validating --> B1 = LearnableParameter() :  -> [50 x 1]
Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [50 x 1 x *], [50 x 1] -> [50 x 1 x *]
Validating --> H2 = Sigmoid (W1*H1+B1) : [50 x 1 x *] -> [50 x 1 x *]
Validating --> W2*H1 = Times (W2, H2) : [2 x 50], [50 x 1 x *] -> [2 x 1 x *]
Validating --> B2 = LearnableParameter() :  -> [2 x 1]
Validating --> HLast = Plus (W2*H1, B2) : [2 x 1 x *], [2 x 1] -> [2 x 1 x *]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [2 x *], [2 x 1 x *] -> [1]
Validating --> EvalErrorPrediction = ErrorPrediction (labels, HLast) : [2 x *], [2 x 1 x *] -> [1]
Validating --> PosteriorProb = Softmax (HLast) : [2 x 1 x *] -> [2 x 1 x *]
Validating --> Prior = Mean (labels) : [2 x *] -> [2]
Validating --> LogOfPrior = Log (Prior) : [2] -> [2]
Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [2 x 1 x *], [2] -> [2 x 1 x *]

Validating network. 17 nodes to process in pass 2.


Validating network, final pass.



12 out of 25 nodes do not share the minibatch layout with the input data.

Post-processing network complete.

07/13/2016 12:23:07: Created model with 25 nodes on GPU 0.

07/13/2016 12:23:07: Training criterion node(s):
07/13/2016 12:23:07: 	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax

07/13/2016 12:23:07: Evaluation criterion node(s):

07/13/2016 12:23:07: 	EvalErrorPrediction = ErrorPrediction


Allocating matrices for forward and/or backward propagation.

Memory Sharing Structure:

(nil): {[EvalErrorPrediction Gradient[1]] [InvStdOfFeatures Gradient[2]] [LogOfPrior Gradient[2]] [MVNormalizedFeatures Gradient[2 x *]] [MeanOfFeatures Gradient[2]] [PosteriorProb Gradient[2 x 1 x *]] [PosteriorProb Value[2 x 1 x *]] [Prior Gradient[2]] [ScaledLogLikelihood Gradient[2 x 1 x *]] [features Gradient[2 x *]] [labels Gradient[2 x *]] }
0x7ff3bfa19c28: {[B1 Value[50 x 1]] }
0x7ff3bfa1af78: {[W2 Value[2 x 50]] }
0x7ff3bfa1b8a8: {[B2 Value[2 x 1]] }
0x7ff3bfa1c888: {[labels Value[2 x *]] }
0x7ff3bfa1dac8: {[Prior Value[2]] }
0x7ff3bfa232c8: {[EvalErrorPrediction Value[1]] }
0x7ff3bfa235e8: {[ScaledLogLikelihood Value[2 x 1 x *]] }
0x7ff3bfa237a8: {[CrossEntropyWithSoftmax Value[1]] }
0x7ff3bfa23c38: {[W0 Gradient[50 x 2]] [W0*features+B0 Value[50 x 1 x *]] }
0x7ff3bfa23da8: {[LogOfPrior Value[2]] }
0x7ff3bfa25538: {[MVNormalizedFeatures Value[2 x *]] }
0x7ff3bfa25cf8: {[W0*features Value[50 x *]] }
0x7ff3bfa25f08: {[H1 Value[50 x 1 x *]] [W0*features Gradient[50 x *]] }
0x7ff3bfa26068: {[W0*features+B0 Gradient[50 x 1 x *]] [W1*H1 Value[50 x 1 x *]] }
0x7ff3bfa261c8: {[W1 Gradient[50 x 50]] [W1*H1+B1 Value[50 x 1 x *]] }
0x7ff3bfa26388: {[H2 Value[50 x 1 x *]] [W1*H1 Gradient[50 x 1 x *]] }
0x7ff3bfa26548: {[B0 Gradient[50 x 1]] [H1 Gradient[50 x 1 x *]] [W1*H1+B1 Gradient[50 x 1 x *]] [W2*H1 Value[2 x 1 x *]] }
0x7ff3bfa26708: {[HLast Value[2 x 1 x *]] [W2 Gradient[2 x 50]] }
0x7ff3bfa27268: {[CrossEntropyWithSoftmax Gradient[1]] }
0x7ff3bfa27428: {[B1 Gradient[50 x 1]] [H2 Gradient[50 x 1 x *]] [HLast Gradient[2 x 1 x *]] }
0x7ff3bfa275e8: {[W2*H1 Gradient[2 x 1 x *]] }
0x7ff3bfa277a8: {[B2 Gradient[2 x 1]] }
0x7ff3c033f898: {[W0 Value[50 x 2]] }
0x7ff3c035cdc8: {[B0 Value[50 x 1]] }
0x7ff3c035eee8: {[W1 Value[50 x 50]] }
0x7ff3c2983f28: {[InvStdOfFeatures Value[2]] }
0x7ff3c2986588: {[MeanOfFeatures Value[2]] }
0x7ff3c76bd3a8: {[features Value[2 x *]] }


07/13/2016 12:23:07: Precomputing --> 3 PreCompute nodes found.

07/13/2016 12:23:07: 	MeanOfFeatures = Mean()
07/13/2016 12:23:07: 	InvStdOfFeatures = InvStdDev()
07/13/2016 12:23:07: 	Prior = Mean()
BlockRandomizer::StartEpoch: epoch 0: frames [0..10000] (first sequence at sample 0), data subset 0 of 1

07/13/2016 12:23:07: Precomputing --> Completed.


07/13/2016 12:23:07: Starting Epoch 1: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 0: frames [0..10000] (first sequence at sample 0), data subset 0 of 1

07/13/2016 12:23:07: Starting minibatch loop.
07/13/2016 12:23:07:  Epoch[ 1 of 50]-Minibatch[   1-  10]: CrossEntropyWithSoftmax = 0.81617508 * 1280; EvalErrorPrediction = 0.51796875 * 1280; time = 0.0280s; samplesPerSecond = 45740.4
07/13/2016 12:23:08:  Epoch[ 1 of 50]-Minibatch[  11-  20]: CrossEntropyWithSoftmax = 0.73377447 * 1280; EvalErrorPrediction = 0.51796875 * 1280; time = 0.0266s; samplesPerSecond = 48203.7
07/13/2016 12:23:08:  Epoch[ 1 of 50]-Minibatch[  21-  30]: CrossEntropyWithSoftmax = 0.71287031 * 1280; EvalErrorPrediction = 0.48906250 * 1280; time = 0.0265s; samplesPerSecond = 48238.2
07/13/2016 12:23:08:  Epoch[ 1 of 50]-Minibatch[  31-  40]: CrossEntropyWithSoftmax = 0.69614067 * 1280; EvalErrorPrediction = 0.48203125 * 1280; time = 0.0264s; samplesPerSecond = 48486.7
07/13/2016 12:23:08:  Epoch[ 1 of 50]-Minibatch[  41-  50]: CrossEntropyWithSoftmax = 0.72144070 * 1280; EvalErrorPrediction = 0.47968750 * 1280; time = 0.0265s; samplesPerSecond = 48252.7
07/13/2016 12:23:08:  Epoch[ 1 of 50]-Minibatch[  51-  60]: CrossEntropyWithSoftmax = 0.74117203 * 1280; EvalErrorPrediction = 0.45781250 * 1280; time = 0.0264s; samplesPerSecond = 48540.0
07/13/2016 12:23:08:  Epoch[ 1 of 50]-Minibatch[  61-  70]: CrossEntropyWithSoftmax = 0.73851471 * 1280; EvalErrorPrediction = 0.45468750 * 1280; time = 0.0265s; samplesPerSecond = 48214.6
07/13/2016 12:23:08: Finished Epoch[ 1 of 50]: [Training] CrossEntropyWithSoftmax = 0.73239038 * 10000; EvalErrorPrediction = 0.48410000 * 10000; totalSamplesSeen = 10000; learningRatePerSample = 0.1; epochTime=0.223268s
07/13/2016 12:23:08: SGD: Saving checkpoint model '/tmp/cntk-test-20160713121920.930131/Speech_Simple@debug_gpu/models/simple.dnn.1'

07/13/2016 12:23:08: Starting Epoch 2: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 1: frames [10000..20000] (first sequence at sample 10000), data subset 0 of 1

07/13/2016 12:23:08: Starting minibatch loop.
07/13/2016 12:23:08:  Epoch[ 2 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.49843268 * 1280; EvalErrorPrediction = 0.27500000 * 1280; time = 0.0271s; samplesPerSecond = 47168.1
07/13/2016 12:23:08:  Epoch[ 2 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.23827281 * 1280; EvalErrorPrediction = 0.10078125 * 1280; time = 0.0263s; samplesPerSecond = 48687.7
07/13/2016 12:23:08:  Epoch[ 2 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.21230659 * 1280; EvalErrorPrediction = 0.08828125 * 1280; time = 0.0264s; samplesPerSecond = 48514.3
07/13/2016 12:23:08:  Epoch[ 2 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.26566648 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0264s; samplesPerSecond = 48505.1
07/13/2016 12:23:08:  Epoch[ 2 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.23675966 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0264s; samplesPerSecond = 48483.0
07/13/2016 12:23:08:  Epoch[ 2 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.22643671 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 0.0262s; samplesPerSecond = 48875.5
07/13/2016 12:23:08:  Epoch[ 2 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16871567 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0262s; samplesPerSecond = 48894.2
07/13/2016 12:23:08: Finished Epoch[ 2 of 50]: [Training] CrossEntropyWithSoftmax = 0.25624265 * 10000; EvalErrorPrediction = 0.10820000 * 10000; totalSamplesSeen = 20000; learningRatePerSample = 0.1; epochTime=0.213967s
07/13/2016 12:23:08: SGD: Saving checkpoint model '/tmp/cntk-test-20160713121920.930131/Speech_Simple@debug_gpu/models/simple.dnn.2'

07/13/2016 12:23:08: Starting Epoch 3: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 2: frames [20000..30000] (first sequence at sample 20000), data subset 0 of 1

07/13/2016 12:23:08: Starting minibatch loop.
07/13/2016 12:23:08:  Epoch[ 3 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15800086 * 1280; EvalErrorPrediction = 0.06171875 * 1280; time = 0.0269s; samplesPerSecond = 47530.6
07/13/2016 12:23:08:  Epoch[ 3 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16581289 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0261s; samplesPerSecond = 49034.6
07/13/2016 12:23:08:  Epoch[ 3 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.19208786 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0262s; samplesPerSecond = 48828.9
07/13/2016 12:23:08:  Epoch[ 3 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16155334 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0262s; samplesPerSecond = 48830.7
07/13/2016 12:23:08:  Epoch[ 3 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.20824003 * 1280; EvalErrorPrediction = 0.10546875 * 1280; time = 0.0262s; samplesPerSecond = 48909.1
07/13/2016 12:23:08:  Epoch[ 3 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15917091 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0262s; samplesPerSecond = 48827.0
07/13/2016 12:23:08:  Epoch[ 3 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16028433 * 1280; EvalErrorPrediction = 0.06875000 * 1280; time = 0.0263s; samplesPerSecond = 48715.5
07/13/2016 12:23:08: Finished Epoch[ 3 of 50]: [Training] CrossEntropyWithSoftmax = 0.17245027 * 10000; EvalErrorPrediction = 0.07720000 * 10000; totalSamplesSeen = 30000; learningRatePerSample = 0.1; epochTime=0.213069s
07/13/2016 12:23:08: SGD: Saving checkpoint model '/tmp/cntk-test-20160713121920.930131/Speech_Simple@debug_gpu/models/simple.dnn.3'

07/13/2016 12:23:08: Starting Epoch 4: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 3: frames [30000..40000] (first sequence at sample 30000), data subset 0 of 1

07/13/2016 12:23:08: Starting minibatch loop.
07/13/2016 12:23:08:  Epoch[ 4 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.18641645 * 1280; EvalErrorPrediction = 0.08984375 * 1280; time = 0.0272s; samplesPerSecond = 47096.9
07/13/2016 12:23:08:  Epoch[ 4 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17437385 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0266s; samplesPerSecond = 48205.5
07/13/2016 12:23:08:  Epoch[ 4 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14729838 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0263s; samplesPerSecond = 48674.8
07/13/2016 12:23:08:  Epoch[ 4 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16334481 * 1280; EvalErrorPrediction = 0.06718750 * 1280; time = 0.0263s; samplesPerSecond = 48752.6
07/13/2016 12:23:08:  Epoch[ 4 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14964414 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.0263s; samplesPerSecond = 48708.1
07/13/2016 12:23:08:  Epoch[ 4 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.18884563 * 1280; EvalErrorPrediction = 0.09375000 * 1280; time = 0.0262s; samplesPerSecond = 48886.7
07/13/2016 12:23:08:  Epoch[ 4 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16661625 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 0.0294s; samplesPerSecond = 43538.9
07/13/2016 12:23:08: Finished Epoch[ 4 of 50]: [Training] CrossEntropyWithSoftmax = 0.16787476 * 10000; EvalErrorPrediction = 0.07800000 * 10000; totalSamplesSeen = 40000; learningRatePerSample = 0.1; epochTime=0.218495s
07/13/2016 12:23:08: SGD: Saving checkpoint model '/tmp/cntk-test-20160713121920.930131/Speech_Simple@debug_gpu/models/simple.dnn.4'

07/13/2016 12:23:08: Starting Epoch 5: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 4: frames [40000..50000] (first sequence at sample 40000), data subset 0 of 1

07/13/2016 12:23:08: Starting minibatch loop.
07/13/2016 12:23:08:  Epoch[ 5 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.14795867 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.0273s; samplesPerSecond = 46874.4
07/13/2016 12:23:08:  Epoch[ 5 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.18887879 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 0.0263s; samplesPerSecond = 48647.0
07/13/2016 12:23:08:  Epoch[ 5 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.19039090 * 1280; EvalErrorPrediction = 0.08750000 * 1280; time = 0.0263s; samplesPerSecond = 48748.9
07/13/2016 12:23:08:  Epoch[ 5 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16367989 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0261s; samplesPerSecond = 48961.5
07/13/2016 12:23:08:  Epoch[ 5 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14825420 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.0262s; samplesPerSecond = 48849.4
07/13/2016 12:23:08:  Epoch[ 5 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17402649 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0263s; samplesPerSecond = 48628.5
07/13/2016 12:23:09:  Epoch[ 5 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.18850470 * 1280; EvalErrorPrediction = 0.08671875 * 1280; time = 0.0262s; samplesPerSecond = 48851.2
07/13/2016 12:23:09: Finished Epoch[ 5 of 50]: [Training] CrossEntropyWithSoftmax = 0.16812375 * 10000; EvalErrorPrediction = 0.07640000 * 10000; totalSamplesSeen = 50000; learningRatePerSample = 0.1; epochTime=0.213592s
07/13/2016 12:23:09: SGD: Saving checkpoint model '/tmp/cntk-test-20160713121920.930131/Speech_Simple@debug_gpu/models/simple.dnn.5'

07/13/2016 12:23:09: Starting Epoch 6: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 5: frames [50000..60000] (first sequence at sample 50000), data subset 0 of 1

07/13/2016 12:23:09: Starting minibatch loop.
07/13/2016 12:23:09:  Epoch[ 6 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16417043 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0270s; samplesPerSecond = 47442.6
07/13/2016 12:23:09:  Epoch[ 6 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15806546 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0263s; samplesPerSecond = 48632.2
07/13/2016 12:23:09:  Epoch[ 6 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15316274 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0263s; samplesPerSecond = 48743.3
07/13/2016 12:23:09:  Epoch[ 6 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16868696 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0261s; samplesPerSecond = 48948.4
07/13/2016 12:23:09:  Epoch[ 6 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16524391 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0261s; samplesPerSecond = 49012.1
07/13/2016 12:23:09:  Epoch[ 6 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16858387 * 1280; EvalErrorPrediction = 0.08593750 * 1280; time = 0.0262s; samplesPerSecond = 48918.4
07/13/2016 12:23:09:  Epoch[ 6 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15710440 * 1280; EvalErrorPrediction = 0.06796875 * 1280; time = 0.0261s; samplesPerSecond = 49083.5
07/13/2016 12:23:09: Finished Epoch[ 6 of 50]: [Training] CrossEntropyWithSoftmax = 0.16169860 * 10000; EvalErrorPrediction = 0.07590000 * 10000; totalSamplesSeen = 60000; learningRatePerSample = 0.1; epochTime=0.212805s
07/13/2016 12:23:09: SGD: Saving checkpoint model '/tmp/cntk-test-20160713121920.930131/Speech_Simple@debug_gpu/models/simple.dnn.6'

07/13/2016 12:23:09: Starting Epoch 7: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 6: frames [60000..70000] (first sequence at sample 60000), data subset 0 of 1

07/13/2016 12:23:09: Starting minibatch loop.
07/13/2016 12:23:09:  Epoch[ 7 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.18160713 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0269s; samplesPerSecond = 47608.4
07/13/2016 12:23:09:  Epoch[ 7 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.19635506 * 1280; EvalErrorPrediction = 0.08671875 * 1280; time = 0.0263s; samplesPerSecond = 48735.9
07/13/2016 12:23:09:  Epoch[ 7 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17201478 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0262s; samplesPerSecond = 48791.6
07/13/2016 12:23:09:  Epoch[ 7 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16116476 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0262s; samplesPerSecond = 48799.1
07/13/2016 12:23:09:  Epoch[ 7 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14690967 * 1280; EvalErrorPrediction = 0.06796875 * 1280; time = 0.0262s; samplesPerSecond = 48786.1
07/13/2016 12:23:09:  Epoch[ 7 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17914429 * 1280; EvalErrorPrediction = 0.08671875 * 1280; time = 0.0261s; samplesPerSecond = 48982.1
07/13/2016 12:23:09:  Epoch[ 7 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15242701 * 1280; EvalErrorPrediction = 0.06875000 * 1280; time = 0.0262s; samplesPerSecond = 48840.0
07/13/2016 12:23:09: Finished Epoch[ 7 of 50]: [Training] CrossEntropyWithSoftmax = 0.17052689 * 10000; EvalErrorPrediction = 0.07780000 * 10000; totalSamplesSeen = 70000; learningRatePerSample = 0.1; epochTime=0.212893s
07/13/2016 12:23:09: SGD: Saving checkpoint model '/tmp/cntk-test-20160713121920.930131/Speech_Simple@debug_gpu/models/simple.dnn.7'

07/13/2016 12:23:09: Starting Epoch 8: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 7: frames [70000..80000] (first sequence at sample 70000), data subset 0 of 1

07/13/2016 12:23:09: Starting minibatch loop.
07/13/2016 12:23:09:  Epoch[ 8 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.19076351 * 1280; EvalErrorPrediction = 0.08906250 * 1280; time = 0.0269s; samplesPerSecond = 47622.6
07/13/2016 12:23:09:  Epoch[ 8 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15753578 * 1280; EvalErrorPrediction = 0.06875000 * 1280; time = 0.0261s; samplesPerSecond = 49047.8
07/13/2016 12:23:09:  Epoch[ 8 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16156237 * 1280; EvalErrorPrediction = 0.06640625 * 1280; time = 0.0260s; samplesPerSecond = 49213.7
07/13/2016 12:23:09:  Epoch[ 8 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15250692 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0261s; samplesPerSecond = 48991.5
07/13/2016 12:23:09:  Epoch[ 8 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16825066 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0263s; samplesPerSecond = 48593.4
07/13/2016 12:23:09:  Epoch[ 8 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.18632565 * 1280; EvalErrorPrediction = 0.08750000 * 1280; time = 0.0265s; samplesPerSecond = 48362.1
07/13/2016 12:23:09:  Epoch[ 8 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14869471 * 1280; EvalErrorPrediction = 0.06796875 * 1280; time = 0.0262s; samplesPerSecond = 48793.5
07/13/2016 12:23:09: Finished Epoch[ 8 of 50]: [Training] CrossEntropyWithSoftmax = 0.16726311 * 10000; EvalErrorPrediction = 0.07660000 * 10000; totalSamplesSeen = 80000; learningRatePerSample = 0.1; epochTime=0.213076s
07/13/2016 12:23:09: SGD: Saving checkpoint model '/tmp/cntk-test-20160713121920.930131/Speech_Simple@debug_gpu/models/simple.dnn.8'

07/13/2016 12:23:09: Starting Epoch 9: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 8: frames [80000..90000] (first sequence at sample 80000), data subset 0 of 1

07/13/2016 12:23:09: Starting minibatch loop.
07/13/2016 12:23:09:  Epoch[ 9 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16929054 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0270s; samplesPerSecond = 47333.8
07/13/2016 12:23:09:  Epoch[ 9 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17313080 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0262s; samplesPerSecond = 48886.7
07/13/2016 12:23:09:  Epoch[ 9 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16014233 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0262s; samplesPerSecond = 48853.1
07/13/2016 12:23:09:  Epoch[ 9 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15436630 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 0.0263s; samplesPerSecond = 48708.1
07/13/2016 12:23:09:  Epoch[ 9 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.13862023 * 1280; EvalErrorPrediction = 0.05703125 * 1280; time = 0.0262s; samplesPerSecond = 48827.0
07/13/2016 12:23:09:  Epoch[ 9 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17191691 * 1280; EvalErrorPrediction = 0.08359375 * 1280; time = 0.0261s; samplesPerSecond = 49087.3
07/13/2016 12:23:09:  Epoch[ 9 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14892521 * 1280; EvalErrorPrediction = 0.06406250 * 1280; time = 0.0263s; samplesPerSecond = 48665.5
07/13/2016 12:23:09: Finished Epoch[ 9 of 50]: [Training] CrossEntropyWithSoftmax = 0.16023846 * 10000; EvalErrorPrediction = 0.07450000 * 10000; totalSamplesSeen = 90000; learningRatePerSample = 0.1; epochTime=0.213139s
07/13/2016 12:23:09: SGD: Saving checkpoint model '/tmp/cntk-test-20160713121920.930131/Speech_Simple@debug_gpu/models/simple.dnn.9'

07/13/2016 12:23:09: Starting Epoch 10: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 9: frames [90000..100000] (first sequence at sample 90000), data subset 0 of 1

07/13/2016 12:23:09: Starting minibatch loop.
07/13/2016 12:23:09:  Epoch[10 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15953543 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0268s; samplesPerSecond = 47690.0
07/13/2016 12:23:09:  Epoch[10 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16755600 * 1280; EvalErrorPrediction = 0.08593750 * 1280; time = 0.0262s; samplesPerSecond = 48804.7
07/13/2016 12:23:09:  Epoch[10 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14238112 * 1280; EvalErrorPrediction = 0.06484375 * 1280; time = 0.0263s; samplesPerSecond = 48634.1
07/13/2016 12:23:10:  Epoch[10 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.17691965 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0262s; samplesPerSecond = 48946.5
07/13/2016 12:23:10:  Epoch[10 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16566796 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0262s; samplesPerSecond = 48916.6
07/13/2016 12:23:10:  Epoch[10 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16127262 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 0.0263s; samplesPerSecond = 48732.2
07/13/2016 12:23:10:  Epoch[10 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14459457 * 1280; EvalErrorPrediction = 0.06718750 * 1280; time = 0.0263s; samplesPerSecond = 48691.4
07/13/2016 12:23:10: Finished Epoch[10 of 50]: [Training] CrossEntropyWithSoftmax = 0.15843966 * 10000; EvalErrorPrediction = 0.07470000 * 10000; totalSamplesSeen = 100000; learningRatePerSample = 0.1; epochTime=0.213179s
07/13/2016 12:23:10: SGD: Saving checkpoint model '/tmp/cntk-test-20160713121920.930131/Speech_Simple@debug_gpu/models/simple.dnn.10'

07/13/2016 12:23:10: Starting Epoch 11: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 10: frames [100000..110000] (first sequence at sample 100000), data subset 0 of 1

07/13/2016 12:23:10: Starting minibatch loop.
07/13/2016 12:23:10:  Epoch[11 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15813996 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0268s; samplesPerSecond = 47684.7
07/13/2016 12:23:10:  Epoch[11 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15605491 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0263s; samplesPerSecond = 48600.8
07/13/2016 12:23:10:  Epoch[11 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15871444 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0263s; samplesPerSecond = 48665.5
07/13/2016 12:23:10:  Epoch[11 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.18369932 * 1280; EvalErrorPrediction = 0.09140625 * 1280; time = 0.0263s; samplesPerSecond = 48584.2
07/13/2016 12:23:10:  Epoch[11 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16956115 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0262s; samplesPerSecond = 48819.6
07/13/2016 12:23:10:  Epoch[11 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16034946 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0263s; samplesPerSecond = 48593.4
07/13/2016 12:23:10:  Epoch[11 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15532827 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0263s; samplesPerSecond = 48700.7
07/13/2016 12:23:10: Finished Epoch[11 of 50]: [Training] CrossEntropyWithSoftmax = 0.16192614 * 10000; EvalErrorPrediction = 0.07640000 * 10000; totalSamplesSeen = 110000; learningRatePerSample = 0.1; epochTime=0.213428s
07/13/2016 12:23:10: SGD: Saving checkpoint model '/tmp/cntk-test-20160713121920.930131/Speech_Simple@debug_gpu/models/simple.dnn.11'

07/13/2016 12:23:10: Starting Epoch 12: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 11: frames [110000..120000] (first sequence at sample 110000), data subset 0 of 1

07/13/2016 12:23:10: Starting minibatch loop.
07/13/2016 12:23:10:  Epoch[12 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.14863362 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0268s; samplesPerSecond = 47787.9
07/13/2016 12:23:10:  Epoch[12 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16842790 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0262s; samplesPerSecond = 48795.4
07/13/2016 12:23:10:  Epoch[12 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17496700 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0263s; samplesPerSecond = 48697.0
07/13/2016 12:23:10:  Epoch[12 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16903710 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0262s; samplesPerSecond = 48873.6
07/13/2016 12:23:10:  Epoch[12 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.19188952 * 1280; EvalErrorPrediction = 0.08828125 * 1280; time = 0.0262s; samplesPerSecond = 48765.6
07/13/2016 12:23:10:  Epoch[12 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14883680 * 1280; EvalErrorPrediction = 0.06640625 * 1280; time = 0.0262s; samplesPerSecond = 48789.8
07/13/2016 12:23:10:  Epoch[12 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16941414 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0263s; samplesPerSecond = 48674.8
07/13/2016 12:23:10: Finished Epoch[12 of 50]: [Training] CrossEntropyWithSoftmax = 0.16702577 * 10000; EvalErrorPrediction = 0.07700000 * 10000; totalSamplesSeen = 120000; learningRatePerSample = 0.1; epochTime=0.213104s
07/13/2016 12:23:10: SGD: Saving checkpoint model '/tmp/cntk-test-20160713121920.930131/Speech_Simple@debug_gpu/models/simple.dnn.12'

07/13/2016 12:23:10: Starting Epoch 13: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 12: frames [120000..130000] (first sequence at sample 120000), data subset 0 of 1

07/13/2016 12:23:10: Starting minibatch loop.
07/13/2016 12:23:10:  Epoch[13 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15751876 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0269s; samplesPerSecond = 47567.7
07/13/2016 12:23:10:  Epoch[13 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15110375 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0263s; samplesPerSecond = 48676.6
07/13/2016 12:23:10:  Epoch[13 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16237354 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0264s; samplesPerSecond = 48461.0
07/13/2016 12:23:10:  Epoch[13 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16139441 * 1280; EvalErrorPrediction = 0.06875000 * 1280; time = 0.0263s; samplesPerSecond = 48719.2
07/13/2016 12:23:10:  Epoch[13 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.18865657 * 1280; EvalErrorPrediction = 0.09218750 * 1280; time = 0.0263s; samplesPerSecond = 48689.6
07/13/2016 12:23:10:  Epoch[13 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16029387 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.0264s; samplesPerSecond = 48575.0
07/13/2016 12:23:10:  Epoch[13 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.18121386 * 1280; EvalErrorPrediction = 0.08906250 * 1280; time = 0.0262s; samplesPerSecond = 48856.8
07/13/2016 12:23:10: Finished Epoch[13 of 50]: [Training] CrossEntropyWithSoftmax = 0.16550040 * 10000; EvalErrorPrediction = 0.07720000 * 10000; totalSamplesSeen = 130000; learningRatePerSample = 0.1; epochTime=0.213756s
07/13/2016 12:23:10: SGD: Saving checkpoint model '/tmp/cntk-test-20160713121920.930131/Speech_Simple@debug_gpu/models/simple.dnn.13'

07/13/2016 12:23:10: Starting Epoch 14: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 13: frames [130000..140000] (first sequence at sample 130000), data subset 0 of 1

07/13/2016 12:23:10: Starting minibatch loop.
07/13/2016 12:23:10:  Epoch[14 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16697839 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0268s; samplesPerSecond = 47707.8
07/13/2016 12:23:10:  Epoch[14 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16038507 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0262s; samplesPerSecond = 48862.4
07/13/2016 12:23:10:  Epoch[14 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16519830 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0262s; samplesPerSecond = 48948.4
07/13/2016 12:23:10:  Epoch[14 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14744382 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0262s; samplesPerSecond = 48761.9
07/13/2016 12:23:10:  Epoch[14 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15347919 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0263s; samplesPerSecond = 48628.5
07/13/2016 12:23:10:  Epoch[14 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16583862 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0262s; samplesPerSecond = 48866.2
07/13/2016 12:23:10:  Epoch[14 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16769333 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 0.0261s; samplesPerSecond = 49047.8
07/13/2016 12:23:10: Finished Epoch[14 of 50]: [Training] CrossEntropyWithSoftmax = 0.16058110 * 10000; EvalErrorPrediction = 0.07530000 * 10000; totalSamplesSeen = 140000; learningRatePerSample = 0.1; epochTime=0.213137s
07/13/2016 12:23:10: SGD: Saving checkpoint model '/tmp/cntk-test-20160713121920.930131/Speech_Simple@debug_gpu/models/simple.dnn.14'

07/13/2016 12:23:10: Starting Epoch 15: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 14: frames [140000..150000] (first sequence at sample 140000), data subset 0 of 1

07/13/2016 12:23:10: Starting minibatch loop.
07/13/2016 12:23:10:  Epoch[15 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17504191 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0268s; samplesPerSecond = 47723.8
07/13/2016 12:23:11:  Epoch[15 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17398829 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0263s; samplesPerSecond = 48652.6
07/13/2016 12:23:11:  Epoch[15 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16190443 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0263s; samplesPerSecond = 48684.0
07/13/2016 12:23:11:  Epoch[15 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.17221560 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0263s; samplesPerSecond = 48639.6
07/13/2016 12:23:11:  Epoch[15 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.17401280 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0261s; samplesPerSecond = 48999.0
07/13/2016 12:23:11:  Epoch[15 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17121601 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0261s; samplesPerSecond = 49094.8
07/13/2016 12:23:11:  Epoch[15 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17040396 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 0.0261s; samplesPerSecond = 49000.8
07/13/2016 12:23:11: Finished Epoch[15 of 50]: [Training] CrossEntropyWithSoftmax = 0.17091884 * 10000; EvalErrorPrediction = 0.07830000 * 10000; totalSamplesSeen = 150000; learningRatePerSample = 0.1; epochTime=0.212827s
07/13/2016 12:23:11: SGD: Saving checkpoint model '/tmp/cntk-test-20160713121920.930131/Speech_Simple@debug_gpu/models/simple.dnn.15'

07/13/2016 12:23:11: Starting Epoch 16: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 15: frames [150000..160000] (first sequence at sample 150000), data subset 0 of 1

07/13/2016 12:23:11: Starting minibatch loop.
07/13/2016 12:23:11:  Epoch[16 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.14499781 * 1280; EvalErrorPrediction = 0.06875000 * 1280; time = 0.0268s; samplesPerSecond = 47674.0
07/13/2016 12:23:11:  Epoch[16 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17145011 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0262s; samplesPerSecond = 48800.9
07/13/2016 12:23:11:  Epoch[16 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16693316 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0268s; samplesPerSecond = 47846.9
07/13/2016 12:23:11:  Epoch[16 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14426079 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0267s; samplesPerSecond = 47941.9
07/13/2016 12:23:11:  Epoch[16 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15098538 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0266s; samplesPerSecond = 48203.7
07/13/2016 12:23:11:  Epoch[16 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15499597 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0263s; samplesPerSecond = 48752.6
07/13/2016 12:23:11:  Epoch[16 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15641975 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 0.0256s; samplesPerSecond = 49910.3
07/13/2016 12:23:11: Finished Epoch[16 of 50]: [Training] CrossEntropyWithSoftmax = 0.15964780 * 10000; EvalErrorPrediction = 0.07560000 * 10000; totalSamplesSeen = 160000; learningRatePerSample = 0.1; epochTime=0.213545s
07/13/2016 12:23:11: SGD: Saving checkpoint model '/tmp/cntk-test-20160713121920.930131/Speech_Simple@debug_gpu/models/simple.dnn.16'

07/13/2016 12:23:11: Starting Epoch 17: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 16: frames [160000..170000] (first sequence at sample 160000), data subset 0 of 1

07/13/2016 12:23:11: Starting minibatch loop.
07/13/2016 12:23:11:  Epoch[17 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17199061 * 1280; EvalErrorPrediction = 0.08359375 * 1280; time = 0.0263s; samplesPerSecond = 48669.2
07/13/2016 12:23:11:  Epoch[17 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16243212 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0257s; samplesPerSecond = 49712.6
07/13/2016 12:23:11:  Epoch[17 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16780829 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 0.0262s; samplesPerSecond = 48946.5
07/13/2016 12:23:11:  Epoch[17 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15655594 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0261s; samplesPerSecond = 48987.7
07/13/2016 12:23:11:  Epoch[17 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15865726 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0261s; samplesPerSecond = 48974.6
07/13/2016 12:23:11:  Epoch[17 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14919052 * 1280; EvalErrorPrediction = 0.06484375 * 1280; time = 0.0260s; samplesPerSecond = 49141.9
07/13/2016 12:23:11:  Epoch[17 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15324907 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0267s; samplesPerSecond = 47940.1
07/13/2016 12:23:11: Finished Epoch[17 of 50]: [Training] CrossEntropyWithSoftmax = 0.15978616 * 10000; EvalErrorPrediction = 0.07410000 * 10000; totalSamplesSeen = 170000; learningRatePerSample = 0.1; epochTime=0.212117s
07/13/2016 12:23:11: SGD: Saving checkpoint model '/tmp/cntk-test-20160713121920.930131/Speech_Simple@debug_gpu/models/simple.dnn.17'

07/13/2016 12:23:11: Starting Epoch 18: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 17: frames [170000..180000] (first sequence at sample 170000), data subset 0 of 1

07/13/2016 12:23:11: Starting minibatch loop.
07/13/2016 12:23:11:  Epoch[18 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16007935 * 1280; EvalErrorPrediction = 0.06796875 * 1280; time = 0.0274s; samplesPerSecond = 46793.9
07/13/2016 12:23:11:  Epoch[18 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15282840 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 0.0266s; samplesPerSecond = 48205.5
07/13/2016 12:23:11:  Epoch[18 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17086225 * 1280; EvalErrorPrediction = 0.08359375 * 1280; time = 0.0264s; samplesPerSecond = 48494.0
07/13/2016 12:23:11:  Epoch[18 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15249200 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 0.0263s; samplesPerSecond = 48671.1
07/13/2016 12:23:11:  Epoch[18 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.18579068 * 1280; EvalErrorPrediction = 0.08515625 * 1280; time = 0.0265s; samplesPerSecond = 48331.1
07/13/2016 12:23:11:  Epoch[18 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16916323 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0264s; samplesPerSecond = 48446.3
07/13/2016 12:23:11:  Epoch[18 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15036688 * 1280; EvalErrorPrediction = 0.06875000 * 1280; time = 0.0264s; samplesPerSecond = 48536.3
07/13/2016 12:23:11: Finished Epoch[18 of 50]: [Training] CrossEntropyWithSoftmax = 0.16232883 * 10000; EvalErrorPrediction = 0.07540000 * 10000; totalSamplesSeen = 180000; learningRatePerSample = 0.1; epochTime=0.214824s
07/13/2016 12:23:11: SGD: Saving checkpoint model '/tmp/cntk-test-20160713121920.930131/Speech_Simple@debug_gpu/models/simple.dnn.18'

07/13/2016 12:23:11: Starting Epoch 19: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 18: frames [180000..190000] (first sequence at sample 180000), data subset 0 of 1

07/13/2016 12:23:11: Starting minibatch loop.
07/13/2016 12:23:11:  Epoch[19 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.14655702 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0271s; samplesPerSecond = 47192.4
07/13/2016 12:23:11:  Epoch[19 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15965455 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0263s; samplesPerSecond = 48658.1
07/13/2016 12:23:11:  Epoch[19 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16810975 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0263s; samplesPerSecond = 48671.1
07/13/2016 12:23:11:  Epoch[19 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.17923827 * 1280; EvalErrorPrediction = 0.08671875 * 1280; time = 0.0264s; samplesPerSecond = 48569.5
07/13/2016 12:23:11:  Epoch[19 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.18138485 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0264s; samplesPerSecond = 48517.9
07/13/2016 12:23:11:  Epoch[19 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.19831581 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0264s; samplesPerSecond = 48527.1
07/13/2016 12:23:12:  Epoch[19 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15901518 * 1280; EvalErrorPrediction = 0.06718750 * 1280; time = 0.0263s; samplesPerSecond = 48687.7
07/13/2016 12:23:12: Finished Epoch[19 of 50]: [Training] CrossEntropyWithSoftmax = 0.16842527 * 10000; EvalErrorPrediction = 0.07800000 * 10000; totalSamplesSeen = 190000; learningRatePerSample = 0.1; epochTime=0.21407s
07/13/2016 12:23:12: SGD: Saving checkpoint model '/tmp/cntk-test-20160713121920.930131/Speech_Simple@debug_gpu/models/simple.dnn.19'

07/13/2016 12:23:12: Starting Epoch 20: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 19: frames [190000..200000] (first sequence at sample 190000), data subset 0 of 1

07/13/2016 12:23:12: Starting minibatch loop.
07/13/2016 12:23:12:  Epoch[20 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16536105 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0271s; samplesPerSecond = 47182.0
07/13/2016 12:23:12:  Epoch[20 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.18725352 * 1280; EvalErrorPrediction = 0.09609375 * 1280; time = 0.0264s; samplesPerSecond = 48552.9
07/13/2016 12:23:12:  Epoch[20 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17445228 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0264s; samplesPerSecond = 48540.0
07/13/2016 12:23:12:  Epoch[20 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15546021 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 0.0264s; samplesPerSecond = 48523.4
07/13/2016 12:23:12:  Epoch[20 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16204348 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 0.0263s; samplesPerSecond = 48578.7
07/13/2016 12:23:12:  Epoch[20 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.18671112 * 1280; EvalErrorPrediction = 0.08593750 * 1280; time = 0.0263s; samplesPerSecond = 48619.3
07/13/2016 12:23:12:  Epoch[20 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16987848 * 1280; EvalErrorPrediction = 0.06484375 * 1280; time = 0.0265s; samplesPerSecond = 48321.9
07/13/2016 12:23:12: Finished Epoch[20 of 50]: [Training] CrossEntropyWithSoftmax = 0.16896514 * 10000; EvalErrorPrediction = 0.07840000 * 10000; totalSamplesSeen = 200000; learningRatePerSample = 0.1; epochTime=0.21437s
07/13/2016 12:23:12: SGD: Saving checkpoint model '/tmp/cntk-test-20160713121920.930131/Speech_Simple@debug_gpu/models/simple.dnn.20'

07/13/2016 12:23:12: Starting Epoch 21: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 20: frames [200000..210000] (first sequence at sample 200000), data subset 0 of 1

07/13/2016 12:23:12: Starting minibatch loop.
07/13/2016 12:23:12:  Epoch[21 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16469028 * 1280; EvalErrorPrediction = 0.08359375 * 1280; time = 0.0289s; samplesPerSecond = 44304.5
07/13/2016 12:23:12:  Epoch[21 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15381479 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.0263s; samplesPerSecond = 48745.2
07/13/2016 12:23:12:  Epoch[21 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15882838 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0263s; samplesPerSecond = 48685.9
07/13/2016 12:23:12:  Epoch[21 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16333494 * 1280; EvalErrorPrediction = 0.06718750 * 1280; time = 0.0265s; samplesPerSecond = 48389.5
07/13/2016 12:23:12:  Epoch[21 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.17477932 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0264s; samplesPerSecond = 48501.4
07/13/2016 12:23:12:  Epoch[21 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15844307 * 1280; EvalErrorPrediction = 0.06250000 * 1280; time = 0.0264s; samplesPerSecond = 48560.3
07/13/2016 12:23:12:  Epoch[21 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.18186140 * 1280; EvalErrorPrediction = 0.08750000 * 1280; time = 0.0262s; samplesPerSecond = 48841.9
07/13/2016 12:23:12: Finished Epoch[21 of 50]: [Training] CrossEntropyWithSoftmax = 0.16533986 * 10000; EvalErrorPrediction = 0.07570000 * 10000; totalSamplesSeen = 210000; learningRatePerSample = 0.1; epochTime=0.21593s
07/13/2016 12:23:12: SGD: Saving checkpoint model '/tmp/cntk-test-20160713121920.930131/Speech_Simple@debug_gpu/models/simple.dnn.21'

07/13/2016 12:23:12: Starting Epoch 22: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 21: frames [210000..220000] (first sequence at sample 210000), data subset 0 of 1

07/13/2016 12:23:12: Starting minibatch loop.
07/13/2016 12:23:12:  Epoch[22 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.20349460 * 1280; EvalErrorPrediction = 0.09765625 * 1280; time = 0.0271s; samplesPerSecond = 47208.1
07/13/2016 12:23:12:  Epoch[22 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17329526 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0263s; samplesPerSecond = 48730.3
07/13/2016 12:23:12:  Epoch[22 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16117549 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 0.0263s; samplesPerSecond = 48676.6
07/13/2016 12:23:12:  Epoch[22 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15503263 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0264s; samplesPerSecond = 48396.9
07/13/2016 12:23:12:  Epoch[22 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16139951 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 0.0266s; samplesPerSecond = 48185.5
07/13/2016 12:23:12:  Epoch[22 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16247711 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0267s; samplesPerSecond = 48024.6
07/13/2016 12:23:12:  Epoch[22 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17946978 * 1280; EvalErrorPrediction = 0.08750000 * 1280; time = 0.0267s; samplesPerSecond = 48019.2
07/13/2016 12:23:12: Finished Epoch[22 of 50]: [Training] CrossEntropyWithSoftmax = 0.16675659 * 10000; EvalErrorPrediction = 0.07770000 * 10000; totalSamplesSeen = 220000; learningRatePerSample = 0.1; epochTime=0.215435s
07/13/2016 12:23:12: SGD: Saving checkpoint model '/tmp/cntk-test-20160713121920.930131/Speech_Simple@debug_gpu/models/simple.dnn.22'

07/13/2016 12:23:12: Starting Epoch 23: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 22: frames [220000..230000] (first sequence at sample 220000), data subset 0 of 1

07/13/2016 12:23:12: Starting minibatch loop.
07/13/2016 12:23:12:  Epoch[23 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17159755 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 0.0274s; samplesPerSecond = 46676.1
07/13/2016 12:23:12:  Epoch[23 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17114067 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0267s; samplesPerSecond = 47970.6
07/13/2016 12:23:12:  Epoch[23 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15244133 * 1280; EvalErrorPrediction = 0.06796875 * 1280; time = 0.0267s; samplesPerSecond = 47918.5
07/13/2016 12:23:12:  Epoch[23 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15626545 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0267s; samplesPerSecond = 47995.8
07/13/2016 12:23:12:  Epoch[23 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16120472 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0267s; samplesPerSecond = 47911.4
07/13/2016 12:23:12:  Epoch[23 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14013500 * 1280; EvalErrorPrediction = 0.06796875 * 1280; time = 0.0266s; samplesPerSecond = 48133.0
07/13/2016 12:23:12:  Epoch[23 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16929522 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0267s; samplesPerSecond = 48019.2
07/13/2016 12:23:12: Finished Epoch[23 of 50]: [Training] CrossEntropyWithSoftmax = 0.15960048 * 10000; EvalErrorPrediction = 0.07490000 * 10000; totalSamplesSeen = 230000; learningRatePerSample = 0.1; epochTime=0.216601s
07/13/2016 12:23:12: SGD: Saving checkpoint model '/tmp/cntk-test-20160713121920.930131/Speech_Simple@debug_gpu/models/simple.dnn.23'

07/13/2016 12:23:12: Starting Epoch 24: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 23: frames [230000..240000] (first sequence at sample 230000), data subset 0 of 1

07/13/2016 12:23:12: Starting minibatch loop.
07/13/2016 12:23:12:  Epoch[24 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17182534 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0271s; samplesPerSecond = 47164.6
07/13/2016 12:23:12:  Epoch[24 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15354176 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 0.0265s; samplesPerSecond = 48325.6
07/13/2016 12:23:12:  Epoch[24 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16197512 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0264s; samplesPerSecond = 48437.1
07/13/2016 12:23:13:  Epoch[24 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16589231 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0265s; samplesPerSecond = 48362.1
07/13/2016 12:23:13:  Epoch[24 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16722522 * 1280; EvalErrorPrediction = 0.06796875 * 1280; time = 0.0264s; samplesPerSecond = 48437.1
07/13/2016 12:23:13:  Epoch[24 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17564621 * 1280; EvalErrorPrediction = 0.08515625 * 1280; time = 0.0266s; samplesPerSecond = 48209.1
07/13/2016 12:23:13:  Epoch[24 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16375513 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0267s; samplesPerSecond = 47911.4
07/13/2016 12:23:13: Finished Epoch[24 of 50]: [Training] CrossEntropyWithSoftmax = 0.16714675 * 10000; EvalErrorPrediction = 0.07680000 * 10000; totalSamplesSeen = 240000; learningRatePerSample = 0.1; epochTime=0.215958s
07/13/2016 12:23:13: SGD: Saving checkpoint model '/tmp/cntk-test-20160713121920.930131/Speech_Simple@debug_gpu/models/simple.dnn.24'

07/13/2016 12:23:13: Starting Epoch 25: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 24: frames [240000..250000] (first sequence at sample 240000), data subset 0 of 1

07/13/2016 12:23:13: Starting minibatch loop.
07/13/2016 12:23:13:  Epoch[25 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17995143 * 1280; EvalErrorPrediction = 0.08359375 * 1280; time = 0.0273s; samplesPerSecond = 46871.0
07/13/2016 12:23:13:  Epoch[25 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.18855677 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0267s; samplesPerSecond = 47983.2
07/13/2016 12:23:13:  Epoch[25 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16692853 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 0.0263s; samplesPerSecond = 48613.7
07/13/2016 12:23:13:  Epoch[25 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.17160010 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0264s; samplesPerSecond = 48565.8
07/13/2016 12:23:13:  Epoch[25 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15487237 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0265s; samplesPerSecond = 48210.9
07/13/2016 12:23:13:  Epoch[25 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14489584 * 1280; EvalErrorPrediction = 0.06406250 * 1280; time = 0.0265s; samplesPerSecond = 48247.3
07/13/2016 12:23:13:  Epoch[25 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16311197 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0263s; samplesPerSecond = 48600.8
07/13/2016 12:23:13: Finished Epoch[25 of 50]: [Training] CrossEntropyWithSoftmax = 0.16767448 * 10000; EvalErrorPrediction = 0.07770000 * 10000; totalSamplesSeen = 250000; learningRatePerSample = 0.1; epochTime=0.215034s
07/13/2016 12:23:13: SGD: Saving checkpoint model '/tmp/cntk-test-20160713121920.930131/Speech_Simple@debug_gpu/models/simple.dnn.25'

07/13/2016 12:23:13: Starting Epoch 26: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 25: frames [250000..260000] (first sequence at sample 250000), data subset 0 of 1

07/13/2016 12:23:13: Starting minibatch loop.
07/13/2016 12:23:13:  Epoch[26 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16878678 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0272s; samplesPerSecond = 47076.1
07/13/2016 12:23:13:  Epoch[26 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15142335 * 1280; EvalErrorPrediction = 0.06640625 * 1280; time = 0.0265s; samplesPerSecond = 48327.4
07/13/2016 12:23:13:  Epoch[26 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15124254 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 0.0264s; samplesPerSecond = 48406.0
07/13/2016 12:23:13:  Epoch[26 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15940919 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0263s; samplesPerSecond = 48606.4
07/13/2016 12:23:13:  Epoch[26 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.17065420 * 1280; EvalErrorPrediction = 0.08593750 * 1280; time = 0.0264s; samplesPerSecond = 48428.0
07/13/2016 12:23:13:  Epoch[26 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14535627 * 1280; EvalErrorPrediction = 0.06562500 * 1280; time = 0.0264s; samplesPerSecond = 48446.3
07/13/2016 12:23:13:  Epoch[26 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17644186 * 1280; EvalErrorPrediction = 0.08671875 * 1280; time = 0.0265s; samplesPerSecond = 48278.2
07/13/2016 12:23:13: Finished Epoch[26 of 50]: [Training] CrossEntropyWithSoftmax = 0.15937396 * 10000; EvalErrorPrediction = 0.07440000 * 10000; totalSamplesSeen = 260000; learningRatePerSample = 0.1; epochTime=0.214774s
07/13/2016 12:23:13: SGD: Saving checkpoint model '/tmp/cntk-test-20160713121920.930131/Speech_Simple@debug_gpu/models/simple.dnn.26'

07/13/2016 12:23:13: Starting Epoch 27: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 26: frames [260000..270000] (first sequence at sample 260000), data subset 0 of 1

07/13/2016 12:23:13: Starting minibatch loop.
07/13/2016 12:23:13:  Epoch[27 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15709606 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0272s; samplesPerSecond = 47038.1
07/13/2016 12:23:13:  Epoch[27 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16543273 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0266s; samplesPerSecond = 48196.4
07/13/2016 12:23:13:  Epoch[27 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15277243 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0267s; samplesPerSecond = 47936.5
07/13/2016 12:23:13:  Epoch[27 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16587291 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0267s; samplesPerSecond = 47947.3
07/13/2016 12:23:13:  Epoch[27 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15222979 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0267s; samplesPerSecond = 47888.1
07/13/2016 12:23:13:  Epoch[27 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15051155 * 1280; EvalErrorPrediction = 0.06796875 * 1280; time = 0.0266s; samplesPerSecond = 48031.8
07/13/2016 12:23:13:  Epoch[27 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.18173809 * 1280; EvalErrorPrediction = 0.08750000 * 1280; time = 0.0266s; samplesPerSecond = 48145.6
07/13/2016 12:23:13: Finished Epoch[27 of 50]: [Training] CrossEntropyWithSoftmax = 0.15830378 * 10000; EvalErrorPrediction = 0.07530000 * 10000; totalSamplesSeen = 270000; learningRatePerSample = 0.1; epochTime=0.216479s
07/13/2016 12:23:13: SGD: Saving checkpoint model '/tmp/cntk-test-20160713121920.930131/Speech_Simple@debug_gpu/models/simple.dnn.27'

07/13/2016 12:23:13: Starting Epoch 28: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 27: frames [270000..280000] (first sequence at sample 270000), data subset 0 of 1

07/13/2016 12:23:13: Starting minibatch loop.
07/13/2016 12:23:13:  Epoch[28 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16907721 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0273s; samplesPerSecond = 46955.2
07/13/2016 12:23:13:  Epoch[28 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14707675 * 1280; EvalErrorPrediction = 0.06328125 * 1280; time = 0.0266s; samplesPerSecond = 48113.1
07/13/2016 12:23:13:  Epoch[28 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14986830 * 1280; EvalErrorPrediction = 0.06796875 * 1280; time = 0.0266s; samplesPerSecond = 48098.6
07/13/2016 12:23:13:  Epoch[28 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16217022 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0266s; samplesPerSecond = 48152.9
07/13/2016 12:23:13:  Epoch[28 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.18148379 * 1280; EvalErrorPrediction = 0.08906250 * 1280; time = 0.0266s; samplesPerSecond = 48163.8
07/13/2016 12:23:13:  Epoch[28 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15600395 * 1280; EvalErrorPrediction = 0.06875000 * 1280; time = 0.0267s; samplesPerSecond = 47877.3
07/13/2016 12:23:13:  Epoch[28 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16555967 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0268s; samplesPerSecond = 47771.9
07/13/2016 12:23:13: Finished Epoch[28 of 50]: [Training] CrossEntropyWithSoftmax = 0.16259102 * 10000; EvalErrorPrediction = 0.07560000 * 10000; totalSamplesSeen = 280000; learningRatePerSample = 0.1; epochTime=0.216572s
07/13/2016 12:23:13: SGD: Saving checkpoint model '/tmp/cntk-test-20160713121920.930131/Speech_Simple@debug_gpu/models/simple.dnn.28'

07/13/2016 12:23:13: Starting Epoch 29: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 28: frames [280000..290000] (first sequence at sample 280000), data subset 0 of 1

07/13/2016 12:23:13: Starting minibatch loop.
07/13/2016 12:23:14:  Epoch[29 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16562409 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0275s; samplesPerSecond = 46559.0
07/13/2016 12:23:14:  Epoch[29 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15941446 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0269s; samplesPerSecond = 47597.8
07/13/2016 12:23:14:  Epoch[29 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16366003 * 1280; EvalErrorPrediction = 0.06875000 * 1280; time = 0.0268s; samplesPerSecond = 47681.1
07/13/2016 12:23:14:  Epoch[29 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15629354 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0268s; samplesPerSecond = 47700.7
07/13/2016 12:23:14:  Epoch[29 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14837217 * 1280; EvalErrorPrediction = 0.06875000 * 1280; time = 0.0266s; samplesPerSecond = 48160.1
07/13/2016 12:23:14:  Epoch[29 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15770688 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0265s; samplesPerSecond = 48300.1
07/13/2016 12:23:14:  Epoch[29 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15916605 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0263s; samplesPerSecond = 48597.1
07/13/2016 12:23:14: Finished Epoch[29 of 50]: [Training] CrossEntropyWithSoftmax = 0.15779647 * 10000; EvalErrorPrediction = 0.07340000 * 10000; totalSamplesSeen = 290000; learningRatePerSample = 0.1; epochTime=0.21667s
07/13/2016 12:23:14: SGD: Saving checkpoint model '/tmp/cntk-test-20160713121920.930131/Speech_Simple@debug_gpu/models/simple.dnn.29'

07/13/2016 12:23:14: Starting Epoch 30: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 29: frames [290000..300000] (first sequence at sample 290000), data subset 0 of 1

07/13/2016 12:23:14: Starting minibatch loop.
07/13/2016 12:23:14:  Epoch[30 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.14879410 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0275s; samplesPerSecond = 46611.6
07/13/2016 12:23:14:  Epoch[30 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15640090 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 0.0268s; samplesPerSecond = 47845.1
07/13/2016 12:23:14:  Epoch[30 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.18904819 * 1280; EvalErrorPrediction = 0.08515625 * 1280; time = 0.0268s; samplesPerSecond = 47784.4
07/13/2016 12:23:14:  Epoch[30 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14199157 * 1280; EvalErrorPrediction = 0.06562500 * 1280; time = 0.0267s; samplesPerSecond = 47911.4
07/13/2016 12:23:14:  Epoch[30 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14786630 * 1280; EvalErrorPrediction = 0.06875000 * 1280; time = 0.0266s; samplesPerSecond = 48062.5
07/13/2016 12:23:14:  Epoch[30 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16597714 * 1280; EvalErrorPrediction = 0.08593750 * 1280; time = 0.0267s; samplesPerSecond = 48028.2
07/13/2016 12:23:14:  Epoch[30 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16080675 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0267s; samplesPerSecond = 47927.5
07/13/2016 12:23:14: Finished Epoch[30 of 50]: [Training] CrossEntropyWithSoftmax = 0.15906808 * 10000; EvalErrorPrediction = 0.07570000 * 10000; totalSamplesSeen = 300000; learningRatePerSample = 0.1; epochTime=0.217043s
07/13/2016 12:23:14: SGD: Saving checkpoint model '/tmp/cntk-test-20160713121920.930131/Speech_Simple@debug_gpu/models/simple.dnn.30'

07/13/2016 12:23:14: Starting Epoch 31: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 30: frames [300000..310000] (first sequence at sample 300000), data subset 0 of 1

07/13/2016 12:23:14: Starting minibatch loop.
07/13/2016 12:23:14:  Epoch[31 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16275744 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0273s; samplesPerSecond = 46802.4
07/13/2016 12:23:14:  Epoch[31 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17017746 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0267s; samplesPerSecond = 48028.2
07/13/2016 12:23:14:  Epoch[31 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14321699 * 1280; EvalErrorPrediction = 0.06328125 * 1280; time = 0.0265s; samplesPerSecond = 48347.5
07/13/2016 12:23:14:  Epoch[31 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15120192 * 1280; EvalErrorPrediction = 0.06562500 * 1280; time = 0.0263s; samplesPerSecond = 48669.2
07/13/2016 12:23:14:  Epoch[31 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15285535 * 1280; EvalErrorPrediction = 0.06875000 * 1280; time = 0.0265s; samplesPerSecond = 48336.5
07/13/2016 12:23:14:  Epoch[31 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.13534746 * 1280; EvalErrorPrediction = 0.06562500 * 1280; time = 0.0264s; samplesPerSecond = 48461.0
07/13/2016 12:23:14:  Epoch[31 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17624168 * 1280; EvalErrorPrediction = 0.08359375 * 1280; time = 0.0263s; samplesPerSecond = 48632.2
07/13/2016 12:23:14: Finished Epoch[31 of 50]: [Training] CrossEntropyWithSoftmax = 0.15980447 * 10000; EvalErrorPrediction = 0.07370000 * 10000; totalSamplesSeen = 310000; learningRatePerSample = 0.1; epochTime=0.215143s
07/13/2016 12:23:14: SGD: Saving checkpoint model '/tmp/cntk-test-20160713121920.930131/Speech_Simple@debug_gpu/models/simple.dnn.31'

07/13/2016 12:23:14: Starting Epoch 32: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 31: frames [310000..320000] (first sequence at sample 310000), data subset 0 of 1

07/13/2016 12:23:14: Starting minibatch loop.
07/13/2016 12:23:14:  Epoch[32 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16198599 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 0.0271s; samplesPerSecond = 47190.7
07/13/2016 12:23:14:  Epoch[32 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16215127 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0265s; samplesPerSecond = 48249.1
07/13/2016 12:23:14:  Epoch[32 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.13372493 * 1280; EvalErrorPrediction = 0.06484375 * 1280; time = 0.0265s; samplesPerSecond = 48280.0
07/13/2016 12:23:14:  Epoch[32 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16426897 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0265s; samplesPerSecond = 48376.7
07/13/2016 12:23:14:  Epoch[32 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16832576 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0264s; samplesPerSecond = 48497.7
07/13/2016 12:23:14:  Epoch[32 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16835799 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0265s; samplesPerSecond = 48230.9
07/13/2016 12:23:14:  Epoch[32 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14903240 * 1280; EvalErrorPrediction = 0.06484375 * 1280; time = 0.0264s; samplesPerSecond = 48554.7
07/13/2016 12:23:14: Finished Epoch[32 of 50]: [Training] CrossEntropyWithSoftmax = 0.16206068 * 10000; EvalErrorPrediction = 0.07470000 * 10000; totalSamplesSeen = 320000; learningRatePerSample = 0.1; epochTime=0.215078s
07/13/2016 12:23:14: SGD: Saving checkpoint model '/tmp/cntk-test-20160713121920.930131/Speech_Simple@debug_gpu/models/simple.dnn.32'

07/13/2016 12:23:14: Starting Epoch 33: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 32: frames [320000..330000] (first sequence at sample 320000), data subset 0 of 1

07/13/2016 12:23:14: Starting minibatch loop.
07/13/2016 12:23:14:  Epoch[33 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17260238 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0272s; samplesPerSecond = 47110.8
07/13/2016 12:23:14:  Epoch[33 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15036043 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0265s; samplesPerSecond = 48229.1
07/13/2016 12:23:14:  Epoch[33 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14416060 * 1280; EvalErrorPrediction = 0.06796875 * 1280; time = 0.0264s; samplesPerSecond = 48560.3
07/13/2016 12:23:14:  Epoch[33 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16257315 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0263s; samplesPerSecond = 48597.1
07/13/2016 12:23:14:  Epoch[33 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16877375 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 0.0266s; samplesPerSecond = 48156.5
07/13/2016 12:23:15:  Epoch[33 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15273428 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 0.0265s; samplesPerSecond = 48212.7
07/13/2016 12:23:15:  Epoch[33 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17888365 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0264s; samplesPerSecond = 48406.0
07/13/2016 12:23:15: Finished Epoch[33 of 50]: [Training] CrossEntropyWithSoftmax = 0.16180492 * 10000; EvalErrorPrediction = 0.07540000 * 10000; totalSamplesSeen = 330000; learningRatePerSample = 0.1; epochTime=0.215102s
07/13/2016 12:23:15: SGD: Saving checkpoint model '/tmp/cntk-test-20160713121920.930131/Speech_Simple@debug_gpu/models/simple.dnn.33'

07/13/2016 12:23:15: Starting Epoch 34: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 33: frames [330000..340000] (first sequence at sample 330000), data subset 0 of 1

07/13/2016 12:23:15: Starting minibatch loop.
07/13/2016 12:23:15:  Epoch[34 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17212042 * 1280; EvalErrorPrediction = 0.08437500 * 1280; time = 0.0271s; samplesPerSecond = 47209.8
07/13/2016 12:23:15:  Epoch[34 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16251820 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0264s; samplesPerSecond = 48497.7
07/13/2016 12:23:15:  Epoch[34 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16373565 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0264s; samplesPerSecond = 48481.2
07/13/2016 12:23:15:  Epoch[34 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15235853 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0264s; samplesPerSecond = 48495.9
07/13/2016 12:23:15:  Epoch[34 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14773169 * 1280; EvalErrorPrediction = 0.06484375 * 1280; time = 0.0264s; samplesPerSecond = 48486.7
07/13/2016 12:23:15:  Epoch[34 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15427608 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0264s; samplesPerSecond = 48530.8
07/13/2016 12:23:15:  Epoch[34 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15895214 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0264s; samplesPerSecond = 48426.2
07/13/2016 12:23:15: Finished Epoch[34 of 50]: [Training] CrossEntropyWithSoftmax = 0.15999507 * 10000; EvalErrorPrediction = 0.07510000 * 10000; totalSamplesSeen = 340000; learningRatePerSample = 0.1; epochTime=0.214568s
07/13/2016 12:23:15: SGD: Saving checkpoint model '/tmp/cntk-test-20160713121920.930131/Speech_Simple@debug_gpu/models/simple.dnn.34'

07/13/2016 12:23:15: Starting Epoch 35: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 34: frames [340000..350000] (first sequence at sample 340000), data subset 0 of 1

07/13/2016 12:23:15: Starting minibatch loop.
07/13/2016 12:23:15:  Epoch[35 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16768730 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0270s; samplesPerSecond = 47377.6
07/13/2016 12:23:15:  Epoch[35 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15872076 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0264s; samplesPerSecond = 48575.0
07/13/2016 12:23:15:  Epoch[35 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16511321 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0264s; samplesPerSecond = 48433.5
07/13/2016 12:23:15:  Epoch[35 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15483818 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0264s; samplesPerSecond = 48406.0
07/13/2016 12:23:15:  Epoch[35 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14570861 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 0.0265s; samplesPerSecond = 48283.7
07/13/2016 12:23:15:  Epoch[35 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15019670 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0264s; samplesPerSecond = 48521.6
07/13/2016 12:23:15:  Epoch[35 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.18149843 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0265s; samplesPerSecond = 48227.3
07/13/2016 12:23:15: Finished Epoch[35 of 50]: [Training] CrossEntropyWithSoftmax = 0.16064935 * 10000; EvalErrorPrediction = 0.07610000 * 10000; totalSamplesSeen = 350000; learningRatePerSample = 0.1; epochTime=0.21472s
07/13/2016 12:23:15: SGD: Saving checkpoint model '/tmp/cntk-test-20160713121920.930131/Speech_Simple@debug_gpu/models/simple.dnn.35'

07/13/2016 12:23:15: Starting Epoch 36: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 35: frames [350000..360000] (first sequence at sample 350000), data subset 0 of 1

07/13/2016 12:23:15: Starting minibatch loop.
07/13/2016 12:23:15:  Epoch[36 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17114042 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0272s; samplesPerSecond = 47031.2
07/13/2016 12:23:15:  Epoch[36 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15853363 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 0.0264s; samplesPerSecond = 48475.7
07/13/2016 12:23:15:  Epoch[36 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16492014 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 0.0265s; samplesPerSecond = 48347.5
07/13/2016 12:23:15:  Epoch[36 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16080680 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0267s; samplesPerSecond = 47985.0
07/13/2016 12:23:15:  Epoch[36 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15284743 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 0.0267s; samplesPerSecond = 48006.6
07/13/2016 12:23:15:  Epoch[36 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15469093 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0267s; samplesPerSecond = 48006.6
07/13/2016 12:23:15:  Epoch[36 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.18092909 * 1280; EvalErrorPrediction = 0.08437500 * 1280; time = 0.0266s; samplesPerSecond = 48104.0
07/13/2016 12:23:15: Finished Epoch[36 of 50]: [Training] CrossEntropyWithSoftmax = 0.16307070 * 10000; EvalErrorPrediction = 0.07690000 * 10000; totalSamplesSeen = 360000; learningRatePerSample = 0.1; epochTime=0.215894s
07/13/2016 12:23:15: SGD: Saving checkpoint model '/tmp/cntk-test-20160713121920.930131/Speech_Simple@debug_gpu/models/simple.dnn.36'

07/13/2016 12:23:15: Starting Epoch 37: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 36: frames [360000..370000] (first sequence at sample 360000), data subset 0 of 1

07/13/2016 12:23:15: Starting minibatch loop.
07/13/2016 12:23:15:  Epoch[37 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15121933 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 0.0272s; samplesPerSecond = 47074.4
07/13/2016 12:23:15:  Epoch[37 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15874637 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 0.0265s; samplesPerSecond = 48369.4
07/13/2016 12:23:15:  Epoch[37 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17776804 * 1280; EvalErrorPrediction = 0.08671875 * 1280; time = 0.0264s; samplesPerSecond = 48457.3
07/13/2016 12:23:15:  Epoch[37 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15243282 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0264s; samplesPerSecond = 48466.5
07/13/2016 12:23:15:  Epoch[37 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15466056 * 1280; EvalErrorPrediction = 0.06562500 * 1280; time = 0.0264s; samplesPerSecond = 48495.9
07/13/2016 12:23:15:  Epoch[37 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14456706 * 1280; EvalErrorPrediction = 0.06796875 * 1280; time = 0.0265s; samplesPerSecond = 48329.2
07/13/2016 12:23:15:  Epoch[37 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16275949 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0263s; samplesPerSecond = 48610.1
07/13/2016 12:23:15: Finished Epoch[37 of 50]: [Training] CrossEntropyWithSoftmax = 0.15827069 * 10000; EvalErrorPrediction = 0.07470000 * 10000; totalSamplesSeen = 370000; learningRatePerSample = 0.1; epochTime=0.214636s
07/13/2016 12:23:15: SGD: Saving checkpoint model '/tmp/cntk-test-20160713121920.930131/Speech_Simple@debug_gpu/models/simple.dnn.37'

07/13/2016 12:23:15: Starting Epoch 38: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 37: frames [370000..380000] (first sequence at sample 370000), data subset 0 of 1

07/13/2016 12:23:15: Starting minibatch loop.
07/13/2016 12:23:15:  Epoch[38 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16772083 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 0.0271s; samplesPerSecond = 47316.3
07/13/2016 12:23:15:  Epoch[38 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15543102 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0265s; samplesPerSecond = 48285.5
07/13/2016 12:23:16:  Epoch[38 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15747359 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 0.0266s; samplesPerSecond = 48048.0
07/13/2016 12:23:16:  Epoch[38 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.18036132 * 1280; EvalErrorPrediction = 0.08437500 * 1280; time = 0.0265s; samplesPerSecond = 48220.0
07/13/2016 12:23:16:  Epoch[38 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16553798 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0267s; samplesPerSecond = 47888.1
07/13/2016 12:23:16:  Epoch[38 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16498775 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0265s; samplesPerSecond = 48241.8
07/13/2016 12:23:16:  Epoch[38 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14760447 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 0.0264s; samplesPerSecond = 48519.8
07/13/2016 12:23:16: Finished Epoch[38 of 50]: [Training] CrossEntropyWithSoftmax = 0.16437140 * 10000; EvalErrorPrediction = 0.07690000 * 10000; totalSamplesSeen = 380000; learningRatePerSample = 0.1; epochTime=0.215299s
07/13/2016 12:23:16: SGD: Saving checkpoint model '/tmp/cntk-test-20160713121920.930131/Speech_Simple@debug_gpu/models/simple.dnn.38'

07/13/2016 12:23:16: Starting Epoch 39: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 38: frames [380000..390000] (first sequence at sample 380000), data subset 0 of 1

07/13/2016 12:23:16: Starting minibatch loop.
07/13/2016 12:23:16:  Epoch[39 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15486622 * 1280; EvalErrorPrediction = 0.06406250 * 1280; time = 0.0272s; samplesPerSecond = 47019.1
07/13/2016 12:23:16:  Epoch[39 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17947733 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0263s; samplesPerSecond = 48650.7
07/13/2016 12:23:16:  Epoch[39 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17070038 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 0.0264s; samplesPerSecond = 48532.6
07/13/2016 12:23:16:  Epoch[39 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.17012653 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0265s; samplesPerSecond = 48343.8
07/13/2016 12:23:16:  Epoch[39 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14479184 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 0.0265s; samplesPerSecond = 48371.2
07/13/2016 12:23:16:  Epoch[39 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.13912868 * 1280; EvalErrorPrediction = 0.06171875 * 1280; time = 0.0262s; samplesPerSecond = 48882.9
07/13/2016 12:23:16:  Epoch[39 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15967226 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 0.0263s; samplesPerSecond = 48610.1
07/13/2016 12:23:16: Finished Epoch[39 of 50]: [Training] CrossEntropyWithSoftmax = 0.16386038 * 10000; EvalErrorPrediction = 0.07550000 * 10000; totalSamplesSeen = 390000; learningRatePerSample = 0.1; epochTime=0.21453s
07/13/2016 12:23:16: SGD: Saving checkpoint model '/tmp/cntk-test-20160713121920.930131/Speech_Simple@debug_gpu/models/simple.dnn.39'

07/13/2016 12:23:16: Starting Epoch 40: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 39: frames [390000..400000] (first sequence at sample 390000), data subset 0 of 1

07/13/2016 12:23:16: Starting minibatch loop.
07/13/2016 12:23:16:  Epoch[40 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17116028 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 0.0270s; samplesPerSecond = 47477.7
07/13/2016 12:23:16:  Epoch[40 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15966750 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0264s; samplesPerSecond = 48512.4
07/13/2016 12:23:16:  Epoch[40 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15952737 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0263s; samplesPerSecond = 48732.2
07/13/2016 12:23:16:  Epoch[40 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15408745 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0264s; samplesPerSecond = 48501.4
07/13/2016 12:23:16:  Epoch[40 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15742240 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 0.0263s; samplesPerSecond = 48593.4
07/13/2016 12:23:16:  Epoch[40 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16165428 * 1280; EvalErrorPrediction = 0.06718750 * 1280; time = 0.0264s; samplesPerSecond = 48523.4
07/13/2016 12:23:16:  Epoch[40 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.18436918 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0263s; samplesPerSecond = 48752.6
07/13/2016 12:23:16: Finished Epoch[40 of 50]: [Training] CrossEntropyWithSoftmax = 0.16481310 * 10000; EvalErrorPrediction = 0.07570000 * 10000; totalSamplesSeen = 400000; learningRatePerSample = 0.1; epochTime=0.214028s
07/13/2016 12:23:16: SGD: Saving checkpoint model '/tmp/cntk-test-20160713121920.930131/Speech_Simple@debug_gpu/models/simple.dnn.40'

07/13/2016 12:23:16: Starting Epoch 41: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 40: frames [400000..410000] (first sequence at sample 400000), data subset 0 of 1

07/13/2016 12:23:16: Starting minibatch loop.
07/13/2016 12:23:16:  Epoch[41 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17456944 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0271s; samplesPerSecond = 47164.6
07/13/2016 12:23:16:  Epoch[41 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14992547 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.0267s; samplesPerSecond = 47995.8
07/13/2016 12:23:16:  Epoch[41 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16370704 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0265s; samplesPerSecond = 48227.3
07/13/2016 12:23:16:  Epoch[41 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16085882 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0265s; samplesPerSecond = 48373.1
07/13/2016 12:23:16:  Epoch[41 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15773911 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0263s; samplesPerSecond = 48591.6
07/13/2016 12:23:16:  Epoch[41 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14436550 * 1280; EvalErrorPrediction = 0.06171875 * 1280; time = 0.0264s; samplesPerSecond = 48565.8
07/13/2016 12:23:16:  Epoch[41 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15339108 * 1280; EvalErrorPrediction = 0.06875000 * 1280; time = 0.0264s; samplesPerSecond = 48431.6
07/13/2016 12:23:16: Finished Epoch[41 of 50]: [Training] CrossEntropyWithSoftmax = 0.15843987 * 10000; EvalErrorPrediction = 0.07380000 * 10000; totalSamplesSeen = 410000; learningRatePerSample = 0.1; epochTime=0.215016s
07/13/2016 12:23:16: SGD: Saving checkpoint model '/tmp/cntk-test-20160713121920.930131/Speech_Simple@debug_gpu/models/simple.dnn.41'

07/13/2016 12:23:16: Starting Epoch 42: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 41: frames [410000..420000] (first sequence at sample 410000), data subset 0 of 1

07/13/2016 12:23:16: Starting minibatch loop.
07/13/2016 12:23:16:  Epoch[42 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17765868 * 1280; EvalErrorPrediction = 0.09062500 * 1280; time = 0.0270s; samplesPerSecond = 47375.8
07/13/2016 12:23:16:  Epoch[42 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15345802 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.0264s; samplesPerSecond = 48541.8
07/13/2016 12:23:16:  Epoch[42 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15648363 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0264s; samplesPerSecond = 48475.7
07/13/2016 12:23:16:  Epoch[42 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15764861 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0275s; samplesPerSecond = 46555.6
07/13/2016 12:23:16:  Epoch[42 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16663527 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0263s; samplesPerSecond = 48678.5
07/13/2016 12:23:16:  Epoch[42 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14366312 * 1280; EvalErrorPrediction = 0.06562500 * 1280; time = 0.0265s; samplesPerSecond = 48267.3
07/13/2016 12:23:16:  Epoch[42 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15641041 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0265s; samplesPerSecond = 48371.2
07/13/2016 12:23:17: Finished Epoch[42 of 50]: [Training] CrossEntropyWithSoftmax = 0.15860306 * 10000; EvalErrorPrediction = 0.07620000 * 10000; totalSamplesSeen = 420000; learningRatePerSample = 0.1; epochTime=0.215787s
07/13/2016 12:23:17: SGD: Saving checkpoint model '/tmp/cntk-test-20160713121920.930131/Speech_Simple@debug_gpu/models/simple.dnn.42'

07/13/2016 12:23:17: Starting Epoch 43: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 42: frames [420000..430000] (first sequence at sample 420000), data subset 0 of 1

07/13/2016 12:23:17: Starting minibatch loop.
07/13/2016 12:23:17:  Epoch[43 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15629972 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0270s; samplesPerSecond = 47409.2
07/13/2016 12:23:17:  Epoch[43 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15308679 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0263s; samplesPerSecond = 48632.2
07/13/2016 12:23:17:  Epoch[43 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.13974707 * 1280; EvalErrorPrediction = 0.06171875 * 1280; time = 0.0264s; samplesPerSecond = 48499.5
07/13/2016 12:23:17:  Epoch[43 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15581870 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0263s; samplesPerSecond = 48584.2
07/13/2016 12:23:17:  Epoch[43 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14598870 * 1280; EvalErrorPrediction = 0.06562500 * 1280; time = 0.0264s; samplesPerSecond = 48514.3
07/13/2016 12:23:17:  Epoch[43 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.18108988 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0265s; samplesPerSecond = 48367.6
07/13/2016 12:23:17:  Epoch[43 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17168808 * 1280; EvalErrorPrediction = 0.08359375 * 1280; time = 0.0264s; samplesPerSecond = 48494.0
07/13/2016 12:23:17: Finished Epoch[43 of 50]: [Training] CrossEntropyWithSoftmax = 0.15814004 * 10000; EvalErrorPrediction = 0.07360000 * 10000; totalSamplesSeen = 430000; learningRatePerSample = 0.1; epochTime=0.214397s
07/13/2016 12:23:17: SGD: Saving checkpoint model '/tmp/cntk-test-20160713121920.930131/Speech_Simple@debug_gpu/models/simple.dnn.43'

07/13/2016 12:23:17: Starting Epoch 44: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 43: frames [430000..440000] (first sequence at sample 430000), data subset 0 of 1

07/13/2016 12:23:17: Starting minibatch loop.
07/13/2016 12:23:17:  Epoch[44 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17231209 * 1280; EvalErrorPrediction = 0.08828125 * 1280; time = 0.0271s; samplesPerSecond = 47263.9
07/13/2016 12:23:17:  Epoch[44 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.13793182 * 1280; EvalErrorPrediction = 0.06171875 * 1280; time = 0.0265s; samplesPerSecond = 48298.2
07/13/2016 12:23:17:  Epoch[44 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16530783 * 1280; EvalErrorPrediction = 0.08359375 * 1280; time = 0.0264s; samplesPerSecond = 48543.7
07/13/2016 12:23:17:  Epoch[44 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.19532485 * 1280; EvalErrorPrediction = 0.08593750 * 1280; time = 0.0263s; samplesPerSecond = 48587.9
07/13/2016 12:23:17:  Epoch[44 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.17846689 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 0.0265s; samplesPerSecond = 48391.4
07/13/2016 12:23:17:  Epoch[44 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.21160450 * 1280; EvalErrorPrediction = 0.09375000 * 1280; time = 0.0264s; samplesPerSecond = 48446.3
07/13/2016 12:23:17:  Epoch[44 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.18801451 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0264s; samplesPerSecond = 48495.9
07/13/2016 12:23:17: Finished Epoch[44 of 50]: [Training] CrossEntropyWithSoftmax = 0.17975632 * 10000; EvalErrorPrediction = 0.08190000 * 10000; totalSamplesSeen = 440000; learningRatePerSample = 0.1; epochTime=0.21441s
07/13/2016 12:23:17: SGD: Saving checkpoint model '/tmp/cntk-test-20160713121920.930131/Speech_Simple@debug_gpu/models/simple.dnn.44'

07/13/2016 12:23:17: Starting Epoch 45: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 44: frames [440000..450000] (first sequence at sample 440000), data subset 0 of 1

07/13/2016 12:23:17: Starting minibatch loop.
07/13/2016 12:23:17:  Epoch[45 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.19800919 * 1280; EvalErrorPrediction = 0.08593750 * 1280; time = 0.0272s; samplesPerSecond = 47135.1
07/13/2016 12:23:17:  Epoch[45 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15382904 * 1280; EvalErrorPrediction = 0.06875000 * 1280; time = 0.0264s; samplesPerSecond = 48543.7
07/13/2016 12:23:17:  Epoch[45 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16011503 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 0.0263s; samplesPerSecond = 48634.1
07/13/2016 12:23:17:  Epoch[45 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.17285686 * 1280; EvalErrorPrediction = 0.08515625 * 1280; time = 0.0263s; samplesPerSecond = 48695.1
07/13/2016 12:23:17:  Epoch[45 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.12871919 * 1280; EvalErrorPrediction = 0.05546875 * 1280; time = 0.0265s; samplesPerSecond = 48327.4
07/13/2016 12:23:17:  Epoch[45 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.19098673 * 1280; EvalErrorPrediction = 0.09218750 * 1280; time = 0.0265s; samplesPerSecond = 48393.2
07/13/2016 12:23:17:  Epoch[45 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.18352175 * 1280; EvalErrorPrediction = 0.08750000 * 1280; time = 0.0265s; samplesPerSecond = 48283.7
07/13/2016 12:23:17: Finished Epoch[45 of 50]: [Training] CrossEntropyWithSoftmax = 0.16838304 * 10000; EvalErrorPrediction = 0.07700000 * 10000; totalSamplesSeen = 450000; learningRatePerSample = 0.1; epochTime=0.214631s
07/13/2016 12:23:17: SGD: Saving checkpoint model '/tmp/cntk-test-20160713121920.930131/Speech_Simple@debug_gpu/models/simple.dnn.45'

07/13/2016 12:23:17: Starting Epoch 46: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 45: frames [450000..460000] (first sequence at sample 450000), data subset 0 of 1

07/13/2016 12:23:17: Starting minibatch loop.
07/13/2016 12:23:17:  Epoch[46 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17409599 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0271s; samplesPerSecond = 47209.8
07/13/2016 12:23:17:  Epoch[46 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15440207 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0263s; samplesPerSecond = 48578.7
07/13/2016 12:23:17:  Epoch[46 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16372373 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0264s; samplesPerSecond = 48457.3
07/13/2016 12:23:17:  Epoch[46 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.17626615 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0264s; samplesPerSecond = 48455.5
07/13/2016 12:23:17:  Epoch[46 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.19316645 * 1280; EvalErrorPrediction = 0.08984375 * 1280; time = 0.0264s; samplesPerSecond = 48563.9
07/13/2016 12:23:17:  Epoch[46 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16905041 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0263s; samplesPerSecond = 48647.0
07/13/2016 12:23:17:  Epoch[46 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16094189 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0263s; samplesPerSecond = 48752.6
07/13/2016 12:23:17: Finished Epoch[46 of 50]: [Training] CrossEntropyWithSoftmax = 0.17035063 * 10000; EvalErrorPrediction = 0.08000000 * 10000; totalSamplesSeen = 460000; learningRatePerSample = 0.1; epochTime=0.214215s
07/13/2016 12:23:17: SGD: Saving checkpoint model '/tmp/cntk-test-20160713121920.930131/Speech_Simple@debug_gpu/models/simple.dnn.46'

07/13/2016 12:23:17: Starting Epoch 47: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 46: frames [460000..470000] (first sequence at sample 460000), data subset 0 of 1

07/13/2016 12:23:17: Starting minibatch loop.
07/13/2016 12:23:17:  Epoch[47 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.19717933 * 1280; EvalErrorPrediction = 0.08593750 * 1280; time = 0.0270s; samplesPerSecond = 47360.0
07/13/2016 12:23:17:  Epoch[47 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17599429 * 1280; EvalErrorPrediction = 0.08437500 * 1280; time = 0.0264s; samplesPerSecond = 48481.2
07/13/2016 12:23:17:  Epoch[47 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16111016 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 0.0263s; samplesPerSecond = 48691.4
07/13/2016 12:23:17:  Epoch[47 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.17828107 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0264s; samplesPerSecond = 48479.3
07/13/2016 12:23:18:  Epoch[47 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.17307177 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0264s; samplesPerSecond = 48501.4
07/13/2016 12:23:18:  Epoch[47 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15202827 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.0262s; samplesPerSecond = 48812.1
07/13/2016 12:23:18:  Epoch[47 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14770594 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.0266s; samplesPerSecond = 48095.0
07/13/2016 12:23:18: Finished Epoch[47 of 50]: [Training] CrossEntropyWithSoftmax = 0.16891559 * 10000; EvalErrorPrediction = 0.07650000 * 10000; totalSamplesSeen = 470000; learningRatePerSample = 0.1; epochTime=0.214935s
07/13/2016 12:23:18: SGD: Saving checkpoint model '/tmp/cntk-test-20160713121920.930131/Speech_Simple@debug_gpu/models/simple.dnn.47'

07/13/2016 12:23:18: Starting Epoch 48: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 47: frames [470000..480000] (first sequence at sample 470000), data subset 0 of 1

07/13/2016 12:23:18: Starting minibatch loop.
07/13/2016 12:23:18:  Epoch[48 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.18937275 * 1280; EvalErrorPrediction = 0.08828125 * 1280; time = 0.0272s; samplesPerSecond = 46977.6
07/13/2016 12:23:18:  Epoch[48 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16697199 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0267s; samplesPerSecond = 47925.7
07/13/2016 12:23:18:  Epoch[48 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16790347 * 1280; EvalErrorPrediction = 0.08359375 * 1280; time = 0.0265s; samplesPerSecond = 48312.8
07/13/2016 12:23:18:  Epoch[48 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15334325 * 1280; EvalErrorPrediction = 0.06718750 * 1280; time = 0.0264s; samplesPerSecond = 48431.6
07/13/2016 12:23:18:  Epoch[48 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.13439155 * 1280; EvalErrorPrediction = 0.06015625 * 1280; time = 0.0267s; samplesPerSecond = 47974.2
07/13/2016 12:23:18:  Epoch[48 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17633085 * 1280; EvalErrorPrediction = 0.09062500 * 1280; time = 0.0267s; samplesPerSecond = 47889.9
07/13/2016 12:23:18:  Epoch[48 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16360836 * 1280; EvalErrorPrediction = 0.08359375 * 1280; time = 0.0267s; samplesPerSecond = 47950.9
07/13/2016 12:23:18: Finished Epoch[48 of 50]: [Training] CrossEntropyWithSoftmax = 0.16220248 * 10000; EvalErrorPrediction = 0.07660000 * 10000; totalSamplesSeen = 480000; learningRatePerSample = 0.1; epochTime=0.216049s
07/13/2016 12:23:18: SGD: Saving checkpoint model '/tmp/cntk-test-20160713121920.930131/Speech_Simple@debug_gpu/models/simple.dnn.48'

07/13/2016 12:23:18: Starting Epoch 49: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 48: frames [480000..490000] (first sequence at sample 480000), data subset 0 of 1

07/13/2016 12:23:18: Starting minibatch loop.
07/13/2016 12:23:18:  Epoch[49 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17351888 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0271s; samplesPerSecond = 47237.7
07/13/2016 12:23:18:  Epoch[49 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16539623 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0264s; samplesPerSecond = 48400.5
07/13/2016 12:23:18:  Epoch[49 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17113481 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0265s; samplesPerSecond = 48260.0
07/13/2016 12:23:18:  Epoch[49 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15255375 * 1280; EvalErrorPrediction = 0.06250000 * 1280; time = 0.0264s; samplesPerSecond = 48517.9
07/13/2016 12:23:18:  Epoch[49 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.18179188 * 1280; EvalErrorPrediction = 0.08593750 * 1280; time = 0.0262s; samplesPerSecond = 48802.8
07/13/2016 12:23:18:  Epoch[49 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14414072 * 1280; EvalErrorPrediction = 0.05937500 * 1280; time = 0.0264s; samplesPerSecond = 48396.9
07/13/2016 12:23:18:  Epoch[49 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16890459 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0264s; samplesPerSecond = 48450.0
07/13/2016 12:23:18: Finished Epoch[49 of 50]: [Training] CrossEntropyWithSoftmax = 0.16371610 * 10000; EvalErrorPrediction = 0.07560000 * 10000; totalSamplesSeen = 490000; learningRatePerSample = 0.1; epochTime=0.214581s
07/13/2016 12:23:18: SGD: Saving checkpoint model '/tmp/cntk-test-20160713121920.930131/Speech_Simple@debug_gpu/models/simple.dnn.49'

07/13/2016 12:23:18: Starting Epoch 50: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 49: frames [490000..500000] (first sequence at sample 490000), data subset 0 of 1

07/13/2016 12:23:18: Starting minibatch loop.
07/13/2016 12:23:18:  Epoch[50 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17541753 * 1280; EvalErrorPrediction = 0.08359375 * 1280; time = 0.0269s; samplesPerSecond = 47548.3
07/13/2016 12:23:18:  Epoch[50 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16571552 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.0266s; samplesPerSecond = 48098.6
07/13/2016 12:23:18:  Epoch[50 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15297840 * 1280; EvalErrorPrediction = 0.06875000 * 1280; time = 0.0264s; samplesPerSecond = 48406.0
07/13/2016 12:23:18:  Epoch[50 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15474615 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 0.0267s; samplesPerSecond = 47972.4
07/13/2016 12:23:18:  Epoch[50 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15424118 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 0.0264s; samplesPerSecond = 48396.9
07/13/2016 12:23:18:  Epoch[50 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14947748 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.0265s; samplesPerSecond = 48320.1
07/13/2016 12:23:18:  Epoch[50 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14548969 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 0.0264s; samplesPerSecond = 48558.4
07/13/2016 12:23:18: Finished Epoch[50 of 50]: [Training] CrossEntropyWithSoftmax = 0.15954734 * 10000; EvalErrorPrediction = 0.07370000 * 10000; totalSamplesSeen = 500000; learningRatePerSample = 0.1; epochTime=0.214981s
07/13/2016 12:23:18: SGD: Saving checkpoint model '/tmp/cntk-test-20160713121920.930131/Speech_Simple@debug_gpu/models/simple.dnn'
07/13/2016 12:23:18: CNTKCommandTrainEnd: Simple_Demo

07/13/2016 12:23:18: Action "train" complete.


07/13/2016 12:23:18: ##############################################################################
07/13/2016 12:23:18: #                                                                            #
07/13/2016 12:23:18: # Action "write"                                                             #
07/13/2016 12:23:18: #                                                                            #
07/13/2016 12:23:18: ##############################################################################


Post-processing network...

7 roots:
	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
	EvalErrorPrediction = ErrorPrediction()
	InvStdOfFeatures = InvStdDev()
	MeanOfFeatures = Mean()
	PosteriorProb = Softmax()
	Prior = Mean()
	ScaledLogLikelihood = Minus()

Validating network. 25 nodes to process in pass 1.

Validating --> labels = InputValue() :  -> [2 x *1]
Validating --> W2 = LearnableParameter() :  -> [2 x 50]
Validating --> W1 = LearnableParameter() :  -> [50 x 50]
Validating --> W0 = LearnableParameter() :  -> [50 x 2]
Validating --> features = InputValue() :  -> [2 x *1]
Validating --> MeanOfFeatures = Mean (features) : [2 x *1] -> [2]
Validating --> InvStdOfFeatures = InvStdDev (features) : [2 x *1] -> [2]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [2 x *1], [2], [2] -> [2 x *1]
Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [50 x 2], [2 x *1] -> [50 x *1]
Validating --> B0 = LearnableParameter() :  -> [50 x 1]
Validating --> W0*features+B0 = Plus (W0*features, B0) : [50 x *1], [50 x 1] -> [50 x 1 x *1]
Validating --> H1 = Sigmoid (W0*features+B0) : [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> W1*H1 = Times (W1, H1) : [50 x 50], [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> B1 = LearnableParameter() :  -> [50 x 1]
Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [50 x 1 x *1], [50 x 1] -> [50 x 1 x *1]
Validating --> H2 = Sigmoid (W1*H1+B1) : [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> W2*H1 = Times (W2, H2) : [2 x 50], [50 x 1 x *1] -> [2 x 1 x *1]
Validating --> B2 = LearnableParameter() :  -> [2 x 1]
Validating --> HLast = Plus (W2*H1, B2) : [2 x 1 x *1], [2 x 1] -> [2 x 1 x *1]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [2 x *1], [2 x 1 x *1] -> [1]
Validating --> EvalErrorPrediction = ErrorPrediction (labels, HLast) : [2 x *1], [2 x 1 x *1] -> [1]
Validating --> PosteriorProb = Softmax (HLast) : [2 x 1 x *1] -> [2 x 1 x *1]
Validating --> Prior = Mean (labels) : [2 x *1] -> [2]
Validating --> LogOfPrior = Log (Prior) : [2] -> [2]
Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [2 x 1 x *1], [2] -> [2 x 1 x *1]

Validating network. 17 nodes to process in pass 2.


Validating network, final pass.



12 out of 25 nodes do not share the minibatch layout with the input data.

Post-processing network complete.



Allocating matrices for forward and/or backward propagation.

Memory Sharing Structure:

(nil): {[B0 Gradient[50 x 1]] [B1 Gradient[50 x 1]] [B2 Gradient[2 x 1]] [CrossEntropyWithSoftmax Gradient[1]] [CrossEntropyWithSoftmax Value[1]] [EvalErrorPrediction Gradient[1]] [EvalErrorPrediction Value[1]] [H1 Gradient[50 x 1 x *1]] [H2 Gradient[50 x 1 x *1]] [HLast Gradient[2 x 1 x *1]] [InvStdOfFeatures Gradient[2]] [LogOfPrior Gradient[2]] [MVNormalizedFeatures Gradient[2 x *1]] [MeanOfFeatures Gradient[2]] [PosteriorProb Gradient[2 x 1 x *1]] [PosteriorProb Value[2 x 1 x *1]] [Prior Gradient[2]] [ScaledLogLikelihood Gradient[2 x 1 x *1]] [W0 Gradient[50 x 2]] [W0*features Gradient[50 x *1]] [W0*features+B0 Gradient[50 x 1 x *1]] [W1 Gradient[50 x 50]] [W1*H1 Gradient[50 x 1 x *1]] [W1*H1+B1 Gradient[50 x 1 x *1]] [W2 Gradient[2 x 50]] [W2*H1 Gradient[2 x 1 x *1]] [features Gradient[2 x *1]] [labels Gradient[2 x *1]] }
0x7ff3b8898f98: {[B2 Value[2 x 1]] }
0x7ff3b8899e98: {[features Value[2 x *1]] }
0x7ff3b88a5b28: {[InvStdOfFeatures Value[2]] }
0x7ff3b88a69d8: {[labels Value[2 x *1]] }
0x7ff3b88a7538: {[MeanOfFeatures Value[2]] }
0x7ff3b88a8538: {[Prior Value[2]] }
0x7ff3b88a9348: {[W0 Value[50 x 2]] }
0x7ff3b88a9668: {[W1 Value[50 x 50]] }
0x7ff3b88ab2e8: {[W2 Value[2 x 50]] }
0x7ff3bfa1c048: {[B0 Value[50 x 1]] }
0x7ff3c033ed38: {[B1 Value[50 x 1]] }
0x7ff3c76c2358: {[ScaledLogLikelihood Value[2 x 1 x *1]] }
0x7ff3c76c2a48: {[W0*features Value[50 x *1]] }
0x7ff3c76c2b38: {[LogOfPrior Value[2]] }
0x7ff3c76c4448: {[MVNormalizedFeatures Value[2 x *1]] }
0x7ff3c76c4ab8: {[W0*features+B0 Value[50 x 1 x *1]] }
0x7ff3c76c4c78: {[H1 Value[50 x 1 x *1]] }
0x7ff3c76c4e38: {[W1*H1 Value[50 x 1 x *1]] }
0x7ff3c76c4ff8: {[W1*H1+B1 Value[50 x 1 x *1]] }
0x7ff3c76c51b8: {[H2 Value[50 x 1 x *1]] }
0x7ff3c76c5378: {[W2*H1 Value[2 x 1 x *1]] }
0x7ff3c76c5538: {[HLast Value[2 x 1 x *1]] }

Minibatch[0]: ActualMBSize = 603
Written to /tmp/cntk-test-20160713121920.930131/Speech_Simple@debug_gpu/SimpleOutput*
Total Samples Evaluated = 603

07/13/2016 12:23:18: Action "write" complete.

07/13/2016 12:23:18: __COMPLETED__
=== Deleting last epoch data
==== Re-running from checkpoint
=== Running /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/build/gpu/debug/bin/cntk configFile=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Simple/cntk.cntk currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data RunDir=/tmp/cntk-test-20160713121920.930131/Speech_Simple@debug_gpu DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Simple OutputDir=/tmp/cntk-test-20160713121920.930131/Speech_Simple@debug_gpu DeviceId=0 timestamping=true makeMode=true
-------------------------------------------------------------------
Build info: 

		Built time: Jul 13 2016 11:58:00
		Last modified date: Tue Jul 12 04:28:35 2016
		Build type: debug
		Build target: GPU
		With 1bit-SGD: no
		Math lib: mkl
		CUDA_PATH: /usr/local/cuda-7.5
		CUB_PATH: /usr/local/cub-1.4.1
		CUDNN_PATH: /usr/local/cudnn-4.0
		Build Branch: HEAD
		Build SHA1: 50bb4c8afbc87c14548a5b5f315a064186a5cb5f
		Built by philly on 2bc22072e267
		Build Path: /home/philly/jenkins/workspace/CNTK-Build-Linux
-------------------------------------------------------------------
Changed current directory to /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
07/13/2016 12:23:20: -------------------------------------------------------------------
07/13/2016 12:23:20: Build info: 

07/13/2016 12:23:20: 		Built time: Jul 13 2016 11:58:00
07/13/2016 12:23:20: 		Last modified date: Tue Jul 12 04:28:35 2016
07/13/2016 12:23:20: 		Build type: debug
07/13/2016 12:23:20: 		Build target: GPU
07/13/2016 12:23:20: 		With 1bit-SGD: no
07/13/2016 12:23:20: 		Math lib: mkl
07/13/2016 12:23:20: 		CUDA_PATH: /usr/local/cuda-7.5
07/13/2016 12:23:20: 		CUB_PATH: /usr/local/cub-1.4.1
07/13/2016 12:23:20: 		CUDNN_PATH: /usr/local/cudnn-4.0
07/13/2016 12:23:20: 		Build Branch: HEAD
07/13/2016 12:23:20: 		Build SHA1: 50bb4c8afbc87c14548a5b5f315a064186a5cb5f
07/13/2016 12:23:20: 		Built by philly on 2bc22072e267
07/13/2016 12:23:20: 		Build Path: /home/philly/jenkins/workspace/CNTK-Build-Linux
07/13/2016 12:23:20: -------------------------------------------------------------------
07/13/2016 12:23:21: -------------------------------------------------------------------
07/13/2016 12:23:21: GPU info:

07/13/2016 12:23:21: 		Device[0]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3071 MB
07/13/2016 12:23:21: 		Device[1]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3071 MB
07/13/2016 12:23:21: 		Device[2]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3071 MB
07/13/2016 12:23:21: 		Device[3]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3071 MB
07/13/2016 12:23:21: -------------------------------------------------------------------

07/13/2016 12:23:21: Running on localhost at 2016/07/13 12:23:21
07/13/2016 12:23:21: Command line: 
/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/build/gpu/debug/bin/cntk  configFile=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Simple/cntk.cntk  currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data  RunDir=/tmp/cntk-test-20160713121920.930131/Speech_Simple@debug_gpu  DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data  ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Simple  OutputDir=/tmp/cntk-test-20160713121920.930131/Speech_Simple@debug_gpu  DeviceId=0  timestamping=true  makeMode=true



07/13/2016 12:23:21: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
07/13/2016 12:23:21: command=Simple_Demo:Simple_Demo_Output
DeviceNumber=-1
precision=float
modelPath=$RunDir$/models/simple.dnn
deviceId=$DeviceNumber$
outputNodeNames=ScaledLogLikelihood
traceLevel=1
Simple_Demo=[
    action=train
    SimpleNetworkBuilder=[
        layerSizes=2:50*2:2
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ErrorPrediction
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0 
        minibatchSize=128
        learningRatesPerSample=0.1
        momentumAsTimeConstant=2500
        dropoutRate=0.0
        maxEpochs=50
        keepCheckPointFiles = true
    ]
    reader=[
        readerType=CNTKTextFormatReader
        file=$DataDir$/SimpleDataTrain_cntk_text.txt
        input = [
            features=[
dim = 2      
                format = "dense"
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
]
Simple_Demo_Output=[
    action=write
    reader=[
        readerType=CNTKTextFormatReader
        file=$DataDir$/SimpleDataTest_cntk_text.txt
        input = [
            features=[
dim = 2 
                format = "dense" 
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
outputPath=$RunDir$/SimpleOutput    
]
currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
RunDir=/tmp/cntk-test-20160713121920.930131/Speech_Simple@debug_gpu
DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Simple
OutputDir=/tmp/cntk-test-20160713121920.930131/Speech_Simple@debug_gpu
DeviceId=0
timestamping=true
makeMode=true

07/13/2016 12:23:21: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<

07/13/2016 12:23:21: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
07/13/2016 12:23:21: command=Simple_Demo:Simple_Demo_Output
DeviceNumber=-1
precision=float
modelPath=/tmp/cntk-test-20160713121920.930131/Speech_Simple@debug_gpu/models/simple.dnn
deviceId=-1
outputNodeNames=ScaledLogLikelihood
traceLevel=1
Simple_Demo=[
    action=train
    SimpleNetworkBuilder=[
        layerSizes=2:50*2:2
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ErrorPrediction
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0 
        minibatchSize=128
        learningRatesPerSample=0.1
        momentumAsTimeConstant=2500
        dropoutRate=0.0
        maxEpochs=50
        keepCheckPointFiles = true
    ]
    reader=[
        readerType=CNTKTextFormatReader
        file=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/SimpleDataTrain_cntk_text.txt
        input = [
            features=[
dim = 2      
                format = "dense"
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
]
Simple_Demo_Output=[
    action=write
    reader=[
        readerType=CNTKTextFormatReader
        file=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/SimpleDataTest_cntk_text.txt
        input = [
            features=[
dim = 2 
                format = "dense" 
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
outputPath=/tmp/cntk-test-20160713121920.930131/Speech_Simple@debug_gpu/SimpleOutput    
]
currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
RunDir=/tmp/cntk-test-20160713121920.930131/Speech_Simple@debug_gpu
DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Simple
OutputDir=/tmp/cntk-test-20160713121920.930131/Speech_Simple@debug_gpu
DeviceId=0
timestamping=true
makeMode=true

07/13/2016 12:23:21: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<

07/13/2016 12:23:21: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
configparameters: cntk.cntk:command=Simple_Demo:Simple_Demo_Output
configparameters: cntk.cntk:ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Simple
configparameters: cntk.cntk:currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
configparameters: cntk.cntk:DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
configparameters: cntk.cntk:deviceId=0
configparameters: cntk.cntk:DeviceNumber=-1
configparameters: cntk.cntk:makeMode=true
configparameters: cntk.cntk:modelPath=/tmp/cntk-test-20160713121920.930131/Speech_Simple@debug_gpu/models/simple.dnn
configparameters: cntk.cntk:OutputDir=/tmp/cntk-test-20160713121920.930131/Speech_Simple@debug_gpu
configparameters: cntk.cntk:outputNodeNames=ScaledLogLikelihood
configparameters: cntk.cntk:precision=float
configparameters: cntk.cntk:RunDir=/tmp/cntk-test-20160713121920.930131/Speech_Simple@debug_gpu
configparameters: cntk.cntk:Simple_Demo=[
    action=train
    SimpleNetworkBuilder=[
        layerSizes=2:50*2:2
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ErrorPrediction
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0 
        minibatchSize=128
        learningRatesPerSample=0.1
        momentumAsTimeConstant=2500
        dropoutRate=0.0
        maxEpochs=50
        keepCheckPointFiles = true
    ]
    reader=[
        readerType=CNTKTextFormatReader
        file=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/SimpleDataTrain_cntk_text.txt
        input = [
            features=[
dim = 2      
                format = "dense"
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
]

configparameters: cntk.cntk:Simple_Demo_Output=[
    action=write
    reader=[
        readerType=CNTKTextFormatReader
        file=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/SimpleDataTest_cntk_text.txt
        input = [
            features=[
dim = 2 
                format = "dense" 
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
outputPath=/tmp/cntk-test-20160713121920.930131/Speech_Simple@debug_gpu/SimpleOutput    
]

configparameters: cntk.cntk:timestamping=true
configparameters: cntk.cntk:traceLevel=1
07/13/2016 12:23:21: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
07/13/2016 12:23:21: Commands: Simple_Demo Simple_Demo_Output
07/13/2016 12:23:21: Precision = "float"
07/13/2016 12:23:21: CNTKModelPath: /tmp/cntk-test-20160713121920.930131/Speech_Simple@debug_gpu/models/simple.dnn
07/13/2016 12:23:21: CNTKCommandTrainInfo: Simple_Demo : 50
07/13/2016 12:23:21: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 50

07/13/2016 12:23:21: ##############################################################################
07/13/2016 12:23:21: #                                                                            #
07/13/2016 12:23:21: # Action "train"                                                             #
07/13/2016 12:23:21: #                                                                            #
07/13/2016 12:23:21: ##############################################################################

07/13/2016 12:23:21: CNTKCommandTrainBegin: Simple_Demo
SimpleNetworkBuilder Using GPU 0

07/13/2016 12:23:21: Starting from checkpoint. Loading network from '/tmp/cntk-test-20160713121920.930131/Speech_Simple@debug_gpu/models/simple.dnn.49'.

Post-processing network...

7 roots:
	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
	EvalErrorPrediction = ErrorPrediction()
	InvStdOfFeatures = InvStdDev()
	MeanOfFeatures = Mean()
	PosteriorProb = Softmax()
	Prior = Mean()
	ScaledLogLikelihood = Minus()

Validating network. 25 nodes to process in pass 1.

Validating --> labels = InputValue() :  -> [2 x *1]
Validating --> W2 = LearnableParameter() :  -> [2 x 50]
Validating --> W1 = LearnableParameter() :  -> [50 x 50]
Validating --> W0 = LearnableParameter() :  -> [50 x 2]
Validating --> features = InputValue() :  -> [2 x *1]
Validating --> MeanOfFeatures = Mean (features) : [2 x *1] -> [2]
Validating --> InvStdOfFeatures = InvStdDev (features) : [2 x *1] -> [2]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [2 x *1], [2], [2] -> [2 x *1]
Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [50 x 2], [2 x *1] -> [50 x *1]
Validating --> B0 = LearnableParameter() :  -> [50 x 1]
Validating --> W0*features+B0 = Plus (W0*features, B0) : [50 x *1], [50 x 1] -> [50 x 1 x *1]
Validating --> H1 = Sigmoid (W0*features+B0) : [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> W1*H1 = Times (W1, H1) : [50 x 50], [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> B1 = LearnableParameter() :  -> [50 x 1]
Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [50 x 1 x *1], [50 x 1] -> [50 x 1 x *1]
Validating --> H2 = Sigmoid (W1*H1+B1) : [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> W2*H1 = Times (W2, H2) : [2 x 50], [50 x 1 x *1] -> [2 x 1 x *1]
Validating --> B2 = LearnableParameter() :  -> [2 x 1]
Validating --> HLast = Plus (W2*H1, B2) : [2 x 1 x *1], [2 x 1] -> [2 x 1 x *1]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [2 x *1], [2 x 1 x *1] -> [1]
Validating --> EvalErrorPrediction = ErrorPrediction (labels, HLast) : [2 x *1], [2 x 1 x *1] -> [1]
Validating --> PosteriorProb = Softmax (HLast) : [2 x 1 x *1] -> [2 x 1 x *1]
Validating --> Prior = Mean (labels) : [2 x *1] -> [2]
Validating --> LogOfPrior = Log (Prior) : [2] -> [2]
Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [2 x 1 x *1], [2] -> [2 x 1 x *1]

Validating network. 17 nodes to process in pass 2.


Validating network, final pass.



12 out of 25 nodes do not share the minibatch layout with the input data.

Post-processing network complete.

07/13/2016 12:23:21: Loaded model with 25 nodes on GPU 0.

07/13/2016 12:23:21: Training criterion node(s):
07/13/2016 12:23:21: 	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax

07/13/2016 12:23:21: Evaluation criterion node(s):

07/13/2016 12:23:21: 	EvalErrorPrediction = ErrorPrediction


Allocating matrices for forward and/or backward propagation.

Memory Sharing Structure:

(nil): {[EvalErrorPrediction Gradient[1]] [InvStdOfFeatures Gradient[2]] [LogOfPrior Gradient[2]] [MVNormalizedFeatures Gradient[2 x *1]] [MeanOfFeatures Gradient[2]] [PosteriorProb Gradient[2 x 1 x *1]] [PosteriorProb Value[2 x 1 x *1]] [Prior Gradient[2]] [ScaledLogLikelihood Gradient[2 x 1 x *1]] [features Gradient[2 x *1]] [labels Gradient[2 x *1]] }
0x7ff3d5141c48: {[features Value[2 x *1]] }
0x7ff3d5142f58: {[InvStdOfFeatures Value[2]] }
0x7ff3d5143e38: {[labels Value[2 x *1]] }
0x7ff3d5144b98: {[MeanOfFeatures Value[2]] }
0x7ff3d5145c08: {[Prior Value[2]] }
0x7ff3d5146348: {[W0 Value[50 x 2]] }
0x7ff3d5146c68: {[W1 Value[50 x 50]] }
0x7ff3d5148068: {[W2 Value[2 x 50]] }
0x7ff3d514e308: {[EvalErrorPrediction Value[1]] }
0x7ff3d514e4c8: {[ScaledLogLikelihood Value[2 x 1 x *1]] }
0x7ff3d514e688: {[CrossEntropyWithSoftmax Value[1]] }
0x7ff3d514eb88: {[LogOfPrior Value[2]] }
0x7ff3d514fd88: {[MVNormalizedFeatures Value[2 x *1]] }
0x7ff3d5150488: {[W0*features Value[50 x *1]] }
0x7ff3d51509b8: {[W0 Gradient[50 x 2]] [W0*features+B0 Value[50 x 1 x *1]] }
0x7ff3d5150b18: {[H1 Value[50 x 1 x *1]] [W0*features Gradient[50 x *1]] }
0x7ff3d5150cd8: {[W0*features+B0 Gradient[50 x 1 x *1]] [W1*H1 Value[50 x 1 x *1]] }
0x7ff3d5150e98: {[W1 Gradient[50 x 50]] [W1*H1+B1 Value[50 x 1 x *1]] }
0x7ff3d5151058: {[H2 Value[50 x 1 x *1]] [W1*H1 Gradient[50 x 1 x *1]] }
0x7ff3d5151218: {[B0 Gradient[50 x 1]] [H1 Gradient[50 x 1 x *1]] [W1*H1+B1 Gradient[50 x 1 x *1]] [W2*H1 Value[2 x 1 x *1]] }
0x7ff3d51513d8: {[HLast Value[2 x 1 x *1]] [W2 Gradient[2 x 50]] }
0x7ff3d5151f38: {[CrossEntropyWithSoftmax Gradient[1]] }
0x7ff3d51520f8: {[B1 Gradient[50 x 1]] [H2 Gradient[50 x 1 x *1]] [HLast Gradient[2 x 1 x *1]] }
0x7ff3d51522b8: {[W2*H1 Gradient[2 x 1 x *1]] }
0x7ff3d5152478: {[B2 Gradient[2 x 1]] }
0x7ff3d77ea428: {[B2 Value[2 x 1]] }
0x7ff3dc44f718: {[B0 Value[50 x 1]] }
0x7ff3dc4bae28: {[B1 Value[50 x 1]] }

07/13/2016 12:23:21: No PreCompute nodes found, skipping PreCompute step.

07/13/2016 12:23:21: Starting Epoch 50: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 49: frames [490000..500000] (first sequence at sample 490000), data subset 0 of 1

07/13/2016 12:23:21: Starting minibatch loop.
07/13/2016 12:23:21:  Epoch[50 of 50]-Minibatch[   1-  10, 0.00000000000003%]: CrossEntropyWithSoftmax = 0.17541753 * 1280; EvalErrorPrediction = 0.08359375 * 1280; time = 0.2070s; samplesPerSecond = 6183.8
07/13/2016 12:23:21:  Epoch[50 of 50]-Minibatch[  11-  20, 0.00000000000006%]: CrossEntropyWithSoftmax = 0.16571552 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.0267s; samplesPerSecond = 47943.7
07/13/2016 12:23:21:  Epoch[50 of 50]-Minibatch[  21-  30, 0.00000000000008%]: CrossEntropyWithSoftmax = 0.15297840 * 1280; EvalErrorPrediction = 0.06875000 * 1280; time = 0.0263s; samplesPerSecond = 48582.4
07/13/2016 12:23:21:  Epoch[50 of 50]-Minibatch[  31-  40, 0.00000000000011%]: CrossEntropyWithSoftmax = 0.15474615 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 0.0265s; samplesPerSecond = 48336.5
07/13/2016 12:23:21:  Epoch[50 of 50]-Minibatch[  41-  50, 0.00000000000014%]: CrossEntropyWithSoftmax = 0.15424118 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 0.0265s; samplesPerSecond = 48332.9
07/13/2016 12:23:21:  Epoch[50 of 50]-Minibatch[  51-  60, 0.00000000000017%]: CrossEntropyWithSoftmax = 0.14947748 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.0266s; samplesPerSecond = 48187.3
07/13/2016 12:23:21:  Epoch[50 of 50]-Minibatch[  61-  70, 0.00000000000019%]: CrossEntropyWithSoftmax = 0.14548969 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 0.0265s; samplesPerSecond = 48340.2
07/13/2016 12:23:21: Finished Epoch[50 of 50]: [Training] CrossEntropyWithSoftmax = 0.15954734 * 10000; EvalErrorPrediction = 0.07370000 * 10000; totalSamplesSeen = 500000; learningRatePerSample = 0.1; epochTime=0.403095s
07/13/2016 12:23:21: SGD: Saving checkpoint model '/tmp/cntk-test-20160713121920.930131/Speech_Simple@debug_gpu/models/simple.dnn'
07/13/2016 12:23:21: CNTKCommandTrainEnd: Simple_Demo

07/13/2016 12:23:21: Action "train" complete.


07/13/2016 12:23:21: ##############################################################################
07/13/2016 12:23:21: #                                                                            #
07/13/2016 12:23:21: # Action "write"                                                             #
07/13/2016 12:23:21: #                                                                            #
07/13/2016 12:23:21: ##############################################################################


Post-processing network...

7 roots:
	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
	EvalErrorPrediction = ErrorPrediction()
	InvStdOfFeatures = InvStdDev()
	MeanOfFeatures = Mean()
	PosteriorProb = Softmax()
	Prior = Mean()
	ScaledLogLikelihood = Minus()

Validating network. 25 nodes to process in pass 1.

Validating --> labels = InputValue() :  -> [2 x *2]
Validating --> W2 = LearnableParameter() :  -> [2 x 50]
Validating --> W1 = LearnableParameter() :  -> [50 x 50]
Validating --> W0 = LearnableParameter() :  -> [50 x 2]
Validating --> features = InputValue() :  -> [2 x *2]
Validating --> MeanOfFeatures = Mean (features) : [2 x *2] -> [2]
Validating --> InvStdOfFeatures = InvStdDev (features) : [2 x *2] -> [2]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [2 x *2], [2], [2] -> [2 x *2]
Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [50 x 2], [2 x *2] -> [50 x *2]
Validating --> B0 = LearnableParameter() :  -> [50 x 1]
Validating --> W0*features+B0 = Plus (W0*features, B0) : [50 x *2], [50 x 1] -> [50 x 1 x *2]
Validating --> H1 = Sigmoid (W0*features+B0) : [50 x 1 x *2] -> [50 x 1 x *2]
Validating --> W1*H1 = Times (W1, H1) : [50 x 50], [50 x 1 x *2] -> [50 x 1 x *2]
Validating --> B1 = LearnableParameter() :  -> [50 x 1]
Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [50 x 1 x *2], [50 x 1] -> [50 x 1 x *2]
Validating --> H2 = Sigmoid (W1*H1+B1) : [50 x 1 x *2] -> [50 x 1 x *2]
Validating --> W2*H1 = Times (W2, H2) : [2 x 50], [50 x 1 x *2] -> [2 x 1 x *2]
Validating --> B2 = LearnableParameter() :  -> [2 x 1]
Validating --> HLast = Plus (W2*H1, B2) : [2 x 1 x *2], [2 x 1] -> [2 x 1 x *2]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [2 x *2], [2 x 1 x *2] -> [1]
Validating --> EvalErrorPrediction = ErrorPrediction (labels, HLast) : [2 x *2], [2 x 1 x *2] -> [1]
Validating --> PosteriorProb = Softmax (HLast) : [2 x 1 x *2] -> [2 x 1 x *2]
Validating --> Prior = Mean (labels) : [2 x *2] -> [2]
Validating --> LogOfPrior = Log (Prior) : [2] -> [2]
Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [2 x 1 x *2], [2] -> [2 x 1 x *2]

Validating network. 17 nodes to process in pass 2.


Validating network, final pass.



12 out of 25 nodes do not share the minibatch layout with the input data.

Post-processing network complete.



Allocating matrices for forward and/or backward propagation.

Memory Sharing Structure:

(nil): {[B0 Gradient[50 x 1]] [B1 Gradient[50 x 1]] [B2 Gradient[2 x 1]] [CrossEntropyWithSoftmax Gradient[1]] [CrossEntropyWithSoftmax Value[1]] [EvalErrorPrediction Gradient[1]] [EvalErrorPrediction Value[1]] [H1 Gradient[50 x 1 x *2]] [H2 Gradient[50 x 1 x *2]] [HLast Gradient[2 x 1 x *2]] [InvStdOfFeatures Gradient[2]] [LogOfPrior Gradient[2]] [MVNormalizedFeatures Gradient[2 x *2]] [MeanOfFeatures Gradient[2]] [PosteriorProb Gradient[2 x 1 x *2]] [PosteriorProb Value[2 x 1 x *2]] [Prior Gradient[2]] [ScaledLogLikelihood Gradient[2 x 1 x *2]] [W0 Gradient[50 x 2]] [W0*features Gradient[50 x *2]] [W0*features+B0 Gradient[50 x 1 x *2]] [W1 Gradient[50 x 50]] [W1*H1 Gradient[50 x 1 x *2]] [W1*H1+B1 Gradient[50 x 1 x *2]] [W2 Gradient[2 x 50]] [W2*H1 Gradient[2 x 1 x *2]] [features Gradient[2 x *2]] [labels Gradient[2 x *2]] }
0x7ff3d5150f78: {[B0 Value[50 x 1]] }
0x7ff3d51512e8: {[ScaledLogLikelihood Value[2 x 1 x *2]] }
0x7ff3d5151bd8: {[B1 Value[50 x 1]] }
0x7ff3db286298: {[MeanOfFeatures Value[2]] }
0x7ff3db287308: {[Prior Value[2]] }
0x7ff3db287de8: {[W1 Value[50 x 50]] }
0x7ff3db2880f8: {[W0 Value[50 x 2]] }
0x7ff3db28a0b8: {[W2 Value[2 x 50]] }
0x7ff3db299bd8: {[MVNormalizedFeatures Value[2 x *2]] }
0x7ff3db299cc8: {[LogOfPrior Value[2]] }
0x7ff3db29b558: {[W0*features Value[50 x *2]] }
0x7ff3db29bb48: {[W0*features+B0 Value[50 x 1 x *2]] }
0x7ff3db29bd08: {[H1 Value[50 x 1 x *2]] }
0x7ff3db29bec8: {[W1*H1 Value[50 x 1 x *2]] }
0x7ff3db29c088: {[W1*H1+B1 Value[50 x 1 x *2]] }
0x7ff3db29c248: {[H2 Value[50 x 1 x *2]] }
0x7ff3db29c408: {[W2*H1 Value[2 x 1 x *2]] }
0x7ff3db29c5c8: {[HLast Value[2 x 1 x *2]] }
0x7ff3db2a1278: {[B2 Value[2 x 1]] }
0x7ff3db2a2a88: {[features Value[2 x *2]] }
0x7ff3db2a3b38: {[InvStdOfFeatures Value[2]] }
0x7ff3db2a4278: {[labels Value[2 x *2]] }

Minibatch[0]: ActualMBSize = 603
Written to /tmp/cntk-test-20160713121920.930131/Speech_Simple@debug_gpu/SimpleOutput*
Total Samples Evaluated = 603

07/13/2016 12:23:21: Action "write" complete.

07/13/2016 12:23:21: __COMPLETED__
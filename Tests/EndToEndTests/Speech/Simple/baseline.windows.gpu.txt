CPU info:
    CPU Model Name: Intel(R) Xeon(R) CPU W3565 @ 3.20GHz
    Hardware threads: 8
    Total Memory: 12580436 kB
-------------------------------------------------------------------
=== Running /cygdrive/c/jenkins/workspace/CNTK-Test-Windows-W1/x64/debug/cntk.exe configFile=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple/cntk.cntk currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714055016.501646\Speech_Simple@debug_gpu DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714055016.501646\Speech_Simple@debug_gpu DeviceId=0 timestamping=true
-------------------------------------------------------------------
Build info: 

		Built time: Jul 14 2016 05:11:35
		Last modified date: Thu Jul 14 03:20:47 2016
		Build type: Debug
		Build target: GPU
		With 1bit-SGD: no
		Math lib: mkl
		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.5
		CUB_PATH: C:\src\cub-1.4.1
		CUDNN_PATH: c:\NVIDIA\cudnn-4.0\cuda
		Build Branch: HEAD
		Build SHA1: 72bee394bf461e8f6f0feb593a8416c05f481957
		Built by svcphil on liana-08-w
		Build Path: c:\jenkins\workspace\CNTK-Build-Windows\Source\CNTK\
-------------------------------------------------------------------
Changed current directory to C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
07/14/2016 06:29:25: -------------------------------------------------------------------
07/14/2016 06:29:25: Build info: 

07/14/2016 06:29:25: 		Built time: Jul 14 2016 05:11:35
07/14/2016 06:29:25: 		Last modified date: Thu Jul 14 03:20:47 2016
07/14/2016 06:29:25: 		Build type: Debug
07/14/2016 06:29:25: 		Build target: GPU
07/14/2016 06:29:25: 		With 1bit-SGD: no
07/14/2016 06:29:25: 		Math lib: mkl
07/14/2016 06:29:25: 		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.5
07/14/2016 06:29:25: 		CUB_PATH: C:\src\cub-1.4.1
07/14/2016 06:29:25: 		CUDNN_PATH: c:\NVIDIA\cudnn-4.0\cuda
07/14/2016 06:29:25: 		Build Branch: HEAD
07/14/2016 06:29:25: 		Build SHA1: 72bee394bf461e8f6f0feb593a8416c05f481957
07/14/2016 06:29:25: 		Built by svcphil on liana-08-w
07/14/2016 06:29:25: 		Build Path: c:\jenkins\workspace\CNTK-Build-Windows\Source\CNTK\
07/14/2016 06:29:25: -------------------------------------------------------------------
07/14/2016 06:29:26: -------------------------------------------------------------------
07/14/2016 06:29:26: GPU info:

07/14/2016 06:29:26: 		Device[0]: cores = 2496; computeCapability = 5.2; type = "Quadro M4000"; memory = 8192 MB
07/14/2016 06:29:26: -------------------------------------------------------------------

07/14/2016 06:29:26: Running on cntk-muc01 at 2016/07/14 06:29:26
07/14/2016 06:29:26: Command line: 
C:\jenkins\workspace\CNTK-Test-Windows-W1\x64\debug\cntk.exe  configFile=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple/cntk.cntk  currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data  RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714055016.501646\Speech_Simple@debug_gpu  DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data  ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple  OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714055016.501646\Speech_Simple@debug_gpu  DeviceId=0  timestamping=true



07/14/2016 06:29:26: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
07/14/2016 06:29:26: command=Simple_Demo:Simple_Demo_Output
DeviceNumber=-1
precision=float
modelPath=$RunDir$/models/simple.dnn
deviceId=$DeviceNumber$
outputNodeNames=ScaledLogLikelihood
traceLevel=1
Simple_Demo=[
    action=train
    SimpleNetworkBuilder=[
        layerSizes=2:50*2:2
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ErrorPrediction
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0 
        minibatchSize=128
        learningRatesPerSample=0.1
        momentumAsTimeConstant=2500
        dropoutRate=0.0
        maxEpochs=50
        keepCheckPointFiles = true
    ]
    reader=[
        readerType=CNTKTextFormatReader
        file=$DataDir$/SimpleDataTrain_cntk_text.txt
        input = [
            features=[
dim = 2      
                format = "dense"
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
]
Simple_Demo_Output=[
    action=write
    reader=[
        readerType=CNTKTextFormatReader
        file=$DataDir$/SimpleDataTest_cntk_text.txt
        input = [
            features=[
dim = 2 
                format = "dense" 
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
outputPath=$RunDir$/SimpleOutput    
]
currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714055016.501646\Speech_Simple@debug_gpu
DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple
OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714055016.501646\Speech_Simple@debug_gpu
DeviceId=0
timestamping=true

07/14/2016 06:29:26: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<

07/14/2016 06:29:26: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
07/14/2016 06:29:26: command=Simple_Demo:Simple_Demo_Output
DeviceNumber=-1
precision=float
modelPath=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714055016.501646\Speech_Simple@debug_gpu/models/simple.dnn
deviceId=-1
outputNodeNames=ScaledLogLikelihood
traceLevel=1
Simple_Demo=[
    action=train
    SimpleNetworkBuilder=[
        layerSizes=2:50*2:2
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ErrorPrediction
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0 
        minibatchSize=128
        learningRatesPerSample=0.1
        momentumAsTimeConstant=2500
        dropoutRate=0.0
        maxEpochs=50
        keepCheckPointFiles = true
    ]
    reader=[
        readerType=CNTKTextFormatReader
        file=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/SimpleDataTrain_cntk_text.txt
        input = [
            features=[
dim = 2      
                format = "dense"
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
]
Simple_Demo_Output=[
    action=write
    reader=[
        readerType=CNTKTextFormatReader
        file=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/SimpleDataTest_cntk_text.txt
        input = [
            features=[
dim = 2 
                format = "dense" 
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
outputPath=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714055016.501646\Speech_Simple@debug_gpu/SimpleOutput    
]
currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714055016.501646\Speech_Simple@debug_gpu
DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple
OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714055016.501646\Speech_Simple@debug_gpu
DeviceId=0
timestamping=true

07/14/2016 06:29:26: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<

07/14/2016 06:29:26: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
configparameters: cntk.cntk:command=Simple_Demo:Simple_Demo_Output
configparameters: cntk.cntk:ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple
configparameters: cntk.cntk:currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
configparameters: cntk.cntk:DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
configparameters: cntk.cntk:deviceId=0
configparameters: cntk.cntk:DeviceNumber=-1
configparameters: cntk.cntk:modelPath=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714055016.501646\Speech_Simple@debug_gpu/models/simple.dnn
configparameters: cntk.cntk:OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714055016.501646\Speech_Simple@debug_gpu
configparameters: cntk.cntk:outputNodeNames=ScaledLogLikelihood
configparameters: cntk.cntk:precision=float
configparameters: cntk.cntk:RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714055016.501646\Speech_Simple@debug_gpu
configparameters: cntk.cntk:Simple_Demo=[
    action=train
    SimpleNetworkBuilder=[
        layerSizes=2:50*2:2
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ErrorPrediction
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0 
        minibatchSize=128
        learningRatesPerSample=0.1
        momentumAsTimeConstant=2500
        dropoutRate=0.0
        maxEpochs=50
        keepCheckPointFiles = true
    ]
    reader=[
        readerType=CNTKTextFormatReader
        file=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/SimpleDataTrain_cntk_text.txt
        input = [
            features=[
dim = 2      
                format = "dense"
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
]

configparameters: cntk.cntk:Simple_Demo_Output=[
    action=write
    reader=[
        readerType=CNTKTextFormatReader
        file=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/SimpleDataTest_cntk_text.txt
        input = [
            features=[
dim = 2 
                format = "dense" 
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
outputPath=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714055016.501646\Speech_Simple@debug_gpu/SimpleOutput    
]

configparameters: cntk.cntk:timestamping=true
configparameters: cntk.cntk:traceLevel=1
07/14/2016 06:29:26: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
07/14/2016 06:29:26: Commands: Simple_Demo Simple_Demo_Output
07/14/2016 06:29:26: Precision = "float"
07/14/2016 06:29:26: CNTKModelPath: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714055016.501646\Speech_Simple@debug_gpu/models/simple.dnn
07/14/2016 06:29:26: CNTKCommandTrainInfo: Simple_Demo : 50
07/14/2016 06:29:26: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 50

07/14/2016 06:29:26: ##############################################################################
07/14/2016 06:29:26: #                                                                            #
07/14/2016 06:29:26: # Action "train"                                                             #
07/14/2016 06:29:26: #                                                                            #
07/14/2016 06:29:26: ##############################################################################

07/14/2016 06:29:26: CNTKCommandTrainBegin: Simple_Demo
SimpleNetworkBuilder Using GPU 0

07/14/2016 06:29:26: Creating virgin network.
Microsoft::MSR::CNTK::GPUMatrix<ElemType>::SetUniformRandomValue (GPU): creating curand object with seed 1, sizeof(ElemType)==4

Post-processing network...

7 roots:
	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
	EvalErrorPrediction = ErrorPrediction()
	InvStdOfFeatures = InvStdDev()
	MeanOfFeatures = Mean()
	PosteriorProb = Softmax()
	Prior = Mean()
	ScaledLogLikelihood = Minus()

Validating network. 25 nodes to process in pass 1.

Validating --> labels = InputValue() :  -> [2 x *]
Validating --> W2 = LearnableParameter() :  -> [2 x 50]
Validating --> W1 = LearnableParameter() :  -> [50 x 50]
Validating --> W0 = LearnableParameter() :  -> [50 x 2]
Validating --> features = InputValue() :  -> [2 x *]
Validating --> MeanOfFeatures = Mean (features) : [2 x *] -> [2]
Validating --> InvStdOfFeatures = InvStdDev (features) : [2 x *] -> [2]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [2 x *], [2], [2] -> [2 x *]
Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [50 x 2], [2 x *] -> [50 x *]
Validating --> B0 = LearnableParameter() :  -> [50 x 1]
Validating --> W0*features+B0 = Plus (W0*features, B0) : [50 x *], [50 x 1] -> [50 x 1 x *]
Validating --> H1 = Sigmoid (W0*features+B0) : [50 x 1 x *] -> [50 x 1 x *]
Validating --> W1*H1 = Times (W1, H1) : [50 x 50], [50 x 1 x *] -> [50 x 1 x *]
Validating --> B1 = LearnableParameter() :  -> [50 x 1]
Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [50 x 1 x *], [50 x 1] -> [50 x 1 x *]
Validating --> H2 = Sigmoid (W1*H1+B1) : [50 x 1 x *] -> [50 x 1 x *]
Validating --> W2*H1 = Times (W2, H2) : [2 x 50], [50 x 1 x *] -> [2 x 1 x *]
Validating --> B2 = LearnableParameter() :  -> [2 x 1]
Validating --> HLast = Plus (W2*H1, B2) : [2 x 1 x *], [2 x 1] -> [2 x 1 x *]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [2 x *], [2 x 1 x *] -> [1]
Validating --> EvalErrorPrediction = ErrorPrediction (labels, HLast) : [2 x *], [2 x 1 x *] -> [1]
Validating --> PosteriorProb = Softmax (HLast) : [2 x 1 x *] -> [2 x 1 x *]
Validating --> Prior = Mean (labels) : [2 x *] -> [2]
Validating --> LogOfPrior = Log (Prior) : [2] -> [2]
Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [2 x 1 x *], [2] -> [2 x 1 x *]

Validating network. 17 nodes to process in pass 2.


Validating network, final pass.



12 out of 25 nodes do not share the minibatch layout with the input data.

Post-processing network complete.

07/14/2016 06:29:27: Created model with 25 nodes on GPU 0.

07/14/2016 06:29:27: Training criterion node(s):
07/14/2016 06:29:27: 	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax

07/14/2016 06:29:27: Evaluation criterion node(s):

07/14/2016 06:29:27: 	EvalErrorPrediction = ErrorPrediction


Allocating matrices for forward and/or backward propagation.

Memory Sharing Structure:

0000000000000000: {[EvalErrorPrediction Gradient[1]] [InvStdOfFeatures Gradient[2]] [LogOfPrior Gradient[2]] [MVNormalizedFeatures Gradient[2 x *]] [MeanOfFeatures Gradient[2]] [PosteriorProb Gradient[2 x 1 x *]] [PosteriorProb Value[2 x 1 x *]] [Prior Gradient[2]] [ScaledLogLikelihood Gradient[2 x 1 x *]] [features Gradient[2 x *]] [labels Gradient[2 x *]] }
0000004A94972910: {[MeanOfFeatures Value[2]] }
0000004A94B23EA0: {[W0*features+B0 Gradient[50 x 1 x *]] [W1*H1 Value[50 x 1 x *]] }
0000004A94B23F70: {[HLast Value[2 x 1 x *]] [W2 Gradient[2 x 50]] }
0000004A94B241E0: {[H2 Value[50 x 1 x *]] [W1*H1 Gradient[50 x 1 x *]] }
0000004A94B24380: {[ScaledLogLikelihood Value[2 x 1 x *]] }
0000004A94B24450: {[B2 Value[2 x 1]] }
0000004A94B24520: {[CrossEntropyWithSoftmax Gradient[1]] }
0000004A94B245F0: {[W2 Value[2 x 50]] }
0000004A94B246C0: {[W2*H1 Gradient[2 x 1 x *]] }
0000004A94B24790: {[EvalErrorPrediction Value[1]] }
0000004A94B24930: {[LogOfPrior Value[2]] }
0000004A94B24A00: {[B0 Value[50 x 1]] }
0000004A94B24AD0: {[B1 Gradient[50 x 1]] [H2 Gradient[50 x 1 x *]] [HLast Gradient[2 x 1 x *]] }
0000004A94B24C70: {[CrossEntropyWithSoftmax Value[1]] }
0000004A94B24D40: {[H1 Value[50 x 1 x *]] [W0*features Gradient[50 x *]] }
0000004A94B24E10: {[W1 Gradient[50 x 50]] [W1*H1+B1 Value[50 x 1 x *]] }
0000004A94B24EE0: {[Prior Value[2]] }
0000004A94B24FB0: {[W1 Value[50 x 50]] }
0000004A94B25150: {[B1 Value[50 x 1]] }
0000004A94B25220: {[labels Value[2 x *]] }
0000004A94B252F0: {[MVNormalizedFeatures Value[2 x *]] }
0000004A94B253C0: {[W0 Gradient[50 x 2]] [W0*features+B0 Value[50 x 1 x *]] }
0000004A94B25490: {[B2 Gradient[2 x 1]] }
0000004A94B257D0: {[W0 Value[50 x 2]] }
0000004A94B25970: {[InvStdOfFeatures Value[2]] }
0000004A94B25BE0: {[W0*features Value[50 x *]] }
0000004A94B25CB0: {[B0 Gradient[50 x 1]] [H1 Gradient[50 x 1 x *]] [W1*H1+B1 Gradient[50 x 1 x *]] [W2*H1 Value[2 x 1 x *]] }
0000004AFD89B3B0: {[features Value[2 x *]] }


07/14/2016 06:29:27: Precomputing --> 3 PreCompute nodes found.

07/14/2016 06:29:27: 	MeanOfFeatures = Mean()
07/14/2016 06:29:27: 	InvStdOfFeatures = InvStdDev()
07/14/2016 06:29:27: 	Prior = Mean()
BlockRandomizer::StartEpoch: epoch 0: frames [0..10000] (first sequence at sample 0), data subset 0 of 1

07/14/2016 06:29:28: Precomputing --> Completed.


07/14/2016 06:29:28: Starting Epoch 1: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 0: frames [0..10000] (first sequence at sample 0), data subset 0 of 1

07/14/2016 06:29:28: Starting minibatch loop.
07/14/2016 06:29:28:  Epoch[ 1 of 50]-Minibatch[   1-  10]: CrossEntropyWithSoftmax = 0.80036049 * 1280; EvalErrorPrediction = 0.49375000 * 1280; time = 0.0754s; samplesPerSecond = 16983.3
07/14/2016 06:29:28:  Epoch[ 1 of 50]-Minibatch[  11-  20]: CrossEntropyWithSoftmax = 0.73963814 * 1280; EvalErrorPrediction = 0.50000000 * 1280; time = 0.0691s; samplesPerSecond = 18533.8
07/14/2016 06:29:28:  Epoch[ 1 of 50]-Minibatch[  21-  30]: CrossEntropyWithSoftmax = 0.69798355 * 1280; EvalErrorPrediction = 0.47500000 * 1280; time = 0.0687s; samplesPerSecond = 18645.0
07/14/2016 06:29:28:  Epoch[ 1 of 50]-Minibatch[  31-  40]: CrossEntropyWithSoftmax = 0.69287663 * 1280; EvalErrorPrediction = 0.46328125 * 1280; time = 0.0686s; samplesPerSecond = 18668.1
07/14/2016 06:29:28:  Epoch[ 1 of 50]-Minibatch[  41-  50]: CrossEntropyWithSoftmax = 0.69632664 * 1280; EvalErrorPrediction = 0.47265625 * 1280; time = 0.0689s; samplesPerSecond = 18567.9
07/14/2016 06:29:28:  Epoch[ 1 of 50]-Minibatch[  51-  60]: CrossEntropyWithSoftmax = 0.59482651 * 1280; EvalErrorPrediction = 0.36718750 * 1280; time = 0.0697s; samplesPerSecond = 18351.3
07/14/2016 06:29:28:  Epoch[ 1 of 50]-Minibatch[  61-  70]: CrossEntropyWithSoftmax = 0.28369522 * 1280; EvalErrorPrediction = 0.10078125 * 1280; time = 0.0685s; samplesPerSecond = 18678.2
07/14/2016 06:29:28: Finished Epoch[ 1 of 50]: [Training] CrossEntropyWithSoftmax = 0.59631074 * 10000; EvalErrorPrediction = 0.37620000 * 10000; totalSamplesSeen = 10000; learningRatePerSample = 0.1; epochTime=0.779693s
07/14/2016 06:29:28: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714055016.501646\Speech_Simple@debug_gpu/models/simple.dnn.1'

07/14/2016 06:29:28: Starting Epoch 2: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 1: frames [10000..20000] (first sequence at sample 10000), data subset 0 of 1

07/14/2016 06:29:28: Starting minibatch loop.
07/14/2016 06:29:28:  Epoch[ 2 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.22116990 * 1280; EvalErrorPrediction = 0.08984375 * 1280; time = 0.0666s; samplesPerSecond = 19229.3
07/14/2016 06:29:28:  Epoch[ 2 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.19309688 * 1280; EvalErrorPrediction = 0.06484375 * 1280; time = 0.0660s; samplesPerSecond = 19388.7
07/14/2016 06:29:29:  Epoch[ 2 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.22011085 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 0.0685s; samplesPerSecond = 18683.9
07/14/2016 06:29:29:  Epoch[ 2 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.23732114 * 1280; EvalErrorPrediction = 0.08984375 * 1280; time = 0.0691s; samplesPerSecond = 18525.0
07/14/2016 06:29:29:  Epoch[ 2 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.17715120 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0683s; samplesPerSecond = 18730.4
07/14/2016 06:29:29:  Epoch[ 2 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.20253534 * 1280; EvalErrorPrediction = 0.08359375 * 1280; time = 0.0685s; samplesPerSecond = 18688.9
07/14/2016 06:29:29:  Epoch[ 2 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.18395786 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0680s; samplesPerSecond = 18823.8
07/14/2016 06:29:29: Finished Epoch[ 2 of 50]: [Training] CrossEntropyWithSoftmax = 0.20174019 * 10000; EvalErrorPrediction = 0.08010000 * 10000; totalSamplesSeen = 20000; learningRatePerSample = 0.1; epochTime=0.647471s
07/14/2016 06:29:29: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714055016.501646\Speech_Simple@debug_gpu/models/simple.dnn.2'

07/14/2016 06:29:29: Starting Epoch 3: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 2: frames [20000..30000] (first sequence at sample 20000), data subset 0 of 1

07/14/2016 06:29:29: Starting minibatch loop.
07/14/2016 06:29:29:  Epoch[ 3 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15787796 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0802s; samplesPerSecond = 15960.1
07/14/2016 06:29:29:  Epoch[ 3 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.21919509 * 1280; EvalErrorPrediction = 0.09218750 * 1280; time = 0.0645s; samplesPerSecond = 19836.0
07/14/2016 06:29:29:  Epoch[ 3 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.22407804 * 1280; EvalErrorPrediction = 0.09375000 * 1280; time = 0.0651s; samplesPerSecond = 19673.2
07/14/2016 06:29:29:  Epoch[ 3 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.18424897 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0634s; samplesPerSecond = 20203.0
07/14/2016 06:29:29:  Epoch[ 3 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.19865546 * 1280; EvalErrorPrediction = 0.08515625 * 1280; time = 0.0621s; samplesPerSecond = 20613.2
07/14/2016 06:29:29:  Epoch[ 3 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.19954777 * 1280; EvalErrorPrediction = 0.08671875 * 1280; time = 0.0643s; samplesPerSecond = 19917.2
07/14/2016 06:29:29:  Epoch[ 3 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.18475504 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 0.0649s; samplesPerSecond = 19730.9
07/14/2016 06:29:30: Finished Epoch[ 3 of 50]: [Training] CrossEntropyWithSoftmax = 0.19457751 * 10000; EvalErrorPrediction = 0.08350000 * 10000; totalSamplesSeen = 30000; learningRatePerSample = 0.1; epochTime=0.631615s
07/14/2016 06:29:30: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714055016.501646\Speech_Simple@debug_gpu/models/simple.dnn.3'

07/14/2016 06:29:30: Starting Epoch 4: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 3: frames [30000..40000] (first sequence at sample 30000), data subset 0 of 1

07/14/2016 06:29:30: Starting minibatch loop.
07/14/2016 06:29:30:  Epoch[ 4 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.20615716 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0646s; samplesPerSecond = 19799.5
07/14/2016 06:29:30:  Epoch[ 4 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.23653307 * 1280; EvalErrorPrediction = 0.09375000 * 1280; time = 0.0621s; samplesPerSecond = 20603.0
07/14/2016 06:29:30:  Epoch[ 4 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15982165 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0621s; samplesPerSecond = 20621.2
07/14/2016 06:29:30:  Epoch[ 4 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.17472682 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0621s; samplesPerSecond = 20598.0
07/14/2016 06:29:30:  Epoch[ 4 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16936812 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0621s; samplesPerSecond = 20613.9
07/14/2016 06:29:30:  Epoch[ 4 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.18025608 * 1280; EvalErrorPrediction = 0.08593750 * 1280; time = 0.0624s; samplesPerSecond = 20526.3
07/14/2016 06:29:30:  Epoch[ 4 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15101624 * 1280; EvalErrorPrediction = 0.06640625 * 1280; time = 0.0623s; samplesPerSecond = 20536.8
07/14/2016 06:29:30: Finished Epoch[ 4 of 50]: [Training] CrossEntropyWithSoftmax = 0.17931101 * 10000; EvalErrorPrediction = 0.08010000 * 10000; totalSamplesSeen = 40000; learningRatePerSample = 0.1; epochTime=0.605539s
07/14/2016 06:29:30: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714055016.501646\Speech_Simple@debug_gpu/models/simple.dnn.4'

07/14/2016 06:29:30: Starting Epoch 5: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 4: frames [40000..50000] (first sequence at sample 40000), data subset 0 of 1

07/14/2016 06:29:30: Starting minibatch loop.
07/14/2016 06:29:30:  Epoch[ 5 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16290021 * 1280; EvalErrorPrediction = 0.06875000 * 1280; time = 0.0875s; samplesPerSecond = 14632.1
07/14/2016 06:29:30:  Epoch[ 5 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14657037 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0869s; samplesPerSecond = 14725.7
07/14/2016 06:29:31:  Epoch[ 5 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15137298 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.0735s; samplesPerSecond = 17410.2
07/14/2016 06:29:31:  Epoch[ 5 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.17363105 * 1280; EvalErrorPrediction = 0.08984375 * 1280; time = 0.0709s; samplesPerSecond = 18041.9
07/14/2016 06:29:31:  Epoch[ 5 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16768327 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0712s; samplesPerSecond = 17976.3
07/14/2016 06:29:31:  Epoch[ 5 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17201014 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0708s; samplesPerSecond = 18070.7
07/14/2016 06:29:31:  Epoch[ 5 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15547333 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0708s; samplesPerSecond = 18075.5
07/14/2016 06:29:31: Finished Epoch[ 5 of 50]: [Training] CrossEntropyWithSoftmax = 0.16151650 * 10000; EvalErrorPrediction = 0.07600000 * 10000; totalSamplesSeen = 50000; learningRatePerSample = 0.1; epochTime=0.705564s
07/14/2016 06:29:31: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714055016.501646\Speech_Simple@debug_gpu/models/simple.dnn.5'

07/14/2016 06:29:31: Starting Epoch 6: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 5: frames [50000..60000] (first sequence at sample 50000), data subset 0 of 1

07/14/2016 06:29:31: Starting minibatch loop.
07/14/2016 06:29:31:  Epoch[ 6 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15754119 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0646s; samplesPerSecond = 19817.3
07/14/2016 06:29:31:  Epoch[ 6 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15110322 * 1280; EvalErrorPrediction = 0.06796875 * 1280; time = 0.0622s; samplesPerSecond = 20584.4
07/14/2016 06:29:31:  Epoch[ 6 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.13633235 * 1280; EvalErrorPrediction = 0.06171875 * 1280; time = 0.0644s; samplesPerSecond = 19879.5
07/14/2016 06:29:31:  Epoch[ 6 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14975395 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0636s; samplesPerSecond = 20138.5
07/14/2016 06:29:31:  Epoch[ 6 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16291628 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 0.0646s; samplesPerSecond = 19799.2
07/14/2016 06:29:31:  Epoch[ 6 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17918401 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0649s; samplesPerSecond = 19723.6
07/14/2016 06:29:31:  Epoch[ 6 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16897411 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0632s; samplesPerSecond = 20242.9
07/14/2016 06:29:32: Finished Epoch[ 6 of 50]: [Training] CrossEntropyWithSoftmax = 0.16222866 * 10000; EvalErrorPrediction = 0.07610000 * 10000; totalSamplesSeen = 60000; learningRatePerSample = 0.1; epochTime=0.616017s
07/14/2016 06:29:32: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714055016.501646\Speech_Simple@debug_gpu/models/simple.dnn.6'

07/14/2016 06:29:32: Starting Epoch 7: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 6: frames [60000..70000] (first sequence at sample 60000), data subset 0 of 1

07/14/2016 06:29:32: Starting minibatch loop.
07/14/2016 06:29:32:  Epoch[ 7 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15293255 * 1280; EvalErrorPrediction = 0.06718750 * 1280; time = 0.0883s; samplesPerSecond = 14493.2
07/14/2016 06:29:32:  Epoch[ 7 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17988107 * 1280; EvalErrorPrediction = 0.08359375 * 1280; time = 0.0852s; samplesPerSecond = 15030.7
07/14/2016 06:29:32:  Epoch[ 7 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.18310168 * 1280; EvalErrorPrediction = 0.08515625 * 1280; time = 0.0666s; samplesPerSecond = 19221.0
07/14/2016 06:29:32:  Epoch[ 7 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14703221 * 1280; EvalErrorPrediction = 0.05703125 * 1280; time = 0.0632s; samplesPerSecond = 20258.6
07/14/2016 06:29:32:  Epoch[ 7 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14987464 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0632s; samplesPerSecond = 20268.9
07/14/2016 06:29:32:  Epoch[ 7 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14907417 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.0636s; samplesPerSecond = 20125.5
07/14/2016 06:29:32:  Epoch[ 7 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15333843 * 1280; EvalErrorPrediction = 0.06562500 * 1280; time = 0.0626s; samplesPerSecond = 20461.7
07/14/2016 06:29:32: Finished Epoch[ 7 of 50]: [Training] CrossEntropyWithSoftmax = 0.16399935 * 10000; EvalErrorPrediction = 0.07420000 * 10000; totalSamplesSeen = 70000; learningRatePerSample = 0.1; epochTime=0.660093s
07/14/2016 06:29:32: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714055016.501646\Speech_Simple@debug_gpu/models/simple.dnn.7'

07/14/2016 06:29:32: Starting Epoch 8: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 7: frames [70000..80000] (first sequence at sample 70000), data subset 0 of 1

07/14/2016 06:29:32: Starting minibatch loop.
07/14/2016 06:29:32:  Epoch[ 8 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17712796 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0653s; samplesPerSecond = 19609.0
07/14/2016 06:29:32:  Epoch[ 8 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15530257 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 0.0619s; samplesPerSecond = 20664.8
07/14/2016 06:29:32:  Epoch[ 8 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15755689 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0635s; samplesPerSecond = 20151.8
07/14/2016 06:29:33:  Epoch[ 8 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.18656712 * 1280; EvalErrorPrediction = 0.09062500 * 1280; time = 0.0639s; samplesPerSecond = 20024.7
07/14/2016 06:29:33:  Epoch[ 8 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15906930 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0646s; samplesPerSecond = 19802.3
07/14/2016 06:29:33:  Epoch[ 8 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17213850 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0628s; samplesPerSecond = 20377.6
07/14/2016 06:29:33:  Epoch[ 8 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17070332 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0638s; samplesPerSecond = 20056.1
07/14/2016 06:29:33: Finished Epoch[ 8 of 50]: [Training] CrossEntropyWithSoftmax = 0.16772355 * 10000; EvalErrorPrediction = 0.07660000 * 10000; totalSamplesSeen = 80000; learningRatePerSample = 0.1; epochTime=0.614993s
07/14/2016 06:29:33: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714055016.501646\Speech_Simple@debug_gpu/models/simple.dnn.8'

07/14/2016 06:29:33: Starting Epoch 9: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 8: frames [80000..90000] (first sequence at sample 80000), data subset 0 of 1

07/14/2016 06:29:33: Starting minibatch loop.
07/14/2016 06:29:33:  Epoch[ 9 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17198269 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0666s; samplesPerSecond = 19218.4
07/14/2016 06:29:33:  Epoch[ 9 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16227412 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0639s; samplesPerSecond = 20035.7
07/14/2016 06:29:33:  Epoch[ 9 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14194391 * 1280; EvalErrorPrediction = 0.06484375 * 1280; time = 0.0638s; samplesPerSecond = 20055.2
07/14/2016 06:29:33:  Epoch[ 9 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.13591185 * 1280; EvalErrorPrediction = 0.06250000 * 1280; time = 0.0628s; samplesPerSecond = 20384.1
07/14/2016 06:29:33:  Epoch[ 9 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16893721 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0618s; samplesPerSecond = 20702.3
07/14/2016 06:29:33:  Epoch[ 9 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17256761 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 0.0633s; samplesPerSecond = 20211.9
07/14/2016 06:29:33:  Epoch[ 9 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15469122 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.0621s; samplesPerSecond = 20628.2
07/14/2016 06:29:34: Finished Epoch[ 9 of 50]: [Training] CrossEntropyWithSoftmax = 0.15945801 * 10000; EvalErrorPrediction = 0.07400000 * 10000; totalSamplesSeen = 90000; learningRatePerSample = 0.1; epochTime=0.613329s
07/14/2016 06:29:34: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714055016.501646\Speech_Simple@debug_gpu/models/simple.dnn.9'

07/14/2016 06:29:34: Starting Epoch 10: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 9: frames [90000..100000] (first sequence at sample 90000), data subset 0 of 1

07/14/2016 06:29:34: Starting minibatch loop.
07/14/2016 06:29:34:  Epoch[10 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17939832 * 1280; EvalErrorPrediction = 0.08437500 * 1280; time = 0.0671s; samplesPerSecond = 19083.7
07/14/2016 06:29:34:  Epoch[10 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17711463 * 1280; EvalErrorPrediction = 0.08750000 * 1280; time = 0.0628s; samplesPerSecond = 20373.4
07/14/2016 06:29:34:  Epoch[10 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16516178 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0624s; samplesPerSecond = 20499.7
07/14/2016 06:29:34:  Epoch[10 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16810260 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0624s; samplesPerSecond = 20511.8
07/14/2016 06:29:34:  Epoch[10 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14347167 * 1280; EvalErrorPrediction = 0.06875000 * 1280; time = 0.0641s; samplesPerSecond = 19968.8
07/14/2016 06:29:34:  Epoch[10 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15378065 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.0637s; samplesPerSecond = 20099.9
07/14/2016 06:29:34:  Epoch[10 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16807785 * 1280; EvalErrorPrediction = 0.08437500 * 1280; time = 0.0645s; samplesPerSecond = 19849.3
07/14/2016 06:29:34: Finished Epoch[10 of 50]: [Training] CrossEntropyWithSoftmax = 0.16372339 * 10000; EvalErrorPrediction = 0.07690000 * 10000; totalSamplesSeen = 100000; learningRatePerSample = 0.1; epochTime=0.616445s
07/14/2016 06:29:34: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714055016.501646\Speech_Simple@debug_gpu/models/simple.dnn.10'

07/14/2016 06:29:34: Starting Epoch 11: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 10: frames [100000..110000] (first sequence at sample 100000), data subset 0 of 1

07/14/2016 06:29:34: Starting minibatch loop.
07/14/2016 06:29:34:  Epoch[11 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17368636 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 0.0671s; samplesPerSecond = 19080.6
07/14/2016 06:29:34:  Epoch[11 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16964107 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0649s; samplesPerSecond = 19722.0
07/14/2016 06:29:34:  Epoch[11 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16779490 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0625s; samplesPerSecond = 20489.8
07/14/2016 06:29:34:  Epoch[11 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.17030134 * 1280; EvalErrorPrediction = 0.08984375 * 1280; time = 0.0623s; samplesPerSecond = 20530.6
07/14/2016 06:29:35:  Epoch[11 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.13490191 * 1280; EvalErrorPrediction = 0.05781250 * 1280; time = 0.0641s; samplesPerSecond = 19981.3
07/14/2016 06:29:35:  Epoch[11 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16300955 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 0.0647s; samplesPerSecond = 19774.8
07/14/2016 06:29:35:  Epoch[11 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16420202 * 1280; EvalErrorPrediction = 0.06718750 * 1280; time = 0.0637s; samplesPerSecond = 20095.8
07/14/2016 06:29:35: Finished Epoch[11 of 50]: [Training] CrossEntropyWithSoftmax = 0.16507054 * 10000; EvalErrorPrediction = 0.07650000 * 10000; totalSamplesSeen = 110000; learningRatePerSample = 0.1; epochTime=0.617341s
07/14/2016 06:29:35: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714055016.501646\Speech_Simple@debug_gpu/models/simple.dnn.11'

07/14/2016 06:29:35: Starting Epoch 12: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 11: frames [110000..120000] (first sequence at sample 110000), data subset 0 of 1

07/14/2016 06:29:35: Starting minibatch loop.
07/14/2016 06:29:35:  Epoch[12 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.19670932 * 1280; EvalErrorPrediction = 0.08359375 * 1280; time = 0.0646s; samplesPerSecond = 19820.1
07/14/2016 06:29:35:  Epoch[12 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17821176 * 1280; EvalErrorPrediction = 0.08359375 * 1280; time = 0.0619s; samplesPerSecond = 20675.2
07/14/2016 06:29:35:  Epoch[12 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.20371313 * 1280; EvalErrorPrediction = 0.08437500 * 1280; time = 0.0618s; samplesPerSecond = 20708.3
07/14/2016 06:29:35:  Epoch[12 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.18041258 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0628s; samplesPerSecond = 20388.7
07/14/2016 06:29:35:  Epoch[12 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.17273192 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0618s; samplesPerSecond = 20715.7
07/14/2016 06:29:35:  Epoch[12 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15537434 * 1280; EvalErrorPrediction = 0.06875000 * 1280; time = 0.0638s; samplesPerSecond = 20057.7
07/14/2016 06:29:35:  Epoch[12 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16492987 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0636s; samplesPerSecond = 20133.1
07/14/2016 06:29:35: Finished Epoch[12 of 50]: [Training] CrossEntropyWithSoftmax = 0.17856027 * 10000; EvalErrorPrediction = 0.07830000 * 10000; totalSamplesSeen = 120000; learningRatePerSample = 0.1; epochTime=0.609321s
07/14/2016 06:29:36: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714055016.501646\Speech_Simple@debug_gpu/models/simple.dnn.12'

07/14/2016 06:29:36: Starting Epoch 13: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 12: frames [120000..130000] (first sequence at sample 120000), data subset 0 of 1

07/14/2016 06:29:36: Starting minibatch loop.
07/14/2016 06:29:36:  Epoch[13 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17911556 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0864s; samplesPerSecond = 14816.2
07/14/2016 06:29:36:  Epoch[13 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17248518 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0856s; samplesPerSecond = 14960.6
07/14/2016 06:29:36:  Epoch[13 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15460196 * 1280; EvalErrorPrediction = 0.06406250 * 1280; time = 0.0740s; samplesPerSecond = 17306.2
07/14/2016 06:29:36:  Epoch[13 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.17442007 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0708s; samplesPerSecond = 18070.4
07/14/2016 06:29:36:  Epoch[13 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16468239 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0707s; samplesPerSecond = 18113.1
07/14/2016 06:29:36:  Epoch[13 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16221886 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0711s; samplesPerSecond = 18006.9
07/14/2016 06:29:36:  Epoch[13 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16967449 * 1280; EvalErrorPrediction = 0.08359375 * 1280; time = 0.0713s; samplesPerSecond = 17947.0
07/14/2016 06:29:36: Finished Epoch[13 of 50]: [Training] CrossEntropyWithSoftmax = 0.16631365 * 10000; EvalErrorPrediction = 0.07630000 * 10000; totalSamplesSeen = 130000; learningRatePerSample = 0.1; epochTime=0.70416s
07/14/2016 06:29:36: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714055016.501646\Speech_Simple@debug_gpu/models/simple.dnn.13'

07/14/2016 06:29:36: Starting Epoch 14: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 13: frames [130000..140000] (first sequence at sample 130000), data subset 0 of 1

07/14/2016 06:29:36: Starting minibatch loop.
07/14/2016 06:29:36:  Epoch[14 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16934264 * 1280; EvalErrorPrediction = 0.08359375 * 1280; time = 0.0867s; samplesPerSecond = 14757.8
07/14/2016 06:29:37:  Epoch[14 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15462241 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0850s; samplesPerSecond = 15050.3
07/14/2016 06:29:37:  Epoch[14 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.20348213 * 1280; EvalErrorPrediction = 0.09453125 * 1280; time = 0.0741s; samplesPerSecond = 17279.1
07/14/2016 06:29:37:  Epoch[14 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16968780 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 0.0710s; samplesPerSecond = 18032.7
07/14/2016 06:29:37:  Epoch[14 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15051937 * 1280; EvalErrorPrediction = 0.06796875 * 1280; time = 0.0707s; samplesPerSecond = 18093.7
07/14/2016 06:29:37:  Epoch[14 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15649366 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0714s; samplesPerSecond = 17926.7
07/14/2016 06:29:37:  Epoch[14 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16648664 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0712s; samplesPerSecond = 17982.8
07/14/2016 06:29:37: Finished Epoch[14 of 50]: [Training] CrossEntropyWithSoftmax = 0.16638087 * 10000; EvalErrorPrediction = 0.07740000 * 10000; totalSamplesSeen = 140000; learningRatePerSample = 0.1; epochTime=0.705349s
07/14/2016 06:29:37: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714055016.501646\Speech_Simple@debug_gpu/models/simple.dnn.14'

07/14/2016 06:29:37: Starting Epoch 15: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 14: frames [140000..150000] (first sequence at sample 140000), data subset 0 of 1

07/14/2016 06:29:37: Starting minibatch loop.
07/14/2016 06:29:37:  Epoch[15 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.19874434 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0875s; samplesPerSecond = 14631.6
07/14/2016 06:29:37:  Epoch[15 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.23146358 * 1280; EvalErrorPrediction = 0.09062500 * 1280; time = 0.0863s; samplesPerSecond = 14834.2
07/14/2016 06:29:37:  Epoch[15 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17828455 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0665s; samplesPerSecond = 19239.7
07/14/2016 06:29:37:  Epoch[15 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.17506065 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.0634s; samplesPerSecond = 20196.3
07/14/2016 06:29:37:  Epoch[15 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16163616 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0637s; samplesPerSecond = 20086.0
07/14/2016 06:29:38:  Epoch[15 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17310820 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0632s; samplesPerSecond = 20252.8
07/14/2016 06:29:38:  Epoch[15 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15649385 * 1280; EvalErrorPrediction = 0.06640625 * 1280; time = 0.0633s; samplesPerSecond = 20234.6
07/14/2016 06:29:38: Finished Epoch[15 of 50]: [Training] CrossEntropyWithSoftmax = 0.18043081 * 10000; EvalErrorPrediction = 0.07570000 * 10000; totalSamplesSeen = 150000; learningRatePerSample = 0.1; epochTime=0.662341s
07/14/2016 06:29:38: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714055016.501646\Speech_Simple@debug_gpu/models/simple.dnn.15'

07/14/2016 06:29:38: Starting Epoch 16: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 15: frames [150000..160000] (first sequence at sample 150000), data subset 0 of 1

07/14/2016 06:29:38: Starting minibatch loop.
07/14/2016 06:29:38:  Epoch[16 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17766747 * 1280; EvalErrorPrediction = 0.08593750 * 1280; time = 0.0887s; samplesPerSecond = 14437.0
07/14/2016 06:29:38:  Epoch[16 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17266994 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 0.0866s; samplesPerSecond = 14776.5
07/14/2016 06:29:38:  Epoch[16 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.13951435 * 1280; EvalErrorPrediction = 0.06562500 * 1280; time = 0.0738s; samplesPerSecond = 17343.2
07/14/2016 06:29:38:  Epoch[16 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14980383 * 1280; EvalErrorPrediction = 0.06640625 * 1280; time = 0.0709s; samplesPerSecond = 18061.2
07/14/2016 06:29:38:  Epoch[16 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15229244 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 0.0711s; samplesPerSecond = 18000.8
07/14/2016 06:29:38:  Epoch[16 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16172876 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 0.0709s; samplesPerSecond = 18057.7
07/14/2016 06:29:38:  Epoch[16 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17338495 * 1280; EvalErrorPrediction = 0.08515625 * 1280; time = 0.0707s; samplesPerSecond = 18109.8
07/14/2016 06:29:39: Finished Epoch[16 of 50]: [Training] CrossEntropyWithSoftmax = 0.16054852 * 10000; EvalErrorPrediction = 0.07450000 * 10000; totalSamplesSeen = 160000; learningRatePerSample = 0.1; epochTime=0.707871s
07/14/2016 06:29:39: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714055016.501646\Speech_Simple@debug_gpu/models/simple.dnn.16'

07/14/2016 06:29:39: Starting Epoch 17: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 16: frames [160000..170000] (first sequence at sample 160000), data subset 0 of 1

07/14/2016 06:29:39: Starting minibatch loop.
07/14/2016 06:29:39:  Epoch[17 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17172073 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0710s; samplesPerSecond = 18031.0
07/14/2016 06:29:39:  Epoch[17 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15973872 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0647s; samplesPerSecond = 19772.9
07/14/2016 06:29:39:  Epoch[17 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15235903 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 0.0622s; samplesPerSecond = 20593.0
07/14/2016 06:29:39:  Epoch[17 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16841578 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0634s; samplesPerSecond = 20190.2
07/14/2016 06:29:39:  Epoch[17 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.17763777 * 1280; EvalErrorPrediction = 0.08359375 * 1280; time = 0.0626s; samplesPerSecond = 20455.8
07/14/2016 06:29:39:  Epoch[17 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17554998 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0620s; samplesPerSecond = 20653.8
07/14/2016 06:29:39:  Epoch[17 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17380972 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 0.0621s; samplesPerSecond = 20615.9
07/14/2016 06:29:39: Finished Epoch[17 of 50]: [Training] CrossEntropyWithSoftmax = 0.16769557 * 10000; EvalErrorPrediction = 0.07830000 * 10000; totalSamplesSeen = 170000; learningRatePerSample = 0.1; epochTime=0.615914s
07/14/2016 06:29:39: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714055016.501646\Speech_Simple@debug_gpu/models/simple.dnn.17'

07/14/2016 06:29:39: Starting Epoch 18: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 17: frames [170000..180000] (first sequence at sample 170000), data subset 0 of 1

07/14/2016 06:29:39: Starting minibatch loop.
07/14/2016 06:29:39:  Epoch[18 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.18546271 * 1280; EvalErrorPrediction = 0.08828125 * 1280; time = 0.0663s; samplesPerSecond = 19320.2
07/14/2016 06:29:39:  Epoch[18 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16662569 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 0.0630s; samplesPerSecond = 20311.7
07/14/2016 06:29:39:  Epoch[18 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15380311 * 1280; EvalErrorPrediction = 0.06718750 * 1280; time = 0.0624s; samplesPerSecond = 20523.0
07/14/2016 06:29:39:  Epoch[18 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16768489 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0631s; samplesPerSecond = 20282.7
07/14/2016 06:29:39:  Epoch[18 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14958158 * 1280; EvalErrorPrediction = 0.06640625 * 1280; time = 0.0632s; samplesPerSecond = 20246.8
07/14/2016 06:29:40:  Epoch[18 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15028095 * 1280; EvalErrorPrediction = 0.05937500 * 1280; time = 0.0634s; samplesPerSecond = 20183.9
07/14/2016 06:29:40:  Epoch[18 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.18185120 * 1280; EvalErrorPrediction = 0.08359375 * 1280; time = 0.0642s; samplesPerSecond = 19947.9
07/14/2016 06:29:40: Finished Epoch[18 of 50]: [Training] CrossEntropyWithSoftmax = 0.16518080 * 10000; EvalErrorPrediction = 0.07490000 * 10000; totalSamplesSeen = 180000; learningRatePerSample = 0.1; epochTime=0.613551s
07/14/2016 06:29:40: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714055016.501646\Speech_Simple@debug_gpu/models/simple.dnn.18'

07/14/2016 06:29:40: Starting Epoch 19: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 18: frames [180000..190000] (first sequence at sample 180000), data subset 0 of 1

07/14/2016 06:29:40: Starting minibatch loop.
07/14/2016 06:29:40:  Epoch[19 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16063714 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.0666s; samplesPerSecond = 19209.1
07/14/2016 06:29:40:  Epoch[19 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14225507 * 1280; EvalErrorPrediction = 0.06640625 * 1280; time = 0.0642s; samplesPerSecond = 19938.3
07/14/2016 06:29:40:  Epoch[19 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17917566 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0648s; samplesPerSecond = 19758.6
07/14/2016 06:29:40:  Epoch[19 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14452543 * 1280; EvalErrorPrediction = 0.06640625 * 1280; time = 0.0635s; samplesPerSecond = 20169.2
07/14/2016 06:29:40:  Epoch[19 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14539242 * 1280; EvalErrorPrediction = 0.06875000 * 1280; time = 0.0649s; samplesPerSecond = 19729.3
07/14/2016 06:29:40:  Epoch[19 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.18495607 * 1280; EvalErrorPrediction = 0.08906250 * 1280; time = 0.0635s; samplesPerSecond = 20148.6
07/14/2016 06:29:40:  Epoch[19 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17280903 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 0.0628s; samplesPerSecond = 20371.5
07/14/2016 06:29:40: Finished Epoch[19 of 50]: [Training] CrossEntropyWithSoftmax = 0.16193760 * 10000; EvalErrorPrediction = 0.07480000 * 10000; totalSamplesSeen = 190000; learningRatePerSample = 0.1; epochTime=0.619394s
07/14/2016 06:29:40: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714055016.501646\Speech_Simple@debug_gpu/models/simple.dnn.19'

07/14/2016 06:29:40: Starting Epoch 20: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 19: frames [190000..200000] (first sequence at sample 190000), data subset 0 of 1

07/14/2016 06:29:40: Starting minibatch loop.
07/14/2016 06:29:40:  Epoch[20 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15184443 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.0654s; samplesPerSecond = 19581.7
07/14/2016 06:29:41:  Epoch[20 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16657751 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0636s; samplesPerSecond = 20126.7
07/14/2016 06:29:41:  Epoch[20 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14949384 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0636s; samplesPerSecond = 20132.1
07/14/2016 06:29:41:  Epoch[20 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15632596 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0633s; samplesPerSecond = 20224.4
07/14/2016 06:29:41:  Epoch[20 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16432872 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0618s; samplesPerSecond = 20705.6
07/14/2016 06:29:41:  Epoch[20 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17501149 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0623s; samplesPerSecond = 20552.3
07/14/2016 06:29:41:  Epoch[20 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17746801 * 1280; EvalErrorPrediction = 0.08515625 * 1280; time = 0.0620s; samplesPerSecond = 20637.8
07/14/2016 06:29:41: Finished Epoch[20 of 50]: [Training] CrossEntropyWithSoftmax = 0.16092581 * 10000; EvalErrorPrediction = 0.07610000 * 10000; totalSamplesSeen = 200000; learningRatePerSample = 0.1; epochTime=0.609835s
07/14/2016 06:29:41: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714055016.501646\Speech_Simple@debug_gpu/models/simple.dnn.20'

07/14/2016 06:29:41: Starting Epoch 21: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 20: frames [200000..210000] (first sequence at sample 200000), data subset 0 of 1

07/14/2016 06:29:41: Starting minibatch loop.
07/14/2016 06:29:41:  Epoch[21 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17402220 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0645s; samplesPerSecond = 19848.0
07/14/2016 06:29:41:  Epoch[21 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14624035 * 1280; EvalErrorPrediction = 0.06796875 * 1280; time = 0.0625s; samplesPerSecond = 20490.8
07/14/2016 06:29:41:  Epoch[21 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15844958 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.0635s; samplesPerSecond = 20162.6
07/14/2016 06:29:41:  Epoch[21 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.17417960 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 0.0623s; samplesPerSecond = 20561.6
07/14/2016 06:29:41:  Epoch[21 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16426048 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0618s; samplesPerSecond = 20696.9
07/14/2016 06:29:41:  Epoch[21 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15479612 * 1280; EvalErrorPrediction = 0.06796875 * 1280; time = 0.0618s; samplesPerSecond = 20697.2
07/14/2016 06:29:41:  Epoch[21 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15938969 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 0.0618s; samplesPerSecond = 20712.6
07/14/2016 06:29:42: Finished Epoch[21 of 50]: [Training] CrossEntropyWithSoftmax = 0.16048846 * 10000; EvalErrorPrediction = 0.07340000 * 10000; totalSamplesSeen = 210000; learningRatePerSample = 0.1; epochTime=0.605428s
07/14/2016 06:29:42: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714055016.501646\Speech_Simple@debug_gpu/models/simple.dnn.21'

07/14/2016 06:29:42: Starting Epoch 22: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 21: frames [210000..220000] (first sequence at sample 210000), data subset 0 of 1

07/14/2016 06:29:42: Starting minibatch loop.
07/14/2016 06:29:42:  Epoch[22 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16001737 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0728s; samplesPerSecond = 17592.1
07/14/2016 06:29:42:  Epoch[22 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14515526 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.0686s; samplesPerSecond = 18649.1
07/14/2016 06:29:42:  Epoch[22 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16188889 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0689s; samplesPerSecond = 18581.2
07/14/2016 06:29:42:  Epoch[22 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.13927827 * 1280; EvalErrorPrediction = 0.06484375 * 1280; time = 0.0694s; samplesPerSecond = 18456.3
07/14/2016 06:29:42:  Epoch[22 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16674910 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0681s; samplesPerSecond = 18790.1
07/14/2016 06:29:42:  Epoch[22 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16127305 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0691s; samplesPerSecond = 18532.7
07/14/2016 06:29:42:  Epoch[22 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.19687061 * 1280; EvalErrorPrediction = 0.09218750 * 1280; time = 0.0689s; samplesPerSecond = 18572.5
07/14/2016 06:29:42: Finished Epoch[22 of 50]: [Training] CrossEntropyWithSoftmax = 0.16183080 * 10000; EvalErrorPrediction = 0.07510000 * 10000; totalSamplesSeen = 220000; learningRatePerSample = 0.1; epochTime=0.657921s
07/14/2016 06:29:42: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714055016.501646\Speech_Simple@debug_gpu/models/simple.dnn.22'

07/14/2016 06:29:42: Starting Epoch 23: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 22: frames [220000..230000] (first sequence at sample 220000), data subset 0 of 1

07/14/2016 06:29:42: Starting minibatch loop.
07/14/2016 06:29:42:  Epoch[23 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17607409 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0648s; samplesPerSecond = 19761.9
07/14/2016 06:29:42:  Epoch[23 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.19716116 * 1280; EvalErrorPrediction = 0.08750000 * 1280; time = 0.0626s; samplesPerSecond = 20438.8
07/14/2016 06:29:43:  Epoch[23 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.18957045 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 0.0643s; samplesPerSecond = 19894.6
07/14/2016 06:29:43:  Epoch[23 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15243316 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0652s; samplesPerSecond = 19623.5
07/14/2016 06:29:43:  Epoch[23 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16202574 * 1280; EvalErrorPrediction = 0.06796875 * 1280; time = 0.0629s; samplesPerSecond = 20351.4
07/14/2016 06:29:43:  Epoch[23 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17661686 * 1280; EvalErrorPrediction = 0.08750000 * 1280; time = 0.0623s; samplesPerSecond = 20534.5
07/14/2016 06:29:43:  Epoch[23 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16391754 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 0.0630s; samplesPerSecond = 20309.7
07/14/2016 06:29:43: Finished Epoch[23 of 50]: [Training] CrossEntropyWithSoftmax = 0.17173041 * 10000; EvalErrorPrediction = 0.07810000 * 10000; totalSamplesSeen = 230000; learningRatePerSample = 0.1; epochTime=0.612382s
07/14/2016 06:29:43: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714055016.501646\Speech_Simple@debug_gpu/models/simple.dnn.23'

07/14/2016 06:29:43: Starting Epoch 24: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 23: frames [230000..240000] (first sequence at sample 230000), data subset 0 of 1

07/14/2016 06:29:43: Starting minibatch loop.
07/14/2016 06:29:43:  Epoch[24 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.19773014 * 1280; EvalErrorPrediction = 0.08750000 * 1280; time = 0.0651s; samplesPerSecond = 19662.7
07/14/2016 06:29:43:  Epoch[24 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14453895 * 1280; EvalErrorPrediction = 0.06406250 * 1280; time = 0.0642s; samplesPerSecond = 19928.7
07/14/2016 06:29:43:  Epoch[24 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16398263 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0652s; samplesPerSecond = 19636.4
07/14/2016 06:29:43:  Epoch[24 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15639038 * 1280; EvalErrorPrediction = 0.06718750 * 1280; time = 0.0643s; samplesPerSecond = 19903.0
07/14/2016 06:29:43:  Epoch[24 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16038284 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0644s; samplesPerSecond = 19884.4
07/14/2016 06:29:43:  Epoch[24 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17344370 * 1280; EvalErrorPrediction = 0.09140625 * 1280; time = 0.0641s; samplesPerSecond = 19982.2
07/14/2016 06:29:43:  Epoch[24 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14828548 * 1280; EvalErrorPrediction = 0.06875000 * 1280; time = 0.0649s; samplesPerSecond = 19718.7
07/14/2016 06:29:44: Finished Epoch[24 of 50]: [Training] CrossEntropyWithSoftmax = 0.16218142 * 10000; EvalErrorPrediction = 0.07480000 * 10000; totalSamplesSeen = 240000; learningRatePerSample = 0.1; epochTime=0.621622s
07/14/2016 06:29:44: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714055016.501646\Speech_Simple@debug_gpu/models/simple.dnn.24'

07/14/2016 06:29:44: Starting Epoch 25: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 24: frames [240000..250000] (first sequence at sample 240000), data subset 0 of 1

07/14/2016 06:29:44: Starting minibatch loop.
07/14/2016 06:29:44:  Epoch[25 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15957245 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0880s; samplesPerSecond = 14539.8
07/14/2016 06:29:44:  Epoch[25 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15021566 * 1280; EvalErrorPrediction = 0.06796875 * 1280; time = 0.0856s; samplesPerSecond = 14954.0
07/14/2016 06:29:44:  Epoch[25 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16501615 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0663s; samplesPerSecond = 19302.7
07/14/2016 06:29:44:  Epoch[25 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15441861 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0621s; samplesPerSecond = 20604.3
07/14/2016 06:29:44:  Epoch[25 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15622401 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0618s; samplesPerSecond = 20724.0
07/14/2016 06:29:44:  Epoch[25 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14617267 * 1280; EvalErrorPrediction = 0.06796875 * 1280; time = 0.0618s; samplesPerSecond = 20708.0
07/14/2016 06:29:44:  Epoch[25 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16190443 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0618s; samplesPerSecond = 20721.0
07/14/2016 06:29:44: Finished Epoch[25 of 50]: [Training] CrossEntropyWithSoftmax = 0.15772073 * 10000; EvalErrorPrediction = 0.07490000 * 10000; totalSamplesSeen = 250000; learningRatePerSample = 0.1; epochTime=0.654637s
07/14/2016 06:29:44: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714055016.501646\Speech_Simple@debug_gpu/models/simple.dnn.25'

07/14/2016 06:29:44: Starting Epoch 26: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 25: frames [250000..260000] (first sequence at sample 250000), data subset 0 of 1

07/14/2016 06:29:44: Starting minibatch loop.
07/14/2016 06:29:44:  Epoch[26 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16135296 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0669s; samplesPerSecond = 19146.2
07/14/2016 06:29:44:  Epoch[26 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14880558 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 0.0633s; samplesPerSecond = 20226.3
07/14/2016 06:29:44:  Epoch[26 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15580225 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 0.0624s; samplesPerSecond = 20503.0
07/14/2016 06:29:45:  Epoch[26 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.17643390 * 1280; EvalErrorPrediction = 0.08515625 * 1280; time = 0.0635s; samplesPerSecond = 20148.6
07/14/2016 06:29:45:  Epoch[26 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15827289 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0636s; samplesPerSecond = 20136.2
07/14/2016 06:29:45:  Epoch[26 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15517025 * 1280; EvalErrorPrediction = 0.06640625 * 1280; time = 0.0640s; samplesPerSecond = 20002.5
07/14/2016 06:29:45:  Epoch[26 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15697403 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 0.0634s; samplesPerSecond = 20181.0
07/14/2016 06:29:45: Finished Epoch[26 of 50]: [Training] CrossEntropyWithSoftmax = 0.16062526 * 10000; EvalErrorPrediction = 0.07490000 * 10000; totalSamplesSeen = 260000; learningRatePerSample = 0.1; epochTime=0.615791s
07/14/2016 06:29:45: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714055016.501646\Speech_Simple@debug_gpu/models/simple.dnn.26'

07/14/2016 06:29:45: Starting Epoch 27: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 26: frames [260000..270000] (first sequence at sample 260000), data subset 0 of 1

07/14/2016 06:29:45: Starting minibatch loop.
07/14/2016 06:29:45:  Epoch[27 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16729536 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0663s; samplesPerSecond = 19317.3
07/14/2016 06:29:45:  Epoch[27 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15974035 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.0639s; samplesPerSecond = 20037.3
07/14/2016 06:29:45:  Epoch[27 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16978917 * 1280; EvalErrorPrediction = 0.08515625 * 1280; time = 0.0632s; samplesPerSecond = 20257.0
07/14/2016 06:29:45:  Epoch[27 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16220069 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0639s; samplesPerSecond = 20038.5
07/14/2016 06:29:45:  Epoch[27 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16348400 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0620s; samplesPerSecond = 20640.8
07/14/2016 06:29:45:  Epoch[27 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.19333305 * 1280; EvalErrorPrediction = 0.09140625 * 1280; time = 0.0618s; samplesPerSecond = 20699.2
07/14/2016 06:29:45:  Epoch[27 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16584311 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0619s; samplesPerSecond = 20676.2
07/14/2016 06:29:45: Finished Epoch[27 of 50]: [Training] CrossEntropyWithSoftmax = 0.16406160 * 10000; EvalErrorPrediction = 0.07600000 * 10000; totalSamplesSeen = 270000; learningRatePerSample = 0.1; epochTime=0.610186s
07/14/2016 06:29:45: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714055016.501646\Speech_Simple@debug_gpu/models/simple.dnn.27'

07/14/2016 06:29:46: Starting Epoch 28: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 27: frames [270000..280000] (first sequence at sample 270000), data subset 0 of 1

07/14/2016 06:29:46: Starting minibatch loop.
07/14/2016 06:29:46:  Epoch[28 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.14939382 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.0734s; samplesPerSecond = 17436.1
07/14/2016 06:29:46:  Epoch[28 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16335790 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 0.0691s; samplesPerSecond = 18519.3
07/14/2016 06:29:46:  Epoch[28 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16594296 * 1280; EvalErrorPrediction = 0.08359375 * 1280; time = 0.0689s; samplesPerSecond = 18583.6
07/14/2016 06:29:46:  Epoch[28 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16329641 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0692s; samplesPerSecond = 18503.0
07/14/2016 06:29:46:  Epoch[28 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.13549676 * 1280; EvalErrorPrediction = 0.06015625 * 1280; time = 0.0688s; samplesPerSecond = 18606.5
07/14/2016 06:29:46:  Epoch[28 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15654936 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0690s; samplesPerSecond = 18561.8
07/14/2016 06:29:46:  Epoch[28 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17186327 * 1280; EvalErrorPrediction = 0.08515625 * 1280; time = 0.0691s; samplesPerSecond = 18536.8
07/14/2016 06:29:46: Finished Epoch[28 of 50]: [Training] CrossEntropyWithSoftmax = 0.15845054 * 10000; EvalErrorPrediction = 0.07530000 * 10000; totalSamplesSeen = 280000; learningRatePerSample = 0.1; epochTime=0.659751s
07/14/2016 06:29:46: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714055016.501646\Speech_Simple@debug_gpu/models/simple.dnn.28'

07/14/2016 06:29:46: Starting Epoch 29: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 28: frames [280000..290000] (first sequence at sample 280000), data subset 0 of 1

07/14/2016 06:29:46: Starting minibatch loop.
07/14/2016 06:29:46:  Epoch[29 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15515273 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0673s; samplesPerSecond = 19033.2
07/14/2016 06:29:46:  Epoch[29 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15193727 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0641s; samplesPerSecond = 19954.5
07/14/2016 06:29:46:  Epoch[29 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15515509 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0631s; samplesPerSecond = 20276.6
07/14/2016 06:29:46:  Epoch[29 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16528397 * 1280; EvalErrorPrediction = 0.06718750 * 1280; time = 0.0633s; samplesPerSecond = 20210.3
07/14/2016 06:29:46:  Epoch[29 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16561127 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0627s; samplesPerSecond = 20413.0
07/14/2016 06:29:47:  Epoch[29 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15405312 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0624s; samplesPerSecond = 20519.4
07/14/2016 06:29:47:  Epoch[29 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15929556 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 0.0624s; samplesPerSecond = 20518.4
07/14/2016 06:29:47: Finished Epoch[29 of 50]: [Training] CrossEntropyWithSoftmax = 0.16125168 * 10000; EvalErrorPrediction = 0.07630000 * 10000; totalSamplesSeen = 290000; learningRatePerSample = 0.1; epochTime=0.613218s
07/14/2016 06:29:47: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714055016.501646\Speech_Simple@debug_gpu/models/simple.dnn.29'

07/14/2016 06:29:47: Starting Epoch 30: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 29: frames [290000..300000] (first sequence at sample 290000), data subset 0 of 1

07/14/2016 06:29:47: Starting minibatch loop.
07/14/2016 06:29:47:  Epoch[30 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15170232 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 0.0882s; samplesPerSecond = 14512.5
07/14/2016 06:29:47:  Epoch[30 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15954515 * 1280; EvalErrorPrediction = 0.06796875 * 1280; time = 0.0855s; samplesPerSecond = 14976.0
07/14/2016 06:29:47:  Epoch[30 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17360318 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0669s; samplesPerSecond = 19145.3
07/14/2016 06:29:47:  Epoch[30 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.17844276 * 1280; EvalErrorPrediction = 0.08593750 * 1280; time = 0.0623s; samplesPerSecond = 20547.4
07/14/2016 06:29:47:  Epoch[30 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16093383 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0621s; samplesPerSecond = 20618.6
07/14/2016 06:29:47:  Epoch[30 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17449245 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0622s; samplesPerSecond = 20586.7
07/14/2016 06:29:47:  Epoch[30 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15459681 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.0619s; samplesPerSecond = 20677.2
07/14/2016 06:29:47: Finished Epoch[30 of 50]: [Training] CrossEntropyWithSoftmax = 0.16250647 * 10000; EvalErrorPrediction = 0.07480000 * 10000; totalSamplesSeen = 300000; learningRatePerSample = 0.1; epochTime=0.657649s
07/14/2016 06:29:47: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714055016.501646\Speech_Simple@debug_gpu/models/simple.dnn.30'

07/14/2016 06:29:47: Starting Epoch 31: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 30: frames [300000..310000] (first sequence at sample 300000), data subset 0 of 1

07/14/2016 06:29:47: Starting minibatch loop.
07/14/2016 06:29:48:  Epoch[31 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15720762 * 1280; EvalErrorPrediction = 0.06875000 * 1280; time = 0.0668s; samplesPerSecond = 19148.2
07/14/2016 06:29:48:  Epoch[31 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14521240 * 1280; EvalErrorPrediction = 0.06328125 * 1280; time = 0.0642s; samplesPerSecond = 19925.3
07/14/2016 06:29:48:  Epoch[31 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16439087 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0649s; samplesPerSecond = 19710.2
07/14/2016 06:29:48:  Epoch[31 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16082745 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0633s; samplesPerSecond = 20211.3
07/14/2016 06:29:48:  Epoch[31 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14755573 * 1280; EvalErrorPrediction = 0.06484375 * 1280; time = 0.0645s; samplesPerSecond = 19843.1
07/14/2016 06:29:48:  Epoch[31 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15268545 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0637s; samplesPerSecond = 20084.4
07/14/2016 06:29:48:  Epoch[31 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17407017 * 1280; EvalErrorPrediction = 0.08671875 * 1280; time = 0.0640s; samplesPerSecond = 20012.2
07/14/2016 06:29:48: Finished Epoch[31 of 50]: [Training] CrossEntropyWithSoftmax = 0.15889849 * 10000; EvalErrorPrediction = 0.07380000 * 10000; totalSamplesSeen = 310000; learningRatePerSample = 0.1; epochTime=0.62025s
07/14/2016 06:29:48: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714055016.501646\Speech_Simple@debug_gpu/models/simple.dnn.31'

07/14/2016 06:29:48: Starting Epoch 32: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 31: frames [310000..320000] (first sequence at sample 310000), data subset 0 of 1

07/14/2016 06:29:48: Starting minibatch loop.
07/14/2016 06:29:48:  Epoch[32 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15827432 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0870s; samplesPerSecond = 14719.4
07/14/2016 06:29:48:  Epoch[32 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15618222 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.0849s; samplesPerSecond = 15071.9
07/14/2016 06:29:48:  Epoch[32 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.19308798 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0738s; samplesPerSecond = 17355.0
07/14/2016 06:29:48:  Epoch[32 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16348395 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.0709s; samplesPerSecond = 18048.5
07/14/2016 06:29:48:  Epoch[32 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16576171 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0708s; samplesPerSecond = 18078.8
07/14/2016 06:29:49:  Epoch[32 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14784937 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0706s; samplesPerSecond = 18125.7
07/14/2016 06:29:49:  Epoch[32 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15527945 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0714s; samplesPerSecond = 17918.6
07/14/2016 06:29:49: Finished Epoch[32 of 50]: [Training] CrossEntropyWithSoftmax = 0.16398002 * 10000; EvalErrorPrediction = 0.07550000 * 10000; totalSamplesSeen = 320000; learningRatePerSample = 0.1; epochTime=0.70417s
07/14/2016 06:29:49: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714055016.501646\Speech_Simple@debug_gpu/models/simple.dnn.32'

07/14/2016 06:29:49: Starting Epoch 33: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 32: frames [320000..330000] (first sequence at sample 320000), data subset 0 of 1

07/14/2016 06:29:49: Starting minibatch loop.
07/14/2016 06:29:49:  Epoch[33 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.18587434 * 1280; EvalErrorPrediction = 0.09687500 * 1280; time = 0.0762s; samplesPerSecond = 16807.2
07/14/2016 06:29:49:  Epoch[33 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14090347 * 1280; EvalErrorPrediction = 0.06250000 * 1280; time = 0.0693s; samplesPerSecond = 18476.3
07/14/2016 06:29:49:  Epoch[33 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.18215172 * 1280; EvalErrorPrediction = 0.08750000 * 1280; time = 0.0694s; samplesPerSecond = 18438.8
07/14/2016 06:29:49:  Epoch[33 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.13720336 * 1280; EvalErrorPrediction = 0.06484375 * 1280; time = 0.0693s; samplesPerSecond = 18467.5
07/14/2016 06:29:49:  Epoch[33 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15587783 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0686s; samplesPerSecond = 18649.1
07/14/2016 06:29:49:  Epoch[33 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16480780 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 0.0693s; samplesPerSecond = 18476.8
07/14/2016 06:29:49:  Epoch[33 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14647770 * 1280; EvalErrorPrediction = 0.06328125 * 1280; time = 0.0680s; samplesPerSecond = 18822.7
07/14/2016 06:29:49: Finished Epoch[33 of 50]: [Training] CrossEntropyWithSoftmax = 0.15912819 * 10000; EvalErrorPrediction = 0.07570000 * 10000; totalSamplesSeen = 330000; learningRatePerSample = 0.1; epochTime=0.659005s
07/14/2016 06:29:49: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714055016.501646\Speech_Simple@debug_gpu/models/simple.dnn.33'

07/14/2016 06:29:49: Starting Epoch 34: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 33: frames [330000..340000] (first sequence at sample 330000), data subset 0 of 1

07/14/2016 06:29:49: Starting minibatch loop.
07/14/2016 06:29:50:  Epoch[34 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17302400 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.0651s; samplesPerSecond = 19660.9
07/14/2016 06:29:50:  Epoch[34 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.18474275 * 1280; EvalErrorPrediction = 0.08750000 * 1280; time = 0.0630s; samplesPerSecond = 20301.7
07/14/2016 06:29:50:  Epoch[34 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14258783 * 1280; EvalErrorPrediction = 0.06406250 * 1280; time = 0.0619s; samplesPerSecond = 20682.9
07/14/2016 06:29:50:  Epoch[34 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.17269487 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0621s; samplesPerSecond = 20611.6
07/14/2016 06:29:50:  Epoch[34 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14969559 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 0.0625s; samplesPerSecond = 20493.1
07/14/2016 06:29:50:  Epoch[34 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15202980 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 0.0622s; samplesPerSecond = 20568.2
07/14/2016 06:29:50:  Epoch[34 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15735149 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0649s; samplesPerSecond = 19731.5
07/14/2016 06:29:50: Finished Epoch[34 of 50]: [Training] CrossEntropyWithSoftmax = 0.16388569 * 10000; EvalErrorPrediction = 0.07540000 * 10000; totalSamplesSeen = 340000; learningRatePerSample = 0.1; epochTime=0.61032s
07/14/2016 06:29:50: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714055016.501646\Speech_Simple@debug_gpu/models/simple.dnn.34'

07/14/2016 06:29:50: Starting Epoch 35: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 34: frames [340000..350000] (first sequence at sample 340000), data subset 0 of 1

07/14/2016 06:29:50: Starting minibatch loop.
07/14/2016 06:29:50:  Epoch[35 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15619233 * 1280; EvalErrorPrediction = 0.06640625 * 1280; time = 0.0732s; samplesPerSecond = 17474.6
07/14/2016 06:29:50:  Epoch[35 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.18307903 * 1280; EvalErrorPrediction = 0.08515625 * 1280; time = 0.0659s; samplesPerSecond = 19437.5
07/14/2016 06:29:50:  Epoch[35 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15644803 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0642s; samplesPerSecond = 19934.0
07/14/2016 06:29:50:  Epoch[35 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15553851 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 0.0638s; samplesPerSecond = 20057.4
07/14/2016 06:29:50:  Epoch[35 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.19766560 * 1280; EvalErrorPrediction = 0.08593750 * 1280; time = 0.0641s; samplesPerSecond = 19980.6
07/14/2016 06:29:51:  Epoch[35 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.21991892 * 1280; EvalErrorPrediction = 0.08906250 * 1280; time = 0.0652s; samplesPerSecond = 19620.2
07/14/2016 06:29:51:  Epoch[35 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.18715935 * 1280; EvalErrorPrediction = 0.08437500 * 1280; time = 0.0637s; samplesPerSecond = 20086.3
07/14/2016 06:29:51: Finished Epoch[35 of 50]: [Training] CrossEntropyWithSoftmax = 0.18030537 * 10000; EvalErrorPrediction = 0.07940000 * 10000; totalSamplesSeen = 350000; learningRatePerSample = 0.1; epochTime=0.629331s
07/14/2016 06:29:51: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714055016.501646\Speech_Simple@debug_gpu/models/simple.dnn.35'

07/14/2016 06:29:51: Starting Epoch 36: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 35: frames [350000..360000] (first sequence at sample 350000), data subset 0 of 1

07/14/2016 06:29:51: Starting minibatch loop.
07/14/2016 06:29:51:  Epoch[36 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.18170671 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0729s; samplesPerSecond = 17568.4
07/14/2016 06:29:51:  Epoch[36 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16017992 * 1280; EvalErrorPrediction = 0.06796875 * 1280; time = 0.0686s; samplesPerSecond = 18670.6
07/14/2016 06:29:51:  Epoch[36 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16765616 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0690s; samplesPerSecond = 18559.9
07/14/2016 06:29:51:  Epoch[36 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15750723 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0712s; samplesPerSecond = 17981.3
07/14/2016 06:29:51:  Epoch[36 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.18048148 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 0.0678s; samplesPerSecond = 18887.1
07/14/2016 06:29:51:  Epoch[36 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14256363 * 1280; EvalErrorPrediction = 0.06093750 * 1280; time = 0.0702s; samplesPerSecond = 18226.9
07/14/2016 06:29:51:  Epoch[36 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15442762 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0688s; samplesPerSecond = 18591.4
07/14/2016 06:29:51: Finished Epoch[36 of 50]: [Training] CrossEntropyWithSoftmax = 0.16341525 * 10000; EvalErrorPrediction = 0.07440000 * 10000; totalSamplesSeen = 360000; learningRatePerSample = 0.1; epochTime=0.661617s
07/14/2016 06:29:51: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714055016.501646\Speech_Simple@debug_gpu/models/simple.dnn.36'

07/14/2016 06:29:51: Starting Epoch 37: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 36: frames [360000..370000] (first sequence at sample 360000), data subset 0 of 1

07/14/2016 06:29:51: Starting minibatch loop.
07/14/2016 06:29:51:  Epoch[37 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15917722 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0656s; samplesPerSecond = 19497.6
07/14/2016 06:29:52:  Epoch[37 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16814622 * 1280; EvalErrorPrediction = 0.08671875 * 1280; time = 0.0636s; samplesPerSecond = 20130.2
07/14/2016 06:29:52:  Epoch[37 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16003413 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0627s; samplesPerSecond = 20416.3
07/14/2016 06:29:52:  Epoch[37 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15501971 * 1280; EvalErrorPrediction = 0.06718750 * 1280; time = 0.0643s; samplesPerSecond = 19912.3
07/14/2016 06:29:52:  Epoch[37 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15562119 * 1280; EvalErrorPrediction = 0.06562500 * 1280; time = 0.0646s; samplesPerSecond = 19825.3
07/14/2016 06:29:52:  Epoch[37 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14988656 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.0640s; samplesPerSecond = 20001.9
07/14/2016 06:29:52:  Epoch[37 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15406599 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0644s; samplesPerSecond = 19866.2
07/14/2016 06:29:52: Finished Epoch[37 of 50]: [Training] CrossEntropyWithSoftmax = 0.15919351 * 10000; EvalErrorPrediction = 0.07490000 * 10000; totalSamplesSeen = 370000; learningRatePerSample = 0.1; epochTime=0.617871s
07/14/2016 06:29:52: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714055016.501646\Speech_Simple@debug_gpu/models/simple.dnn.37'

07/14/2016 06:29:52: Starting Epoch 38: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 37: frames [370000..380000] (first sequence at sample 370000), data subset 0 of 1

07/14/2016 06:29:52: Starting minibatch loop.
07/14/2016 06:29:52:  Epoch[38 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15367353 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0859s; samplesPerSecond = 14900.0
07/14/2016 06:29:52:  Epoch[38 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16441548 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0852s; samplesPerSecond = 15027.9
07/14/2016 06:29:52:  Epoch[38 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15641241 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0741s; samplesPerSecond = 17279.6
07/14/2016 06:29:52:  Epoch[38 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15751104 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0711s; samplesPerSecond = 18000.5
07/14/2016 06:29:53:  Epoch[38 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14075346 * 1280; EvalErrorPrediction = 0.06562500 * 1280; time = 0.0712s; samplesPerSecond = 17982.1
07/14/2016 06:29:53:  Epoch[38 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.18122568 * 1280; EvalErrorPrediction = 0.08906250 * 1280; time = 0.0711s; samplesPerSecond = 18003.1
07/14/2016 06:29:53:  Epoch[38 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15811825 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0710s; samplesPerSecond = 18039.9
07/14/2016 06:29:53: Finished Epoch[38 of 50]: [Training] CrossEntropyWithSoftmax = 0.15896145 * 10000; EvalErrorPrediction = 0.07530000 * 10000; totalSamplesSeen = 380000; learningRatePerSample = 0.1; epochTime=0.703288s
07/14/2016 06:29:53: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714055016.501646\Speech_Simple@debug_gpu/models/simple.dnn.38'

07/14/2016 06:29:53: Starting Epoch 39: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 38: frames [380000..390000] (first sequence at sample 380000), data subset 0 of 1

07/14/2016 06:29:53: Starting minibatch loop.
07/14/2016 06:29:53:  Epoch[39 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.18427458 * 1280; EvalErrorPrediction = 0.09453125 * 1280; time = 0.0655s; samplesPerSecond = 19555.1
07/14/2016 06:29:53:  Epoch[39 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.13643181 * 1280; EvalErrorPrediction = 0.05937500 * 1280; time = 0.0621s; samplesPerSecond = 20599.3
07/14/2016 06:29:53:  Epoch[39 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17226083 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0624s; samplesPerSecond = 20516.1
07/14/2016 06:29:53:  Epoch[39 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.19652777 * 1280; EvalErrorPrediction = 0.08671875 * 1280; time = 0.0624s; samplesPerSecond = 20509.9
07/14/2016 06:29:53:  Epoch[39 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16720552 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0647s; samplesPerSecond = 19798.3
07/14/2016 06:29:53:  Epoch[39 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14424458 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 0.0646s; samplesPerSecond = 19826.5
07/14/2016 06:29:53:  Epoch[39 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.18201818 * 1280; EvalErrorPrediction = 0.08437500 * 1280; time = 0.0645s; samplesPerSecond = 19859.1
07/14/2016 06:29:53: Finished Epoch[39 of 50]: [Training] CrossEntropyWithSoftmax = 0.16832518 * 10000; EvalErrorPrediction = 0.07860000 * 10000; totalSamplesSeen = 390000; learningRatePerSample = 0.1; epochTime=0.613857s
07/14/2016 06:29:53: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714055016.501646\Speech_Simple@debug_gpu/models/simple.dnn.39'

07/14/2016 06:29:53: Starting Epoch 40: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 39: frames [390000..400000] (first sequence at sample 390000), data subset 0 of 1

07/14/2016 06:29:53: Starting minibatch loop.
07/14/2016 06:29:54:  Epoch[40 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17715715 * 1280; EvalErrorPrediction = 0.08671875 * 1280; time = 0.0669s; samplesPerSecond = 19129.3
07/14/2016 06:29:54:  Epoch[40 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14618925 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0621s; samplesPerSecond = 20622.9
07/14/2016 06:29:54:  Epoch[40 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15543664 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0629s; samplesPerSecond = 20357.9
07/14/2016 06:29:54:  Epoch[40 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.18061681 * 1280; EvalErrorPrediction = 0.08359375 * 1280; time = 0.0633s; samplesPerSecond = 20211.0
07/14/2016 06:29:54:  Epoch[40 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.17406306 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0627s; samplesPerSecond = 20421.2
07/14/2016 06:29:54:  Epoch[40 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16000032 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 0.0629s; samplesPerSecond = 20334.2
07/14/2016 06:29:54:  Epoch[40 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17971268 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0619s; samplesPerSecond = 20664.2
07/14/2016 06:29:54: Finished Epoch[40 of 50]: [Training] CrossEntropyWithSoftmax = 0.16703212 * 10000; EvalErrorPrediction = 0.07850000 * 10000; totalSamplesSeen = 400000; learningRatePerSample = 0.1; epochTime=0.610439s
07/14/2016 06:29:54: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714055016.501646\Speech_Simple@debug_gpu/models/simple.dnn.40'

07/14/2016 06:29:54: Starting Epoch 41: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 40: frames [400000..410000] (first sequence at sample 400000), data subset 0 of 1

07/14/2016 06:29:54: Starting minibatch loop.
07/14/2016 06:29:54:  Epoch[41 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16707519 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0840s; samplesPerSecond = 15236.1
07/14/2016 06:29:54:  Epoch[41 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.19174658 * 1280; EvalErrorPrediction = 0.09375000 * 1280; time = 0.0812s; samplesPerSecond = 15767.4
07/14/2016 06:29:54:  Epoch[41 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16827059 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0746s; samplesPerSecond = 17157.3
07/14/2016 06:29:54:  Epoch[41 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15983658 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0709s; samplesPerSecond = 18053.6
07/14/2016 06:29:54:  Epoch[41 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14744978 * 1280; EvalErrorPrediction = 0.06718750 * 1280; time = 0.0710s; samplesPerSecond = 18024.9
07/14/2016 06:29:55:  Epoch[41 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17100906 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 0.0708s; samplesPerSecond = 18087.5
07/14/2016 06:29:55:  Epoch[41 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14591980 * 1280; EvalErrorPrediction = 0.06796875 * 1280; time = 0.0707s; samplesPerSecond = 18092.9
07/14/2016 06:29:55: Finished Epoch[41 of 50]: [Training] CrossEntropyWithSoftmax = 0.16258346 * 10000; EvalErrorPrediction = 0.07600000 * 10000; totalSamplesSeen = 410000; learningRatePerSample = 0.1; epochTime=0.69687s
07/14/2016 06:29:55: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714055016.501646\Speech_Simple@debug_gpu/models/simple.dnn.41'

07/14/2016 06:29:55: Starting Epoch 42: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 41: frames [410000..420000] (first sequence at sample 410000), data subset 0 of 1

07/14/2016 06:29:55: Starting minibatch loop.
07/14/2016 06:29:55:  Epoch[42 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.18113455 * 1280; EvalErrorPrediction = 0.08515625 * 1280; time = 0.0665s; samplesPerSecond = 19255.4
07/14/2016 06:29:55:  Epoch[42 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15155247 * 1280; EvalErrorPrediction = 0.06718750 * 1280; time = 0.0628s; samplesPerSecond = 20366.0
07/14/2016 06:29:55:  Epoch[42 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15002353 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0634s; samplesPerSecond = 20175.6
07/14/2016 06:29:55:  Epoch[42 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16651502 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0647s; samplesPerSecond = 19773.5
07/14/2016 06:29:55:  Epoch[42 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15552535 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.0644s; samplesPerSecond = 19880.7
07/14/2016 06:29:55:  Epoch[42 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15147028 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0650s; samplesPerSecond = 19696.6
07/14/2016 06:29:55:  Epoch[42 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14123554 * 1280; EvalErrorPrediction = 0.06562500 * 1280; time = 0.0649s; samplesPerSecond = 19720.2
07/14/2016 06:29:55: Finished Epoch[42 of 50]: [Training] CrossEntropyWithSoftmax = 0.15764998 * 10000; EvalErrorPrediction = 0.07420000 * 10000; totalSamplesSeen = 420000; learningRatePerSample = 0.1; epochTime=0.621343s
07/14/2016 06:29:55: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714055016.501646\Speech_Simple@debug_gpu/models/simple.dnn.42'

07/14/2016 06:29:55: Starting Epoch 43: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 42: frames [420000..430000] (first sequence at sample 420000), data subset 0 of 1

07/14/2016 06:29:55: Starting minibatch loop.
07/14/2016 06:29:55:  Epoch[43 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16230578 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0657s; samplesPerSecond = 19476.0
07/14/2016 06:29:56:  Epoch[43 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15012784 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0646s; samplesPerSecond = 19822.8
07/14/2016 06:29:56:  Epoch[43 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16311612 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0641s; samplesPerSecond = 19982.8
07/14/2016 06:29:56:  Epoch[43 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.17134414 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0651s; samplesPerSecond = 19672.3
07/14/2016 06:29:56:  Epoch[43 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16546602 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0626s; samplesPerSecond = 20443.7
07/14/2016 06:29:56:  Epoch[43 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14619284 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0633s; samplesPerSecond = 20211.6
07/14/2016 06:29:56:  Epoch[43 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15290995 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 0.0649s; samplesPerSecond = 19735.7
07/14/2016 06:29:56: Finished Epoch[43 of 50]: [Training] CrossEntropyWithSoftmax = 0.15969183 * 10000; EvalErrorPrediction = 0.07440000 * 10000; totalSamplesSeen = 430000; learningRatePerSample = 0.1; epochTime=0.618791s
07/14/2016 06:29:56: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714055016.501646\Speech_Simple@debug_gpu/models/simple.dnn.43'

07/14/2016 06:29:56: Starting Epoch 44: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 43: frames [430000..440000] (first sequence at sample 430000), data subset 0 of 1

07/14/2016 06:29:56: Starting minibatch loop.
07/14/2016 06:29:56:  Epoch[44 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.14937947 * 1280; EvalErrorPrediction = 0.06875000 * 1280; time = 0.0650s; samplesPerSecond = 19698.4
07/14/2016 06:29:56:  Epoch[44 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15367455 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0625s; samplesPerSecond = 20465.9
07/14/2016 06:29:56:  Epoch[44 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15897200 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0621s; samplesPerSecond = 20610.3
07/14/2016 06:29:56:  Epoch[44 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15164909 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 0.0624s; samplesPerSecond = 20500.7
07/14/2016 06:29:56:  Epoch[44 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14775019 * 1280; EvalErrorPrediction = 0.06796875 * 1280; time = 0.0638s; samplesPerSecond = 20051.1
07/14/2016 06:29:56:  Epoch[44 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16762619 * 1280; EvalErrorPrediction = 0.08906250 * 1280; time = 0.0627s; samplesPerSecond = 20412.1
07/14/2016 06:29:56:  Epoch[44 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16773577 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0629s; samplesPerSecond = 20345.6
07/14/2016 06:29:57: Finished Epoch[44 of 50]: [Training] CrossEntropyWithSoftmax = 0.15810917 * 10000; EvalErrorPrediction = 0.07480000 * 10000; totalSamplesSeen = 440000; learningRatePerSample = 0.1; epochTime=0.610883s
07/14/2016 06:29:57: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714055016.501646\Speech_Simple@debug_gpu/models/simple.dnn.44'

07/14/2016 06:29:57: Starting Epoch 45: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 44: frames [440000..450000] (first sequence at sample 440000), data subset 0 of 1

07/14/2016 06:29:57: Starting minibatch loop.
07/14/2016 06:29:57:  Epoch[45 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17121557 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0647s; samplesPerSecond = 19781.5
07/14/2016 06:29:57:  Epoch[45 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16828314 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 0.0642s; samplesPerSecond = 19930.2
07/14/2016 06:29:57:  Epoch[45 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16996059 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0637s; samplesPerSecond = 20107.1
07/14/2016 06:29:57:  Epoch[45 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.17045069 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0618s; samplesPerSecond = 20702.9
07/14/2016 06:29:57:  Epoch[45 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15395145 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0618s; samplesPerSecond = 20720.4
07/14/2016 06:29:57:  Epoch[45 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16120186 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 0.0618s; samplesPerSecond = 20712.3
07/14/2016 06:29:57:  Epoch[45 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16864681 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0635s; samplesPerSecond = 20168.9
07/14/2016 06:29:57: Finished Epoch[45 of 50]: [Training] CrossEntropyWithSoftmax = 0.16358768 * 10000; EvalErrorPrediction = 0.07620000 * 10000; totalSamplesSeen = 450000; learningRatePerSample = 0.1; epochTime=0.610205s
07/14/2016 06:29:57: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714055016.501646\Speech_Simple@debug_gpu/models/simple.dnn.45'

07/14/2016 06:29:57: Starting Epoch 46: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 45: frames [450000..460000] (first sequence at sample 450000), data subset 0 of 1

07/14/2016 06:29:57: Starting minibatch loop.
07/14/2016 06:29:57:  Epoch[46 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16116022 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0846s; samplesPerSecond = 15135.6
07/14/2016 06:29:57:  Epoch[46 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15697554 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0821s; samplesPerSecond = 15586.0
07/14/2016 06:29:58:  Epoch[46 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17499006 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0739s; samplesPerSecond = 17329.4
07/14/2016 06:29:58:  Epoch[46 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15880270 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0709s; samplesPerSecond = 18059.2
07/14/2016 06:29:58:  Epoch[46 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15109291 * 1280; EvalErrorPrediction = 0.06875000 * 1280; time = 0.0710s; samplesPerSecond = 18022.1
07/14/2016 06:29:58:  Epoch[46 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16545782 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0708s; samplesPerSecond = 18068.4
07/14/2016 06:29:58:  Epoch[46 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15973282 * 1280; EvalErrorPrediction = 0.06562500 * 1280; time = 0.0710s; samplesPerSecond = 18020.3
07/14/2016 06:29:58: Finished Epoch[46 of 50]: [Training] CrossEntropyWithSoftmax = 0.16358628 * 10000; EvalErrorPrediction = 0.07530000 * 10000; totalSamplesSeen = 460000; learningRatePerSample = 0.1; epochTime=0.69846s
07/14/2016 06:29:58: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714055016.501646\Speech_Simple@debug_gpu/models/simple.dnn.46'

07/14/2016 06:29:58: Starting Epoch 47: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 46: frames [460000..470000] (first sequence at sample 460000), data subset 0 of 1

07/14/2016 06:29:58: Starting minibatch loop.
07/14/2016 06:29:58:  Epoch[47 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.18141196 * 1280; EvalErrorPrediction = 0.08437500 * 1280; time = 0.0881s; samplesPerSecond = 14535.4
07/14/2016 06:29:58:  Epoch[47 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15441945 * 1280; EvalErrorPrediction = 0.06640625 * 1280; time = 0.0854s; samplesPerSecond = 14990.9
07/14/2016 06:29:58:  Epoch[47 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15222993 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0728s; samplesPerSecond = 17583.6
07/14/2016 06:29:58:  Epoch[47 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16630101 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0709s; samplesPerSecond = 18057.4
07/14/2016 06:29:58:  Epoch[47 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15224843 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0711s; samplesPerSecond = 18002.8
07/14/2016 06:29:58:  Epoch[47 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17858076 * 1280; EvalErrorPrediction = 0.08437500 * 1280; time = 0.0704s; samplesPerSecond = 18177.4
07/14/2016 06:29:59:  Epoch[47 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14525757 * 1280; EvalErrorPrediction = 0.06406250 * 1280; time = 0.0712s; samplesPerSecond = 17974.2
07/14/2016 06:29:59: Finished Epoch[47 of 50]: [Training] CrossEntropyWithSoftmax = 0.16240488 * 10000; EvalErrorPrediction = 0.07610000 * 10000; totalSamplesSeen = 470000; learningRatePerSample = 0.1; epochTime=0.704799s
07/14/2016 06:29:59: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714055016.501646\Speech_Simple@debug_gpu/models/simple.dnn.47'

07/14/2016 06:29:59: Starting Epoch 48: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 47: frames [470000..480000] (first sequence at sample 470000), data subset 0 of 1

07/14/2016 06:29:59: Starting minibatch loop.
07/14/2016 06:29:59:  Epoch[48 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.13642299 * 1280; EvalErrorPrediction = 0.06484375 * 1280; time = 0.0667s; samplesPerSecond = 19197.9
07/14/2016 06:29:59:  Epoch[48 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16676848 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0640s; samplesPerSecond = 19999.1
07/14/2016 06:29:59:  Epoch[48 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14500847 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0638s; samplesPerSecond = 20070.6
07/14/2016 06:29:59:  Epoch[48 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15389767 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0633s; samplesPerSecond = 20227.9
07/14/2016 06:29:59:  Epoch[48 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16730480 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0627s; samplesPerSecond = 20412.1
07/14/2016 06:29:59:  Epoch[48 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16550035 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0628s; samplesPerSecond = 20379.2
07/14/2016 06:29:59:  Epoch[48 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17917118 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0628s; samplesPerSecond = 20387.4
07/14/2016 06:29:59: Finished Epoch[48 of 50]: [Training] CrossEntropyWithSoftmax = 0.15956562 * 10000; EvalErrorPrediction = 0.07430000 * 10000; totalSamplesSeen = 480000; learningRatePerSample = 0.1; epochTime=0.614173s
07/14/2016 06:29:59: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714055016.501646\Speech_Simple@debug_gpu/models/simple.dnn.48'

07/14/2016 06:29:59: Starting Epoch 49: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 48: frames [480000..490000] (first sequence at sample 480000), data subset 0 of 1

07/14/2016 06:29:59: Starting minibatch loop.
07/14/2016 06:29:59:  Epoch[49 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17444975 * 1280; EvalErrorPrediction = 0.08593750 * 1280; time = 0.0840s; samplesPerSecond = 15232.3
07/14/2016 06:30:00:  Epoch[49 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16647398 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0835s; samplesPerSecond = 15335.8
07/14/2016 06:30:00:  Epoch[49 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15077062 * 1280; EvalErrorPrediction = 0.06562500 * 1280; time = 0.0738s; samplesPerSecond = 17345.3
07/14/2016 06:30:00:  Epoch[49 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15211225 * 1280; EvalErrorPrediction = 0.06875000 * 1280; time = 0.0711s; samplesPerSecond = 17995.0
07/14/2016 06:30:00:  Epoch[49 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15672250 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0710s; samplesPerSecond = 18023.1
07/14/2016 06:30:00:  Epoch[49 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15014868 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0711s; samplesPerSecond = 17997.0
07/14/2016 06:30:00:  Epoch[49 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17297421 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0622s; samplesPerSecond = 20569.5
07/14/2016 06:30:00: Finished Epoch[49 of 50]: [Training] CrossEntropyWithSoftmax = 0.16187598 * 10000; EvalErrorPrediction = 0.07630000 * 10000; totalSamplesSeen = 490000; learningRatePerSample = 0.1; epochTime=0.684589s
07/14/2016 06:30:00: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714055016.501646\Speech_Simple@debug_gpu/models/simple.dnn.49'

07/14/2016 06:30:00: Starting Epoch 50: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 49: frames [490000..500000] (first sequence at sample 490000), data subset 0 of 1

07/14/2016 06:30:00: Starting minibatch loop.
07/14/2016 06:30:00:  Epoch[50 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15756435 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0860s; samplesPerSecond = 14878.4
07/14/2016 06:30:00:  Epoch[50 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14858251 * 1280; EvalErrorPrediction = 0.06093750 * 1280; time = 0.0869s; samplesPerSecond = 14725.3
07/14/2016 06:30:00:  Epoch[50 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15656338 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0732s; samplesPerSecond = 17488.7
07/14/2016 06:30:00:  Epoch[50 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14671822 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0707s; samplesPerSecond = 18091.9
07/14/2016 06:30:00:  Epoch[50 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16528430 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0711s; samplesPerSecond = 17996.0
07/14/2016 06:30:01:  Epoch[50 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15027752 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0711s; samplesPerSecond = 18012.4
07/14/2016 06:30:01:  Epoch[50 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15038519 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.0708s; samplesPerSecond = 18081.9
07/14/2016 06:30:01: Finished Epoch[50 of 50]: [Training] CrossEntropyWithSoftmax = 0.15902850 * 10000; EvalErrorPrediction = 0.07430000 * 10000; totalSamplesSeen = 500000; learningRatePerSample = 0.1; epochTime=0.704588s
07/14/2016 06:30:01: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714055016.501646\Speech_Simple@debug_gpu/models/simple.dnn'
07/14/2016 06:30:01: CNTKCommandTrainEnd: Simple_Demo

07/14/2016 06:30:01: Action "train" complete.


07/14/2016 06:30:01: ##############################################################################
07/14/2016 06:30:01: #                                                                            #
07/14/2016 06:30:01: # Action "write"                                                             #
07/14/2016 06:30:01: #                                                                            #
07/14/2016 06:30:01: ##############################################################################


Post-processing network...

7 roots:
	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
	EvalErrorPrediction = ErrorPrediction()
	InvStdOfFeatures = InvStdDev()
	MeanOfFeatures = Mean()
	PosteriorProb = Softmax()
	Prior = Mean()
	ScaledLogLikelihood = Minus()

Validating network. 25 nodes to process in pass 1.

Validating --> labels = InputValue() :  -> [2 x *1]
Validating --> W2 = LearnableParameter() :  -> [2 x 50]
Validating --> W1 = LearnableParameter() :  -> [50 x 50]
Validating --> W0 = LearnableParameter() :  -> [50 x 2]
Validating --> features = InputValue() :  -> [2 x *1]
Validating --> MeanOfFeatures = Mean (features) : [2 x *1] -> [2]
Validating --> InvStdOfFeatures = InvStdDev (features) : [2 x *1] -> [2]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [2 x *1], [2], [2] -> [2 x *1]
Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [50 x 2], [2 x *1] -> [50 x *1]
Validating --> B0 = LearnableParameter() :  -> [50 x 1]
Validating --> W0*features+B0 = Plus (W0*features, B0) : [50 x *1], [50 x 1] -> [50 x 1 x *1]
Validating --> H1 = Sigmoid (W0*features+B0) : [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> W1*H1 = Times (W1, H1) : [50 x 50], [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> B1 = LearnableParameter() :  -> [50 x 1]
Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [50 x 1 x *1], [50 x 1] -> [50 x 1 x *1]
Validating --> H2 = Sigmoid (W1*H1+B1) : [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> W2*H1 = Times (W2, H2) : [2 x 50], [50 x 1 x *1] -> [2 x 1 x *1]
Validating --> B2 = LearnableParameter() :  -> [2 x 1]
Validating --> HLast = Plus (W2*H1, B2) : [2 x 1 x *1], [2 x 1] -> [2 x 1 x *1]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [2 x *1], [2 x 1 x *1] -> [1]
Validating --> EvalErrorPrediction = ErrorPrediction (labels, HLast) : [2 x *1], [2 x 1 x *1] -> [1]
Validating --> PosteriorProb = Softmax (HLast) : [2 x 1 x *1] -> [2 x 1 x *1]
Validating --> Prior = Mean (labels) : [2 x *1] -> [2]
Validating --> LogOfPrior = Log (Prior) : [2] -> [2]
Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [2 x 1 x *1], [2] -> [2 x 1 x *1]

Validating network. 17 nodes to process in pass 2.


Validating network, final pass.



12 out of 25 nodes do not share the minibatch layout with the input data.

Post-processing network complete.



Allocating matrices for forward and/or backward propagation.

Memory Sharing Structure:

0000000000000000: {[B0 Gradient[50 x 1]] [B1 Gradient[50 x 1]] [B2 Gradient[2 x 1]] [CrossEntropyWithSoftmax Gradient[1]] [CrossEntropyWithSoftmax Value[1]] [EvalErrorPrediction Gradient[1]] [EvalErrorPrediction Value[1]] [H1 Gradient[50 x 1 x *1]] [H2 Gradient[50 x 1 x *1]] [HLast Gradient[2 x 1 x *1]] [InvStdOfFeatures Gradient[2]] [LogOfPrior Gradient[2]] [MVNormalizedFeatures Gradient[2 x *1]] [MeanOfFeatures Gradient[2]] [PosteriorProb Gradient[2 x 1 x *1]] [PosteriorProb Value[2 x 1 x *1]] [Prior Gradient[2]] [ScaledLogLikelihood Gradient[2 x 1 x *1]] [W0 Gradient[50 x 2]] [W0*features Gradient[50 x *1]] [W0*features+B0 Gradient[50 x 1 x *1]] [W1 Gradient[50 x 50]] [W1*H1 Gradient[50 x 1 x *1]] [W1*H1+B1 Gradient[50 x 1 x *1]] [W2 Gradient[2 x 50]] [W2*H1 Gradient[2 x 1 x *1]] [features Gradient[2 x *1]] [labels Gradient[2 x *1]] }
0000004A901C2B50: {[MVNormalizedFeatures Value[2 x *1]] }
0000004A901C2C20: {[W0*features Value[50 x *1]] }
0000004A901C2DC0: {[B1 Value[50 x 1]] }
0000004A901C2F60: {[labels Value[2 x *1]] }
0000004A901C3030: {[ScaledLogLikelihood Value[2 x 1 x *1]] }
0000004A901C3100: {[H2 Value[50 x 1 x *1]] }
0000004A901C3370: {[LogOfPrior Value[2]] }
0000004A901C3510: {[W2 Value[2 x 50]] }
0000004A901C35E0: {[W0*features+B0 Value[50 x 1 x *1]] }
0000004A901C36B0: {[InvStdOfFeatures Value[2]] }
0000004A901C3920: {[B0 Value[50 x 1]] }
0000004A901C39F0: {[B2 Value[2 x 1]] }
0000004A901C3AC0: {[W1 Value[50 x 50]] }
0000004A901C3C60: {[features Value[2 x *1]] }
0000004A901C3D30: {[W1*H1+B1 Value[50 x 1 x *1]] }
0000004A901C3E00: {[HLast Value[2 x 1 x *1]] }
0000004A901C3FA0: {[MeanOfFeatures Value[2]] }
0000004A901C4070: {[Prior Value[2]] }
0000004A901C4140: {[H1 Value[50 x 1 x *1]] }
0000004A901C4210: {[W2*H1 Value[2 x 1 x *1]] }
0000004A901C47C0: {[W1*H1 Value[50 x 1 x *1]] }
0000004A901C4A30: {[W0 Value[50 x 2]] }

Minibatch[0]: ActualMBSize = 603
Written to C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714055016.501646\Speech_Simple@debug_gpu/SimpleOutput*
Total Samples Evaluated = 603

07/14/2016 06:30:01: Action "write" complete.

07/14/2016 06:30:01: __COMPLETED__
=== Deleting last epoch data
==== Re-running from checkpoint
=== Running /cygdrive/c/jenkins/workspace/CNTK-Test-Windows-W1/x64/debug/cntk.exe configFile=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple/cntk.cntk currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714055016.501646\Speech_Simple@debug_gpu DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714055016.501646\Speech_Simple@debug_gpu DeviceId=0 timestamping=true makeMode=true
-------------------------------------------------------------------
Build info: 

		Built time: Jul 14 2016 05:11:35
		Last modified date: Thu Jul 14 03:20:47 2016
		Build type: Debug
		Build target: GPU
		With 1bit-SGD: no
		Math lib: mkl
		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.5
		CUB_PATH: C:\src\cub-1.4.1
		CUDNN_PATH: c:\NVIDIA\cudnn-4.0\cuda
		Build Branch: HEAD
		Build SHA1: 72bee394bf461e8f6f0feb593a8416c05f481957
		Built by svcphil on liana-08-w
		Build Path: c:\jenkins\workspace\CNTK-Build-Windows\Source\CNTK\
-------------------------------------------------------------------
Changed current directory to C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
07/14/2016 06:30:02: -------------------------------------------------------------------
07/14/2016 06:30:02: Build info: 

07/14/2016 06:30:02: 		Built time: Jul 14 2016 05:11:35
07/14/2016 06:30:02: 		Last modified date: Thu Jul 14 03:20:47 2016
07/14/2016 06:30:02: 		Build type: Debug
07/14/2016 06:30:02: 		Build target: GPU
07/14/2016 06:30:02: 		With 1bit-SGD: no
07/14/2016 06:30:02: 		Math lib: mkl
07/14/2016 06:30:02: 		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.5
07/14/2016 06:30:02: 		CUB_PATH: C:\src\cub-1.4.1
07/14/2016 06:30:02: 		CUDNN_PATH: c:\NVIDIA\cudnn-4.0\cuda
07/14/2016 06:30:02: 		Build Branch: HEAD
07/14/2016 06:30:02: 		Build SHA1: 72bee394bf461e8f6f0feb593a8416c05f481957
07/14/2016 06:30:02: 		Built by svcphil on liana-08-w
07/14/2016 06:30:02: 		Build Path: c:\jenkins\workspace\CNTK-Build-Windows\Source\CNTK\
07/14/2016 06:30:02: -------------------------------------------------------------------
07/14/2016 06:30:03: -------------------------------------------------------------------
07/14/2016 06:30:03: GPU info:

07/14/2016 06:30:03: 		Device[0]: cores = 2496; computeCapability = 5.2; type = "Quadro M4000"; memory = 8192 MB
07/14/2016 06:30:03: -------------------------------------------------------------------

07/14/2016 06:30:03: Running on cntk-muc01 at 2016/07/14 06:30:03
07/14/2016 06:30:03: Command line: 
C:\jenkins\workspace\CNTK-Test-Windows-W1\x64\debug\cntk.exe  configFile=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple/cntk.cntk  currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data  RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714055016.501646\Speech_Simple@debug_gpu  DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data  ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple  OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714055016.501646\Speech_Simple@debug_gpu  DeviceId=0  timestamping=true  makeMode=true



07/14/2016 06:30:03: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
07/14/2016 06:30:03: command=Simple_Demo:Simple_Demo_Output
DeviceNumber=-1
precision=float
modelPath=$RunDir$/models/simple.dnn
deviceId=$DeviceNumber$
outputNodeNames=ScaledLogLikelihood
traceLevel=1
Simple_Demo=[
    action=train
    SimpleNetworkBuilder=[
        layerSizes=2:50*2:2
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ErrorPrediction
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0 
        minibatchSize=128
        learningRatesPerSample=0.1
        momentumAsTimeConstant=2500
        dropoutRate=0.0
        maxEpochs=50
        keepCheckPointFiles = true
    ]
    reader=[
        readerType=CNTKTextFormatReader
        file=$DataDir$/SimpleDataTrain_cntk_text.txt
        input = [
            features=[
dim = 2      
                format = "dense"
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
]
Simple_Demo_Output=[
    action=write
    reader=[
        readerType=CNTKTextFormatReader
        file=$DataDir$/SimpleDataTest_cntk_text.txt
        input = [
            features=[
dim = 2 
                format = "dense" 
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
outputPath=$RunDir$/SimpleOutput    
]
currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714055016.501646\Speech_Simple@debug_gpu
DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple
OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714055016.501646\Speech_Simple@debug_gpu
DeviceId=0
timestamping=true
makeMode=true

07/14/2016 06:30:03: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<

07/14/2016 06:30:03: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
07/14/2016 06:30:03: command=Simple_Demo:Simple_Demo_Output
DeviceNumber=-1
precision=float
modelPath=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714055016.501646\Speech_Simple@debug_gpu/models/simple.dnn
deviceId=-1
outputNodeNames=ScaledLogLikelihood
traceLevel=1
Simple_Demo=[
    action=train
    SimpleNetworkBuilder=[
        layerSizes=2:50*2:2
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ErrorPrediction
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0 
        minibatchSize=128
        learningRatesPerSample=0.1
        momentumAsTimeConstant=2500
        dropoutRate=0.0
        maxEpochs=50
        keepCheckPointFiles = true
    ]
    reader=[
        readerType=CNTKTextFormatReader
        file=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/SimpleDataTrain_cntk_text.txt
        input = [
            features=[
dim = 2      
                format = "dense"
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
]
Simple_Demo_Output=[
    action=write
    reader=[
        readerType=CNTKTextFormatReader
        file=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/SimpleDataTest_cntk_text.txt
        input = [
            features=[
dim = 2 
                format = "dense" 
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
outputPath=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714055016.501646\Speech_Simple@debug_gpu/SimpleOutput    
]
currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714055016.501646\Speech_Simple@debug_gpu
DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple
OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714055016.501646\Speech_Simple@debug_gpu
DeviceId=0
timestamping=true
makeMode=true

07/14/2016 06:30:03: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<

07/14/2016 06:30:03: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
configparameters: cntk.cntk:command=Simple_Demo:Simple_Demo_Output
configparameters: cntk.cntk:ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple
configparameters: cntk.cntk:currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
configparameters: cntk.cntk:DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
configparameters: cntk.cntk:deviceId=0
configparameters: cntk.cntk:DeviceNumber=-1
configparameters: cntk.cntk:makeMode=true
configparameters: cntk.cntk:modelPath=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714055016.501646\Speech_Simple@debug_gpu/models/simple.dnn
configparameters: cntk.cntk:OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714055016.501646\Speech_Simple@debug_gpu
configparameters: cntk.cntk:outputNodeNames=ScaledLogLikelihood
configparameters: cntk.cntk:precision=float
configparameters: cntk.cntk:RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714055016.501646\Speech_Simple@debug_gpu
configparameters: cntk.cntk:Simple_Demo=[
    action=train
    SimpleNetworkBuilder=[
        layerSizes=2:50*2:2
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ErrorPrediction
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0 
        minibatchSize=128
        learningRatesPerSample=0.1
        momentumAsTimeConstant=2500
        dropoutRate=0.0
        maxEpochs=50
        keepCheckPointFiles = true
    ]
    reader=[
        readerType=CNTKTextFormatReader
        file=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/SimpleDataTrain_cntk_text.txt
        input = [
            features=[
dim = 2      
                format = "dense"
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
]

configparameters: cntk.cntk:Simple_Demo_Output=[
    action=write
    reader=[
        readerType=CNTKTextFormatReader
        file=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/SimpleDataTest_cntk_text.txt
        input = [
            features=[
dim = 2 
                format = "dense" 
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
outputPath=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714055016.501646\Speech_Simple@debug_gpu/SimpleOutput    
]

configparameters: cntk.cntk:timestamping=true
configparameters: cntk.cntk:traceLevel=1
07/14/2016 06:30:03: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
07/14/2016 06:30:03: Commands: Simple_Demo Simple_Demo_Output
07/14/2016 06:30:03: Precision = "float"
07/14/2016 06:30:03: CNTKModelPath: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714055016.501646\Speech_Simple@debug_gpu/models/simple.dnn
07/14/2016 06:30:03: CNTKCommandTrainInfo: Simple_Demo : 50
07/14/2016 06:30:03: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 50

07/14/2016 06:30:03: ##############################################################################
07/14/2016 06:30:03: #                                                                            #
07/14/2016 06:30:03: # Action "train"                                                             #
07/14/2016 06:30:03: #                                                                            #
07/14/2016 06:30:03: ##############################################################################

07/14/2016 06:30:03: CNTKCommandTrainBegin: Simple_Demo
SimpleNetworkBuilder Using GPU 0

07/14/2016 06:30:03: Starting from checkpoint. Loading network from 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714055016.501646\Speech_Simple@debug_gpu/models/simple.dnn.49'.

Post-processing network...

7 roots:
	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
	EvalErrorPrediction = ErrorPrediction()
	InvStdOfFeatures = InvStdDev()
	MeanOfFeatures = Mean()
	PosteriorProb = Softmax()
	Prior = Mean()
	ScaledLogLikelihood = Minus()

Validating network. 25 nodes to process in pass 1.

Validating --> labels = InputValue() :  -> [2 x *1]
Validating --> W2 = LearnableParameter() :  -> [2 x 50]
Validating --> W1 = LearnableParameter() :  -> [50 x 50]
Validating --> W0 = LearnableParameter() :  -> [50 x 2]
Validating --> features = InputValue() :  -> [2 x *1]
Validating --> MeanOfFeatures = Mean (features) : [2 x *1] -> [2]
Validating --> InvStdOfFeatures = InvStdDev (features) : [2 x *1] -> [2]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [2 x *1], [2], [2] -> [2 x *1]
Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [50 x 2], [2 x *1] -> [50 x *1]
Validating --> B0 = LearnableParameter() :  -> [50 x 1]
Validating --> W0*features+B0 = Plus (W0*features, B0) : [50 x *1], [50 x 1] -> [50 x 1 x *1]
Validating --> H1 = Sigmoid (W0*features+B0) : [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> W1*H1 = Times (W1, H1) : [50 x 50], [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> B1 = LearnableParameter() :  -> [50 x 1]
Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [50 x 1 x *1], [50 x 1] -> [50 x 1 x *1]
Validating --> H2 = Sigmoid (W1*H1+B1) : [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> W2*H1 = Times (W2, H2) : [2 x 50], [50 x 1 x *1] -> [2 x 1 x *1]
Validating --> B2 = LearnableParameter() :  -> [2 x 1]
Validating --> HLast = Plus (W2*H1, B2) : [2 x 1 x *1], [2 x 1] -> [2 x 1 x *1]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [2 x *1], [2 x 1 x *1] -> [1]
Validating --> EvalErrorPrediction = ErrorPrediction (labels, HLast) : [2 x *1], [2 x 1 x *1] -> [1]
Validating --> PosteriorProb = Softmax (HLast) : [2 x 1 x *1] -> [2 x 1 x *1]
Validating --> Prior = Mean (labels) : [2 x *1] -> [2]
Validating --> LogOfPrior = Log (Prior) : [2] -> [2]
Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [2 x 1 x *1], [2] -> [2 x 1 x *1]

Validating network. 17 nodes to process in pass 2.


Validating network, final pass.



12 out of 25 nodes do not share the minibatch layout with the input data.

Post-processing network complete.

07/14/2016 06:30:04: Loaded model with 25 nodes on GPU 0.

07/14/2016 06:30:04: Training criterion node(s):
07/14/2016 06:30:04: 	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax

07/14/2016 06:30:04: Evaluation criterion node(s):

07/14/2016 06:30:04: 	EvalErrorPrediction = ErrorPrediction


Allocating matrices for forward and/or backward propagation.

Memory Sharing Structure:

0000000000000000: {[EvalErrorPrediction Gradient[1]] [InvStdOfFeatures Gradient[2]] [LogOfPrior Gradient[2]] [MVNormalizedFeatures Gradient[2 x *1]] [MeanOfFeatures Gradient[2]] [PosteriorProb Gradient[2 x 1 x *1]] [PosteriorProb Value[2 x 1 x *1]] [Prior Gradient[2]] [ScaledLogLikelihood Gradient[2 x 1 x *1]] [features Gradient[2 x *1]] [labels Gradient[2 x *1]] }
0000006E87A460A0: {[B0 Value[50 x 1]] }
0000006E87B566D0: {[B1 Value[50 x 1]] }
0000006E96E24250: {[W0 Value[50 x 2]] }
0000006E96E243F0: {[CrossEntropyWithSoftmax Gradient[1]] }
0000006E96E244C0: {[W2*H1 Gradient[2 x 1 x *1]] }
0000006E96E24590: {[W2 Value[2 x 50]] }
0000006E96E24730: {[B2 Gradient[2 x 1]] }
0000006E96E248D0: {[MVNormalizedFeatures Value[2 x *1]] }
0000006E96E24C10: {[EvalErrorPrediction Value[1]] }
0000006E96E24DB0: {[CrossEntropyWithSoftmax Value[1]] }
0000006E96E24E80: {[B1 Gradient[50 x 1]] [H2 Gradient[50 x 1 x *1]] [HLast Gradient[2 x 1 x *1]] }
0000006E96E24F50: {[W0*features Value[50 x *1]] }
0000006E96E25020: {[W0 Gradient[50 x 2]] [W0*features+B0 Value[50 x 1 x *1]] }
0000006E96E251C0: {[LogOfPrior Value[2]] }
0000006E96E25290: {[labels Value[2 x *1]] }
0000006E96E25360: {[Prior Value[2]] }
0000006E96E25430: {[InvStdOfFeatures Value[2]] }
0000006E96E25500: {[W1 Value[50 x 50]] }
0000006E96E255D0: {[ScaledLogLikelihood Value[2 x 1 x *1]] }
0000006E96E256A0: {[W0*features+B0 Gradient[50 x 1 x *1]] [W1*H1 Value[50 x 1 x *1]] }
0000006E96E25770: {[W1 Gradient[50 x 50]] [W1*H1+B1 Value[50 x 1 x *1]] }
0000006E96E25840: {[B2 Value[2 x 1]] }
0000006E96E25910: {[MeanOfFeatures Value[2]] }
0000006E96E259E0: {[H1 Value[50 x 1 x *1]] [W0*features Gradient[50 x *1]] }
0000006E96E25AB0: {[H2 Value[50 x 1 x *1]] [W1*H1 Gradient[50 x 1 x *1]] }
0000006E96E25B80: {[features Value[2 x *1]] }
0000006E96E25C50: {[B0 Gradient[50 x 1]] [H1 Gradient[50 x 1 x *1]] [W1*H1+B1 Gradient[50 x 1 x *1]] [W2*H1 Value[2 x 1 x *1]] }
0000006E96E25D20: {[HLast Value[2 x 1 x *1]] [W2 Gradient[2 x 50]] }

07/14/2016 06:30:04: No PreCompute nodes found, skipping PreCompute step.

07/14/2016 06:30:04: Starting Epoch 50: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 49: frames [490000..500000] (first sequence at sample 490000), data subset 0 of 1

07/14/2016 06:30:04: Starting minibatch loop.
07/14/2016 06:30:04:  Epoch[50 of 50]-Minibatch[   1-  10, 0.00000000000003%]: CrossEntropyWithSoftmax = 0.15756435 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.4543s; samplesPerSecond = 2817.5
07/14/2016 06:30:04:  Epoch[50 of 50]-Minibatch[  11-  20, 0.00000000000006%]: CrossEntropyWithSoftmax = 0.14858251 * 1280; EvalErrorPrediction = 0.06093750 * 1280; time = 0.0694s; samplesPerSecond = 18432.9
07/14/2016 06:30:04:  Epoch[50 of 50]-Minibatch[  21-  30, 0.00000000000008%]: CrossEntropyWithSoftmax = 0.15656338 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0696s; samplesPerSecond = 18380.2
07/14/2016 06:30:04:  Epoch[50 of 50]-Minibatch[  31-  40, 0.00000000000011%]: CrossEntropyWithSoftmax = 0.14671822 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0699s; samplesPerSecond = 18309.3
07/14/2016 06:30:04:  Epoch[50 of 50]-Minibatch[  41-  50, 0.00000000000014%]: CrossEntropyWithSoftmax = 0.16528430 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0699s; samplesPerSecond = 18306.6
07/14/2016 06:30:05:  Epoch[50 of 50]-Minibatch[  51-  60, 0.00000000000017%]: CrossEntropyWithSoftmax = 0.15027752 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0699s; samplesPerSecond = 18305.6
07/14/2016 06:30:05:  Epoch[50 of 50]-Minibatch[  61-  70, 0.00000000000019%]: CrossEntropyWithSoftmax = 0.15038519 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.0705s; samplesPerSecond = 18143.9
07/14/2016 06:30:05: Finished Epoch[50 of 50]: [Training] CrossEntropyWithSoftmax = 0.15902850 * 10000; EvalErrorPrediction = 0.07430000 * 10000; totalSamplesSeen = 500000; learningRatePerSample = 0.1; epochTime=1.16983s
07/14/2016 06:30:05: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714055016.501646\Speech_Simple@debug_gpu/models/simple.dnn'
07/14/2016 06:30:05: CNTKCommandTrainEnd: Simple_Demo

07/14/2016 06:30:05: Action "train" complete.


07/14/2016 06:30:05: ##############################################################################
07/14/2016 06:30:05: #                                                                            #
07/14/2016 06:30:05: # Action "write"                                                             #
07/14/2016 06:30:05: #                                                                            #
07/14/2016 06:30:05: ##############################################################################


Post-processing network...

7 roots:
	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
	EvalErrorPrediction = ErrorPrediction()
	InvStdOfFeatures = InvStdDev()
	MeanOfFeatures = Mean()
	PosteriorProb = Softmax()
	Prior = Mean()
	ScaledLogLikelihood = Minus()

Validating network. 25 nodes to process in pass 1.

Validating --> labels = InputValue() :  -> [2 x *2]
Validating --> W2 = LearnableParameter() :  -> [2 x 50]
Validating --> W1 = LearnableParameter() :  -> [50 x 50]
Validating --> W0 = LearnableParameter() :  -> [50 x 2]
Validating --> features = InputValue() :  -> [2 x *2]
Validating --> MeanOfFeatures = Mean (features) : [2 x *2] -> [2]
Validating --> InvStdOfFeatures = InvStdDev (features) : [2 x *2] -> [2]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [2 x *2], [2], [2] -> [2 x *2]
Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [50 x 2], [2 x *2] -> [50 x *2]
Validating --> B0 = LearnableParameter() :  -> [50 x 1]
Validating --> W0*features+B0 = Plus (W0*features, B0) : [50 x *2], [50 x 1] -> [50 x 1 x *2]
Validating --> H1 = Sigmoid (W0*features+B0) : [50 x 1 x *2] -> [50 x 1 x *2]
Validating --> W1*H1 = Times (W1, H1) : [50 x 50], [50 x 1 x *2] -> [50 x 1 x *2]
Validating --> B1 = LearnableParameter() :  -> [50 x 1]
Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [50 x 1 x *2], [50 x 1] -> [50 x 1 x *2]
Validating --> H2 = Sigmoid (W1*H1+B1) : [50 x 1 x *2] -> [50 x 1 x *2]
Validating --> W2*H1 = Times (W2, H2) : [2 x 50], [50 x 1 x *2] -> [2 x 1 x *2]
Validating --> B2 = LearnableParameter() :  -> [2 x 1]
Validating --> HLast = Plus (W2*H1, B2) : [2 x 1 x *2], [2 x 1] -> [2 x 1 x *2]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [2 x *2], [2 x 1 x *2] -> [1]
Validating --> EvalErrorPrediction = ErrorPrediction (labels, HLast) : [2 x *2], [2 x 1 x *2] -> [1]
Validating --> PosteriorProb = Softmax (HLast) : [2 x 1 x *2] -> [2 x 1 x *2]
Validating --> Prior = Mean (labels) : [2 x *2] -> [2]
Validating --> LogOfPrior = Log (Prior) : [2] -> [2]
Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [2 x 1 x *2], [2] -> [2 x 1 x *2]

Validating network. 17 nodes to process in pass 2.


Validating network, final pass.



12 out of 25 nodes do not share the minibatch layout with the input data.

Post-processing network complete.



Allocating matrices for forward and/or backward propagation.

Memory Sharing Structure:

0000000000000000: {[B0 Gradient[50 x 1]] [B1 Gradient[50 x 1]] [B2 Gradient[2 x 1]] [CrossEntropyWithSoftmax Gradient[1]] [CrossEntropyWithSoftmax Value[1]] [EvalErrorPrediction Gradient[1]] [EvalErrorPrediction Value[1]] [H1 Gradient[50 x 1 x *2]] [H2 Gradient[50 x 1 x *2]] [HLast Gradient[2 x 1 x *2]] [InvStdOfFeatures Gradient[2]] [LogOfPrior Gradient[2]] [MVNormalizedFeatures Gradient[2 x *2]] [MeanOfFeatures Gradient[2]] [PosteriorProb Gradient[2 x 1 x *2]] [PosteriorProb Value[2 x 1 x *2]] [Prior Gradient[2]] [ScaledLogLikelihood Gradient[2 x 1 x *2]] [W0 Gradient[50 x 2]] [W0*features Gradient[50 x *2]] [W0*features+B0 Gradient[50 x 1 x *2]] [W1 Gradient[50 x 50]] [W1*H1 Gradient[50 x 1 x *2]] [W1*H1+B1 Gradient[50 x 1 x *2]] [W2 Gradient[2 x 50]] [W2*H1 Gradient[2 x 1 x *2]] [features Gradient[2 x *2]] [labels Gradient[2 x *2]] }
0000006E96B53A70: {[W2*H1 Value[2 x 1 x *2]] }
0000006E96B53DB0: {[HLast Value[2 x 1 x *2]] }
0000006E96B53E80: {[InvStdOfFeatures Value[2]] }
0000006E96B53F50: {[W1 Value[50 x 50]] }
0000006E96B54020: {[MeanOfFeatures Value[2]] }
0000006E96B540F0: {[ScaledLogLikelihood Value[2 x 1 x *2]] }
0000006E96B54290: {[MVNormalizedFeatures Value[2 x *2]] }
0000006E96B54360: {[W0*features+B0 Value[50 x 1 x *2]] }
0000006E96B54430: {[W1*H1+B1 Value[50 x 1 x *2]] }
0000006E96B54910: {[H1 Value[50 x 1 x *2]] }
0000006E96B549E0: {[Prior Value[2]] }
0000006E96B54AB0: {[H2 Value[50 x 1 x *2]] }
0000006E96B54DF0: {[B2 Value[2 x 1]] }
0000006E96B54EC0: {[B0 Value[50 x 1]] }
0000006E96B54F90: {[features Value[2 x *2]] }
0000006E96B55130: {[LogOfPrior Value[2]] }
0000006E96B55200: {[W0*features Value[50 x *2]] }
0000006E96B55540: {[B1 Value[50 x 1]] }
0000006E96B55610: {[W0 Value[50 x 2]] }
0000006E96B556E0: {[labels Value[2 x *2]] }
0000006E96B55880: {[W2 Value[2 x 50]] }
0000006E96B55950: {[W1*H1 Value[50 x 1 x *2]] }

Minibatch[0]: ActualMBSize = 603
Written to C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714055016.501646\Speech_Simple@debug_gpu/SimpleOutput*
Total Samples Evaluated = 603

07/14/2016 06:30:05: Action "write" complete.

07/14/2016 06:30:05: __COMPLETED__
CPU info:
    CPU Model Name: Intel(R) Xeon(R) CPU E5-2630 v2 @ 2.60GHz
    Hardware threads: 24
    Total Memory: 264172964 kB
-------------------------------------------------------------------
Looking for data in: /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Examples/Image/Miscellaneous/CIFAR-10
Looking for data in: /home/philly/data/CNTKTestData
Copying test data to local directory
Done copying data
Starting cntk run
=== Running /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/build/gpu/release/bin/cntk configFile=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Examples/Image/Miscellaneous/CIFAR-10/06_RegressionSimple/../../../../../../../Examples/Image/Miscellaneous/CIFAR-10/06_RegressionSimple.cntk currentDirectory=/tmp/cntk-test-20161004183114.547828/Examples/Image/Miscellaneous/CIFAR-10_06_RegressionSimple@release_cpu RunDir=/tmp/cntk-test-20161004183114.547828/Examples/Image/Miscellaneous/CIFAR-10_06_RegressionSimple@release_cpu DataDir=/tmp/cntk-test-20161004183114.547828/Examples/Image/Miscellaneous/CIFAR-10_06_RegressionSimple@release_cpu ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Examples/Image/Miscellaneous/CIFAR-10/06_RegressionSimple/../../../../../../../Examples/Image/Miscellaneous/CIFAR-10 OutputDir=/tmp/cntk-test-20161004183114.547828/Examples/Image/Miscellaneous/CIFAR-10_06_RegressionSimple@release_cpu DeviceId=-1 timestamping=true [command=TrainConvNet:Test] forceDeterministicAlgorithms=true stderr=-
CNTK 1.7.2+ (HEAD 5bb8b8, Oct  4 2016 13:17:20) on localhost at 2016/10/04 18:31:15

/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/build/gpu/release/bin/cntk  configFile=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Examples/Image/Miscellaneous/CIFAR-10/06_RegressionSimple/../../../../../../../Examples/Image/Miscellaneous/CIFAR-10/06_RegressionSimple.cntk  currentDirectory=/tmp/cntk-test-20161004183114.547828/Examples/Image/Miscellaneous/CIFAR-10_06_RegressionSimple@release_cpu  RunDir=/tmp/cntk-test-20161004183114.547828/Examples/Image/Miscellaneous/CIFAR-10_06_RegressionSimple@release_cpu  DataDir=/tmp/cntk-test-20161004183114.547828/Examples/Image/Miscellaneous/CIFAR-10_06_RegressionSimple@release_cpu  ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Examples/Image/Miscellaneous/CIFAR-10/06_RegressionSimple/../../../../../../../Examples/Image/Miscellaneous/CIFAR-10  OutputDir=/tmp/cntk-test-20161004183114.547828/Examples/Image/Miscellaneous/CIFAR-10_06_RegressionSimple@release_cpu  DeviceId=-1  timestamping=true  [command=TrainConvNet:Test]  forceDeterministicAlgorithms=true  stderr=-
Changed current directory to /tmp/cntk-test-20161004183114.547828/Examples/Image/Miscellaneous/CIFAR-10_06_RegressionSimple@release_cpu
10/04/2016 18:31:15: Redirecting stderr to file -_TrainConvNet_Test.log
10/04/2016 18:31:15: -------------------------------------------------------------------
10/04/2016 18:31:15: Build info: 

10/04/2016 18:31:15: 		Built time: Oct  4 2016 13:17:20
10/04/2016 18:31:15: 		Last modified date: Tue Oct  4 11:58:41 2016
10/04/2016 18:31:15: 		Build type: release
10/04/2016 18:31:15: 		Build target: GPU
10/04/2016 18:31:15: 		With 1bit-SGD: no
10/04/2016 18:31:15: 		Math lib: mkl
10/04/2016 18:31:15: 		CUDA_PATH: /usr/local/cuda-7.5
10/04/2016 18:31:15: 		CUB_PATH: /usr/local/cub-1.4.1
10/04/2016 18:31:15: 		CUDNN_PATH: /usr/local/cudnn-5.1
10/04/2016 18:31:15: 		Build Branch: HEAD
10/04/2016 18:31:15: 		Build SHA1: 5bb8b8090cc5baa3b5586cee5a6611cb1aa88d97
10/04/2016 18:31:15: 		Built by philly on 9b019bb2e014
10/04/2016 18:31:15: 		Build Path: /home/philly/jenkins/workspace/CNTK-Build-Linux
10/04/2016 18:31:15: -------------------------------------------------------------------
10/04/2016 18:31:16: -------------------------------------------------------------------
10/04/2016 18:31:16: GPU info:

10/04/2016 18:31:16: 		Device[0]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3071 MB
10/04/2016 18:31:16: 		Device[1]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3071 MB
10/04/2016 18:31:16: 		Device[2]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3071 MB
10/04/2016 18:31:16: 		Device[3]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3071 MB
10/04/2016 18:31:16: -------------------------------------------------------------------

Configuration After Processing and Variable Resolution:

configparameters: 06_RegressionSimple.cntk:command=TrainConvNet:Test
configparameters: 06_RegressionSimple.cntk:configDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Examples/Image/Miscellaneous/CIFAR-10/06_RegressionSimple/../../../../../../../Examples/Image/Miscellaneous/CIFAR-10
configparameters: 06_RegressionSimple.cntk:currentDirectory=/tmp/cntk-test-20161004183114.547828/Examples/Image/Miscellaneous/CIFAR-10_06_RegressionSimple@release_cpu
configparameters: 06_RegressionSimple.cntk:dataDir=/tmp/cntk-test-20161004183114.547828/Examples/Image/Miscellaneous/CIFAR-10_06_RegressionSimple@release_cpu
configparameters: 06_RegressionSimple.cntk:deviceId=-1
configparameters: 06_RegressionSimple.cntk:forceDeterministicAlgorithms=true
configparameters: 06_RegressionSimple.cntk:makeMode=false
configparameters: 06_RegressionSimple.cntk:modelDir=/tmp/cntk-test-20161004183114.547828/Examples/Image/Miscellaneous/CIFAR-10_06_RegressionSimple@release_cpu/Models
configparameters: 06_RegressionSimple.cntk:modelPath=/tmp/cntk-test-20161004183114.547828/Examples/Image/Miscellaneous/CIFAR-10_06_RegressionSimple@release_cpu/Models/06_RegressionSimple.cmf
configparameters: 06_RegressionSimple.cntk:outputDir=/tmp/cntk-test-20161004183114.547828/Examples/Image/Miscellaneous/CIFAR-10_06_RegressionSimple@release_cpu
configparameters: 06_RegressionSimple.cntk:rootDir=.
configparameters: 06_RegressionSimple.cntk:RunDir=/tmp/cntk-test-20161004183114.547828/Examples/Image/Miscellaneous/CIFAR-10_06_RegressionSimple@release_cpu
configparameters: 06_RegressionSimple.cntk:stderr=-
configparameters: 06_RegressionSimple.cntk:Test={
    action = "test"
    minibatchSize = 512
    outputNodeNames = (ol, regrLabels, rmse)
    outputPath = "/tmp/cntk-test-20161004183114.547828/Examples/Image/Miscellaneous/CIFAR-10_06_RegressionSimple@release_cpu/06_RegressionSimple"
    reader = {
        verbosity = 0 ; randomize = false
        deserializers = ({
            type = "ImageDeserializer" ; module = "ImageReader"
            file = "/tmp/cntk-test-20161004183114.547828/Examples/Image/Miscellaneous/CIFAR-10_06_RegressionSimple@release_cpu/cifar-10-batches-py/test_map.txt"
            input = {
                features = { transforms = (
                    { type = "Scale" ; width = 32 ; height = 32 ; channels = 3 ; interpolations = "linear" } :
                    { type = "Transpose" }
                )}
                ignored = { labelDim = 10 }
            }
        } : {
            type = "CNTKTextFormatDeserializer" ; module = "CNTKTextFormatReader"
            file = "/tmp/cntk-test-20161004183114.547828/Examples/Image/Miscellaneous/CIFAR-10_06_RegressionSimple@release_cpu/cifar-10-batches-py/test_regrLabels.txt"
            input = {
                regrLabels = { dim = 3 ; format = "dense" }
            }
        })
    }
}

configparameters: 06_RegressionSimple.cntk:timestamping=true
configparameters: 06_RegressionSimple.cntk:traceLevel=1
configparameters: 06_RegressionSimple.cntk:TrainConvNet={
    action = "train"
    BrainScriptNetworkBuilder = [
        imageShape = 32:32:3
        featScale = Constant(1/256)
        labelDim = 3
        model (features) = {
            featNorm = Scale(features, featScale)
            h1 = LinearLayer {100,      init="gaussian", initValueScale=1.5} (featNorm)
            ol = LinearLayer {labelDim, init="gaussian", initValueScale=1.5} (h1)
        }.ol
        features = Input {imageShape}
        regrLabels = Input {labelDim}
        ol = model (features)
        sqerr = SquareError (regrLabels, ol)
        rmse = Sqrt (Constant(1/labelDim).* sqerr)
        featureNodes    = (features)
        labelNodes      = (regrLabels)
        criterionNodes  = (rmse)
        evaluationNodes = (rmse)
        OutputNodes     = (ol)
    ]
    SGD = {
        epochSize = 0
        maxEpochs = 2
        minibatchSize = 128
        learningRatesPerSample = 0.0005
        momentumAsTimeConstant = 1024
        firstMBsToShowResult = 5 ; numMBsToShowResult = 50
    }
    reader = {
        verbosity = 0 ; randomize = true
        deserializers = ({
            type = "ImageDeserializer" ; module = "ImageReader"
            file = "/tmp/cntk-test-20161004183114.547828/Examples/Image/Miscellaneous/CIFAR-10_06_RegressionSimple@release_cpu/cifar-10-batches-py/train_map.txt"
            input = {
                features = { transforms = (
                    { type = "Scale" ; width = 32 ; height = 32 ; channels = 3 ; interpolations = "linear" } :
                    { type = "Transpose" }
                )}
                ignored = { labelDim = 10 }
            }
        } : {
            type = "CNTKTextFormatDeserializer" ; module = "CNTKTextFormatReader"
            file = "/tmp/cntk-test-20161004183114.547828/Examples/Image/Miscellaneous/CIFAR-10_06_RegressionSimple@release_cpu/cifar-10-batches-py/train_regrLabels.txt"
            input = {
                regrLabels = { dim = 3 ; format = "dense" }
            }
        })
    }
}

configparameters: 06_RegressionSimple.cntk:Write={
    action = "write"
    minibatchSize = 1
    outputNodeNames = (ol, regrLabels, rmse)
    outputPath = "/tmp/cntk-test-20161004183114.547828/Examples/Image/Miscellaneous/CIFAR-10_06_RegressionSimple@release_cpu/06_RegressionSimple"
    reader = {
        verbosity = 0 ; randomize = false
        deserializers = ({
            type = "ImageDeserializer" ; module = "ImageReader"
            file = "/tmp/cntk-test-20161004183114.547828/Examples/Image/Miscellaneous/CIFAR-10_06_RegressionSimple@release_cpu/cifar-10-batches-py/test_map.txt"
            input = {
                features = { transforms = (
                    { type = "Scale" ; width = 32 ; height = 32 ; channels = 3 ; interpolations = "linear" } :
                    { type = "Transpose" }
                )}
                ignored = { labelDim = 10 }
            }
        } : {
            type = "CNTKTextFormatDeserializer" ; module = "CNTKTextFormatReader"
            file = "/tmp/cntk-test-20161004183114.547828/Examples/Image/Miscellaneous/CIFAR-10_06_RegressionSimple@release_cpu/cifar-10-batches-py/test_regrLabels.txt"
            input = {
                regrLabels = { dim = 3 ; format = "dense" }
            }
        })
    }
}

10/04/2016 18:31:16: Commands: TrainConvNet Test
10/04/2016 18:31:16: precision = "float"
10/04/2016 18:31:16: WARNING: forceDeterministcAlgorithms flag is specified. Using 1 CPU thread for processing.

10/04/2016 18:31:16: ##############################################################################
10/04/2016 18:31:16: #                                                                            #
10/04/2016 18:31:16: # TrainConvNet command (train action)                                        #
10/04/2016 18:31:16: #                                                                            #
10/04/2016 18:31:16: ##############################################################################

10/04/2016 18:31:16: 
Creating virgin network.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[3 x 0] as gaussian later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[100 x 0] as gaussian later when dimensions are fully known.

Post-processing network...

1 roots:
	rmse = Sqrt()

Validating network. 16 nodes to process in pass 1.

Validating --> rmse.z.ElementTimesArgs[0] = LearnableParameter() :  -> [1 x 1]
Validating --> regrLabels = InputValue() :  -> [3 x *]
Validating --> ol.ol.W = LearnableParameter() :  -> [3 x 0]
Validating --> ol.h1.W = LearnableParameter() :  -> [100 x 0]
Validating --> features = InputValue() :  -> [32 x 32 x 3 x *]
Validating --> featScale = LearnableParameter() :  -> [1 x 1]
Validating --> ol.featNorm = ElementTimes (features, featScale) : [32 x 32 x 3 x *], [1 x 1] -> [32 x 32 x 3 x *]
Node 'ol.h1.W' (LearnableParameter operation) operation: Tensor shape was inferred as [100 x 32 x 32 x 3].
Node 'ol.h1.W' (LearnableParameter operation): Initializing Parameter[100 x 32 x 32 x 3] <- gaussian(seed=2, init dims=[100 x 3072], range=0.005413*1.500000, onCPU=true.
)Validating --> ol.h1.PlusArgs[0] = Times (ol.h1.W, ol.featNorm) : [100 x 32 x 32 x 3], [32 x 32 x 3 x *] -> [100 x *]
Validating --> ol.h1.b = LearnableParameter() :  -> [100]
Validating --> ol.h1 = Plus (ol.h1.PlusArgs[0], ol.h1.b) : [100 x *], [100] -> [100 x *]
Node 'ol.ol.W' (LearnableParameter operation) operation: Tensor shape was inferred as [3 x 100].
Node 'ol.ol.W' (LearnableParameter operation): Initializing Parameter[3 x 100] <- gaussian(seed=1, init dims=[3 x 100], range=0.030000*1.500000, onCPU=true.
)Validating --> ol.ol.PlusArgs[0] = Times (ol.ol.W, ol.h1) : [3 x 100], [100 x *] -> [3 x *]
Validating --> ol.ol.b = LearnableParameter() :  -> [3]
Validating --> ol = Plus (ol.ol.PlusArgs[0], ol.ol.b) : [3 x *], [3] -> [3 x *]
Validating --> sqerr = SquareError (regrLabels, ol) : [3 x *], [3 x *] -> [1]
Validating --> rmse.z = ElementTimes (rmse.z.ElementTimesArgs[0], sqerr) : [1 x 1], [1] -> [1 x 1]
Validating --> rmse = Sqrt (rmse.z) : [1 x 1] -> [1 x 1]

Validating network. 8 nodes to process in pass 2.


Validating network, final pass.




Post-processing network complete.

10/04/2016 18:31:16: 
Model has 16 nodes. Using CPU.

10/04/2016 18:31:16: Training criterion:   rmse = Sqrt


Allocating matrices for forward and/or backward propagation.

Memory Sharing: Out of 27 matrices, 13 are shared as 6, and 14 are not shared.

	{ ol.h1 : [100 x *]
	  ol.h1.W : [100 x 32 x 32 x 3] (gradient) }
	{ ol.h1.PlusArgs[0] : [100 x *] (gradient)
	  ol.ol.PlusArgs[0] : [3 x *] }
	{ ol : [3 x *]
	  ol.ol.W : [3 x 100] (gradient) }
	{ ol.ol.b : [3] (gradient)
	  sqerr : [1] }
	{ ol.h1.b : [100] (gradient)
	  ol.ol.PlusArgs[0] : [3 x *] (gradient) }
	{ ol : [3 x *] (gradient)
	  ol.h1 : [100 x *] (gradient)
	  rmse.z : [1 x 1] }


10/04/2016 18:31:16: Training 307603 parameters in 4 out of 4 parameter tensors and 11 nodes with gradient:

10/04/2016 18:31:16: 	Node 'ol.h1.W' (LearnableParameter operation) : [100 x 32 x 32 x 3]
10/04/2016 18:31:16: 	Node 'ol.h1.b' (LearnableParameter operation) : [100]
10/04/2016 18:31:16: 	Node 'ol.ol.W' (LearnableParameter operation) : [3 x 100]
10/04/2016 18:31:16: 	Node 'ol.ol.b' (LearnableParameter operation) : [3]

10/04/2016 18:31:16: No PreCompute nodes found, or all already computed. Skipping pre-computation step.

10/04/2016 18:31:16: Starting Epoch 1: learning rate per sample = 0.000500  effective momentum = 0.882497  momentum as time constant = 1024.0 samples

10/04/2016 18:31:16: Starting minibatch loop.
10/04/2016 18:31:17:  Epoch[ 1 of 2]-Minibatch[   1-   1]: rmse = 0.04111860 * 128; time = 0.3085s; samplesPerSecond = 414.9
10/04/2016 18:31:17:  Epoch[ 1 of 2]-Minibatch[   2-   2]: rmse = 0.03852484 * 128; time = 0.0142s; samplesPerSecond = 9021.1
10/04/2016 18:31:17:  Epoch[ 1 of 2]-Minibatch[   3-   3]: rmse = 0.03659149 * 128; time = 0.0128s; samplesPerSecond = 10018.8
10/04/2016 18:31:17:  Epoch[ 1 of 2]-Minibatch[   4-   4]: rmse = 0.03164160 * 128; time = 0.0130s; samplesPerSecond = 9869.7
10/04/2016 18:31:17:  Epoch[ 1 of 2]-Minibatch[   5-   5]: rmse = 0.02515954 * 128; time = 0.0139s; samplesPerSecond = 9221.2
10/04/2016 18:31:17:  Epoch[ 1 of 2]-Minibatch[   6-  50]: rmse = 0.00579823 * 5760; time = 0.6165s; samplesPerSecond = 9342.4
10/04/2016 18:31:18:  Epoch[ 1 of 2]-Minibatch[  51- 100]: rmse = 0.00148286 * 6400; time = 0.7076s; samplesPerSecond = 9044.4
10/04/2016 18:31:19:  Epoch[ 1 of 2]-Minibatch[ 101- 150]: rmse = 0.00089940 * 6400; time = 0.7144s; samplesPerSecond = 8958.3
10/04/2016 18:31:19:  Epoch[ 1 of 2]-Minibatch[ 151- 200]: rmse = 0.00063363 * 6400; time = 0.6745s; samplesPerSecond = 9487.9
10/04/2016 18:31:20:  Epoch[ 1 of 2]-Minibatch[ 201- 250]: rmse = 0.00054030 * 6400; time = 0.6833s; samplesPerSecond = 9366.3
10/04/2016 18:31:21:  Epoch[ 1 of 2]-Minibatch[ 251- 300]: rmse = 0.00050786 * 6400; time = 0.7476s; samplesPerSecond = 8561.1
10/04/2016 18:31:22:  Epoch[ 1 of 2]-Minibatch[ 301- 350]: rmse = 0.00048295 * 6400; time = 0.7766s; samplesPerSecond = 8240.9
10/04/2016 18:31:22: Finished Epoch[ 1 of 2]: [Training] rmse = 0.00174322 * 50000; totalSamplesSeen = 50000; learningRatePerSample = 0.00050000002; epochTime=5.99185s
10/04/2016 18:31:22: SGD: Saving checkpoint model '/tmp/cntk-test-20161004183114.547828/Examples/Image/Miscellaneous/CIFAR-10_06_RegressionSimple@release_cpu/Models/06_RegressionSimple.cmf.1'

10/04/2016 18:31:22: Starting Epoch 2: learning rate per sample = 0.000500  effective momentum = 0.882497  momentum as time constant = 1024.0 samples

10/04/2016 18:31:22: Starting minibatch loop.
10/04/2016 18:31:22:  Epoch[ 2 of 2]-Minibatch[   1-   1, 0.29%]: rmse = 0.00060821 * 128; time = 0.0786s; samplesPerSecond = 1627.8
10/04/2016 18:31:22:  Epoch[ 2 of 2]-Minibatch[   2-   2, 0.57%]: rmse = 0.00070442 * 128; time = 0.0130s; samplesPerSecond = 9859.8
10/04/2016 18:31:22:  Epoch[ 2 of 2]-Minibatch[   3-   3, 0.86%]: rmse = 0.00049610 * 128; time = 0.0130s; samplesPerSecond = 9823.5
10/04/2016 18:31:22:  Epoch[ 2 of 2]-Minibatch[   4-   4, 1.14%]: rmse = 0.00092890 * 128; time = 0.0132s; samplesPerSecond = 9681.6
10/04/2016 18:31:22:  Epoch[ 2 of 2]-Minibatch[   5-   5, 1.43%]: rmse = 0.00058175 * 128; time = 0.0133s; samplesPerSecond = 9613.9
10/04/2016 18:31:23:  Epoch[ 2 of 2]-Minibatch[   6-  50, 14.29%]: rmse = 0.00050198 * 5760; time = 0.6231s; samplesPerSecond = 9243.8
10/04/2016 18:31:24:  Epoch[ 2 of 2]-Minibatch[  51- 100, 28.57%]: rmse = 0.00043366 * 6400; time = 0.6840s; samplesPerSecond = 9356.7
10/04/2016 18:31:24:  Epoch[ 2 of 2]-Minibatch[ 101- 150, 42.86%]: rmse = 0.00041920 * 6400; time = 0.6804s; samplesPerSecond = 9406.2
10/04/2016 18:31:25:  Epoch[ 2 of 2]-Minibatch[ 151- 200, 57.14%]: rmse = 0.00041836 * 6400; time = 0.6733s; samplesPerSecond = 9505.8
10/04/2016 18:31:26:  Epoch[ 2 of 2]-Minibatch[ 201- 250, 71.43%]: rmse = 0.00041610 * 6400; time = 0.6796s; samplesPerSecond = 9418.0
10/04/2016 18:31:26:  Epoch[ 2 of 2]-Minibatch[ 251- 300, 85.71%]: rmse = 0.00040250 * 6400; time = 0.7406s; samplesPerSecond = 8641.4
10/04/2016 18:31:27:  Epoch[ 2 of 2]-Minibatch[ 301- 350, 100.00%]: rmse = 0.00039970 * 6400; time = 0.8186s; samplesPerSecond = 7817.8
10/04/2016 18:31:28: Finished Epoch[ 2 of 2]: [Training] rmse = 0.00042659 * 50000; totalSamplesSeen = 100000; learningRatePerSample = 0.00050000002; epochTime=5.69642s
10/04/2016 18:31:28: SGD: Saving checkpoint model '/tmp/cntk-test-20161004183114.547828/Examples/Image/Miscellaneous/CIFAR-10_06_RegressionSimple@release_cpu/Models/06_RegressionSimple.cmf'

10/04/2016 18:31:28: Action "train" complete.


10/04/2016 18:31:28: ##############################################################################
10/04/2016 18:31:28: #                                                                            #
10/04/2016 18:31:28: # Test command (test action)                                                 #
10/04/2016 18:31:28: #                                                                            #
10/04/2016 18:31:28: ##############################################################################


Post-processing network...

1 roots:
	rmse = Sqrt()

Validating network. 16 nodes to process in pass 1.

Validating --> rmse.z.ElementTimesArgs[0] = LearnableParameter() :  -> [1 x 1]
Validating --> regrLabels = InputValue() :  -> [3 x *1]
Validating --> ol.ol.W = LearnableParameter() :  -> [3 x 100]
Validating --> ol.h1.W = LearnableParameter() :  -> [100 x 32 x 32 x 3]
Validating --> features = InputValue() :  -> [32 x 32 x 3 x *1]
Validating --> featScale = LearnableParameter() :  -> [1 x 1]
Validating --> ol.featNorm = ElementTimes (features, featScale) : [32 x 32 x 3 x *1], [1 x 1] -> [32 x 32 x 3 x *1]
Validating --> ol.h1.PlusArgs[0] = Times (ol.h1.W, ol.featNorm) : [100 x 32 x 32 x 3], [32 x 32 x 3 x *1] -> [100 x *1]
Validating --> ol.h1.b = LearnableParameter() :  -> [100]
Validating --> ol.h1 = Plus (ol.h1.PlusArgs[0], ol.h1.b) : [100 x *1], [100] -> [100 x *1]
Validating --> ol.ol.PlusArgs[0] = Times (ol.ol.W, ol.h1) : [3 x 100], [100 x *1] -> [3 x *1]
Validating --> ol.ol.b = LearnableParameter() :  -> [3]
Validating --> ol = Plus (ol.ol.PlusArgs[0], ol.ol.b) : [3 x *1], [3] -> [3 x *1]
Validating --> sqerr = SquareError (regrLabels, ol) : [3 x *1], [3 x *1] -> [1]
Validating --> rmse.z = ElementTimes (rmse.z.ElementTimesArgs[0], sqerr) : [1 x 1], [1] -> [1 x 1]
Validating --> rmse = Sqrt (rmse.z) : [1 x 1] -> [1 x 1]

Validating network. 8 nodes to process in pass 2.


Validating network, final pass.




Post-processing network complete.

evalNodeNames are not specified, using all the default evalnodes and training criterion nodes.


Allocating matrices for forward and/or backward propagation.

Memory Sharing: Out of 16 matrices, 0 are shared as 0, and 16 are not shared.


10/04/2016 18:31:29: Minibatch[1-20]: rmse = 0.00104491 * 10000
10/04/2016 18:31:29: Final Results: Minibatch[1-20]: rmse = 0.00104491 * 10000

10/04/2016 18:31:29: Action "test" complete.

10/04/2016 18:31:29: __COMPLETED__
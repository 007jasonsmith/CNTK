CPU info:
    CPU Model Name: Intel(R) Xeon(R) CPU E5-2630 v2 @ 2.60GHz
    Hardware threads: 24
    Total Memory: 268381192 kB
-------------------------------------------------------------------
=== Running /cygdrive/c/jenkins/workspace/CNTK-Test-Windows-W1/x64/debug/cntk.exe configFile=C:\jenkins\workspace\CNTK-Test-Windows-W1\Examples\Text\PennTreebank\Config/rnn.cntk currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Examples\Text\PennTreebank\Data RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714054332.293697\Examples\Text\PennTreebank_RNN@debug_cpu DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Examples\Text\PennTreebank\Data ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Examples\Text\PennTreebank\Config OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714054332.293697\Examples\Text\PennTreebank_RNN@debug_cpu DeviceId=-1 timestamping=true initOnCPUOnly=true command=writeWordAndClassInfo:train:test train=[SGD=[maxEpochs=3]] train=[epochSize=2048]] test=[SGD=[maxEpochs=3]] train=[epochSize=2048]]
-------------------------------------------------------------------
Build info: 

		Built time: Jul 14 2016 05:11:35
		Last modified date: Thu Jul 14 03:20:47 2016
		Build type: Debug
		Build target: GPU
		With 1bit-SGD: no
		Math lib: mkl
		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.5
		CUB_PATH: C:\src\cub-1.4.1
		CUDNN_PATH: c:\NVIDIA\cudnn-4.0\cuda
		Build Branch: HEAD
		Build SHA1: 72bee394bf461e8f6f0feb593a8416c05f481957
		Built by svcphil on liana-08-w
		Build Path: c:\jenkins\workspace\CNTK-Build-Windows\Source\CNTK\
-------------------------------------------------------------------
Changed current directory to C:\jenkins\workspace\CNTK-Test-Windows-W1\Examples\Text\PennTreebank\Data
07/14/2016 05:50:57: -------------------------------------------------------------------
07/14/2016 05:50:57: Build info: 

07/14/2016 05:50:57: 		Built time: Jul 14 2016 05:11:35
07/14/2016 05:50:57: 		Last modified date: Thu Jul 14 03:20:47 2016
07/14/2016 05:50:57: 		Build type: Debug
07/14/2016 05:50:57: 		Build target: GPU
07/14/2016 05:50:57: 		With 1bit-SGD: no
07/14/2016 05:50:57: 		Math lib: mkl
07/14/2016 05:50:57: 		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.5
07/14/2016 05:50:57: 		CUB_PATH: C:\src\cub-1.4.1
07/14/2016 05:50:57: 		CUDNN_PATH: c:\NVIDIA\cudnn-4.0\cuda
07/14/2016 05:50:57: 		Build Branch: HEAD
07/14/2016 05:50:57: 		Build SHA1: 72bee394bf461e8f6f0feb593a8416c05f481957
07/14/2016 05:50:57: 		Built by svcphil on liana-08-w
07/14/2016 05:50:57: 		Build Path: c:\jenkins\workspace\CNTK-Build-Windows\Source\CNTK\
07/14/2016 05:50:57: -------------------------------------------------------------------
07/14/2016 05:50:59: -------------------------------------------------------------------
07/14/2016 05:50:59: GPU info:

07/14/2016 05:50:59: 		Device[0]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3072 MB
07/14/2016 05:50:59: 		Device[1]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3072 MB
07/14/2016 05:50:59: 		Device[2]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3072 MB
07/14/2016 05:50:59: -------------------------------------------------------------------

07/14/2016 05:50:59: Running on DPHAIM-25 at 2016/07/14 05:50:59
07/14/2016 05:50:59: Command line: 
C:\jenkins\workspace\CNTK-Test-Windows-W1\x64\debug\cntk.exe  configFile=C:\jenkins\workspace\CNTK-Test-Windows-W1\Examples\Text\PennTreebank\Config/rnn.cntk  currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Examples\Text\PennTreebank\Data  RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714054332.293697\Examples\Text\PennTreebank_RNN@debug_cpu  DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Examples\Text\PennTreebank\Data  ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Examples\Text\PennTreebank\Config  OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714054332.293697\Examples\Text\PennTreebank_RNN@debug_cpu  DeviceId=-1  timestamping=true  initOnCPUOnly=true  command=writeWordAndClassInfo:train:test  train=[SGD=[maxEpochs=3]]  train=[epochSize=2048]]  test=[SGD=[maxEpochs=3]]  train=[epochSize=2048]]



07/14/2016 05:50:59: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
07/14/2016 05:50:59: RootDir = ".."
ConfigDir = "$RootDir$/Config"
DataDir   = "$RootDir$/Data"
OutputDir = "$RootDir$/Output"
ModelDir  = "$OutputDir$/Models"
deviceId = "auto"
command = writeWordAndClassInfo:train:test:write
precision  = "float"
traceLevel = 1
modelPath  = "$ModelDir$/rnn.dnn"
numCPUThreads = 1
confVocabSize = 10000
confClassSize = 50
trainFile = "ptb.train.txt"
validFile = "ptb.valid.txt"
testFile  = "ptb.test.txt"
writeWordAndClassInfo = [
    action = "writeWordAndClass"
    inputFile = "$DataDir$/$trainFile$"
    beginSequence = "</s>"
    endSequence   = "</s>"
    outputVocabFile = "$ModelDir$/vocab.txt"
    outputWord2Cls  = "$ModelDir$/word2cls.txt"
    outputCls2Index = "$ModelDir$/cls2idx.txt"
    vocabSize = "$confVocabSize$"
    nbrClass = "$confClassSize$"
    cutoff = 0
    printValues = true
]
train = [
    action = "train"
    traceLevel = 1
epochSize = 0               
    SimpleNetworkBuilder = [
rnnType = "CLASSLSTM"   
recurrentLayer = 1      
        trainingCriterion = "classCrossEntropyWithSoftmax"
        evalCriterion     = "classCrossEntropyWithSoftmax"
        initValueScale = 6.0
        uniformInit = true
        layerSizes = "$confVocabSize$:150:200:10000"
defaultHiddenActivity = 0.1 
        addPrior = false
        addDropoutNodes = false
        applyMeanVarNorm = false
lookupTableOrder = 1        
        vocabSize = "$confVocabSize$"
        nbrClass  = "$confClassSize$"
    ]
    SGD = [
        minibatchSize = 128:256:512
        learningRatesPerSample = 0.1
        momentumPerMB = 0
        gradientClippingWithTruncation = true
        clippingThresholdPerSample = 15.0
        maxEpochs = 16
        numMBsToShowResult = 100
        gradUpdateType = "none"
        loadBestModel = true
        dropoutRate = 0.0
        AutoAdjust = [
            autoAdjustLR = "adjustAfterEpoch"
            reduceLearnRateIfImproveLessThan = 0.001
            continueReduce = false
            increaseLearnRateIfImproveMoreThan = 1000000000
            learnRateDecreaseFactor = 0.5
            learnRateIncreaseFactor = 1.382
            numMiniBatch4LRSearch = 100
            numPrevLearnRates = 5
            numBestSearchEpoch = 1
        ]
    ]
    reader = [
        readerType = "LMSequenceReader"
randomize = "none"              
nbruttsineachrecurrentiter = 0  
cacheBlockSize = 2000000        
        wordclass = "$ModelDir$/vocab.txt"
        wfile = "$OutputDir$/sequenceSentence.bin"
        wsize = 256
        wrecords = 1000
        windowSize = "$confVocabSize$"
        file = "$DataDir$/$trainFile$"
        features = [
            dim = 0
            sectionType = "data"
        ]
        labelIn = [
            dim = 1
            labelType = "Category"
            beginSequence = "</s>"
            endSequence = "</s>"
            labelDim = "$confVocabSize$"
            labelMappingFile = "$OutputDir$/sentenceLabels.txt"
            elementSize = 4
            sectionType = "labels"
            mapping = [
                wrecords = 11                
                elementSize = 10
                sectionType = "labelMapping"
            ]
            category = [
                dim = 11
                sectionType = "categoryLabels"
            ]
        ]
        labels = [
            dim = 1
            labelType = "NextWord"
            beginSequence = "O"
            endSequence = "O"
            labelDim = "$confVocabSize$"
            labelMappingFile = "$OutputDir$/sentenceLabels.out.txt"
            elementSize = 4
            sectionType = "labels"
            mapping = [
                wrecords = 3
                elementSize = 10
                sectionType = "labelMapping"
            ]
            category = [
                dim = 3
                sectionType = categoryLabels
            ]
        ]
    ]
    cvReader = [
        readerType = "LMSequenceReader"
        randomize = "none"
nbruttsineachrecurrentiter = 0  
cacheBlockSize = 2000000        
        wordclass = "$ModelDir$/vocab.txt"
        wfile = "$OutputDir$/sequenceSentence.valid.bin"
        wsize = 256
        wrecords = 1000
        windowSize = "$confVocabSize$"
        file = "$DataDir$/$validFile$"
        features = [
            dim = 0
            sectionType = "data"
        ]
        labelIn = [
            dim = 1
            labelDim = "$confVocabSize$"
            labelMappingFile = "$OutputDir$/sentenceLabels.out.txt"
            labelType = "Category"
            beginSequence = "</s>"
            endSequence = "</s>"
            elementSize = 4
            sectionType = "labels"
            mapping = [
                wrecords = 11
                elementSize = 10
                sectionType = "labelMapping"
            ]
            category = [
                dim = 11
                sectionType = "categoryLabels"
            ]
        ]
        labels = [
            dim = 1
            labelType = "NextWord"
            beginSequence = "O"
            endSequence = "O"
            labelDim = "$confVocabSize$"
            labelMappingFile = "$OutputDir$/sentenceLabels.out.txt"
            elementSize = 4
            sectionType = "labels"
            mapping = [
                wrecords = 3
                elementSize = 10
                sectionType = "labelMapping"
            ]
            category = [
                dim = 3
                sectionType = "categoryLabels"
            ]
        ]
    ]
]
test = [
    action = "eval"
minibatchSize = 8192                
    traceLevel = 1
    epochSize = 0
    reader = [
        readerType = "LMSequenceReader"
        randomize = "none"
nbruttsineachrecurrentiter = 0  
cacheBlockSize = 2000000        
        wordclass = "$ModelDir$/vocab.txt"
        wfile = "$OutputDir$/sequenceSentence.bin"
        wsize = 256
        wrecords = 1000
        windowSize = "$confVocabSize$"
        file = "$DataDir$/$testFile$"
        features = [
            dim = 0
            sectionType = "data"
        ]
        labelIn = [
            dim = 1
            labelDim = "$confVocabSize$"
            labelMappingFile = "$OutputDir$/sentenceLabels.txt"
            labelType = "Category"
            beginSequence = "</s>"
            endSequence = "</s>"
            elementSize = 4
            sectionType = "labels"
            mapping = [
                wrecords = 11
                elementSize = 10
                sectionType = "labelMapping"
            ]
            category = [
                dim = 11
                sectionType = "categoryLabels"
            ]
        ]
        labels = [
            dim = 1
            labelType = "NextWord"
            beginSequence = "O"
            endSequence = "O"
            labelDim = "$confVocabSize$"
            labelMappingFile = "$OutputDir$/sentenceLabels.out.txt"
            elementSize = 4
            sectionType = "labels"
            mapping = [
                wrecords = 3
                elementSize = 10
                sectionType = "labelMapping"
            ]
            category = [
                dim = 3
                sectionType = "categoryLabels"
            ]
        ]
    ]
]
write = [
    action = "write"
    outputPath = "$OutputDir$/Write"
outputNodeNames = TrainNodeClassBasedCrossEntropy 
    format = [
sequencePrologue = "log P(W)="    
        type = "real"
    ]
minibatchSize = 8192                
    traceLevel = 1
    epochSize = 0
    reader = [
        readerType = "LMSequenceReader"
randomize = "none"              
nbruttsineachrecurrentiter = 1  
cacheBlockSize = 1              
        wordclass = "$ModelDir$/vocab.txt"
        wfile = "$OutputDir$/sequenceSentence.bin"
        wsize = 256
        wrecords = 1000
        windowSize = "$confVocabSize$"
        file = "$DataDir$/$testFile$"
        features = [
            dim = 0
            sectionType = "data"
        ]
        labelIn = [
            dim = 1
            labelDim = "$confVocabSize$"
            labelMappingFile = "$OutputDir$/sentenceLabels.txt"
            labelType = "Category"
            beginSequence = "</s>"
            endSequence = "</s>"
            elementSize = 4
            sectionType = "labels"
            mapping = [
                wrecords = 11
                elementSize = 10
                sectionType = "labelMapping"
            ]
            category = [
                dim = 11
                sectionType = "categoryLabels"
            ]
        ]
        labels = [
            dim = 1
            labelType = "NextWord"
            beginSequence = "O"
            endSequence = "O"
            labelDim = "$confVocabSize$"
            labelMappingFile = "$OutputDir$/sentenceLabels.out.txt"
            elementSize = 4
            sectionType = "labels"
            mapping = [
                wrecords = 3
                elementSize = 10
                sectionType = "labelMapping"
            ]
            category = [
                dim = 3
                sectionType = "categoryLabels"
            ]
        ]
    ]
]
currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Examples\Text\PennTreebank\Data
RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714054332.293697\Examples\Text\PennTreebank_RNN@debug_cpu
DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Examples\Text\PennTreebank\Data
ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Examples\Text\PennTreebank\Config
OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714054332.293697\Examples\Text\PennTreebank_RNN@debug_cpu
DeviceId=-1
timestamping=true
initOnCPUOnly=true
command=writeWordAndClassInfo:train:test
train=[SGD=[maxEpochs=3]]
train=[epochSize=2048]]
test=[SGD=[maxEpochs=3]]
train=[epochSize=2048]]

07/14/2016 05:50:59: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<

07/14/2016 05:50:59: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
07/14/2016 05:50:59: RootDir = ".."
ConfigDir = "../Config"
DataDir   = "../Data"
OutputDir = "../Output"
ModelDir  = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714054332.293697\Examples\Text\PennTreebank_RNN@debug_cpu/Models"
deviceId = "auto"
command = writeWordAndClassInfo:train:test:write
precision  = "float"
traceLevel = 1
modelPath  = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714054332.293697\Examples\Text\PennTreebank_RNN@debug_cpu/Models/rnn.dnn"
numCPUThreads = 1
confVocabSize = 10000
confClassSize = 50
trainFile = "ptb.train.txt"
validFile = "ptb.valid.txt"
testFile  = "ptb.test.txt"
writeWordAndClassInfo = [
    action = "writeWordAndClass"
    inputFile = "C:\jenkins\workspace\CNTK-Test-Windows-W1\Examples\Text\PennTreebank\Data/ptb.train.txt"
    beginSequence = "</s>"
    endSequence   = "</s>"
    outputVocabFile = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714054332.293697\Examples\Text\PennTreebank_RNN@debug_cpu/Models/vocab.txt"
    outputWord2Cls  = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714054332.293697\Examples\Text\PennTreebank_RNN@debug_cpu/Models/word2cls.txt"
    outputCls2Index = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714054332.293697\Examples\Text\PennTreebank_RNN@debug_cpu/Models/cls2idx.txt"
    vocabSize = "10000"
    nbrClass = "50"
    cutoff = 0
    printValues = true
]
train = [
    action = "train"
    traceLevel = 1
epochSize = 0               
    SimpleNetworkBuilder = [
rnnType = "CLASSLSTM"   
recurrentLayer = 1      
        trainingCriterion = "classCrossEntropyWithSoftmax"
        evalCriterion     = "classCrossEntropyWithSoftmax"
        initValueScale = 6.0
        uniformInit = true
        layerSizes = "10000:150:200:10000"
defaultHiddenActivity = 0.1 
        addPrior = false
        addDropoutNodes = false
        applyMeanVarNorm = false
lookupTableOrder = 1        
        vocabSize = "10000"
        nbrClass  = "50"
    ]
    SGD = [
        minibatchSize = 128:256:512
        learningRatesPerSample = 0.1
        momentumPerMB = 0
        gradientClippingWithTruncation = true
        clippingThresholdPerSample = 15.0
        maxEpochs = 16
        numMBsToShowResult = 100
        gradUpdateType = "none"
        loadBestModel = true
        dropoutRate = 0.0
        AutoAdjust = [
            autoAdjustLR = "adjustAfterEpoch"
            reduceLearnRateIfImproveLessThan = 0.001
            continueReduce = false
            increaseLearnRateIfImproveMoreThan = 1000000000
            learnRateDecreaseFactor = 0.5
            learnRateIncreaseFactor = 1.382
            numMiniBatch4LRSearch = 100
            numPrevLearnRates = 5
            numBestSearchEpoch = 1
        ]
    ]
    reader = [
        readerType = "LMSequenceReader"
randomize = "none"              
nbruttsineachrecurrentiter = 0  
cacheBlockSize = 2000000        
        wordclass = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714054332.293697\Examples\Text\PennTreebank_RNN@debug_cpu/Models/vocab.txt"
        wfile = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714054332.293697\Examples\Text\PennTreebank_RNN@debug_cpu/sequenceSentence.bin"
        wsize = 256
        wrecords = 1000
        windowSize = "10000"
        file = "C:\jenkins\workspace\CNTK-Test-Windows-W1\Examples\Text\PennTreebank\Data/ptb.train.txt"
        features = [
            dim = 0
            sectionType = "data"
        ]
        labelIn = [
            dim = 1
            labelType = "Category"
            beginSequence = "</s>"
            endSequence = "</s>"
            labelDim = "10000"
            labelMappingFile = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714054332.293697\Examples\Text\PennTreebank_RNN@debug_cpu/sentenceLabels.txt"
            elementSize = 4
            sectionType = "labels"
            mapping = [
                wrecords = 11                
                elementSize = 10
                sectionType = "labelMapping"
            ]
            category = [
                dim = 11
                sectionType = "categoryLabels"
            ]
        ]
        labels = [
            dim = 1
            labelType = "NextWord"
            beginSequence = "O"
            endSequence = "O"
            labelDim = "10000"
            labelMappingFile = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714054332.293697\Examples\Text\PennTreebank_RNN@debug_cpu/sentenceLabels.out.txt"
            elementSize = 4
            sectionType = "labels"
            mapping = [
                wrecords = 3
                elementSize = 10
                sectionType = "labelMapping"
            ]
            category = [
                dim = 3
                sectionType = categoryLabels
            ]
        ]
    ]
    cvReader = [
        readerType = "LMSequenceReader"
        randomize = "none"
nbruttsineachrecurrentiter = 0  
cacheBlockSize = 2000000        
        wordclass = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714054332.293697\Examples\Text\PennTreebank_RNN@debug_cpu/Models/vocab.txt"
        wfile = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714054332.293697\Examples\Text\PennTreebank_RNN@debug_cpu/sequenceSentence.valid.bin"
        wsize = 256
        wrecords = 1000
        windowSize = "10000"
        file = "C:\jenkins\workspace\CNTK-Test-Windows-W1\Examples\Text\PennTreebank\Data/ptb.valid.txt"
        features = [
            dim = 0
            sectionType = "data"
        ]
        labelIn = [
            dim = 1
            labelDim = "10000"
            labelMappingFile = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714054332.293697\Examples\Text\PennTreebank_RNN@debug_cpu/sentenceLabels.out.txt"
            labelType = "Category"
            beginSequence = "</s>"
            endSequence = "</s>"
            elementSize = 4
            sectionType = "labels"
            mapping = [
                wrecords = 11
                elementSize = 10
                sectionType = "labelMapping"
            ]
            category = [
                dim = 11
                sectionType = "categoryLabels"
            ]
        ]
        labels = [
            dim = 1
            labelType = "NextWord"
            beginSequence = "O"
            endSequence = "O"
            labelDim = "10000"
            labelMappingFile = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714054332.293697\Examples\Text\PennTreebank_RNN@debug_cpu/sentenceLabels.out.txt"
            elementSize = 4
            sectionType = "labels"
            mapping = [
                wrecords = 3
                elementSize = 10
                sectionType = "labelMapping"
            ]
            category = [
                dim = 3
                sectionType = "categoryLabels"
            ]
        ]
    ]
]
test = [
    action = "eval"
minibatchSize = 8192                
    traceLevel = 1
    epochSize = 0
    reader = [
        readerType = "LMSequenceReader"
        randomize = "none"
nbruttsineachrecurrentiter = 0  
cacheBlockSize = 2000000        
        wordclass = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714054332.293697\Examples\Text\PennTreebank_RNN@debug_cpu/Models/vocab.txt"
        wfile = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714054332.293697\Examples\Text\PennTreebank_RNN@debug_cpu/sequenceSentence.bin"
        wsize = 256
        wrecords = 1000
        windowSize = "10000"
        file = "C:\jenkins\workspace\CNTK-Test-Windows-W1\Examples\Text\PennTreebank\Data/ptb.test.txt"
        features = [
            dim = 0
            sectionType = "data"
        ]
        labelIn = [
            dim = 1
            labelDim = "10000"
            labelMappingFile = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714054332.293697\Examples\Text\PennTreebank_RNN@debug_cpu/sentenceLabels.txt"
            labelType = "Category"
            beginSequence = "</s>"
            endSequence = "</s>"
            elementSize = 4
            sectionType = "labels"
            mapping = [
                wrecords = 11
                elementSize = 10
                sectionType = "labelMapping"
            ]
            category = [
                dim = 11
                sectionType = "categoryLabels"
            ]
        ]
        labels = [
            dim = 1
            labelType = "NextWord"
            beginSequence = "O"
            endSequence = "O"
            labelDim = "10000"
            labelMappingFile = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714054332.293697\Examples\Text\PennTreebank_RNN@debug_cpu/sentenceLabels.out.txt"
            elementSize = 4
            sectionType = "labels"
            mapping = [
                wrecords = 3
                elementSize = 10
                sectionType = "labelMapping"
            ]
            category = [
                dim = 3
                sectionType = "categoryLabels"
            ]
        ]
    ]
]
write = [
    action = "write"
    outputPath = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714054332.293697\Examples\Text\PennTreebank_RNN@debug_cpu/Write"
outputNodeNames = TrainNodeClassBasedCrossEntropy 
    format = [
sequencePrologue = "log P(W)="    
        type = "real"
    ]
minibatchSize = 8192                
    traceLevel = 1
    epochSize = 0
    reader = [
        readerType = "LMSequenceReader"
randomize = "none"              
nbruttsineachrecurrentiter = 1  
cacheBlockSize = 1              
        wordclass = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714054332.293697\Examples\Text\PennTreebank_RNN@debug_cpu/Models/vocab.txt"
        wfile = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714054332.293697\Examples\Text\PennTreebank_RNN@debug_cpu/sequenceSentence.bin"
        wsize = 256
        wrecords = 1000
        windowSize = "10000"
        file = "C:\jenkins\workspace\CNTK-Test-Windows-W1\Examples\Text\PennTreebank\Data/ptb.test.txt"
        features = [
            dim = 0
            sectionType = "data"
        ]
        labelIn = [
            dim = 1
            labelDim = "10000"
            labelMappingFile = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714054332.293697\Examples\Text\PennTreebank_RNN@debug_cpu/sentenceLabels.txt"
            labelType = "Category"
            beginSequence = "</s>"
            endSequence = "</s>"
            elementSize = 4
            sectionType = "labels"
            mapping = [
                wrecords = 11
                elementSize = 10
                sectionType = "labelMapping"
            ]
            category = [
                dim = 11
                sectionType = "categoryLabels"
            ]
        ]
        labels = [
            dim = 1
            labelType = "NextWord"
            beginSequence = "O"
            endSequence = "O"
            labelDim = "10000"
            labelMappingFile = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714054332.293697\Examples\Text\PennTreebank_RNN@debug_cpu/sentenceLabels.out.txt"
            elementSize = 4
            sectionType = "labels"
            mapping = [
                wrecords = 3
                elementSize = 10
                sectionType = "labelMapping"
            ]
            category = [
                dim = 3
                sectionType = "categoryLabels"
            ]
        ]
    ]
]
currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Examples\Text\PennTreebank\Data
RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714054332.293697\Examples\Text\PennTreebank_RNN@debug_cpu
DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Examples\Text\PennTreebank\Data
ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Examples\Text\PennTreebank\Config
OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714054332.293697\Examples\Text\PennTreebank_RNN@debug_cpu
DeviceId=-1
timestamping=true
initOnCPUOnly=true
command=writeWordAndClassInfo:train:test
train=[SGD=[maxEpochs=3]]
train=[epochSize=2048]]
test=[SGD=[maxEpochs=3]]
train=[epochSize=2048]]

07/14/2016 05:50:59: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<

07/14/2016 05:50:59: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
configparameters: rnn.cntk:]=true
configparameters: rnn.cntk:command=writeWordAndClassInfo:train:test
configparameters: rnn.cntk:confClassSize=50
configparameters: rnn.cntk:ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Examples\Text\PennTreebank\Config
configparameters: rnn.cntk:confVocabSize=10000
configparameters: rnn.cntk:currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Examples\Text\PennTreebank\Data
configparameters: rnn.cntk:DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Examples\Text\PennTreebank\Data
configparameters: rnn.cntk:deviceId=-1
configparameters: rnn.cntk:initOnCPUOnly=true
configparameters: rnn.cntk:ModelDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714054332.293697\Examples\Text\PennTreebank_RNN@debug_cpu/Models
configparameters: rnn.cntk:modelPath=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714054332.293697\Examples\Text\PennTreebank_RNN@debug_cpu/Models/rnn.dnn
configparameters: rnn.cntk:numCPUThreads=1
configparameters: rnn.cntk:OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714054332.293697\Examples\Text\PennTreebank_RNN@debug_cpu
configparameters: rnn.cntk:precision=float
configparameters: rnn.cntk:RootDir=..
configparameters: rnn.cntk:RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714054332.293697\Examples\Text\PennTreebank_RNN@debug_cpu
configparameters: rnn.cntk:test=[
    action = "eval"
minibatchSize = 8192                
    traceLevel = 1
    epochSize = 0
    reader = [
        readerType = "LMSequenceReader"
        randomize = "none"
nbruttsineachrecurrentiter = 0  
cacheBlockSize = 2000000        
        wordclass = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714054332.293697\Examples\Text\PennTreebank_RNN@debug_cpu/Models/vocab.txt"
        wfile = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714054332.293697\Examples\Text\PennTreebank_RNN@debug_cpu/sequenceSentence.bin"
        wsize = 256
        wrecords = 1000
        windowSize = "10000"
        file = "C:\jenkins\workspace\CNTK-Test-Windows-W1\Examples\Text\PennTreebank\Data/ptb.test.txt"
        features = [
            dim = 0
            sectionType = "data"
        ]
        labelIn = [
            dim = 1
            labelDim = "10000"
            labelMappingFile = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714054332.293697\Examples\Text\PennTreebank_RNN@debug_cpu/sentenceLabels.txt"
            labelType = "Category"
            beginSequence = "</s>"
            endSequence = "</s>"
            elementSize = 4
            sectionType = "labels"
            mapping = [
                wrecords = 11
                elementSize = 10
                sectionType = "labelMapping"
            ]
            category = [
                dim = 11
                sectionType = "categoryLabels"
            ]
        ]
        labels = [
            dim = 1
            labelType = "NextWord"
            beginSequence = "O"
            endSequence = "O"
            labelDim = "10000"
            labelMappingFile = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714054332.293697\Examples\Text\PennTreebank_RNN@debug_cpu/sentenceLabels.out.txt"
            elementSize = 4
            sectionType = "labels"
            mapping = [
                wrecords = 3
                elementSize = 10
                sectionType = "labelMapping"
            ]
            category = [
                dim = 3
                sectionType = "categoryLabels"
            ]
        ]
    ]
] [SGD=[maxEpochs=3]]

configparameters: rnn.cntk:testFile=ptb.test.txt
configparameters: rnn.cntk:timestamping=true
configparameters: rnn.cntk:traceLevel=1
configparameters: rnn.cntk:train=[
    action = "train"
    traceLevel = 1
epochSize = 0               
    SimpleNetworkBuilder = [
rnnType = "CLASSLSTM"   
recurrentLayer = 1      
        trainingCriterion = "classCrossEntropyWithSoftmax"
        evalCriterion     = "classCrossEntropyWithSoftmax"
        initValueScale = 6.0
        uniformInit = true
        layerSizes = "10000:150:200:10000"
defaultHiddenActivity = 0.1 
        addPrior = false
        addDropoutNodes = false
        applyMeanVarNorm = false
lookupTableOrder = 1        
        vocabSize = "10000"
        nbrClass  = "50"
    ]
    SGD = [
        minibatchSize = 128:256:512
        learningRatesPerSample = 0.1
        momentumPerMB = 0
        gradientClippingWithTruncation = true
        clippingThresholdPerSample = 15.0
        maxEpochs = 16
        numMBsToShowResult = 100
        gradUpdateType = "none"
        loadBestModel = true
        dropoutRate = 0.0
        AutoAdjust = [
            autoAdjustLR = "adjustAfterEpoch"
            reduceLearnRateIfImproveLessThan = 0.001
            continueReduce = false
            increaseLearnRateIfImproveMoreThan = 1000000000
            learnRateDecreaseFactor = 0.5
            learnRateIncreaseFactor = 1.382
            numMiniBatch4LRSearch = 100
            numPrevLearnRates = 5
            numBestSearchEpoch = 1
        ]
    ]
    reader = [
        readerType = "LMSequenceReader"
randomize = "none"              
nbruttsineachrecurrentiter = 0  
cacheBlockSize = 2000000        
        wordclass = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714054332.293697\Examples\Text\PennTreebank_RNN@debug_cpu/Models/vocab.txt"
        wfile = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714054332.293697\Examples\Text\PennTreebank_RNN@debug_cpu/sequenceSentence.bin"
        wsize = 256
        wrecords = 1000
        windowSize = "10000"
        file = "C:\jenkins\workspace\CNTK-Test-Windows-W1\Examples\Text\PennTreebank\Data/ptb.train.txt"
        features = [
            dim = 0
            sectionType = "data"
        ]
        labelIn = [
            dim = 1
            labelType = "Category"
            beginSequence = "</s>"
            endSequence = "</s>"
            labelDim = "10000"
            labelMappingFile = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714054332.293697\Examples\Text\PennTreebank_RNN@debug_cpu/sentenceLabels.txt"
            elementSize = 4
            sectionType = "labels"
            mapping = [
                wrecords = 11                
                elementSize = 10
                sectionType = "labelMapping"
            ]
            category = [
                dim = 11
                sectionType = "categoryLabels"
            ]
        ]
        labels = [
            dim = 1
            labelType = "NextWord"
            beginSequence = "O"
            endSequence = "O"
            labelDim = "10000"
            labelMappingFile = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714054332.293697\Examples\Text\PennTreebank_RNN@debug_cpu/sentenceLabels.out.txt"
            elementSize = 4
            sectionType = "labels"
            mapping = [
                wrecords = 3
                elementSize = 10
                sectionType = "labelMapping"
            ]
            category = [
                dim = 3
                sectionType = categoryLabels
            ]
        ]
    ]
    cvReader = [
        readerType = "LMSequenceReader"
        randomize = "none"
nbruttsineachrecurrentiter = 0  
cacheBlockSize = 2000000        
        wordclass = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714054332.293697\Examples\Text\PennTreebank_RNN@debug_cpu/Models/vocab.txt"
        wfile = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714054332.293697\Examples\Text\PennTreebank_RNN@debug_cpu/sequenceSentence.valid.bin"
        wsize = 256
        wrecords = 1000
        windowSize = "10000"
        file = "C:\jenkins\workspace\CNTK-Test-Windows-W1\Examples\Text\PennTreebank\Data/ptb.valid.txt"
        features = [
            dim = 0
            sectionType = "data"
        ]
        labelIn = [
            dim = 1
            labelDim = "10000"
            labelMappingFile = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714054332.293697\Examples\Text\PennTreebank_RNN@debug_cpu/sentenceLabels.out.txt"
            labelType = "Category"
            beginSequence = "</s>"
            endSequence = "</s>"
            elementSize = 4
            sectionType = "labels"
            mapping = [
                wrecords = 11
                elementSize = 10
                sectionType = "labelMapping"
            ]
            category = [
                dim = 11
                sectionType = "categoryLabels"
            ]
        ]
        labels = [
            dim = 1
            labelType = "NextWord"
            beginSequence = "O"
            endSequence = "O"
            labelDim = "10000"
            labelMappingFile = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714054332.293697\Examples\Text\PennTreebank_RNN@debug_cpu/sentenceLabels.out.txt"
            elementSize = 4
            sectionType = "labels"
            mapping = [
                wrecords = 3
                elementSize = 10
                sectionType = "labelMapping"
            ]
            category = [
                dim = 3
                sectionType = "categoryLabels"
            ]
        ]
    ]
] [SGD=[maxEpochs=3]] [epochSize=2048] [epochSize=2048]

configparameters: rnn.cntk:trainFile=ptb.train.txt
configparameters: rnn.cntk:validFile=ptb.valid.txt
configparameters: rnn.cntk:write=[
    action = "write"
    outputPath = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714054332.293697\Examples\Text\PennTreebank_RNN@debug_cpu/Write"
outputNodeNames = TrainNodeClassBasedCrossEntropy 
    format = [
sequencePrologue = "log P(W)="    
        type = "real"
    ]
minibatchSize = 8192                
    traceLevel = 1
    epochSize = 0
    reader = [
        readerType = "LMSequenceReader"
randomize = "none"              
nbruttsineachrecurrentiter = 1  
cacheBlockSize = 1              
        wordclass = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714054332.293697\Examples\Text\PennTreebank_RNN@debug_cpu/Models/vocab.txt"
        wfile = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714054332.293697\Examples\Text\PennTreebank_RNN@debug_cpu/sequenceSentence.bin"
        wsize = 256
        wrecords = 1000
        windowSize = "10000"
        file = "C:\jenkins\workspace\CNTK-Test-Windows-W1\Examples\Text\PennTreebank\Data/ptb.test.txt"
        features = [
            dim = 0
            sectionType = "data"
        ]
        labelIn = [
            dim = 1
            labelDim = "10000"
            labelMappingFile = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714054332.293697\Examples\Text\PennTreebank_RNN@debug_cpu/sentenceLabels.txt"
            labelType = "Category"
            beginSequence = "</s>"
            endSequence = "</s>"
            elementSize = 4
            sectionType = "labels"
            mapping = [
                wrecords = 11
                elementSize = 10
                sectionType = "labelMapping"
            ]
            category = [
                dim = 11
                sectionType = "categoryLabels"
            ]
        ]
        labels = [
            dim = 1
            labelType = "NextWord"
            beginSequence = "O"
            endSequence = "O"
            labelDim = "10000"
            labelMappingFile = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714054332.293697\Examples\Text\PennTreebank_RNN@debug_cpu/sentenceLabels.out.txt"
            elementSize = 4
            sectionType = "labels"
            mapping = [
                wrecords = 3
                elementSize = 10
                sectionType = "labelMapping"
            ]
            category = [
                dim = 3
                sectionType = "categoryLabels"
            ]
        ]
    ]
]

configparameters: rnn.cntk:writeWordAndClassInfo=[
    action = "writeWordAndClass"
    inputFile = "C:\jenkins\workspace\CNTK-Test-Windows-W1\Examples\Text\PennTreebank\Data/ptb.train.txt"
    beginSequence = "</s>"
    endSequence   = "</s>"
    outputVocabFile = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714054332.293697\Examples\Text\PennTreebank_RNN@debug_cpu/Models/vocab.txt"
    outputWord2Cls  = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714054332.293697\Examples\Text\PennTreebank_RNN@debug_cpu/Models/word2cls.txt"
    outputCls2Index = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714054332.293697\Examples\Text\PennTreebank_RNN@debug_cpu/Models/cls2idx.txt"
    vocabSize = "10000"
    nbrClass = "50"
    cutoff = 0
    printValues = true
]

07/14/2016 05:50:59: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
07/14/2016 05:50:59: Commands: writeWordAndClassInfo train test
07/14/2016 05:50:59: Precision = "float"
07/14/2016 05:50:59: Using 1 CPU threads.
07/14/2016 05:50:59: CNTKModelPath: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714054332.293697\Examples\Text\PennTreebank_RNN@debug_cpu/Models/rnn.dnn
07/14/2016 05:50:59: CNTKCommandTrainInfo: train : 3
07/14/2016 05:50:59: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 3

07/14/2016 05:50:59: ##############################################################################
07/14/2016 05:50:59: #                                                                            #
07/14/2016 05:50:59: # Action "writeWordAndClass"                                                 #
07/14/2016 05:50:59: #                                                                            #
07/14/2016 05:50:59: ##############################################################################

Vocabulary file    --> C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714054332.293697\Examples\Text\PennTreebank_RNN@debug_cpu/Models/vocab.txt
Word-to-class map  --> C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714054332.293697\Examples\Text\PennTreebank_RNN@debug_cpu/Models/word2cls.txt
Class-to-index map --> C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714054332.293697\Examples\Text\PennTreebank_RNN@debug_cpu/Models/cls2idx.txt

Reading input file inputFile: C:\jenkins\workspace\CNTK-Test-Windows-W1\Examples\Text\PennTreebank\Data/ptb.train.txt
Vocabulary size 10000.
Created vocabulary file with 10000 entries.
Created word-to-class map with 10000 entries.
Created class-to-index map with 50 entries.

07/14/2016 05:51:10: Action "writeWordAndClass" complete.


07/14/2016 05:51:10: ##############################################################################
07/14/2016 05:51:10: #                                                                            #
07/14/2016 05:51:10: # Action "train"                                                             #
07/14/2016 05:51:10: #                                                                            #
07/14/2016 05:51:10: ##############################################################################

07/14/2016 05:51:10: CNTKCommandTrainBegin: train
SimpleNetworkBuilder Using CPU
LMSequenceReader: Label mapping will be created internally on the fly because the labelMappingFile was not found: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714054332.293697\Examples\Text\PennTreebank_RNN@debug_cpu/sentenceLabels.txt
LMSequenceReader: Label mapping will be created internally on the fly because the labelMappingFile was not found: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714054332.293697\Examples\Text\PennTreebank_RNN@debug_cpu/sentenceLabels.out.txt
LMSequenceReader: Input file is 'C:\jenkins\workspace\CNTK-Test-Windows-W1\Examples\Text\PennTreebank\Data/ptb.train.txt'.
LMSequenceReader: Label mapping will be created internally on the fly because the labelMappingFile was not found: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714054332.293697\Examples\Text\PennTreebank_RNN@debug_cpu/sentenceLabels.out.txt
LMSequenceReader: Label mapping will be created internally on the fly because the labelMappingFile was not found: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714054332.293697\Examples\Text\PennTreebank_RNN@debug_cpu/sentenceLabels.out.txt
LMSequenceReader: Input file is 'C:\jenkins\workspace\CNTK-Test-Windows-W1\Examples\Text\PennTreebank\Data/ptb.valid.txt'.

07/14/2016 05:51:14: Creating virgin network.

Post-processing network...

3 roots:
	PosteriorProb = Softmax()
	TrainNodeClassBasedCrossEntropy = ClassBasedCrossEntropyWithSoftmax()
	outputs = TransposeTimes()

Loop[0] --> Loop_AutoName37 -> 31 nodes

	AutoName2	AutoName30	AutoName33
	AutoName1	AutoName21	AutoName24
	AutoName5	AutoName20	AutoName25
	AutoName26	AutoName6	AutoName27
	AutoName0	AutoName8	AutoName11
	AutoName4	AutoName7	AutoName12
	AutoName13	AutoName3	AutoName14
	AutoName15	AutoName17	AutoName18
	AutoName19	AutoName28	AutoName29
	AutoName34	AutoName35	AutoName36
	AutoName37

Validating network. 63 nodes to process in pass 1.

Validating --> W2 = LearnableParameter() :  -> [200 x 10000]
Validating --> WXO0 = LearnableParameter() :  -> [200 x 150]
Validating --> E0 = LearnableParameter() :  -> [150 x 10000]
Validating --> features = SparseInputValue() :  -> [10000 x *]
Validating --> LookupTable = LookupTable (E0, features) : [150 x 10000], [10000 x *] -> [150 x *]
Validating --> AutoName31 = Times (WXO0, LookupTable) : [200 x 150], [150 x *] -> [200 x *]
Validating --> bo0 = LearnableParameter() :  -> [200 x 1]
Validating --> AutoName32 = Plus (AutoName31, bo0) : [200 x *], [200 x 1] -> [200 x 1 x *]
Validating --> WHO0 = LearnableParameter() :  -> [200 x 200]
Validating --> WCO0 = LearnableParameter() :  -> [200 x 1]
Validating --> WXF0 = LearnableParameter() :  -> [200 x 150]
Validating --> AutoName22 = Times (WXF0, LookupTable) : [200 x 150], [150 x *] -> [200 x *]
Validating --> bf0 = LearnableParameter() :  -> [200 x 1]
Validating --> AutoName23 = Plus (AutoName22, bf0) : [200 x *], [200 x 1] -> [200 x 1 x *]
Validating --> WHF0 = LearnableParameter() :  -> [200 x 200]
Validating --> WCF0 = LearnableParameter() :  -> [200 x 1]
Validating --> WXI0 = LearnableParameter() :  -> [200 x 150]
Validating --> AutoName9 = Times (WXI0, LookupTable) : [200 x 150], [150 x *] -> [200 x *]
Validating --> bi0 = LearnableParameter() :  -> [200 x 1]
Validating --> AutoName10 = Plus (AutoName9, bi0) : [200 x *], [200 x 1] -> [200 x 1 x *]
Validating --> WHI0 = LearnableParameter() :  -> [200 x 200]
Validating --> WCI0 = LearnableParameter() :  -> [200 x 1]
Validating --> WXC0 = LearnableParameter() :  -> [200 x 150]
Validating --> AutoName16 = Times (WXC0, LookupTable) : [200 x 150], [150 x *] -> [200 x *]
Validating --> WHC0 = LearnableParameter() :  -> [200 x 200]
Validating --> bc0 = LearnableParameter() :  -> [200 x 1]
Validating --> AutoName30 = Times (WHO0, AutoName2) : [200 x 200], [200] -> [200]
Validating --> AutoName33 = Plus (AutoName32, AutoName30) : [200 x 1 x *], [200] -> [200 x 1 x *]
Validating --> AutoName21 = Times (WHF0, AutoName1) : [200 x 200], [200] -> [200]
Validating --> AutoName24 = Plus (AutoName23, AutoName21) : [200 x 1 x *], [200] -> [200 x 1 x *]
Validating --> AutoName20 = DiagTimes (WCF0, AutoName5) : [200 x 1], [200] -> [200]
Validating --> AutoName25 = Plus (AutoName24, AutoName20) : [200 x 1 x *], [200] -> [200 x 1 x *]
Validating --> AutoName26 = Sigmoid (AutoName25) : [200 x 1 x *] -> [200 x 1 x *]
Validating --> AutoName27 = ElementTimes (AutoName26, AutoName6) : [200 x 1 x *], [200] -> [200 x 1 x *]
Validating --> AutoName8 = Times (WHI0, AutoName0) : [200 x 200], [200] -> [200]
Validating --> AutoName11 = Plus (AutoName10, AutoName8) : [200 x 1 x *], [200] -> [200 x 1 x *]
Validating --> AutoName7 = DiagTimes (WCI0, AutoName4) : [200 x 1], [200] -> [200]
Validating --> AutoName12 = Plus (AutoName11, AutoName7) : [200 x 1 x *], [200] -> [200 x 1 x *]
Validating --> AutoName13 = Sigmoid (AutoName12) : [200 x 1 x *] -> [200 x 1 x *]
Validating --> AutoName14 = Times (WHC0, AutoName3) : [200 x 200], [200] -> [200]
Validating --> AutoName15 = Plus (AutoName14, bc0) : [200], [200 x 1] -> [200 x 1]
Validating --> AutoName17 = Plus (AutoName16, AutoName15) : [200 x *], [200 x 1] -> [200 x 1 x *]
Validating --> AutoName18 = Tanh (AutoName17) : [200 x 1 x *] -> [200 x 1 x *]
Validating --> AutoName19 = ElementTimes (AutoName13, AutoName18) : [200 x 1 x *], [200 x 1 x *] -> [200 x 1 x *]
Validating --> AutoName28 = Plus (AutoName27, AutoName19) : [200 x 1 x *], [200 x 1 x *] -> [200 x 1 x *]
Validating --> AutoName29 = DiagTimes (WCO0, AutoName28) : [200 x 1], [200 x 1 x *] -> [200 x 1 x *]
Validating --> AutoName34 = Plus (AutoName33, AutoName29) : [200 x 1 x *], [200 x 1 x *] -> [200 x 1 x *]
Validating --> AutoName35 = Sigmoid (AutoName34) : [200 x 1 x *] -> [200 x 1 x *]
Validating --> AutoName36 = Tanh (AutoName28) : [200 x 1 x *] -> [200 x 1 x *]
Validating --> AutoName37 = ElementTimes (AutoName35, AutoName36) : [200 x 1 x *], [200 x 1 x *] -> [200 x 1 x *]
Validating --> outputs = TransposeTimes (W2, AutoName37) : [200 x 10000], [200 x 1 x *] -> [10000 x 1 x *]
Validating --> PosteriorProb = Softmax (outputs) : [10000 x 1 x *] -> [10000 x 1 x *]
Validating --> labels = InputValue() :  -> [4 x *]
Validating --> WeightForClassPostProb = LearnableParameter() :  -> [50 x 200]
Validating --> ClassPostProb = Times (WeightForClassPostProb, AutoName37) : [50 x 200], [200 x 1 x *] -> [50 x 1 x *]
Validating --> TrainNodeClassBasedCrossEntropy = ClassBasedCrossEntropyWithSoftmax (labels, AutoName37, W2, ClassPostProb) : [4 x *], [200 x 1 x *], [200 x 10000], [50 x 1 x *] -> [1]

Validating network. 43 nodes to process in pass 2.

Validating --> AutoName2 = PastValue (AutoName37) : [200 x 1 x *] -> [200 x 1 x *]
Validating --> AutoName30 = Times (WHO0, AutoName2) : [200 x 200], [200 x 1 x *] -> [200 x 1 x *]
Validating --> AutoName1 = PastValue (AutoName37) : [200 x 1 x *] -> [200 x 1 x *]
Validating --> AutoName21 = Times (WHF0, AutoName1) : [200 x 200], [200 x 1 x *] -> [200 x 1 x *]
Validating --> AutoName5 = PastValue (AutoName28) : [200 x 1 x *] -> [200 x 1 x *]
Validating --> AutoName20 = DiagTimes (WCF0, AutoName5) : [200 x 1], [200 x 1 x *] -> [200 x 1 x *]
Validating --> AutoName6 = PastValue (AutoName28) : [200 x 1 x *] -> [200 x 1 x *]
Validating --> AutoName0 = PastValue (AutoName37) : [200 x 1 x *] -> [200 x 1 x *]
Validating --> AutoName8 = Times (WHI0, AutoName0) : [200 x 200], [200 x 1 x *] -> [200 x 1 x *]
Validating --> AutoName4 = PastValue (AutoName28) : [200 x 1 x *] -> [200 x 1 x *]
Validating --> AutoName7 = DiagTimes (WCI0, AutoName4) : [200 x 1], [200 x 1 x *] -> [200 x 1 x *]
Validating --> AutoName3 = PastValue (AutoName37) : [200 x 1 x *] -> [200 x 1 x *]
Validating --> AutoName14 = Times (WHC0, AutoName3) : [200 x 200], [200 x 1 x *] -> [200 x 1 x *]
Validating --> AutoName15 = Plus (AutoName14, bc0) : [200 x 1 x *], [200 x 1] -> [200 x 1 x *]

Validating network. 14 nodes to process in pass 3.


Validating network, final pass.



19 out of 63 nodes do not share the minibatch layout with the input data.

Post-processing network complete.

07/14/2016 05:51:14: Created model with 63 nodes on CPU.

07/14/2016 05:51:14: Training criterion node(s):
07/14/2016 05:51:14: 	TrainNodeClassBasedCrossEntropy = ClassBasedCrossEntropyWithSoftmax


Allocating matrices for forward and/or backward propagation.

Memory Sharing Structure:

0000000000000000: {[PosteriorProb Gradient[10000 x 1 x *]] [PosteriorProb Value[10000 x 1 x *]] [features Gradient[10000 x *]] [labels Gradient[4 x *]] [outputs Gradient[10000 x 1 x *]] }
000000114055DF20: {[bc0 Value[200 x 1]] }
000000114055DFF0: {[WHC0 Value[200 x 200]] }
000000114055E0C0: {[AutoName0 Value[200 x 1 x *]] }
000000114055E190: {[WCI0 Value[200 x 1]] }
000000114055E260: {[WCF0 Value[200 x 1]] }
000000114055E330: {[AutoName1 Value[200 x 1 x *]] }
000000114055E400: {[WHI0 Value[200 x 200]] }
000000114055E4D0: {[WXF0 Value[200 x 150]] }
000000114055E5A0: {[bi0 Value[200 x 1]] }
000000114055E670: {[E0 Value[150 x 10000]] }
000000114055E740: {[features Value[10000 x *]] }
000000114055E810: {[bo0 Value[200 x 1]] }
000000114055E8E0: {[WXO0 Value[200 x 150]] }
000000114055E9B0: {[WXI0 Value[200 x 150]] }
000000114055EA80: {[WHF0 Value[200 x 200]] }
000000114055EB50: {[bf0 Value[200 x 1]] }
000000114055EC20: {[WHO0 Value[200 x 200]] }
000000114055ECF0: {[WCO0 Value[200 x 1]] }
000000114055EDC0: {[WXC0 Value[200 x 150]] }
000000115982B330: {[AutoName25 Gradient[200 x 1 x *]] }
000000115982B5A0: {[WHO0 Gradient[200 x 200]] }
000000115982B670: {[AutoName5 Gradient[200 x 1 x *]] }
000000115982B8E0: {[AutoName2 Gradient[200 x 1 x *]] [LookupTable Gradient[150 x *]] }
000000115982BB50: {[AutoName32 Gradient[200 x 1 x *]] }
000000115982BF60: {[AutoName6 Gradient[200 x 1 x *]] }
000000115982C440: {[AutoName1 Gradient[200 x 1 x *]] }
000000115982C510: {[AutoName23 Gradient[200 x 1 x *]] }
000000115982C780: {[AutoName24 Gradient[200 x 1 x *]] }
000000115982C850: {[WHF0 Gradient[200 x 200]] }
000000115982CB90: {[AutoName30 Gradient[200 x 1 x *]] }
000000115982CD30: {[WCF0 Gradient[200 x 1]] }
000000115982CE00: {[AutoName21 Gradient[200 x 1 x *]] }
000000115982CED0: {[AutoName20 Gradient[200 x 1 x *]] }
0000001159C89FE0: {[AutoName33 Gradient[200 x 1 x *]] }
0000001159C8A0B0: {[AutoName36 Gradient[200 x 1 x *]] [ClassPostProb Gradient[50 x 1 x *]] }
0000001159C8A180: {[AutoName29 Gradient[200 x 1 x *]] }
0000001159C8A250: {[AutoName35 Gradient[200 x 1 x *]] [ClassPostProb Value[50 x 1 x *]] }
0000001159C8A3F0: {[AutoName19 Gradient[200 x 1 x *]] }
0000001159C8A4C0: {[TrainNodeClassBasedCrossEntropy Gradient[1]] }
0000001159C8A590: {[AutoName16 Gradient[200 x *]] [bi0 Gradient[200 x 1]] }
0000001159C8A660: {[AutoName7 Gradient[200 x 1 x *]] }
0000001159C8A730: {[AutoName10 Gradient[200 x 1 x *]] }
0000001159C8A800: {[AutoName8 Gradient[200 x 1 x *]] }
0000001159C8A8D0: {[WHI0 Gradient[200 x 200]] }
0000001159C8A9A0: {[AutoName35 Value[200 x 1 x *]] }
0000001159C8AA70: {[AutoName0 Gradient[200 x 1 x *]] }
0000001159C8AB40: {[AutoName26 Gradient[200 x 1 x *]] }
0000001159C8AC10: {[AutoName34 Gradient[200 x 1 x *]] }
0000001159C8ACE0: {[WCO0 Gradient[200 x 1]] }
0000001159C8ADB0: {[WHC0 Gradient[200 x 200]] }
0000001159C8AF50: {[AutoName17 Gradient[200 x 1 x *]] }
0000001159C8B020: {[AutoName12 Gradient[200 x 1 x *]] }
0000001159C8B0F0: {[AutoName36 Value[200 x 1 x *]] }
0000001159C8B1C0: {[AutoName27 Gradient[200 x 1 x *]] }
0000001159C8B290: {[AutoName18 Gradient[200 x 1 x *]] }
0000001159C8B360: {[AutoName28 Gradient[200 x 1 x *]] }
0000001159C8B430: {[AutoName15 Gradient[200 x 1 x *]] }
0000001159C8B500: {[AutoName14 Gradient[200 x 1 x *]] }
0000001159C8B5D0: {[W2 Gradient[200 x 10000]] }
0000001159C8B6A0: {[bc0 Gradient[200 x 1]] }
0000001159C8B770: {[AutoName3 Gradient[200 x 1 x *]] }
0000001159C8B840: {[AutoName11 Gradient[200 x 1 x *]] }
0000001159C8B910: {[AutoName37 Gradient[200 x 1 x *]] }
0000001159C8B9E0: {[AutoName13 Gradient[200 x 1 x *]] }
0000001159C8BB80: {[WeightForClassPostProb Gradient[50 x 200]] }
0000001159C8BD20: {[WCI0 Gradient[200 x 1]] }
0000001159C8BDF0: {[AutoName4 Gradient[200 x 1 x *]] }
0000001159C8BEC0: {[AutoName37 Value[200 x 1 x *]] }
0000001159E105B0: {[AutoName20 Value[200 x 1 x *]] }
0000001159E10680: {[AutoName7 Value[200 x 1 x *]] }
0000001159E10750: {[AutoName28 Value[200 x 1 x *]] }
0000001159E10820: {[AutoName21 Value[200 x 1 x *]] }
0000001159E108F0: {[AutoName29 Value[200 x 1 x *]] }
0000001159E109C0: {[AutoName34 Value[200 x 1 x *]] }
0000001159E10A90: {[W2 Value[200 x 10000]] }
0000001159E10B60: {[outputs Value[10000 x 1 x *]] }
0000001159E10C30: {[AutoName23 Value[200 x 1 x *]] [WXF0 Gradient[200 x 150]] }
0000001159E10D00: {[AutoName6 Value[200 x 1 x *]] }
0000001159E10DD0: {[labels Value[4 x *]] }
0000001159E10EA0: {[AutoName31 Value[200 x *]] [E0 Gradient[150 x 10000]] }
0000001159E10F70: {[AutoName8 Value[200 x 1 x *]] }
0000001159E11040: {[AutoName17 Value[200 x 1 x *]] }
0000001159E11110: {[AutoName4 Value[200 x 1 x *]] }
0000001159E111E0: {[WeightForClassPostProb Value[50 x 200]] }
0000001159E112B0: {[AutoName33 Value[200 x 1 x *]] }
0000001159E11380: {[AutoName14 Value[200 x 1 x *]] }
0000001159E11450: {[AutoName18 Value[200 x 1 x *]] }
0000001159E11520: {[TrainNodeClassBasedCrossEntropy Value[1]] }
0000001159E115F0: {[AutoName19 Value[200 x 1 x *]] }
0000001159E116C0: {[AutoName5 Value[200 x 1 x *]] }
0000001159E11790: {[LookupTable Value[150 x *]] }
0000001159E11860: {[AutoName32 Value[200 x 1 x *]] [WXO0 Gradient[200 x 150]] }
0000001159E11930: {[AutoName16 Value[200 x *]] [AutoName9 Gradient[200 x *]] [bf0 Gradient[200 x 1]] }
0000001159E11A00: {[AutoName25 Value[200 x 1 x *]] }
0000001159E11AD0: {[AutoName11 Value[200 x 1 x *]] }
0000001159E11BA0: {[AutoName13 Value[200 x 1 x *]] }
0000001159E11C70: {[AutoName3 Value[200 x 1 x *]] }
0000001159E11D40: {[AutoName24 Value[200 x 1 x *]] }
0000001159E11E10: {[AutoName26 Value[200 x 1 x *]] }
0000001159E11EE0: {[AutoName22 Value[200 x *]] [AutoName31 Gradient[200 x *]] }
0000001159E11FB0: {[AutoName2 Value[200 x 1 x *]] [WXC0 Gradient[200 x 150]] }
0000001159E12080: {[AutoName22 Gradient[200 x *]] [AutoName9 Value[200 x *]] [bo0 Gradient[200 x 1]] }
0000001159E12150: {[AutoName12 Value[200 x 1 x *]] }
0000001159E12220: {[AutoName15 Value[200 x 1 x *]] }
0000001159E122F0: {[AutoName27 Value[200 x 1 x *]] }
0000001159E123C0: {[AutoName10 Value[200 x 1 x *]] [WXI0 Gradient[200 x 150]] }
0000001159E12490: {[AutoName30 Value[200 x 1 x *]] }

07/14/2016 05:51:14: No PreCompute nodes found, skipping PreCompute step.

07/14/2016 05:51:15: Starting Epoch 1: learning rate per sample = 0.100000  effective momentum = 0.000000  momentum as time constant = 0.0 samples

07/14/2016 05:51:15: Starting minibatch loop.
LMSequenceReader: Reading epoch data... 42068 sequences read.
07/14/2016 05:51:59: Finished Epoch[ 1 of 3]: [Training] TrainNodeClassBasedCrossEntropy = 6.81610253 * 2061; totalSamplesSeen = 2061; learningRatePerSample = 0.1; epochTime=43.7695s
LMSequenceReader: Reading epoch data... 3370 sequences read.
LMSequenceReader: Reading epoch data... 0 sequences read.
07/14/2016 05:53:30: Final Results: Minibatch[1-704]: TrainNodeClassBasedCrossEntropy = 6.49594388 * 73760; perplexity = 662.44920230
07/14/2016 05:53:30: Finished Epoch[ 1 of 3]: [Validate] TrainNodeClassBasedCrossEntropy = 6.49594388 * 73760
07/14/2016 05:53:31: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714054332.293697\Examples\Text\PennTreebank_RNN@debug_cpu/Models/rnn.dnn.1'

07/14/2016 05:53:32: Starting Epoch 2: learning rate per sample = 0.100000  effective momentum = 0.000000  momentum as time constant = 0.0 samples

07/14/2016 05:53:32: Starting minibatch loop.
LMSequenceReader: Reading epoch data... 42068 sequences read.
07/14/2016 05:53:57: Finished Epoch[ 2 of 3]: [Training] TrainNodeClassBasedCrossEntropy = 6.49383794 * 2081; totalSamplesSeen = 4142; learningRatePerSample = 0.1; epochTime=25.345s
LMSequenceReader: Reading epoch data... 3370 sequences read.
LMSequenceReader: Reading epoch data... 0 sequences read.
07/14/2016 05:55:12: Final Results: Minibatch[1-353]: TrainNodeClassBasedCrossEntropy = 6.60359202 * 73760; perplexity = 737.74041425
07/14/2016 05:55:12: Finished Epoch[ 2 of 3]: [Validate] TrainNodeClassBasedCrossEntropy = 6.60359202 * 73760
07/14/2016 05:55:12: Loading (rolling back to) previous model with best training-criterion value: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714054332.293697\Examples\Text\PennTreebank_RNN@debug_cpu/Models/rnn.dnn.1.
07/14/2016 05:55:14: learnRatePerSample reduced to 0.050000001
07/14/2016 05:55:14: SGD: revoke back to and update checkpoint file for epoch 1

07/14/2016 05:55:14: Starting Epoch 2: learning rate per sample = 0.050000  effective momentum = 0.000000  momentum as time constant = 0.0 samples

07/14/2016 05:55:15: Starting minibatch loop.
LMSequenceReader: Reading epoch data... 42068 sequences read.
07/14/2016 05:55:40: Finished Epoch[ 2 of 3]: [Training] TrainNodeClassBasedCrossEntropy = 6.39348430 * 2081; totalSamplesSeen = 4142; learningRatePerSample = 0.050000001; epochTime=25.3229s
LMSequenceReader: Reading epoch data... 3370 sequences read.
LMSequenceReader: Reading epoch data... 0 sequences read.
07/14/2016 05:56:55: Final Results: Minibatch[1-353]: TrainNodeClassBasedCrossEntropy = 6.43778067 * 73760; perplexity = 625.01813875
07/14/2016 05:56:55: Finished Epoch[ 2 of 3]: [Validate] TrainNodeClassBasedCrossEntropy = 6.43778067 * 73760
07/14/2016 05:56:56: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714054332.293697\Examples\Text\PennTreebank_RNN@debug_cpu/Models/rnn.dnn.2'

07/14/2016 05:56:56: Starting Epoch 3: learning rate per sample = 0.050000  effective momentum = 0.000000  momentum as time constant = 0.0 samples

07/14/2016 05:56:57: Starting minibatch loop.
LMSequenceReader: Reading epoch data... 42068 sequences read.
07/14/2016 05:57:15: Finished Epoch[ 3 of 3]: [Training] TrainNodeClassBasedCrossEntropy = 6.29225144 * 2343; totalSamplesSeen = 6485; learningRatePerSample = 0.050000001; epochTime=18.8199s
LMSequenceReader: Reading epoch data... 3370 sequences read.
LMSequenceReader: Reading epoch data... 0 sequences read.
07/14/2016 05:58:24: Final Results: Minibatch[1-193]: TrainNodeClassBasedCrossEntropy = 6.56784864 * 73760; perplexity = 711.83677989
07/14/2016 05:58:24: Finished Epoch[ 3 of 3]: [Validate] TrainNodeClassBasedCrossEntropy = 6.56784864 * 73760
07/14/2016 05:58:24: Loading (rolling back to) previous model with best training-criterion value: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714054332.293697\Examples\Text\PennTreebank_RNN@debug_cpu/Models/rnn.dnn.2.
07/14/2016 05:58:26: learnRatePerSample reduced to 0.025
07/14/2016 05:58:26: SGD: revoke back to and update checkpoint file for epoch 2

07/14/2016 05:58:27: Starting Epoch 3: learning rate per sample = 0.025000  effective momentum = 0.000000  momentum as time constant = 0.0 samples

07/14/2016 05:58:27: Starting minibatch loop.
LMSequenceReader: Reading epoch data... 42068 sequences read.
07/14/2016 05:58:46: Finished Epoch[ 3 of 3]: [Training] TrainNodeClassBasedCrossEntropy = 6.29791283 * 2343; totalSamplesSeen = 6485; learningRatePerSample = 0.025; epochTime=19.0262s
LMSequenceReader: Reading epoch data... 3370 sequences read.
LMSequenceReader: Reading epoch data... 0 sequences read.
07/14/2016 05:59:55: Final Results: Minibatch[1-193]: TrainNodeClassBasedCrossEntropy = 6.42704739 * 73760; perplexity = 618.34551770
07/14/2016 05:59:55: Finished Epoch[ 3 of 3]: [Validate] TrainNodeClassBasedCrossEntropy = 6.42704739 * 73760
07/14/2016 05:59:55: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714054332.293697\Examples\Text\PennTreebank_RNN@debug_cpu/Models/rnn.dnn'
07/14/2016 05:59:57: CNTKCommandTrainEnd: train

07/14/2016 05:59:57: Action "train" complete.


07/14/2016 05:59:57: ##############################################################################
07/14/2016 05:59:57: #                                                                            #
07/14/2016 05:59:57: # Action "eval"                                                              #
07/14/2016 05:59:57: #                                                                            #
07/14/2016 05:59:57: ##############################################################################

LMSequenceReader: Label mapping will be created internally on the fly because the labelMappingFile was not found: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714054332.293697\Examples\Text\PennTreebank_RNN@debug_cpu/sentenceLabels.txt
LMSequenceReader: Label mapping will be created internally on the fly because the labelMappingFile was not found: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714054332.293697\Examples\Text\PennTreebank_RNN@debug_cpu/sentenceLabels.out.txt
LMSequenceReader: Input file is 'C:\jenkins\workspace\CNTK-Test-Windows-W1\Examples\Text\PennTreebank\Data/ptb.test.txt'.

Post-processing network...

3 roots:
	PosteriorProb = Softmax()
	TrainNodeClassBasedCrossEntropy = ClassBasedCrossEntropyWithSoftmax()
	outputs = TransposeTimes()

Loop[0] --> Loop_AutoName37 -> 31 nodes

	AutoName2	AutoName30	AutoName33
	AutoName1	AutoName21	AutoName24
	AutoName5	AutoName20	AutoName25
	AutoName26	AutoName6	AutoName27
	AutoName0	AutoName8	AutoName11
	AutoName4	AutoName7	AutoName12
	AutoName13	AutoName3	AutoName14
	AutoName15	AutoName17	AutoName18
	AutoName19	AutoName28	AutoName29
	AutoName34	AutoName35	AutoName36
	AutoName37

Validating network. 63 nodes to process in pass 1.

Validating --> W2 = LearnableParameter() :  -> [200 x 10000]
Validating --> WXO0 = LearnableParameter() :  -> [200 x 150]
Validating --> E0 = LearnableParameter() :  -> [150 x 10000]
Validating --> features = SparseInputValue() :  -> [10000 x *1]
Validating --> LookupTable = LookupTable (E0, features) : [150 x 10000], [10000 x *1] -> [150 x *1]
Validating --> AutoName31 = Times (WXO0, LookupTable) : [200 x 150], [150 x *1] -> [200 x *1]
Validating --> bo0 = LearnableParameter() :  -> [200 x 1]
Validating --> AutoName32 = Plus (AutoName31, bo0) : [200 x *1], [200 x 1] -> [200 x 1 x *1]
Validating --> WHO0 = LearnableParameter() :  -> [200 x 200]
Validating --> WCO0 = LearnableParameter() :  -> [200 x 1]
Validating --> WXF0 = LearnableParameter() :  -> [200 x 150]
Validating --> AutoName22 = Times (WXF0, LookupTable) : [200 x 150], [150 x *1] -> [200 x *1]
Validating --> bf0 = LearnableParameter() :  -> [200 x 1]
Validating --> AutoName23 = Plus (AutoName22, bf0) : [200 x *1], [200 x 1] -> [200 x 1 x *1]
Validating --> WHF0 = LearnableParameter() :  -> [200 x 200]
Validating --> WCF0 = LearnableParameter() :  -> [200 x 1]
Validating --> WXI0 = LearnableParameter() :  -> [200 x 150]
Validating --> AutoName9 = Times (WXI0, LookupTable) : [200 x 150], [150 x *1] -> [200 x *1]
Validating --> bi0 = LearnableParameter() :  -> [200 x 1]
Validating --> AutoName10 = Plus (AutoName9, bi0) : [200 x *1], [200 x 1] -> [200 x 1 x *1]
Validating --> WHI0 = LearnableParameter() :  -> [200 x 200]
Validating --> WCI0 = LearnableParameter() :  -> [200 x 1]
Validating --> WXC0 = LearnableParameter() :  -> [200 x 150]
Validating --> AutoName16 = Times (WXC0, LookupTable) : [200 x 150], [150 x *1] -> [200 x *1]
Validating --> WHC0 = LearnableParameter() :  -> [200 x 200]
Validating --> bc0 = LearnableParameter() :  -> [200 x 1]
Validating --> AutoName30 = Times (WHO0, AutoName2) : [200 x 200], [200 x 1] -> [200 x 1]
Validating --> AutoName33 = Plus (AutoName32, AutoName30) : [200 x 1 x *1], [200 x 1] -> [200 x 1 x *1]
Validating --> AutoName21 = Times (WHF0, AutoName1) : [200 x 200], [200 x 1] -> [200 x 1]
Validating --> AutoName24 = Plus (AutoName23, AutoName21) : [200 x 1 x *1], [200 x 1] -> [200 x 1 x *1]
Validating --> AutoName20 = DiagTimes (WCF0, AutoName5) : [200 x 1], [200 x 1] -> [200 x 1]
Validating --> AutoName25 = Plus (AutoName24, AutoName20) : [200 x 1 x *1], [200 x 1] -> [200 x 1 x *1]
Validating --> AutoName26 = Sigmoid (AutoName25) : [200 x 1 x *1] -> [200 x 1 x *1]
Validating --> AutoName27 = ElementTimes (AutoName26, AutoName6) : [200 x 1 x *1], [200 x 1] -> [200 x 1 x *1]
Validating --> AutoName8 = Times (WHI0, AutoName0) : [200 x 200], [200 x 1] -> [200 x 1]
Validating --> AutoName11 = Plus (AutoName10, AutoName8) : [200 x 1 x *1], [200 x 1] -> [200 x 1 x *1]
Validating --> AutoName7 = DiagTimes (WCI0, AutoName4) : [200 x 1], [200 x 1] -> [200 x 1]
Validating --> AutoName12 = Plus (AutoName11, AutoName7) : [200 x 1 x *1], [200 x 1] -> [200 x 1 x *1]
Validating --> AutoName13 = Sigmoid (AutoName12) : [200 x 1 x *1] -> [200 x 1 x *1]
Validating --> AutoName14 = Times (WHC0, AutoName3) : [200 x 200], [200 x 1] -> [200 x 1]
Validating --> AutoName15 = Plus (AutoName14, bc0) : [200 x 1], [200 x 1] -> [200 x 1]
Validating --> AutoName17 = Plus (AutoName16, AutoName15) : [200 x *1], [200 x 1] -> [200 x 1 x *1]
Validating --> AutoName18 = Tanh (AutoName17) : [200 x 1 x *1] -> [200 x 1 x *1]
Validating --> AutoName19 = ElementTimes (AutoName13, AutoName18) : [200 x 1 x *1], [200 x 1 x *1] -> [200 x 1 x *1]
Validating --> AutoName28 = Plus (AutoName27, AutoName19) : [200 x 1 x *1], [200 x 1 x *1] -> [200 x 1 x *1]
Validating --> AutoName29 = DiagTimes (WCO0, AutoName28) : [200 x 1], [200 x 1 x *1] -> [200 x 1 x *1]
Validating --> AutoName34 = Plus (AutoName33, AutoName29) : [200 x 1 x *1], [200 x 1 x *1] -> [200 x 1 x *1]
Validating --> AutoName35 = Sigmoid (AutoName34) : [200 x 1 x *1] -> [200 x 1 x *1]
Validating --> AutoName36 = Tanh (AutoName28) : [200 x 1 x *1] -> [200 x 1 x *1]
Validating --> AutoName37 = ElementTimes (AutoName35, AutoName36) : [200 x 1 x *1], [200 x 1 x *1] -> [200 x 1 x *1]
Validating --> outputs = TransposeTimes (W2, AutoName37) : [200 x 10000], [200 x 1 x *1] -> [10000 x 1 x *1]
Validating --> PosteriorProb = Softmax (outputs) : [10000 x 1 x *1] -> [10000 x 1 x *1]
Validating --> labels = InputValue() :  -> [4 x *1]
Validating --> WeightForClassPostProb = LearnableParameter() :  -> [50 x 200]
Validating --> ClassPostProb = Times (WeightForClassPostProb, AutoName37) : [50 x 200], [200 x 1 x *1] -> [50 x 1 x *1]
Validating --> TrainNodeClassBasedCrossEntropy = ClassBasedCrossEntropyWithSoftmax (labels, AutoName37, W2, ClassPostProb) : [4 x *1], [200 x 1 x *1], [200 x 10000], [50 x 1 x *1] -> [1]

Validating network. 43 nodes to process in pass 2.

Validating --> AutoName2 = PastValue (AutoName37) : [200 x 1 x *1] -> [200 x 1 x *1]
Validating --> AutoName30 = Times (WHO0, AutoName2) : [200 x 200], [200 x 1 x *1] -> [200 x 1 x *1]
Validating --> AutoName1 = PastValue (AutoName37) : [200 x 1 x *1] -> [200 x 1 x *1]
Validating --> AutoName21 = Times (WHF0, AutoName1) : [200 x 200], [200 x 1 x *1] -> [200 x 1 x *1]
Validating --> AutoName5 = PastValue (AutoName28) : [200 x 1 x *1] -> [200 x 1 x *1]
Validating --> AutoName20 = DiagTimes (WCF0, AutoName5) : [200 x 1], [200 x 1 x *1] -> [200 x 1 x *1]
Validating --> AutoName6 = PastValue (AutoName28) : [200 x 1 x *1] -> [200 x 1 x *1]
Validating --> AutoName0 = PastValue (AutoName37) : [200 x 1 x *1] -> [200 x 1 x *1]
Validating --> AutoName8 = Times (WHI0, AutoName0) : [200 x 200], [200 x 1 x *1] -> [200 x 1 x *1]
Validating --> AutoName4 = PastValue (AutoName28) : [200 x 1 x *1] -> [200 x 1 x *1]
Validating --> AutoName7 = DiagTimes (WCI0, AutoName4) : [200 x 1], [200 x 1 x *1] -> [200 x 1 x *1]
Validating --> AutoName3 = PastValue (AutoName37) : [200 x 1 x *1] -> [200 x 1 x *1]
Validating --> AutoName14 = Times (WHC0, AutoName3) : [200 x 200], [200 x 1 x *1] -> [200 x 1 x *1]
Validating --> AutoName15 = Plus (AutoName14, bc0) : [200 x 1 x *1], [200 x 1] -> [200 x 1 x *1]

Validating network. 14 nodes to process in pass 3.


Validating network, final pass.



19 out of 63 nodes do not share the minibatch layout with the input data.

Post-processing network complete.

evalNodeNames are not specified, using all the default evalnodes and training criterion nodes.


Allocating matrices for forward and/or backward propagation.

Memory Sharing Structure:

0000000000000000: {[AutoName0 Gradient[200 x 1 x *1]] [AutoName1 Gradient[200 x 1 x *1]] [AutoName10 Gradient[200 x 1 x *1]] [AutoName11 Gradient[200 x 1 x *1]] [AutoName12 Gradient[200 x 1 x *1]] [AutoName13 Gradient[200 x 1 x *1]] [AutoName14 Gradient[200 x 1 x *1]] [AutoName15 Gradient[200 x 1 x *1]] [AutoName16 Gradient[200 x *1]] [AutoName17 Gradient[200 x 1 x *1]] [AutoName18 Gradient[200 x 1 x *1]] [AutoName19 Gradient[200 x 1 x *1]] [AutoName2 Gradient[200 x 1 x *1]] [AutoName20 Gradient[200 x 1 x *1]] [AutoName21 Gradient[200 x 1 x *1]] [AutoName22 Gradient[200 x *1]] [AutoName23 Gradient[200 x 1 x *1]] [AutoName24 Gradient[200 x 1 x *1]] [AutoName25 Gradient[200 x 1 x *1]] [AutoName26 Gradient[200 x 1 x *1]] [AutoName27 Gradient[200 x 1 x *1]] [AutoName28 Gradient[200 x 1 x *1]] [AutoName29 Gradient[200 x 1 x *1]] [AutoName3 Gradient[200 x 1 x *1]] [AutoName30 Gradient[200 x 1 x *1]] [AutoName31 Gradient[200 x *1]] [AutoName32 Gradient[200 x 1 x *1]] [AutoName33 Gradient[200 x 1 x *1]] [AutoName34 Gradient[200 x 1 x *1]] [AutoName35 Gradient[200 x 1 x *1]] [AutoName36 Gradient[200 x 1 x *1]] [AutoName37 Gradient[200 x 1 x *1]] [AutoName4 Gradient[200 x 1 x *1]] [AutoName5 Gradient[200 x 1 x *1]] [AutoName6 Gradient[200 x 1 x *1]] [AutoName7 Gradient[200 x 1 x *1]] [AutoName8 Gradient[200 x 1 x *1]] [AutoName9 Gradient[200 x *1]] [ClassPostProb Gradient[50 x 1 x *1]] [E0 Gradient[150 x 10000]] [LookupTable Gradient[150 x *1]] [PosteriorProb Gradient[10000 x 1 x *1]] [PosteriorProb Value[10000 x 1 x *1]] [TrainNodeClassBasedCrossEntropy Gradient[1]] [W2 Gradient[200 x 10000]] [WCF0 Gradient[200 x 1]] [WCI0 Gradient[200 x 1]] [WCO0 Gradient[200 x 1]] [WHC0 Gradient[200 x 200]] [WHF0 Gradient[200 x 200]] [WHI0 Gradient[200 x 200]] [WHO0 Gradient[200 x 200]] [WXC0 Gradient[200 x 150]] [WXF0 Gradient[200 x 150]] [WXI0 Gradient[200 x 150]] [WXO0 Gradient[200 x 150]] [WeightForClassPostProb Gradient[50 x 200]] [bc0 Gradient[200 x 1]] [bf0 Gradient[200 x 1]] [bi0 Gradient[200 x 1]] [bo0 Gradient[200 x 1]] [features Gradient[10000 x *1]] [labels Gradient[4 x *1]] [outputs Gradient[10000 x 1 x *1]] [outputs Value[10000 x 1 x *1]] }
000000114EC9B0A0: {[AutoName10 Value[200 x 1 x *1]] }
000000114EC9B170: {[WHI0 Value[200 x 200]] }
000000114EC9B240: {[AutoName30 Value[200 x 1 x *1]] }
000000114EC9B310: {[AutoName33 Value[200 x 1 x *1]] }
000000114EC9B3E0: {[AutoName20 Value[200 x 1 x *1]] }
000000114EC9B4B0: {[AutoName24 Value[200 x 1 x *1]] }
000000114EC9B580: {[AutoName26 Value[200 x 1 x *1]] }
000000114EC9B650: {[AutoName14 Value[200 x 1 x *1]] }
000000114EC9B720: {[WXO0 Value[200 x 150]] }
000000114EC9B7F0: {[AutoName17 Value[200 x 1 x *1]] }
000000114EC9B8C0: {[AutoName19 Value[200 x 1 x *1]] }
000000114EC9B990: {[AutoName28 Value[200 x 1 x *1]] }
000000114EC9BA60: {[AutoName32 Value[200 x 1 x *1]] }
000000114EC9BB30: {[AutoName15 Value[200 x 1 x *1]] }
000000114EC9BC00: {[LookupTable Value[150 x *1]] }
000000114EC9BCD0: {[AutoName8 Value[200 x 1 x *1]] }
000000114EC9BDA0: {[AutoName29 Value[200 x 1 x *1]] }
000000114EC9BE70: {[WXI0 Value[200 x 150]] }
000000114EC9BF40: {[AutoName31 Value[200 x *1]] }
000000114EC9C010: {[AutoName34 Value[200 x 1 x *1]] }
000000114EC9C0E0: {[AutoName25 Value[200 x 1 x *1]] }
000000114EC9C1B0: {[AutoName27 Value[200 x 1 x *1]] }
000000114EC9C280: {[AutoName13 Value[200 x 1 x *1]] }
000000114EC9C350: {[AutoName12 Value[200 x 1 x *1]] }
000000114EC9C420: {[AutoName7 Value[200 x 1 x *1]] }
000000114EC9C4F0: {[AutoName18 Value[200 x 1 x *1]] }
000000114EC9C5C0: {[WHC0 Value[200 x 200]] }
000000114EC9C690: {[AutoName21 Value[200 x 1 x *1]] }
000000114EC9C760: {[AutoName11 Value[200 x 1 x *1]] }
000000114EC9C830: {[WXF0 Value[200 x 150]] }
000000114EC9C900: {[WHF0 Value[200 x 200]] }
000000114EC9C9D0: {[TrainNodeClassBasedCrossEntropy Value[1]] }
000000114EC9CAA0: {[AutoName22 Value[200 x *1]] }
000000114EC9CB70: {[AutoName16 Value[200 x *1]] }
000000114EC9CC40: {[WeightForClassPostProb Value[50 x 200]] }
000000114EC9CD10: {[WHO0 Value[200 x 200]] }
000000114EC9CDE0: {[AutoName23 Value[200 x 1 x *1]] }
000000114EC9CEB0: {[AutoName9 Value[200 x *1]] }
000000114EC9CF80: {[WXC0 Value[200 x 150]] }
000000115542F0A0: {[bc0 Value[200 x 1]] }
000000115542F170: {[AutoName1 Value[200 x 1 x *1]] }
000000115542F240: {[bo0 Value[200 x 1]] }
000000115542F310: {[labels Value[4 x *1]] }
000000115542F3E0: {[AutoName4 Value[200 x 1 x *1]] }
000000115542F4B0: {[bi0 Value[200 x 1]] }
000000115542F580: {[WCF0 Value[200 x 1]] }
000000115542F720: {[WCI0 Value[200 x 1]] }
000000115542F7F0: {[AutoName0 Value[200 x 1 x *1]] }
000000115542F8C0: {[W2 Value[200 x 10000]] }
000000115542F990: {[WCO0 Value[200 x 1]] }
000000115542FA60: {[AutoName5 Value[200 x 1 x *1]] }
000000115542FB30: {[features Value[10000 x *1]] }
000000115542FC00: {[AutoName2 Value[200 x 1 x *1]] }
000000115542FCD0: {[bf0 Value[200 x 1]] }
000000115542FDA0: {[AutoName6 Value[200 x 1 x *1]] }
000000115542FE70: {[E0 Value[150 x 10000]] }
000000115542FF40: {[AutoName3 Value[200 x 1 x *1]] }
0000001159ACC0C0: {[AutoName37 Value[200 x 1 x *1]] }
0000001159ACC9B0: {[AutoName35 Value[200 x 1 x *1]] }
0000001159ACCDC0: {[AutoName36 Value[200 x 1 x *1]] }
0000001159ACD030: {[ClassPostProb Value[50 x 1 x *1]] }

LMSequenceReader: Reading epoch data... 3760 sequences read.
LMSequenceReader: Reading epoch data... 0 sequences read.
07/14/2016 06:01:12: Minibatch[1-60]: TrainNodeClassBasedCrossEntropy = 6.37875460 * 82402
07/14/2016 06:01:12: Final Results: Minibatch[1-60]: TrainNodeClassBasedCrossEntropy = 6.37875460 * 82402; perplexity = 589.19347092

07/14/2016 06:01:13: Action "eval" complete.

07/14/2016 06:01:13: __COMPLETED__
precision=float
command=speechTrain
deviceId=$DeviceId$

parallelTrain=false

frameMode=false
Truncated=true

speechTrain=[
    action=train
    modelPath=$RunDir$/models/cntkSpeech.dnn
    deviceId=$DeviceId$
    traceLevel=1
    
    NDLNetworkBuilder=[
        networkDescription=$NDLDir$/lstmp-3layer_WithSelfStab.ndl
    ]    
    
    SGD=[
        epochSize=20480
        minibatchSize=20
        learningRatesPerMB=0.5
        numMBsToShowResult=10
        momentumPerMB=0:0.9
        maxEpochs=4
        keepCheckPointFiles=true       
    ]
    reader=[
      readerType=HTKMLFReader
      readMethod=blockRandomize
      miniBatchMode=Partial
      nbruttsineachrecurrentiter=32
      randomize=Auto
      verbosity=0
      features=[
          dim=363
          type=Real
          scpFile=$DataDir$/glob_0000.scp
      ]
  
      labels=[
          mlfFile=$DataDir$/glob_0000.mlf
          labelMappingFile=$DataDir$/state.list
        
          labelDim=132
          labelType=Category
      ]
    ]


    # replicating the above with BrainScript   --this is 100% converted from NDL
    originalExperimentalNetworkBuilder=[

        LSTMPComponentWithSelfStab(inputDim, outputDim, cellDim, inputx) =
        [
            Wxo = Parameter(cellDim, inputDim, init='uniform', initValueScale=1, initOnCPUOnly=true, randomSeed=1); # difference to NDL: 'uniform' must be quoted as a string
            Wxi = Parameter(cellDim, inputDim, init='uniform', initValueScale=1, initOnCPUOnly=true, randomSeed=1);
            Wxf = Parameter(cellDim, inputDim, init='uniform', initValueScale=1, initOnCPUOnly=true, randomSeed=1);
            Wxc = Parameter(cellDim, inputDim, init='uniform', initValueScale=1, initOnCPUOnly=true, randomSeed=1);

            bo = Parameter(cellDim, 1, init='fixedValue', value=0.0); # difference to NDL: 'fixedValue' must be quoted as a string and is case-sensitive
            bc = Parameter(cellDim, 1, init='fixedValue', value=0.0);
            bi = Parameter(cellDim, 1, init='fixedValue', value=0.0);
            bf = Parameter(cellDim, 1, init='fixedValue', value=0.0);

            Whi = Parameter(cellDim, outputDim, init='uniform', initValueScale=1, initOnCPUOnly=true, randomSeed=1);
            Wci = Parameter(cellDim, 1, init='uniform', initValueScale=1, initOnCPUOnly=true, randomSeed=1);
            Whf = Parameter(cellDim, outputDim, init='uniform', initValueScale=1, initOnCPUOnly=true, randomSeed=1);
            Wcf = Parameter(cellDim, 1, init='uniform', initValueScale=1, initOnCPUOnly=true, randomSeed=1);
            Who = Parameter(cellDim, outputDim, init='uniform', initValueScale=1, initOnCPUOnly=true, randomSeed=1);
            Wco = Parameter(cellDim, 1, init='uniform', initValueScale=1, initOnCPUOnly=true, randomSeed=1);
            Whc = Parameter(cellDim, outputDim, init='uniform', initValueScale=1, initOnCPUOnly=true, randomSeed=1);
        
            Wmr = Parameter(outputDim, cellDim, init='uniform', initValueScale=1, initOnCPUOnly=true, randomSeed=1);
        
            #we provide a scale value for each weight
        
            sWxo = Parameter(1, 1, init='fixedValue', value=0.0);
            sWxi = Parameter(1, 1, init='fixedValue', value=0.0);
            sWxf = Parameter(1, 1, init='fixedValue', value=0.0);
            sWxc = Parameter(1, 1, init='fixedValue', value=0.0);

            sWhi = Parameter(1, 1, init='fixedValue', value=0.0);
            sWci = Parameter(1, 1, init='fixedValue', value=0.0);
        
            sWhf = Parameter(1, 1, init='fixedValue', value=0.0);
            sWcf = Parameter(1, 1, init='fixedValue', value=0.0);
            sWho = Parameter(1, 1, init='fixedValue', value=0.0);
            sWco = Parameter(1, 1, init='fixedValue', value=0.0);
            sWhc = Parameter(1, 1, init='fixedValue', value=0.0);

            sWmr = Parameter(1, 1, init='fixedValue', value=0.0);

            expsWxo = Exp(sWxo);
            expsWxi = Exp(sWxi);
            expsWxf = Exp(sWxf);
            expsWxc = Exp(sWxc);

            expsWhi = Exp(sWhi);
            expsWci = Exp(sWci);     

            expsWhf = Exp(sWhf);
            expsWcf = Exp(sWcf);
            expsWho = Exp(sWho);
            expsWco = Exp(sWco);
            expsWhc = Exp(sWhc);
        
            expsWmr = Exp(sWmr);
        
            #end of scale values        
        
            dh = PastValue(outputDim, 1, output, timeStep=1);
            dc = PastValue(cellDim, 1, ct, timeStep=1);

            Wxix = Times(Wxi, Scale(expsWxi, inputx));
            Whidh = Times(Whi, Scale(expsWhi, dh));
            Wcidc = DiagTimes(Wci, Scale(expsWci, dc));

            it = Sigmoid (Plus ( Plus (Plus (Wxix, bi), Whidh), Wcidc));

            Wxcx = Times(Wxc, Scale(expsWxc, inputx));
            Whcdh = Times(Whc, Scale(expsWhc, dh));
            bit = ElementTimes(it, Tanh( Plus(Wxcx, Plus(Whcdh, bc))));

            Wxfx = Times(Wxf, Scale(expsWxf,inputx));
            Whfdh = Times(Whf, Scale(expsWhf, dh));
            Wcfdc = DiagTimes(Wcf, Scale(expsWcf, dc));

            ft = Sigmoid( Plus (Plus (Plus(Wxfx, bf), Whfdh), Wcfdc));

            bft = ElementTimes(ft, dc);

            ct = Plus(bft, bit);

            Wxox  = Times(Wxo, Scale(expsWxo, inputx));
            Whodh = Times(Who, Scale(expsWho, dh));
            Wcoct = DiagTimes(Wco, Scale(expsWco, ct));

            ot = Sigmoid( Plus( Plus( Plus(Wxox, bo), Whodh), Wcoct));

            mt = ElementTimes(ot, Tanh(ct));

            output = Times(Wmr, Scale(expsWmr, mt)); 
        ]

        #define basic i/o
        baseFeatDim=33
        RowSliceStart=330 
        FeatDim=363
        labelDim=132
        cellDim=1024
        hiddenDim=256

        features=Input(FeatDim, 1, tag='feature')     # differences to NDL: needs the '1'; tag value must be quoted as a string
        labels=Input(labelDim, 1, tag='label')
        feashift=RowSlice(RowSliceStart, baseFeatDim, features);      # shift 5 frames right (x_{t+5} -> x_{t} )


        featNorm = MeanVarNorm(feashift)


        # layer 1
        LSTMoutput1 = LSTMPComponentWithSelfStab(baseFeatDim, hiddenDim, cellDim, featNorm);
        # layer 2 
        LSTMoutput2 = LSTMPComponentWithSelfStab(hiddenDim, hiddenDim, cellDim, LSTMoutput1.output);    # difference to NDL: LSTMoutput1 is a record, must select the output field explicitly
        # layer 3 
        LSTMoutput3 = LSTMPComponentWithSelfStab(hiddenDim, hiddenDim, cellDim, LSTMoutput2.output);

        W = Parameter(labelDim, hiddenDim, init='uniform', initValueScale=1, initOnCPUOnly=true, randomSeed=1);
        b = Parameter(labelDim, 1, init='fixedValue', value=0);
        
        sW = Parameter(1, 1, init='fixedValue', value=0.0);
        expsW = Exp(sW);

        LSTMoutputW = Plus(Times(W, Scale(expsW, LSTMoutput3.output)), b);
        
        cr = CrossEntropyWithSoftmax(labels, LSTMoutputW,tag='criteria');  # differences to NDL: string must be quoted; value is case-sensitive
        Err = ErrorPrediction(labels,LSTMoutputW,tag='eval');
    
        logPrior = LogPrior(labels)	 
        ScaledLogLikelihood=Minus(LSTMoutputW,logPrior,tag='output')
    ]


    # replicating the above with BrainScript  --we will put stuff here
    ExperimentalNetworkBuilder=[

        void = 0        // (BUGBUG: we do not allow zero-argument macros; will be fixed. For now, pass void)
        
        WeightParam(m,n) = Parameter(m, n, init='uniform', initValueScale=1, initOnCPUOnly=true, randomSeed=1)
        BiasParam(m) = Parameter(m, 1, init='fixedValue', value=0.0)
        ScalarParam(void) = Parameter(1, 1, init='fixedValue', value=0.0)

        NewBeta(void) = Exp(ScalarParam(void))
        Stabilize(in) = Scale(NewBeta(void), in)

        LSTMPComponentWithSelfStab(inputDim, outputDim, cellDim, inputx) =
        [
            // parameter macros--these carry their own weight matrices
            B(void) = BiasParam(cellDim)
            Wmr = WeightParam(outputDim, cellDim);

            W(v) = WeightParam(cellDim, inputDim) * Stabilize(v)    // input-to-hidden
            H(h) = WeightParam(cellDim, outputDim) * Stabilize(h)   // hidden-to-hidden
            C(c) = DiagTimes(WeightParam(cellDim, 1), Stabilize(c)) // cell-to-hiddden

            // LSTM cell
            dh = PastValue(outputDim, 1, output);                   // hidden state(t-1)
            dc = PastValue(cellDim, 1, ct);                         // cell(t-1)

            // note: the W(inputx) here are all different, they all come with their own set of weights; same for H(dh), C(dc), and B()
            it = Sigmoid(W(inputx) + B(void) + H(dh) + C(dc))       // input gate(t)
            bit = it .* Tanh(W(inputx) + (H(dh) + B(void)))         // applied to tanh of input network

            ft = Sigmoid(W(inputx) + B(void) + H(dh) + C(dc))       // forget-me-not gate(t)
            bft = ft .* dc                                          // applied to cell(t-1)

            ct = bft + bit                                          // c(t) is sum of both

            ot = Sigmoid(W(inputx) + B(void) + H(dh) + C(ct))       // output gate(t)
            mt = ot .* Tanh(ct)                                     // applied to tanh(cell(t))

            output = Wmr * Stabilize(mt)                            // projection
        ]

        // define basic I/O
        baseFeatDim = 33
        featDim = 11 * baseFeatDim      // TODO: 363--is this the correct explanation?
        labelDim = 132

        // hidden dimensions
        cellDim = 1024
        hiddenDim = 256
        numLSTMs = 3        // number of hidden LSTM model layers

        // features
        features = Input(featDim, 1, tag='feature')
        labels = Input(labelDim, 1, tag='label')
        feashift = RowSlice(featDim - baseFeatDim, baseFeatDim, features);      # shift 5 frames right (x_{t+5} -> x_{t} )  // TODO why 5? Where do I see this?

        featNorm = MeanVarNorm(feashift)

        // define the stack of hidden LSTM layers
        LSTMoutput[k:1..numLSTMs] = if k == 1
                                    then LSTMPComponentWithSelfStab(baseFeatDim, hiddenDim, cellDim, featNorm)
                                    else LSTMPComponentWithSelfStab(hiddenDim,   hiddenDim, cellDim, LSTMoutput[k-1].output)

        // and add a softmax layer on top
        W(in) = WeightParam(labelDim, hiddenDim) * Stabilize(in)
        B = BiasParam(labelDim)
        
        LSTMoutputW = W(LSTMoutput[numLSTMs].output) + B;

        // training
        cr = CrossEntropyWithSoftmax(labels, LSTMoutputW, tag='criterion')  // this is the objective
        Err = ErrorPrediction(labels, LSTMoutputW, tag='eval')              // this also gets tracked

        // decoding
        logPrior = LogPrior(labels)	 
        ScaledLogLikelihood = Minus(LSTMoutputW, logPrior, tag='output')    // sadly we can't say x - y since we want to assign a tag
    ]
]

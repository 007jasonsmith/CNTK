=== Running /home/alrezni/src/cntk/build/release/bin/cntk configFile=/home/alrezni/src/cntk/Tests/Speech/DNN/SequenceTraining/cntk_sequence.config currentDirectory=/tmp/cntk-test-20151216094712.720058/Speech/DNN_SequenceTraining@release_cpu/TestData RunDir=/tmp/cntk-test-20151216094712.720058/Speech/DNN_SequenceTraining@release_cpu DataDir=/tmp/cntk-test-20151216094712.720058/Speech/DNN_SequenceTraining@release_cpu/TestData ConfigDir=/home/alrezni/src/cntk/Tests/Speech/DNN/SequenceTraining DeviceId=-1
-------------------------------------------------------------------
Build info: 

		Built time: Dec 15 2015 16:32:52
		Last modified date: Tue Dec 15 16:31:42 2015
		Build type: release
		Math lib: acml
		CUDA_PATH: /usr/local/cuda-7.0
		CUB_PATH: /usr/local/cub-1.4.1
		Build Branch: master
		Build SHA1: 5e0017ac9c55c23d53cb524c8acb7d6d9bfd0269
-------------------------------------------------------------------
running on localhost at 2015/12/16 10:26:24
command line: 
/home/alrezni/src/cntk/build/release/bin/cntk configFile=/home/alrezni/src/cntk/Tests/Speech/DNN/SequenceTraining/cntk_sequence.config currentDirectory=/tmp/cntk-test-20151216094712.720058/Speech/DNN_SequenceTraining@release_cpu/TestData RunDir=/tmp/cntk-test-20151216094712.720058/Speech/DNN_SequenceTraining@release_cpu DataDir=/tmp/cntk-test-20151216094712.720058/Speech/DNN_SequenceTraining@release_cpu/TestData ConfigDir=/home/alrezni/src/cntk/Tests/Speech/DNN/SequenceTraining DeviceId=-1 

>>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
precision = "float"
deviceId = $DeviceId$
command = dptPre1:addLayer2:dptPre2:addLayer3:speechTrain:replaceCriterionNode:sequenceTrain
ndlMacros = "$ConfigDir$/macros.txt"
globalMeanPath   = "GlobalStats/mean.363"
globalInvStdPath = "GlobalStats/var.363"
globalPriorPath  = "GlobalStats/prior.132"
traceLevel = 1
truncated = false
SGD = [
    epochSize = 81920
    minibatchSize = 256
    learningRatesPerMB = 0.8
    numMBsToShowResult = 10
    momentumPerMB = 0.9
    dropoutRate = 0.0
    maxEpochs = 2
]
dptPre1 = [
    action = "train"
    modelPath = "$RunDir$/models/Pre1/cntkSpeech"
    NDLNetworkBuilder = [
        networkDescription = "$ConfigDir$/dnn_1layer.txt"
    ]
]
addLayer2 = [    
    action = "edit"
    currLayer = 1
    newLayer = 2
    currModel = "$RunDir$/models/Pre1/cntkSpeech"
    newModel  = "$RunDir$/models/Pre2/cntkSpeech.0"
    editPath  = "$ConfigDir$/add_layer.mel"
]
dptPre2 = [
    action = "train"
    modelPath = "$RunDir$/models/Pre2/cntkSpeech"
    NDLNetworkBuilder = [
        networkDescription = "$ConfigDir$/dnn_1layer.txt"
    ]
]
AddLayer3 = [    
    action = "edit"
    currLayer = 2
    newLayer = 3
    currModel = "$RunDir$/models/Pre2/cntkSpeech"
    newModel  = "$RunDir$/models/cntkSpeech.0"
    editPath  = "$ConfigDir$/add_layer.mel"
]
speechTrain = [
    action = "train"
    modelPath = "$RunDir$/models/cntkSpeech"
    traceLevel = 1
    NDLNetworkBuilder = [
        networkDescription = "$ConfigDir$/dnn.txt"
    ]
    SGD = [
        epochSize = 81920
        minibatchSize = 256:512
        learningRatesPerMB = 0.8:1.6
        numMBsToShowResult = 10
        momentumPerSample = 0.999589
        dropoutRate = 0.0
        maxEpochs = 4
        gradUpdateType = "none"
        normWithAveMultiplier = true
        clippingThresholdPerSample = 1#INF
    ]
]
reader = [
    readerType = "HTKMLFReader"
    readMethod = "blockRandomize"
    miniBatchMode = "partial"
    randomize = "auto"
    verbosity = 0
    features = [
        dim = 363
        type = "real"
        scpFile = "$DataDir$/glob_0000.scp"
    ]
    labels = [
        mlfFile = "$DataDir$/glob_0000.mlf"
        labelMappingFile = "$DataDir$/state.list"
        labelDim = 132
        labelType = "category"
    ]
]
replaceCriterionNode = [
    action = "edit"
    currModel = "$RunDir$/models/cntkSpeech"
    newModel  = "$RunDir$/models/cntkSpeech.sequence.0"
    editPath  = "$ConfigDir$/replace_ce_with_sequence_criterion.mel"
]
sequenceTrain = [
    action = "train"
    modelPath = "$RunDir$/models/cntkSpeech.sequence"
    traceLevel = 1
    NDLNetworkBuilder = [
        networkDescription = "$ConfigDir$/nonexistentfile.txt"
    ]
    SGD = [
        epochSize = 81920
        minibatchSize = 10
        learningRatesPerSample = 0.000002
        momentumPerSample = 0.999589
        dropoutRate = 0.0
        maxEpochs = 3
        hsmoothingWeight = 0.95
        frameDropThresh = 1e-10
        numMBsToShowResult = 10
        gradientClippingWithTruncation = true
        clippingThresholdPerSample = 1.0
    ]
    reader = [
        readerType = "HTKMLFReader"
        readMethod = "blockRandomize"
        frameMode = false
        nbruttsineachrecurrentiter = 2
        miniBatchMode = "partial"
        randomize = "auto"
        verbosity = 0
        features = [
            dim = 363
            type = "real"
            scpFile = "$DataDir$/glob_0000.scp"
        ]
        labels = [
            mlfFile = "$DataDir$/glob_0000.mlf"
            labelMappingFile = "$DataDir$/state.list"
            labelDim = 132
            labelType = "category"
        ]
        hmms = [
            phoneFile  = "$DataDir$/model.overalltying"
            transpFile = "$DataDir$/model.transprob"
        ]
        lattices = [
            denlatTocFile = "$DataDir$/*.lats.toc"
        ]
    ]
]
currentDirectory=/tmp/cntk-test-20151216094712.720058/Speech/DNN_SequenceTraining@release_cpu/TestData
RunDir=/tmp/cntk-test-20151216094712.720058/Speech/DNN_SequenceTraining@release_cpu
DataDir=/tmp/cntk-test-20151216094712.720058/Speech/DNN_SequenceTraining@release_cpu/TestData
ConfigDir=/home/alrezni/src/cntk/Tests/Speech/DNN/SequenceTraining
DeviceId=-1

<<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<

>>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
precision = "float"
deviceId = -1
command = dptPre1:addLayer2:dptPre2:addLayer3:speechTrain:replaceCriterionNode:sequenceTrain
ndlMacros = "/home/alrezni/src/cntk/Tests/Speech/DNN/SequenceTraining/macros.txt"
globalMeanPath   = "GlobalStats/mean.363"
globalInvStdPath = "GlobalStats/var.363"
globalPriorPath  = "GlobalStats/prior.132"
traceLevel = 1
truncated = false
SGD = [
    epochSize = 81920
    minibatchSize = 256
    learningRatesPerMB = 0.8
    numMBsToShowResult = 10
    momentumPerMB = 0.9
    dropoutRate = 0.0
    maxEpochs = 2
]
dptPre1 = [
    action = "train"
    modelPath = "/tmp/cntk-test-20151216094712.720058/Speech/DNN_SequenceTraining@release_cpu/models/Pre1/cntkSpeech"
    NDLNetworkBuilder = [
        networkDescription = "/home/alrezni/src/cntk/Tests/Speech/DNN/SequenceTraining/dnn_1layer.txt"
    ]
]
addLayer2 = [    
    action = "edit"
    currLayer = 1
    newLayer = 2
    currModel = "/tmp/cntk-test-20151216094712.720058/Speech/DNN_SequenceTraining@release_cpu/models/Pre1/cntkSpeech"
    newModel  = "/tmp/cntk-test-20151216094712.720058/Speech/DNN_SequenceTraining@release_cpu/models/Pre2/cntkSpeech.0"
    editPath  = "/home/alrezni/src/cntk/Tests/Speech/DNN/SequenceTraining/add_layer.mel"
]
dptPre2 = [
    action = "train"
    modelPath = "/tmp/cntk-test-20151216094712.720058/Speech/DNN_SequenceTraining@release_cpu/models/Pre2/cntkSpeech"
    NDLNetworkBuilder = [
        networkDescription = "/home/alrezni/src/cntk/Tests/Speech/DNN/SequenceTraining/dnn_1layer.txt"
    ]
]
AddLayer3 = [    
    action = "edit"
    currLayer = 2
    newLayer = 3
    currModel = "/tmp/cntk-test-20151216094712.720058/Speech/DNN_SequenceTraining@release_cpu/models/Pre2/cntkSpeech"
    newModel  = "/tmp/cntk-test-20151216094712.720058/Speech/DNN_SequenceTraining@release_cpu/models/cntkSpeech.0"
    editPath  = "/home/alrezni/src/cntk/Tests/Speech/DNN/SequenceTraining/add_layer.mel"
]
speechTrain = [
    action = "train"
    modelPath = "/tmp/cntk-test-20151216094712.720058/Speech/DNN_SequenceTraining@release_cpu/models/cntkSpeech"
    traceLevel = 1
    NDLNetworkBuilder = [
        networkDescription = "/home/alrezni/src/cntk/Tests/Speech/DNN/SequenceTraining/dnn.txt"
    ]
    SGD = [
        epochSize = 81920
        minibatchSize = 256:512
        learningRatesPerMB = 0.8:1.6
        numMBsToShowResult = 10
        momentumPerSample = 0.999589
        dropoutRate = 0.0
        maxEpochs = 4
        gradUpdateType = "none"
        normWithAveMultiplier = true
        clippingThresholdPerSample = 1#INF
    ]
]
reader = [
    readerType = "HTKMLFReader"
    readMethod = "blockRandomize"
    miniBatchMode = "partial"
    randomize = "auto"
    verbosity = 0
    features = [
        dim = 363
        type = "real"
        scpFile = "/tmp/cntk-test-20151216094712.720058/Speech/DNN_SequenceTraining@release_cpu/TestData/glob_0000.scp"
    ]
    labels = [
        mlfFile = "/tmp/cntk-test-20151216094712.720058/Speech/DNN_SequenceTraining@release_cpu/TestData/glob_0000.mlf"
        labelMappingFile = "/tmp/cntk-test-20151216094712.720058/Speech/DNN_SequenceTraining@release_cpu/TestData/state.list"
        labelDim = 132
        labelType = "category"
    ]
]
replaceCriterionNode = [
    action = "edit"
    currModel = "/tmp/cntk-test-20151216094712.720058/Speech/DNN_SequenceTraining@release_cpu/models/cntkSpeech"
    newModel  = "/tmp/cntk-test-20151216094712.720058/Speech/DNN_SequenceTraining@release_cpu/models/cntkSpeech.sequence.0"
    editPath  = "/home/alrezni/src/cntk/Tests/Speech/DNN/SequenceTraining/replace_ce_with_sequence_criterion.mel"
]
sequenceTrain = [
    action = "train"
    modelPath = "/tmp/cntk-test-20151216094712.720058/Speech/DNN_SequenceTraining@release_cpu/models/cntkSpeech.sequence"
    traceLevel = 1
    NDLNetworkBuilder = [
        networkDescription = "/home/alrezni/src/cntk/Tests/Speech/DNN/SequenceTraining/nonexistentfile.txt"
    ]
    SGD = [
        epochSize = 81920
        minibatchSize = 10
        learningRatesPerSample = 0.000002
        momentumPerSample = 0.999589
        dropoutRate = 0.0
        maxEpochs = 3
        hsmoothingWeight = 0.95
        frameDropThresh = 1e-10
        numMBsToShowResult = 10
        gradientClippingWithTruncation = true
        clippingThresholdPerSample = 1.0
    ]
    reader = [
        readerType = "HTKMLFReader"
        readMethod = "blockRandomize"
        frameMode = false
        nbruttsineachrecurrentiter = 2
        miniBatchMode = "partial"
        randomize = "auto"
        verbosity = 0
        features = [
            dim = 363
            type = "real"
            scpFile = "/tmp/cntk-test-20151216094712.720058/Speech/DNN_SequenceTraining@release_cpu/TestData/glob_0000.scp"
        ]
        labels = [
            mlfFile = "/tmp/cntk-test-20151216094712.720058/Speech/DNN_SequenceTraining@release_cpu/TestData/glob_0000.mlf"
            labelMappingFile = "/tmp/cntk-test-20151216094712.720058/Speech/DNN_SequenceTraining@release_cpu/TestData/state.list"
            labelDim = 132
            labelType = "category"
        ]
        hmms = [
            phoneFile  = "/tmp/cntk-test-20151216094712.720058/Speech/DNN_SequenceTraining@release_cpu/TestData/model.overalltying"
            transpFile = "/tmp/cntk-test-20151216094712.720058/Speech/DNN_SequenceTraining@release_cpu/TestData/model.transprob"
        ]
        lattices = [
            denlatTocFile = "/tmp/cntk-test-20151216094712.720058/Speech/DNN_SequenceTraining@release_cpu/TestData/*.lats.toc"
        ]
    ]
]
currentDirectory=/tmp/cntk-test-20151216094712.720058/Speech/DNN_SequenceTraining@release_cpu/TestData
RunDir=/tmp/cntk-test-20151216094712.720058/Speech/DNN_SequenceTraining@release_cpu
DataDir=/tmp/cntk-test-20151216094712.720058/Speech/DNN_SequenceTraining@release_cpu/TestData
ConfigDir=/home/alrezni/src/cntk/Tests/Speech/DNN/SequenceTraining
DeviceId=-1

<<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<

>>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
configparameters: cntk_sequence.config:addLayer2=[    
    action = "edit"
    currLayer = 1
    newLayer = 2
    currModel = "/tmp/cntk-test-20151216094712.720058/Speech/DNN_SequenceTraining@release_cpu/models/Pre1/cntkSpeech"
    newModel  = "/tmp/cntk-test-20151216094712.720058/Speech/DNN_SequenceTraining@release_cpu/models/Pre2/cntkSpeech.0"
    editPath  = "/home/alrezni/src/cntk/Tests/Speech/DNN/SequenceTraining/add_layer.mel"
]

configparameters: cntk_sequence.config:AddLayer3=[    
    action = "edit"
    currLayer = 2
    newLayer = 3
    currModel = "/tmp/cntk-test-20151216094712.720058/Speech/DNN_SequenceTraining@release_cpu/models/Pre2/cntkSpeech"
    newModel  = "/tmp/cntk-test-20151216094712.720058/Speech/DNN_SequenceTraining@release_cpu/models/cntkSpeech.0"
    editPath  = "/home/alrezni/src/cntk/Tests/Speech/DNN/SequenceTraining/add_layer.mel"
]

configparameters: cntk_sequence.config:command=dptPre1:addLayer2:dptPre2:addLayer3:speechTrain:replaceCriterionNode:sequenceTrain
configparameters: cntk_sequence.config:ConfigDir=/home/alrezni/src/cntk/Tests/Speech/DNN/SequenceTraining
configparameters: cntk_sequence.config:currentDirectory=/tmp/cntk-test-20151216094712.720058/Speech/DNN_SequenceTraining@release_cpu/TestData
configparameters: cntk_sequence.config:DataDir=/tmp/cntk-test-20151216094712.720058/Speech/DNN_SequenceTraining@release_cpu/TestData
configparameters: cntk_sequence.config:deviceId=-1
configparameters: cntk_sequence.config:dptPre1=[
    action = "train"
    modelPath = "/tmp/cntk-test-20151216094712.720058/Speech/DNN_SequenceTraining@release_cpu/models/Pre1/cntkSpeech"
    NDLNetworkBuilder = [
        networkDescription = "/home/alrezni/src/cntk/Tests/Speech/DNN/SequenceTraining/dnn_1layer.txt"
    ]
]

configparameters: cntk_sequence.config:dptPre2=[
    action = "train"
    modelPath = "/tmp/cntk-test-20151216094712.720058/Speech/DNN_SequenceTraining@release_cpu/models/Pre2/cntkSpeech"
    NDLNetworkBuilder = [
        networkDescription = "/home/alrezni/src/cntk/Tests/Speech/DNN/SequenceTraining/dnn_1layer.txt"
    ]
]

configparameters: cntk_sequence.config:globalInvStdPath=GlobalStats/var.363
configparameters: cntk_sequence.config:globalMeanPath=GlobalStats/mean.363
configparameters: cntk_sequence.config:globalPriorPath=GlobalStats/prior.132
configparameters: cntk_sequence.config:ndlMacros=/home/alrezni/src/cntk/Tests/Speech/DNN/SequenceTraining/macros.txt
configparameters: cntk_sequence.config:precision=float
configparameters: cntk_sequence.config:reader=[
    readerType = "HTKMLFReader"
    readMethod = "blockRandomize"
    miniBatchMode = "partial"
    randomize = "auto"
    verbosity = 0
    features = [
        dim = 363
        type = "real"
        scpFile = "/tmp/cntk-test-20151216094712.720058/Speech/DNN_SequenceTraining@release_cpu/TestData/glob_0000.scp"
    ]
    labels = [
        mlfFile = "/tmp/cntk-test-20151216094712.720058/Speech/DNN_SequenceTraining@release_cpu/TestData/glob_0000.mlf"
        labelMappingFile = "/tmp/cntk-test-20151216094712.720058/Speech/DNN_SequenceTraining@release_cpu/TestData/state.list"
        labelDim = 132
        labelType = "category"
    ]
]

configparameters: cntk_sequence.config:replaceCriterionNode=[
    action = "edit"
    currModel = "/tmp/cntk-test-20151216094712.720058/Speech/DNN_SequenceTraining@release_cpu/models/cntkSpeech"
    newModel  = "/tmp/cntk-test-20151216094712.720058/Speech/DNN_SequenceTraining@release_cpu/models/cntkSpeech.sequence.0"
    editPath  = "/home/alrezni/src/cntk/Tests/Speech/DNN/SequenceTraining/replace_ce_with_sequence_criterion.mel"
]

configparameters: cntk_sequence.config:RunDir=/tmp/cntk-test-20151216094712.720058/Speech/DNN_SequenceTraining@release_cpu
configparameters: cntk_sequence.config:sequenceTrain=[
    action = "train"
    modelPath = "/tmp/cntk-test-20151216094712.720058/Speech/DNN_SequenceTraining@release_cpu/models/cntkSpeech.sequence"
    traceLevel = 1
    NDLNetworkBuilder = [
        networkDescription = "/home/alrezni/src/cntk/Tests/Speech/DNN/SequenceTraining/nonexistentfile.txt"
    ]
    SGD = [
        epochSize = 81920
        minibatchSize = 10
        learningRatesPerSample = 0.000002
        momentumPerSample = 0.999589
        dropoutRate = 0.0
        maxEpochs = 3
        hsmoothingWeight = 0.95
        frameDropThresh = 1e-10
        numMBsToShowResult = 10
        gradientClippingWithTruncation = true
        clippingThresholdPerSample = 1.0
    ]
    reader = [
        readerType = "HTKMLFReader"
        readMethod = "blockRandomize"
        frameMode = false
        nbruttsineachrecurrentiter = 2
        miniBatchMode = "partial"
        randomize = "auto"
        verbosity = 0
        features = [
            dim = 363
            type = "real"
            scpFile = "/tmp/cntk-test-20151216094712.720058/Speech/DNN_SequenceTraining@release_cpu/TestData/glob_0000.scp"
        ]
        labels = [
            mlfFile = "/tmp/cntk-test-20151216094712.720058/Speech/DNN_SequenceTraining@release_cpu/TestData/glob_0000.mlf"
            labelMappingFile = "/tmp/cntk-test-20151216094712.720058/Speech/DNN_SequenceTraining@release_cpu/TestData/state.list"
            labelDim = 132
            labelType = "category"
        ]
        hmms = [
            phoneFile  = "/tmp/cntk-test-20151216094712.720058/Speech/DNN_SequenceTraining@release_cpu/TestData/model.overalltying"
            transpFile = "/tmp/cntk-test-20151216094712.720058/Speech/DNN_SequenceTraining@release_cpu/TestData/model.transprob"
        ]
        lattices = [
            denlatTocFile = "/tmp/cntk-test-20151216094712.720058/Speech/DNN_SequenceTraining@release_cpu/TestData/*.lats.toc"
        ]
    ]
]

configparameters: cntk_sequence.config:SGD=[
    epochSize = 81920
    minibatchSize = 256
    learningRatesPerMB = 0.8
    numMBsToShowResult = 10
    momentumPerMB = 0.9
    dropoutRate = 0.0
    maxEpochs = 2
]

configparameters: cntk_sequence.config:speechTrain=[
    action = "train"
    modelPath = "/tmp/cntk-test-20151216094712.720058/Speech/DNN_SequenceTraining@release_cpu/models/cntkSpeech"
    traceLevel = 1
    NDLNetworkBuilder = [
        networkDescription = "/home/alrezni/src/cntk/Tests/Speech/DNN/SequenceTraining/dnn.txt"
    ]
    SGD = [
        epochSize = 81920
        minibatchSize = 256:512
        learningRatesPerMB = 0.8:1.6
        numMBsToShowResult = 10
        momentumPerSample = 0.999589
        dropoutRate = 0.0
        maxEpochs = 4
        gradUpdateType = "none"
        normWithAveMultiplier = true
        clippingThresholdPerSample = 1#INF
    ]
]

configparameters: cntk_sequence.config:traceLevel=1
configparameters: cntk_sequence.config:truncated=false
<<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
command: dptPre1 addLayer2 dptPre2 addLayer3 speechTrain replaceCriterionNode sequenceTrain 
precision = float
CNTKModelPath: /tmp/cntk-test-20151216094712.720058/Speech/DNN_SequenceTraining@release_cpu/models/Pre1/cntkSpeech
CNTKCommandTrainInfo: dptPre1 : 2
CNTKModelPath: /tmp/cntk-test-20151216094712.720058/Speech/DNN_SequenceTraining@release_cpu/models/Pre2/cntkSpeech
CNTKCommandTrainInfo: dptPre2 : 2
CNTKModelPath: /tmp/cntk-test-20151216094712.720058/Speech/DNN_SequenceTraining@release_cpu/models/cntkSpeech
CNTKCommandTrainInfo: speechTrain : 4
CNTKModelPath: /tmp/cntk-test-20151216094712.720058/Speech/DNN_SequenceTraining@release_cpu/models/cntkSpeech.sequence
CNTKCommandTrainInfo: sequenceTrain : 3
CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 11
CNTKCommandTrainBegin: dptPre1
NDLBuilder Using CPU
reading script file /tmp/cntk-test-20151216094712.720058/Speech/DNN_SequenceTraining@release_cpu/TestData/glob_0000.scp ... 948 entries
total 132 state names in state list /tmp/cntk-test-20151216094712.720058/Speech/DNN_SequenceTraining@release_cpu/TestData/state.list
htkmlfreader: reading MLF file /tmp/cntk-test-20151216094712.720058/Speech/DNN_SequenceTraining@release_cpu/TestData/glob_0000.mlf ... total 948 entries
...............................................................................................feature set 0: 252734 frames in 948 out of 948 utterances
label set 0: 129 classes
minibatchutterancesource: 948 utterances grouped into 3 chunks, av. chunk size: 316.0 utterances, 84244.7 frames

Post-processing network...

3 roots:
	scaledLogLikelihood = Minus
	cr = CrossEntropyWithSoftmax
	err = ErrorPrediction
FormNestedNetwork: WARNING: Was called twice for scaledLogLikelihood Minus operation
FormNestedNetwork: WARNING: Was called twice for cr CrossEntropyWithSoftmax operation
FormNestedNetwork: WARNING: Was called twice for err ErrorPrediction operation


Validating for node scaledLogLikelihood. 16 nodes to process in pass 1.

Validating --> OL.W = LearnableParameter -> [132, 512]
Validating --> HL1.W = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 1]
Validating --> globalMean = LearnableParameter -> [363, 1]
Validating --> globalInvStd = LearnableParameter -> [363, 1]
Validating --> featNorm = PerDimMeanVarNormalization(features[363, MBSize 1], globalMean[363, 1], globalInvStd[363, 1]) -> [363, MBSize 1]
Validating --> HL1.t = Times(HL1.W[512, 363], featNorm[363, MBSize 1]) -> [512, MBSize 1]
Validating --> HL1.b = LearnableParameter -> [512, 1]
Validating --> HL1.z = Plus(HL1.t[512, MBSize 1], HL1.b[512, 1]) -> [512, MBSize 0]
Validating --> HL1.y = Sigmoid(HL1.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> OL.t = Times(OL.W[132, 512], HL1.y[512, MBSize 0]) -> [132, MBSize 0]
Validating --> OL.b = LearnableParameter -> [132, 1]
Validating --> OL.z = Plus(OL.t[132, MBSize 0], OL.b[132, 1]) -> [132, MBSize 0]
Validating --> globalPrior = LearnableParameter -> [132, 1]
Validating --> logPrior = Log(globalPrior[132, 1]) -> [132, 1]
Validating --> scaledLogLikelihood = Minus(OL.z[132, MBSize 0], logPrior[132, 1]) -> [132, MBSize 0]

Validating for node scaledLogLikelihood. 8 nodes to process in pass 2.

Validating --> OL.W = LearnableParameter -> [132, 512]
Validating --> HL1.W = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 1]
Validating --> globalMean = LearnableParameter -> [363, 1]
Validating --> globalInvStd = LearnableParameter -> [363, 1]
Validating --> featNorm = PerDimMeanVarNormalization(features[363, MBSize 1], globalMean[363, 1], globalInvStd[363, 1]) -> [363, MBSize 1]
Validating --> HL1.t = Times(HL1.W[512, 363], featNorm[363, MBSize 1]) -> [512, MBSize 1]
Validating --> HL1.b = LearnableParameter -> [512, 1]
Validating --> HL1.z = Plus(HL1.t[512, MBSize 1], HL1.b[512, 1]) -> [512, MBSize 0]
Validating --> HL1.y = Sigmoid(HL1.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> OL.t = Times(OL.W[132, 512], HL1.y[512, MBSize 0]) -> [132, MBSize 0]
Validating --> OL.b = LearnableParameter -> [132, 1]
Validating --> OL.z = Plus(OL.t[132, MBSize 0], OL.b[132, 1]) -> [132, MBSize 0]
Validating --> globalPrior = LearnableParameter -> [132, 1]
Validating --> logPrior = Log(globalPrior[132, 1]) -> [132, 1]
Validating --> scaledLogLikelihood = Minus(OL.z[132, MBSize 0], logPrior[132, 1]) -> [132, MBSize 0]

Validating for node scaledLogLikelihood, final verification.

Validating --> OL.W = LearnableParameter -> [132, 512]
Validating --> HL1.W = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 1]
Validating --> globalMean = LearnableParameter -> [363, 1]
Validating --> globalInvStd = LearnableParameter -> [363, 1]
Validating --> featNorm = PerDimMeanVarNormalization(features[363, MBSize 1], globalMean[363, 1], globalInvStd[363, 1]) -> [363, MBSize 1]
Validating --> HL1.t = Times(HL1.W[512, 363], featNorm[363, MBSize 1]) -> [512, MBSize 1]
Validating --> HL1.b = LearnableParameter -> [512, 1]
Validating --> HL1.z = Plus(HL1.t[512, MBSize 1], HL1.b[512, 1]) -> [512, MBSize 0]
Validating --> HL1.y = Sigmoid(HL1.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> OL.t = Times(OL.W[132, 512], HL1.y[512, MBSize 0]) -> [132, MBSize 0]
Validating --> OL.b = LearnableParameter -> [132, 1]
Validating --> OL.z = Plus(OL.t[132, MBSize 0], OL.b[132, 1]) -> [132, MBSize 0]
Validating --> globalPrior = LearnableParameter -> [132, 1]
Validating --> logPrior = Log(globalPrior[132, 1]) -> [132, 1]
Validating --> scaledLogLikelihood = Minus(OL.z[132, MBSize 0], logPrior[132, 1]) -> [132, MBSize 0]

8 out of 16 nodes do not share the minibatch layout with the input data.


Validating for node cr. 15 nodes to process in pass 1.

Validating --> labels = InputValue -> [132, MBSize 1]
Validating --> OL.W = LearnableParameter -> [132, 512]
Validating --> HL1.W = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 1]
Validating --> globalMean = LearnableParameter -> [363, 1]
Validating --> globalInvStd = LearnableParameter -> [363, 1]
Validating --> featNorm = PerDimMeanVarNormalization(features[363, MBSize 1], globalMean[363, 1], globalInvStd[363, 1]) -> [363, MBSize 1]
Validating --> HL1.t = Times(HL1.W[512, 363], featNorm[363, MBSize 1]) -> [512, MBSize 1]
Validating --> HL1.b = LearnableParameter -> [512, 1]
Validating --> HL1.z = Plus(HL1.t[512, MBSize 1], HL1.b[512, 1]) -> [512, MBSize 0]
Validating --> HL1.y = Sigmoid(HL1.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> OL.t = Times(OL.W[132, 512], HL1.y[512, MBSize 0]) -> [132, MBSize 0]
Validating --> OL.b = LearnableParameter -> [132, 1]
Validating --> OL.z = Plus(OL.t[132, MBSize 0], OL.b[132, 1]) -> [132, MBSize 0]
Validating --> cr = CrossEntropyWithSoftmax(labels[132, MBSize 1], OL.z[132, MBSize 0]) -> [1, 1]

Validating for node cr. 6 nodes to process in pass 2.

Validating --> labels = InputValue -> [132, MBSize 1]
Validating --> OL.W = LearnableParameter -> [132, 512]
Validating --> HL1.W = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 1]
Validating --> globalMean = LearnableParameter -> [363, 1]
Validating --> globalInvStd = LearnableParameter -> [363, 1]
Validating --> featNorm = PerDimMeanVarNormalization(features[363, MBSize 1], globalMean[363, 1], globalInvStd[363, 1]) -> [363, MBSize 1]
Validating --> HL1.t = Times(HL1.W[512, 363], featNorm[363, MBSize 1]) -> [512, MBSize 1]
Validating --> HL1.b = LearnableParameter -> [512, 1]
Validating --> HL1.z = Plus(HL1.t[512, MBSize 1], HL1.b[512, 1]) -> [512, MBSize 0]
Validating --> HL1.y = Sigmoid(HL1.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> OL.t = Times(OL.W[132, 512], HL1.y[512, MBSize 0]) -> [132, MBSize 0]
Validating --> OL.b = LearnableParameter -> [132, 1]
Validating --> OL.z = Plus(OL.t[132, MBSize 0], OL.b[132, 1]) -> [132, MBSize 0]
Validating --> cr = CrossEntropyWithSoftmax(labels[132, MBSize 1], OL.z[132, MBSize 0]) -> [1, 1]

Validating for node cr, final verification.

Validating --> labels = InputValue -> [132, MBSize 1]
Validating --> OL.W = LearnableParameter -> [132, 512]
Validating --> HL1.W = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 1]
Validating --> globalMean = LearnableParameter -> [363, 1]
Validating --> globalInvStd = LearnableParameter -> [363, 1]
Validating --> featNorm = PerDimMeanVarNormalization(features[363, MBSize 1], globalMean[363, 1], globalInvStd[363, 1]) -> [363, MBSize 1]
Validating --> HL1.t = Times(HL1.W[512, 363], featNorm[363, MBSize 1]) -> [512, MBSize 1]
Validating --> HL1.b = LearnableParameter -> [512, 1]
Validating --> HL1.z = Plus(HL1.t[512, MBSize 1], HL1.b[512, 1]) -> [512, MBSize 0]
Validating --> HL1.y = Sigmoid(HL1.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> OL.t = Times(OL.W[132, 512], HL1.y[512, MBSize 0]) -> [132, MBSize 0]
Validating --> OL.b = LearnableParameter -> [132, 1]
Validating --> OL.z = Plus(OL.t[132, MBSize 0], OL.b[132, 1]) -> [132, MBSize 0]
Validating --> cr = CrossEntropyWithSoftmax(labels[132, MBSize 1], OL.z[132, MBSize 0]) -> [1, 1]

7 out of 15 nodes do not share the minibatch layout with the input data.


Validating for node err. 15 nodes to process in pass 1.

Validating --> labels = InputValue -> [132, MBSize 1]
Validating --> OL.W = LearnableParameter -> [132, 512]
Validating --> HL1.W = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 1]
Validating --> globalMean = LearnableParameter -> [363, 1]
Validating --> globalInvStd = LearnableParameter -> [363, 1]
Validating --> featNorm = PerDimMeanVarNormalization(features[363, MBSize 1], globalMean[363, 1], globalInvStd[363, 1]) -> [363, MBSize 1]
Validating --> HL1.t = Times(HL1.W[512, 363], featNorm[363, MBSize 1]) -> [512, MBSize 1]
Validating --> HL1.b = LearnableParameter -> [512, 1]
Validating --> HL1.z = Plus(HL1.t[512, MBSize 1], HL1.b[512, 1]) -> [512, MBSize 0]
Validating --> HL1.y = Sigmoid(HL1.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> OL.t = Times(OL.W[132, 512], HL1.y[512, MBSize 0]) -> [132, MBSize 0]
Validating --> OL.b = LearnableParameter -> [132, 1]
Validating --> OL.z = Plus(OL.t[132, MBSize 0], OL.b[132, 1]) -> [132, MBSize 0]
Validating --> err = ErrorPrediction(labels[132, MBSize 1], OL.z[132, MBSize 0]) -> [1, 1]

Validating for node err. 6 nodes to process in pass 2.

Validating --> labels = InputValue -> [132, MBSize 1]
Validating --> OL.W = LearnableParameter -> [132, 512]
Validating --> HL1.W = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 1]
Validating --> globalMean = LearnableParameter -> [363, 1]
Validating --> globalInvStd = LearnableParameter -> [363, 1]
Validating --> featNorm = PerDimMeanVarNormalization(features[363, MBSize 1], globalMean[363, 1], globalInvStd[363, 1]) -> [363, MBSize 1]
Validating --> HL1.t = Times(HL1.W[512, 363], featNorm[363, MBSize 1]) -> [512, MBSize 1]
Validating --> HL1.b = LearnableParameter -> [512, 1]
Validating --> HL1.z = Plus(HL1.t[512, MBSize 1], HL1.b[512, 1]) -> [512, MBSize 0]
Validating --> HL1.y = Sigmoid(HL1.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> OL.t = Times(OL.W[132, 512], HL1.y[512, MBSize 0]) -> [132, MBSize 0]
Validating --> OL.b = LearnableParameter -> [132, 1]
Validating --> OL.z = Plus(OL.t[132, MBSize 0], OL.b[132, 1]) -> [132, MBSize 0]
Validating --> err = ErrorPrediction(labels[132, MBSize 1], OL.z[132, MBSize 0]) -> [1, 1]

Validating for node err, final verification.

Validating --> labels = InputValue -> [132, MBSize 1]
Validating --> OL.W = LearnableParameter -> [132, 512]
Validating --> HL1.W = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 1]
Validating --> globalMean = LearnableParameter -> [363, 1]
Validating --> globalInvStd = LearnableParameter -> [363, 1]
Validating --> featNorm = PerDimMeanVarNormalization(features[363, MBSize 1], globalMean[363, 1], globalInvStd[363, 1]) -> [363, MBSize 1]
Validating --> HL1.t = Times(HL1.W[512, 363], featNorm[363, MBSize 1]) -> [512, MBSize 1]
Validating --> HL1.b = LearnableParameter -> [512, 1]
Validating --> HL1.z = Plus(HL1.t[512, MBSize 1], HL1.b[512, 1]) -> [512, MBSize 0]
Validating --> HL1.y = Sigmoid(HL1.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> OL.t = Times(OL.W[132, 512], HL1.y[512, MBSize 0]) -> [132, MBSize 0]
Validating --> OL.b = LearnableParameter -> [132, 1]
Validating --> OL.z = Plus(OL.t[132, MBSize 0], OL.b[132, 1]) -> [132, MBSize 0]
Validating --> err = ErrorPrediction(labels[132, MBSize 1], OL.z[132, MBSize 0]) -> [1, 1]

7 out of 15 nodes do not share the minibatch layout with the input data.

Post-processing network complete.

SGD using CPU.

Training criterion node(s):
	cr = CrossEntropyWithSoftmax

Evaluation criterion node(s):
	err = ErrorPrediction


Allocating matrices for forward and/or backward propagation.
No PreCompute nodes found, skipping PreCompute step
Set Max Temp Mem Size For Convolution Nodes to 0 samples.
Starting Epoch 1: learning rate per sample = 0.003125  effective momentum = 0.900000  momentum as time constant = 2429.8 samples
minibatchiterator: epoch 0: frames [0..81920] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms

Starting minibatch loop.
 Epoch[ 1 of 2]-Minibatch[   1-  10, 3.12%]: SamplesSeen = 2560; TrainLossPerSample =  3.83132935; EvalErr[0]PerSample = 0.82226562; TotalTime = 0.1008s; SamplesPerSecond = 25387.0
 Epoch[ 1 of 2]-Minibatch[  11-  20, 6.25%]: SamplesSeen = 2560; TrainLossPerSample =  2.83457413; EvalErr[0]PerSample = 0.67890625; TotalTime = 0.0608s; SamplesPerSecond = 42078.3
 Epoch[ 1 of 2]-Minibatch[  21-  30, 9.38%]: SamplesSeen = 2560; TrainLossPerSample =  2.54018173; EvalErr[0]PerSample = 0.63945312; TotalTime = 0.0607s; SamplesPerSecond = 42151.7
 Epoch[ 1 of 2]-Minibatch[  31-  40, 12.50%]: SamplesSeen = 2560; TrainLossPerSample =  2.23101730; EvalErr[0]PerSample = 0.58828125; TotalTime = 0.0566s; SamplesPerSecond = 45220.1
 Epoch[ 1 of 2]-Minibatch[  41-  50, 15.62%]: SamplesSeen = 2560; TrainLossPerSample =  2.03877335; EvalErr[0]PerSample = 0.55234375; TotalTime = 0.0560s; SamplesPerSecond = 45749.4
 Epoch[ 1 of 2]-Minibatch[  51-  60, 18.75%]: SamplesSeen = 2560; TrainLossPerSample =  1.89007111; EvalErr[0]PerSample = 0.51796875; TotalTime = 0.0557s; SamplesPerSecond = 45970.4
 Epoch[ 1 of 2]-Minibatch[  61-  70, 21.88%]: SamplesSeen = 2560; TrainLossPerSample =  1.80725708; EvalErr[0]PerSample = 0.50195312; TotalTime = 0.0557s; SamplesPerSecond = 45940.7
 Epoch[ 1 of 2]-Minibatch[  71-  80, 25.00%]: SamplesSeen = 2560; TrainLossPerSample =  1.73773956; EvalErr[0]PerSample = 0.50117188; TotalTime = 0.0558s; SamplesPerSecond = 45874.8
 Epoch[ 1 of 2]-Minibatch[  81-  90, 28.12%]: SamplesSeen = 2560; TrainLossPerSample =  1.62159882; EvalErr[0]PerSample = 0.48437500; TotalTime = 0.0557s; SamplesPerSecond = 45952.3
 Epoch[ 1 of 2]-Minibatch[  91- 100, 31.25%]: SamplesSeen = 2560; TrainLossPerSample =  1.64018860; EvalErr[0]PerSample = 0.47890625; TotalTime = 0.0592s; SamplesPerSecond = 43262.2
 Epoch[ 1 of 2]-Minibatch[ 101- 110, 34.38%]: SamplesSeen = 2560; TrainLossPerSample =  1.62083740; EvalErr[0]PerSample = 0.47968750; TotalTime = 0.0561s; SamplesPerSecond = 45659.7
 Epoch[ 1 of 2]-Minibatch[ 111- 120, 37.50%]: SamplesSeen = 2560; TrainLossPerSample =  1.61514740; EvalErr[0]PerSample = 0.46640625; TotalTime = 0.0563s; SamplesPerSecond = 45507.1
 Epoch[ 1 of 2]-Minibatch[ 121- 130, 40.62%]: SamplesSeen = 2560; TrainLossPerSample =  1.49160156; EvalErr[0]PerSample = 0.44101563; TotalTime = 0.0562s; SamplesPerSecond = 45562.1
 Epoch[ 1 of 2]-Minibatch[ 131- 140, 43.75%]: SamplesSeen = 2560; TrainLossPerSample =  1.45087891; EvalErr[0]PerSample = 0.43828125; TotalTime = 0.0560s; SamplesPerSecond = 45675.1
 Epoch[ 1 of 2]-Minibatch[ 141- 150, 46.88%]: SamplesSeen = 2560; TrainLossPerSample =  1.42432251; EvalErr[0]PerSample = 0.40937500; TotalTime = 0.0559s; SamplesPerSecond = 45797.7
 Epoch[ 1 of 2]-Minibatch[ 151- 160, 50.00%]: SamplesSeen = 2560; TrainLossPerSample =  1.42227783; EvalErr[0]PerSample = 0.42265625; TotalTime = 0.0558s; SamplesPerSecond = 45905.3
 Epoch[ 1 of 2]-Minibatch[ 161- 170, 53.12%]: SamplesSeen = 2560; TrainLossPerSample =  1.39202576; EvalErr[0]PerSample = 0.39375000; TotalTime = 0.0557s; SamplesPerSecond = 45921.8
 Epoch[ 1 of 2]-Minibatch[ 171- 180, 56.25%]: SamplesSeen = 2560; TrainLossPerSample =  1.39772339; EvalErr[0]PerSample = 0.41367188; TotalTime = 0.0558s; SamplesPerSecond = 45854.3
 Epoch[ 1 of 2]-Minibatch[ 181- 190, 59.38%]: SamplesSeen = 2560; TrainLossPerSample =  1.32752991; EvalErr[0]PerSample = 0.39218750; TotalTime = 0.0558s; SamplesPerSecond = 45872.4
 Epoch[ 1 of 2]-Minibatch[ 191- 200, 62.50%]: SamplesSeen = 2560; TrainLossPerSample =  1.36070557; EvalErr[0]PerSample = 0.41484375; TotalTime = 0.0557s; SamplesPerSecond = 45952.3
 Epoch[ 1 of 2]-Minibatch[ 201- 210, 65.62%]: SamplesSeen = 2560; TrainLossPerSample =  1.39848328; EvalErr[0]PerSample = 0.42304687; TotalTime = 0.0558s; SamplesPerSecond = 45883.9
 Epoch[ 1 of 2]-Minibatch[ 211- 220, 68.75%]: SamplesSeen = 2560; TrainLossPerSample =  1.41366272; EvalErr[0]PerSample = 0.41718750; TotalTime = 0.0558s; SamplesPerSecond = 45893.8
 Epoch[ 1 of 2]-Minibatch[ 221- 230, 71.88%]: SamplesSeen = 2560; TrainLossPerSample =  1.32877502; EvalErr[0]PerSample = 0.39453125; TotalTime = 0.0560s; SamplesPerSecond = 45675.1
 Epoch[ 1 of 2]-Minibatch[ 231- 240, 75.00%]: SamplesSeen = 2560; TrainLossPerSample =  1.33236084; EvalErr[0]PerSample = 0.40039062; TotalTime = 0.0558s; SamplesPerSecond = 45874.0
 Epoch[ 1 of 2]-Minibatch[ 241- 250, 78.12%]: SamplesSeen = 2560; TrainLossPerSample =  1.34082031; EvalErr[0]PerSample = 0.40742187; TotalTime = 0.0557s; SamplesPerSecond = 45941.5
 Epoch[ 1 of 2]-Minibatch[ 251- 260, 81.25%]: SamplesSeen = 2560; TrainLossPerSample =  1.34818115; EvalErr[0]PerSample = 0.40234375; TotalTime = 0.0558s; SamplesPerSecond = 45889.6
 Epoch[ 1 of 2]-Minibatch[ 261- 270, 84.38%]: SamplesSeen = 2560; TrainLossPerSample =  1.29428711; EvalErr[0]PerSample = 0.41367188; TotalTime = 0.0557s; SamplesPerSecond = 45954.7
 Epoch[ 1 of 2]-Minibatch[ 271- 280, 87.50%]: SamplesSeen = 2560; TrainLossPerSample =  1.26860352; EvalErr[0]PerSample = 0.37851563; TotalTime = 0.0557s; SamplesPerSecond = 45924.2
 Epoch[ 1 of 2]-Minibatch[ 281- 290, 90.62%]: SamplesSeen = 2560; TrainLossPerSample =  1.29054565; EvalErr[0]PerSample = 0.38671875; TotalTime = 0.0559s; SamplesPerSecond = 45792.8
 Epoch[ 1 of 2]-Minibatch[ 291- 300, 93.75%]: SamplesSeen = 2560; TrainLossPerSample =  1.26689758; EvalErr[0]PerSample = 0.37109375; TotalTime = 0.0559s; SamplesPerSecond = 45826.4
 Epoch[ 1 of 2]-Minibatch[ 301- 310, 96.88%]: SamplesSeen = 2560; TrainLossPerSample =  1.31538086; EvalErr[0]PerSample = 0.40390625; TotalTime = 0.0557s; SamplesPerSecond = 45976.2
 Epoch[ 1 of 2]-Minibatch[ 311- 320, 100.00%]: SamplesSeen = 2560; TrainLossPerSample =  1.32755737; EvalErr[0]PerSample = 0.41054687; TotalTime = 0.0550s; SamplesPerSecond = 46516.7
Finished Epoch[ 1 of 2]: [Training Set] TrainLossPerSample = 1.6437918; EvalErrPerSample = 0.46396485; AvgLearningRatePerSample = 0.003125; EpochTime=1.9482
Starting Epoch 2: learning rate per sample = 0.003125  effective momentum = 0.900000  momentum as time constant = 2429.8 samples
minibatchiterator: epoch 1: frames [81920..163840] (first utterance at frame 81920), data subset 0 of 1, with 1 datapasses

Starting minibatch loop.
 Epoch[ 2 of 2]-Minibatch[   1-  10, 3.12%]: SamplesSeen = 2560; TrainLossPerSample =  1.26157866; EvalErr[0]PerSample = 0.38007812; TotalTime = 0.0559s; SamplesPerSecond = 45759.2
 Epoch[ 2 of 2]-Minibatch[  11-  20, 6.25%]: SamplesSeen = 2560; TrainLossPerSample =  1.27182264; EvalErr[0]PerSample = 0.39140625; TotalTime = 0.0557s; SamplesPerSecond = 45933.3
 Epoch[ 2 of 2]-Minibatch[  21-  30, 9.38%]: SamplesSeen = 2560; TrainLossPerSample =  1.25893726; EvalErr[0]PerSample = 0.37929687; TotalTime = 0.0557s; SamplesPerSecond = 45939.9
 Epoch[ 2 of 2]-Minibatch[  31-  40, 12.50%]: SamplesSeen = 2560; TrainLossPerSample =  1.24161911; EvalErr[0]PerSample = 0.37539062; TotalTime = 0.0559s; SamplesPerSecond = 45774.0
 Epoch[ 2 of 2]-Minibatch[  41-  50, 15.62%]: SamplesSeen = 2560; TrainLossPerSample =  1.26974945; EvalErr[0]PerSample = 0.38203125; TotalTime = 0.0558s; SamplesPerSecond = 45839.5
 Epoch[ 2 of 2]-Minibatch[  51-  60, 18.75%]: SamplesSeen = 2560; TrainLossPerSample =  1.18642731; EvalErr[0]PerSample = 0.36210938; TotalTime = 0.0557s; SamplesPerSecond = 45944.0
 Epoch[ 2 of 2]-Minibatch[  61-  70, 21.88%]: SamplesSeen = 2560; TrainLossPerSample =  1.19709320; EvalErr[0]PerSample = 0.35781250; TotalTime = 0.0557s; SamplesPerSecond = 45937.4
 Epoch[ 2 of 2]-Minibatch[  71-  80, 25.00%]: SamplesSeen = 2560; TrainLossPerSample =  1.21570816; EvalErr[0]PerSample = 0.37851563; TotalTime = 0.0558s; SamplesPerSecond = 45877.3
 Epoch[ 2 of 2]-Minibatch[  81-  90, 28.12%]: SamplesSeen = 2560; TrainLossPerSample =  1.24040680; EvalErr[0]PerSample = 0.37500000; TotalTime = 0.0557s; SamplesPerSecond = 45967.1
 Epoch[ 2 of 2]-Minibatch[  91- 100, 31.25%]: SamplesSeen = 2560; TrainLossPerSample =  1.22780533; EvalErr[0]PerSample = 0.36953125; TotalTime = 0.0558s; SamplesPerSecond = 45918.5
 Epoch[ 2 of 2]-Minibatch[ 101- 110, 34.38%]: SamplesSeen = 2560; TrainLossPerSample =  1.20197067; EvalErr[0]PerSample = 0.36562500; TotalTime = 0.0558s; SamplesPerSecond = 45908.6
 Epoch[ 2 of 2]-Minibatch[ 111- 120, 37.50%]: SamplesSeen = 2560; TrainLossPerSample =  1.20512390; EvalErr[0]PerSample = 0.36367187; TotalTime = 0.0558s; SamplesPerSecond = 45912.7
 Epoch[ 2 of 2]-Minibatch[ 121- 130, 40.62%]: SamplesSeen = 2560; TrainLossPerSample =  1.18534546; EvalErr[0]PerSample = 0.35898438; TotalTime = 0.0558s; SamplesPerSecond = 45885.5
 Epoch[ 2 of 2]-Minibatch[ 131- 140, 43.75%]: SamplesSeen = 2560; TrainLossPerSample =  1.16091156; EvalErr[0]PerSample = 0.36171875; TotalTime = 0.0557s; SamplesPerSecond = 45920.1
 Epoch[ 2 of 2]-Minibatch[ 141- 150, 46.88%]: SamplesSeen = 2560; TrainLossPerSample =  1.15581207; EvalErr[0]PerSample = 0.33906250; TotalTime = 0.0559s; SamplesPerSecond = 45828.9
 Epoch[ 2 of 2]-Minibatch[ 151- 160, 50.00%]: SamplesSeen = 2560; TrainLossPerSample =  1.11231842; EvalErr[0]PerSample = 0.34179688; TotalTime = 0.0558s; SamplesPerSecond = 45904.5
 Epoch[ 2 of 2]-Minibatch[ 161- 170, 53.12%]: SamplesSeen = 2560; TrainLossPerSample =  1.10982819; EvalErr[0]PerSample = 0.33671875; TotalTime = 0.0566s; SamplesPerSecond = 45262.5
 Epoch[ 2 of 2]-Minibatch[ 171- 180, 56.25%]: SamplesSeen = 2560; TrainLossPerSample =  1.17951050; EvalErr[0]PerSample = 0.34882812; TotalTime = 0.0559s; SamplesPerSecond = 45783.0
 Epoch[ 2 of 2]-Minibatch[ 181- 190, 59.38%]: SamplesSeen = 2560; TrainLossPerSample =  1.13334808; EvalErr[0]PerSample = 0.35234375; TotalTime = 0.0558s; SamplesPerSecond = 45840.3
 Epoch[ 2 of 2]-Minibatch[ 191- 200, 62.50%]: SamplesSeen = 2560; TrainLossPerSample =  1.12929535; EvalErr[0]PerSample = 0.34648438; TotalTime = 0.0557s; SamplesPerSecond = 45928.3
 Epoch[ 2 of 2]-Minibatch[ 201- 210, 65.62%]: SamplesSeen = 2560; TrainLossPerSample =  1.14827423; EvalErr[0]PerSample = 0.35625000; TotalTime = 0.0558s; SamplesPerSecond = 45887.2
 Epoch[ 2 of 2]-Minibatch[ 211- 220, 68.75%]: SamplesSeen = 2560; TrainLossPerSample =  1.11930237; EvalErr[0]PerSample = 0.33710937; TotalTime = 0.0559s; SamplesPerSecond = 45777.2
 Epoch[ 2 of 2]-Minibatch[ 221- 230, 71.88%]: SamplesSeen = 2560; TrainLossPerSample =  1.16259460; EvalErr[0]PerSample = 0.36562500; TotalTime = 0.0557s; SamplesPerSecond = 45969.6
 Epoch[ 2 of 2]-Minibatch[ 231- 240, 75.00%]: SamplesSeen = 2560; TrainLossPerSample =  1.13496094; EvalErr[0]PerSample = 0.34843750; TotalTime = 0.0558s; SamplesPerSecond = 45838.7
 Epoch[ 2 of 2]-Minibatch[ 241- 250, 78.12%]: SamplesSeen = 2560; TrainLossPerSample =  1.07667542; EvalErr[0]PerSample = 0.32578125; TotalTime = 0.0557s; SamplesPerSecond = 45929.2
 Epoch[ 2 of 2]-Minibatch[ 251- 260, 81.25%]: SamplesSeen = 2560; TrainLossPerSample =  1.15973511; EvalErr[0]PerSample = 0.34179688; TotalTime = 0.0560s; SamplesPerSecond = 45734.7
 Epoch[ 2 of 2]-Minibatch[ 261- 270, 84.38%]: SamplesSeen = 2560; TrainLossPerSample =  1.16832275; EvalErr[0]PerSample = 0.35351562; TotalTime = 0.0557s; SamplesPerSecond = 45930.0
 Epoch[ 2 of 2]-Minibatch[ 271- 280, 87.50%]: SamplesSeen = 2560; TrainLossPerSample =  1.14626465; EvalErr[0]PerSample = 0.34570312; TotalTime = 0.0558s; SamplesPerSecond = 45911.0
 Epoch[ 2 of 2]-Minibatch[ 281- 290, 90.62%]: SamplesSeen = 2560; TrainLossPerSample =  1.09096069; EvalErr[0]PerSample = 0.33437500; TotalTime = 0.0558s; SamplesPerSecond = 45892.1
 Epoch[ 2 of 2]-Minibatch[ 291- 300, 93.75%]: SamplesSeen = 2560; TrainLossPerSample =  1.10794678; EvalErr[0]PerSample = 0.33984375; TotalTime = 0.0557s; SamplesPerSecond = 45926.7
 Epoch[ 2 of 2]-Minibatch[ 301- 310, 96.88%]: SamplesSeen = 2560; TrainLossPerSample =  1.16580200; EvalErr[0]PerSample = 0.34531250; TotalTime = 0.0557s; SamplesPerSecond = 45919.3
 Epoch[ 2 of 2]-Minibatch[ 311- 320, 100.00%]: SamplesSeen = 2560; TrainLossPerSample =  1.05586853; EvalErr[0]PerSample = 0.32265625; TotalTime = 0.0550s; SamplesPerSecond = 46548.0
Finished Epoch[ 2 of 2]: [Training Set] TrainLossPerSample = 1.1712912; EvalErrPerSample = 0.35571289; AvgLearningRatePerSample = 0.003125; EpochTime=1.79264
CNTKCommandTrainEnd: dptPre1

Post-processing network...

3 roots:
	cr = CrossEntropyWithSoftmax
	scaledLogLikelihood = Minus
	err = ErrorPrediction
FormNestedNetwork: WARNING: Was called twice for cr CrossEntropyWithSoftmax operation
FormNestedNetwork: WARNING: Was called twice for scaledLogLikelihood Minus operation
FormNestedNetwork: WARNING: Was called twice for err ErrorPrediction operation


Validating for node cr. 15 nodes to process in pass 1.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> OL.W = LearnableParameter -> [132, 512]
Validating --> HL1.W = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> globalMean = LearnableParameter -> [363, 1]
Validating --> globalInvStd = LearnableParameter -> [363, 1]
Validating --> featNorm = PerDimMeanVarNormalization(features[363, MBSize 0], globalMean[363, 1], globalInvStd[363, 1]) -> [363, MBSize 0]
Validating --> HL1.t = Times(HL1.W[512, 363], featNorm[363, MBSize 0]) -> [512, MBSize 0]
Validating --> HL1.b = LearnableParameter -> [512, 1]
Validating --> HL1.z = Plus(HL1.t[512, MBSize 0], HL1.b[512, 1]) -> [512, MBSize 0]
Validating --> HL1.y = Sigmoid(HL1.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> OL.t = Times(OL.W[132, 512], HL1.y[512, MBSize 0]) -> [132, MBSize 0]
Validating --> OL.b = LearnableParameter -> [132, 1]
Validating --> OL.z = Plus(OL.t[132, MBSize 0], OL.b[132, 1]) -> [132, MBSize 0]
Validating --> cr = CrossEntropyWithSoftmax(labels[132, MBSize 0], OL.z[132, MBSize 0]) -> [1, 1]

Validating for node cr. 7 nodes to process in pass 2.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> OL.W = LearnableParameter -> [132, 512]
Validating --> HL1.W = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> globalMean = LearnableParameter -> [363, 1]
Validating --> globalInvStd = LearnableParameter -> [363, 1]
Validating --> featNorm = PerDimMeanVarNormalization(features[363, MBSize 0], globalMean[363, 1], globalInvStd[363, 1]) -> [363, MBSize 0]
Validating --> HL1.t = Times(HL1.W[512, 363], featNorm[363, MBSize 0]) -> [512, MBSize 0]
Validating --> HL1.b = LearnableParameter -> [512, 1]
Validating --> HL1.z = Plus(HL1.t[512, MBSize 0], HL1.b[512, 1]) -> [512, MBSize 0]
Validating --> HL1.y = Sigmoid(HL1.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> OL.t = Times(OL.W[132, 512], HL1.y[512, MBSize 0]) -> [132, MBSize 0]
Validating --> OL.b = LearnableParameter -> [132, 1]
Validating --> OL.z = Plus(OL.t[132, MBSize 0], OL.b[132, 1]) -> [132, MBSize 0]
Validating --> cr = CrossEntropyWithSoftmax(labels[132, MBSize 0], OL.z[132, MBSize 0]) -> [1, 1]

Validating for node cr, final verification.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> OL.W = LearnableParameter -> [132, 512]
Validating --> HL1.W = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> globalMean = LearnableParameter -> [363, 1]
Validating --> globalInvStd = LearnableParameter -> [363, 1]
Validating --> featNorm = PerDimMeanVarNormalization(features[363, MBSize 0], globalMean[363, 1], globalInvStd[363, 1]) -> [363, MBSize 0]
Validating --> HL1.t = Times(HL1.W[512, 363], featNorm[363, MBSize 0]) -> [512, MBSize 0]
Validating --> HL1.b = LearnableParameter -> [512, 1]
Validating --> HL1.z = Plus(HL1.t[512, MBSize 0], HL1.b[512, 1]) -> [512, MBSize 0]
Validating --> HL1.y = Sigmoid(HL1.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> OL.t = Times(OL.W[132, 512], HL1.y[512, MBSize 0]) -> [132, MBSize 0]
Validating --> OL.b = LearnableParameter -> [132, 1]
Validating --> OL.z = Plus(OL.t[132, MBSize 0], OL.b[132, 1]) -> [132, MBSize 0]
Validating --> cr = CrossEntropyWithSoftmax(labels[132, MBSize 0], OL.z[132, MBSize 0]) -> [1, 1]

7 out of 15 nodes do not share the minibatch layout with the input data.


Validating for node scaledLogLikelihood. 16 nodes to process in pass 1.

Validating --> OL.W = LearnableParameter -> [132, 512]
Validating --> HL1.W = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> globalMean = LearnableParameter -> [363, 1]
Validating --> globalInvStd = LearnableParameter -> [363, 1]
Validating --> featNorm = PerDimMeanVarNormalization(features[363, MBSize 0], globalMean[363, 1], globalInvStd[363, 1]) -> [363, MBSize 0]
Validating --> HL1.t = Times(HL1.W[512, 363], featNorm[363, MBSize 0]) -> [512, MBSize 0]
Validating --> HL1.b = LearnableParameter -> [512, 1]
Validating --> HL1.z = Plus(HL1.t[512, MBSize 0], HL1.b[512, 1]) -> [512, MBSize 0]
Validating --> HL1.y = Sigmoid(HL1.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> OL.t = Times(OL.W[132, 512], HL1.y[512, MBSize 0]) -> [132, MBSize 0]
Validating --> OL.b = LearnableParameter -> [132, 1]
Validating --> OL.z = Plus(OL.t[132, MBSize 0], OL.b[132, 1]) -> [132, MBSize 0]
Validating --> globalPrior = LearnableParameter -> [132, 1]
Validating --> logPrior = Log(globalPrior[132, 1]) -> [132, 1]
Validating --> scaledLogLikelihood = Minus(OL.z[132, MBSize 0], logPrior[132, 1]) -> [132, MBSize 0]

Validating for node scaledLogLikelihood. 7 nodes to process in pass 2.

Validating --> OL.W = LearnableParameter -> [132, 512]
Validating --> HL1.W = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> globalMean = LearnableParameter -> [363, 1]
Validating --> globalInvStd = LearnableParameter -> [363, 1]
Validating --> featNorm = PerDimMeanVarNormalization(features[363, MBSize 0], globalMean[363, 1], globalInvStd[363, 1]) -> [363, MBSize 0]
Validating --> HL1.t = Times(HL1.W[512, 363], featNorm[363, MBSize 0]) -> [512, MBSize 0]
Validating --> HL1.b = LearnableParameter -> [512, 1]
Validating --> HL1.z = Plus(HL1.t[512, MBSize 0], HL1.b[512, 1]) -> [512, MBSize 0]
Validating --> HL1.y = Sigmoid(HL1.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> OL.t = Times(OL.W[132, 512], HL1.y[512, MBSize 0]) -> [132, MBSize 0]
Validating --> OL.b = LearnableParameter -> [132, 1]
Validating --> OL.z = Plus(OL.t[132, MBSize 0], OL.b[132, 1]) -> [132, MBSize 0]
Validating --> globalPrior = LearnableParameter -> [132, 1]
Validating --> logPrior = Log(globalPrior[132, 1]) -> [132, 1]
Validating --> scaledLogLikelihood = Minus(OL.z[132, MBSize 0], logPrior[132, 1]) -> [132, MBSize 0]

Validating for node scaledLogLikelihood, final verification.

Validating --> OL.W = LearnableParameter -> [132, 512]
Validating --> HL1.W = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> globalMean = LearnableParameter -> [363, 1]
Validating --> globalInvStd = LearnableParameter -> [363, 1]
Validating --> featNorm = PerDimMeanVarNormalization(features[363, MBSize 0], globalMean[363, 1], globalInvStd[363, 1]) -> [363, MBSize 0]
Validating --> HL1.t = Times(HL1.W[512, 363], featNorm[363, MBSize 0]) -> [512, MBSize 0]
Validating --> HL1.b = LearnableParameter -> [512, 1]
Validating --> HL1.z = Plus(HL1.t[512, MBSize 0], HL1.b[512, 1]) -> [512, MBSize 0]
Validating --> HL1.y = Sigmoid(HL1.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> OL.t = Times(OL.W[132, 512], HL1.y[512, MBSize 0]) -> [132, MBSize 0]
Validating --> OL.b = LearnableParameter -> [132, 1]
Validating --> OL.z = Plus(OL.t[132, MBSize 0], OL.b[132, 1]) -> [132, MBSize 0]
Validating --> globalPrior = LearnableParameter -> [132, 1]
Validating --> logPrior = Log(globalPrior[132, 1]) -> [132, 1]
Validating --> scaledLogLikelihood = Minus(OL.z[132, MBSize 0], logPrior[132, 1]) -> [132, MBSize 0]

8 out of 16 nodes do not share the minibatch layout with the input data.


Validating for node err. 15 nodes to process in pass 1.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> OL.W = LearnableParameter -> [132, 512]
Validating --> HL1.W = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> globalMean = LearnableParameter -> [363, 1]
Validating --> globalInvStd = LearnableParameter -> [363, 1]
Validating --> featNorm = PerDimMeanVarNormalization(features[363, MBSize 0], globalMean[363, 1], globalInvStd[363, 1]) -> [363, MBSize 0]
Validating --> HL1.t = Times(HL1.W[512, 363], featNorm[363, MBSize 0]) -> [512, MBSize 0]
Validating --> HL1.b = LearnableParameter -> [512, 1]
Validating --> HL1.z = Plus(HL1.t[512, MBSize 0], HL1.b[512, 1]) -> [512, MBSize 0]
Validating --> HL1.y = Sigmoid(HL1.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> OL.t = Times(OL.W[132, 512], HL1.y[512, MBSize 0]) -> [132, MBSize 0]
Validating --> OL.b = LearnableParameter -> [132, 1]
Validating --> OL.z = Plus(OL.t[132, MBSize 0], OL.b[132, 1]) -> [132, MBSize 0]
Validating --> err = ErrorPrediction(labels[132, MBSize 0], OL.z[132, MBSize 0]) -> [1, 1]

Validating for node err. 6 nodes to process in pass 2.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> OL.W = LearnableParameter -> [132, 512]
Validating --> HL1.W = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> globalMean = LearnableParameter -> [363, 1]
Validating --> globalInvStd = LearnableParameter -> [363, 1]
Validating --> featNorm = PerDimMeanVarNormalization(features[363, MBSize 0], globalMean[363, 1], globalInvStd[363, 1]) -> [363, MBSize 0]
Validating --> HL1.t = Times(HL1.W[512, 363], featNorm[363, MBSize 0]) -> [512, MBSize 0]
Validating --> HL1.b = LearnableParameter -> [512, 1]
Validating --> HL1.z = Plus(HL1.t[512, MBSize 0], HL1.b[512, 1]) -> [512, MBSize 0]
Validating --> HL1.y = Sigmoid(HL1.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> OL.t = Times(OL.W[132, 512], HL1.y[512, MBSize 0]) -> [132, MBSize 0]
Validating --> OL.b = LearnableParameter -> [132, 1]
Validating --> OL.z = Plus(OL.t[132, MBSize 0], OL.b[132, 1]) -> [132, MBSize 0]
Validating --> err = ErrorPrediction(labels[132, MBSize 0], OL.z[132, MBSize 0]) -> [1, 1]

Validating for node err, final verification.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> OL.W = LearnableParameter -> [132, 512]
Validating --> HL1.W = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> globalMean = LearnableParameter -> [363, 1]
Validating --> globalInvStd = LearnableParameter -> [363, 1]
Validating --> featNorm = PerDimMeanVarNormalization(features[363, MBSize 0], globalMean[363, 1], globalInvStd[363, 1]) -> [363, MBSize 0]
Validating --> HL1.t = Times(HL1.W[512, 363], featNorm[363, MBSize 0]) -> [512, MBSize 0]
Validating --> HL1.b = LearnableParameter -> [512, 1]
Validating --> HL1.z = Plus(HL1.t[512, MBSize 0], HL1.b[512, 1]) -> [512, MBSize 0]
Validating --> HL1.y = Sigmoid(HL1.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> OL.t = Times(OL.W[132, 512], HL1.y[512, MBSize 0]) -> [132, MBSize 0]
Validating --> OL.b = LearnableParameter -> [132, 1]
Validating --> OL.z = Plus(OL.t[132, MBSize 0], OL.b[132, 1]) -> [132, MBSize 0]
Validating --> err = ErrorPrediction(labels[132, MBSize 0], OL.z[132, MBSize 0]) -> [1, 1]

7 out of 15 nodes do not share the minibatch layout with the input data.

Post-processing network complete.
CNTKCommandTrainBegin: dptPre2
NDLBuilder Using CPU
reading script file /tmp/cntk-test-20151216094712.720058/Speech/DNN_SequenceTraining@release_cpu/TestData/glob_0000.scp ... 948 entries
total 132 state names in state list /tmp/cntk-test-20151216094712.720058/Speech/DNN_SequenceTraining@release_cpu/TestData/state.list
htkmlfreader: reading MLF file /tmp/cntk-test-20151216094712.720058/Speech/DNN_SequenceTraining@release_cpu/TestData/glob_0000.mlf ... total 948 entries
...............................................................................................feature set 0: 252734 frames in 948 out of 948 utterances
label set 0: 129 classes
minibatchutterancesource: 948 utterances grouped into 3 chunks, av. chunk size: 316.0 utterances, 84244.7 frames
Starting from checkpoint. Load Network From File /tmp/cntk-test-20151216094712.720058/Speech/DNN_SequenceTraining@release_cpu/models/Pre2/cntkSpeech.0.

Post-processing network...

3 roots:
	cr = CrossEntropyWithSoftmax
	scaledLogLikelihood = Minus
	err = ErrorPrediction
FormNestedNetwork: WARNING: Was called twice for cr CrossEntropyWithSoftmax operation
FormNestedNetwork: WARNING: Was called twice for scaledLogLikelihood Minus operation
FormNestedNetwork: WARNING: Was called twice for err ErrorPrediction operation


Validating for node cr. 20 nodes to process in pass 1.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> OL.W = LearnableParameter -> [132, 512]
Validating --> HL2.W = LearnableParameter -> [512, 512]
Validating --> HL1.W = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> globalMean = LearnableParameter -> [363, 1]
Validating --> globalInvStd = LearnableParameter -> [363, 1]
Validating --> featNorm = PerDimMeanVarNormalization(features[363, MBSize 0], globalMean[363, 1], globalInvStd[363, 1]) -> [363, MBSize 0]
Validating --> HL1.t = Times(HL1.W[512, 363], featNorm[363, MBSize 0]) -> [512, MBSize 0]
Validating --> HL1.b = LearnableParameter -> [512, 1]
Validating --> HL1.z = Plus(HL1.t[512, MBSize 0], HL1.b[512, 1]) -> [512, MBSize 0]
Validating --> HL1.y = Sigmoid(HL1.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL2.t = Times(HL2.W[512, 512], HL1.y[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL2.b = LearnableParameter -> [512, 1]
Validating --> HL2.z = Plus(HL2.t[512, MBSize 0], HL2.b[512, 1]) -> [512, MBSize 0]
Validating --> HL2.y = Sigmoid(HL2.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> OL.t = Times(OL.W[132, 512], HL2.y[512, MBSize 0]) -> [132, MBSize 0]
Validating --> OL.b = LearnableParameter -> [132, 1]
Validating --> OL.z = Plus(OL.t[132, MBSize 0], OL.b[132, 1]) -> [132, MBSize 0]
Validating --> cr = CrossEntropyWithSoftmax(labels[132, MBSize 0], OL.z[132, MBSize 0]) -> [1, 1]

Validating for node cr. 10 nodes to process in pass 2.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> OL.W = LearnableParameter -> [132, 512]
Validating --> HL2.W = LearnableParameter -> [512, 512]
Validating --> HL1.W = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> globalMean = LearnableParameter -> [363, 1]
Validating --> globalInvStd = LearnableParameter -> [363, 1]
Validating --> featNorm = PerDimMeanVarNormalization(features[363, MBSize 0], globalMean[363, 1], globalInvStd[363, 1]) -> [363, MBSize 0]
Validating --> HL1.t = Times(HL1.W[512, 363], featNorm[363, MBSize 0]) -> [512, MBSize 0]
Validating --> HL1.b = LearnableParameter -> [512, 1]
Validating --> HL1.z = Plus(HL1.t[512, MBSize 0], HL1.b[512, 1]) -> [512, MBSize 0]
Validating --> HL1.y = Sigmoid(HL1.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL2.t = Times(HL2.W[512, 512], HL1.y[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL2.b = LearnableParameter -> [512, 1]
Validating --> HL2.z = Plus(HL2.t[512, MBSize 0], HL2.b[512, 1]) -> [512, MBSize 0]
Validating --> HL2.y = Sigmoid(HL2.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> OL.t = Times(OL.W[132, 512], HL2.y[512, MBSize 0]) -> [132, MBSize 0]
Validating --> OL.b = LearnableParameter -> [132, 1]
Validating --> OL.z = Plus(OL.t[132, MBSize 0], OL.b[132, 1]) -> [132, MBSize 0]
Validating --> cr = CrossEntropyWithSoftmax(labels[132, MBSize 0], OL.z[132, MBSize 0]) -> [1, 1]

Validating for node cr, final verification.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> OL.W = LearnableParameter -> [132, 512]
Validating --> HL2.W = LearnableParameter -> [512, 512]
Validating --> HL1.W = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> globalMean = LearnableParameter -> [363, 1]
Validating --> globalInvStd = LearnableParameter -> [363, 1]
Validating --> featNorm = PerDimMeanVarNormalization(features[363, MBSize 0], globalMean[363, 1], globalInvStd[363, 1]) -> [363, MBSize 0]
Validating --> HL1.t = Times(HL1.W[512, 363], featNorm[363, MBSize 0]) -> [512, MBSize 0]
Validating --> HL1.b = LearnableParameter -> [512, 1]
Validating --> HL1.z = Plus(HL1.t[512, MBSize 0], HL1.b[512, 1]) -> [512, MBSize 0]
Validating --> HL1.y = Sigmoid(HL1.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL2.t = Times(HL2.W[512, 512], HL1.y[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL2.b = LearnableParameter -> [512, 1]
Validating --> HL2.z = Plus(HL2.t[512, MBSize 0], HL2.b[512, 1]) -> [512, MBSize 0]
Validating --> HL2.y = Sigmoid(HL2.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> OL.t = Times(OL.W[132, 512], HL2.y[512, MBSize 0]) -> [132, MBSize 0]
Validating --> OL.b = LearnableParameter -> [132, 1]
Validating --> OL.z = Plus(OL.t[132, MBSize 0], OL.b[132, 1]) -> [132, MBSize 0]
Validating --> cr = CrossEntropyWithSoftmax(labels[132, MBSize 0], OL.z[132, MBSize 0]) -> [1, 1]

9 out of 20 nodes do not share the minibatch layout with the input data.


Validating for node scaledLogLikelihood. 21 nodes to process in pass 1.

Validating --> OL.W = LearnableParameter -> [132, 512]
Validating --> HL2.W = LearnableParameter -> [512, 512]
Validating --> HL1.W = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> globalMean = LearnableParameter -> [363, 1]
Validating --> globalInvStd = LearnableParameter -> [363, 1]
Validating --> featNorm = PerDimMeanVarNormalization(features[363, MBSize 0], globalMean[363, 1], globalInvStd[363, 1]) -> [363, MBSize 0]
Validating --> HL1.t = Times(HL1.W[512, 363], featNorm[363, MBSize 0]) -> [512, MBSize 0]
Validating --> HL1.b = LearnableParameter -> [512, 1]
Validating --> HL1.z = Plus(HL1.t[512, MBSize 0], HL1.b[512, 1]) -> [512, MBSize 0]
Validating --> HL1.y = Sigmoid(HL1.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL2.t = Times(HL2.W[512, 512], HL1.y[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL2.b = LearnableParameter -> [512, 1]
Validating --> HL2.z = Plus(HL2.t[512, MBSize 0], HL2.b[512, 1]) -> [512, MBSize 0]
Validating --> HL2.y = Sigmoid(HL2.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> OL.t = Times(OL.W[132, 512], HL2.y[512, MBSize 0]) -> [132, MBSize 0]
Validating --> OL.b = LearnableParameter -> [132, 1]
Validating --> OL.z = Plus(OL.t[132, MBSize 0], OL.b[132, 1]) -> [132, MBSize 0]
Validating --> globalPrior = LearnableParameter -> [132, 1]
Validating --> logPrior = Log(globalPrior[132, 1]) -> [132, 1]
Validating --> scaledLogLikelihood = Minus(OL.z[132, MBSize 0], logPrior[132, 1]) -> [132, MBSize 0]

Validating for node scaledLogLikelihood. 10 nodes to process in pass 2.

Validating --> OL.W = LearnableParameter -> [132, 512]
Validating --> HL2.W = LearnableParameter -> [512, 512]
Validating --> HL1.W = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> globalMean = LearnableParameter -> [363, 1]
Validating --> globalInvStd = LearnableParameter -> [363, 1]
Validating --> featNorm = PerDimMeanVarNormalization(features[363, MBSize 0], globalMean[363, 1], globalInvStd[363, 1]) -> [363, MBSize 0]
Validating --> HL1.t = Times(HL1.W[512, 363], featNorm[363, MBSize 0]) -> [512, MBSize 0]
Validating --> HL1.b = LearnableParameter -> [512, 1]
Validating --> HL1.z = Plus(HL1.t[512, MBSize 0], HL1.b[512, 1]) -> [512, MBSize 0]
Validating --> HL1.y = Sigmoid(HL1.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL2.t = Times(HL2.W[512, 512], HL1.y[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL2.b = LearnableParameter -> [512, 1]
Validating --> HL2.z = Plus(HL2.t[512, MBSize 0], HL2.b[512, 1]) -> [512, MBSize 0]
Validating --> HL2.y = Sigmoid(HL2.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> OL.t = Times(OL.W[132, 512], HL2.y[512, MBSize 0]) -> [132, MBSize 0]
Validating --> OL.b = LearnableParameter -> [132, 1]
Validating --> OL.z = Plus(OL.t[132, MBSize 0], OL.b[132, 1]) -> [132, MBSize 0]
Validating --> globalPrior = LearnableParameter -> [132, 1]
Validating --> logPrior = Log(globalPrior[132, 1]) -> [132, 1]
Validating --> scaledLogLikelihood = Minus(OL.z[132, MBSize 0], logPrior[132, 1]) -> [132, MBSize 0]

Validating for node scaledLogLikelihood, final verification.

Validating --> OL.W = LearnableParameter -> [132, 512]
Validating --> HL2.W = LearnableParameter -> [512, 512]
Validating --> HL1.W = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> globalMean = LearnableParameter -> [363, 1]
Validating --> globalInvStd = LearnableParameter -> [363, 1]
Validating --> featNorm = PerDimMeanVarNormalization(features[363, MBSize 0], globalMean[363, 1], globalInvStd[363, 1]) -> [363, MBSize 0]
Validating --> HL1.t = Times(HL1.W[512, 363], featNorm[363, MBSize 0]) -> [512, MBSize 0]
Validating --> HL1.b = LearnableParameter -> [512, 1]
Validating --> HL1.z = Plus(HL1.t[512, MBSize 0], HL1.b[512, 1]) -> [512, MBSize 0]
Validating --> HL1.y = Sigmoid(HL1.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL2.t = Times(HL2.W[512, 512], HL1.y[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL2.b = LearnableParameter -> [512, 1]
Validating --> HL2.z = Plus(HL2.t[512, MBSize 0], HL2.b[512, 1]) -> [512, MBSize 0]
Validating --> HL2.y = Sigmoid(HL2.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> OL.t = Times(OL.W[132, 512], HL2.y[512, MBSize 0]) -> [132, MBSize 0]
Validating --> OL.b = LearnableParameter -> [132, 1]
Validating --> OL.z = Plus(OL.t[132, MBSize 0], OL.b[132, 1]) -> [132, MBSize 0]
Validating --> globalPrior = LearnableParameter -> [132, 1]
Validating --> logPrior = Log(globalPrior[132, 1]) -> [132, 1]
Validating --> scaledLogLikelihood = Minus(OL.z[132, MBSize 0], logPrior[132, 1]) -> [132, MBSize 0]

10 out of 21 nodes do not share the minibatch layout with the input data.


Validating for node err. 20 nodes to process in pass 1.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> OL.W = LearnableParameter -> [132, 512]
Validating --> HL2.W = LearnableParameter -> [512, 512]
Validating --> HL1.W = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> globalMean = LearnableParameter -> [363, 1]
Validating --> globalInvStd = LearnableParameter -> [363, 1]
Validating --> featNorm = PerDimMeanVarNormalization(features[363, MBSize 0], globalMean[363, 1], globalInvStd[363, 1]) -> [363, MBSize 0]
Validating --> HL1.t = Times(HL1.W[512, 363], featNorm[363, MBSize 0]) -> [512, MBSize 0]
Validating --> HL1.b = LearnableParameter -> [512, 1]
Validating --> HL1.z = Plus(HL1.t[512, MBSize 0], HL1.b[512, 1]) -> [512, MBSize 0]
Validating --> HL1.y = Sigmoid(HL1.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL2.t = Times(HL2.W[512, 512], HL1.y[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL2.b = LearnableParameter -> [512, 1]
Validating --> HL2.z = Plus(HL2.t[512, MBSize 0], HL2.b[512, 1]) -> [512, MBSize 0]
Validating --> HL2.y = Sigmoid(HL2.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> OL.t = Times(OL.W[132, 512], HL2.y[512, MBSize 0]) -> [132, MBSize 0]
Validating --> OL.b = LearnableParameter -> [132, 1]
Validating --> OL.z = Plus(OL.t[132, MBSize 0], OL.b[132, 1]) -> [132, MBSize 0]
Validating --> err = ErrorPrediction(labels[132, MBSize 0], OL.z[132, MBSize 0]) -> [1, 1]

Validating for node err. 9 nodes to process in pass 2.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> OL.W = LearnableParameter -> [132, 512]
Validating --> HL2.W = LearnableParameter -> [512, 512]
Validating --> HL1.W = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> globalMean = LearnableParameter -> [363, 1]
Validating --> globalInvStd = LearnableParameter -> [363, 1]
Validating --> featNorm = PerDimMeanVarNormalization(features[363, MBSize 0], globalMean[363, 1], globalInvStd[363, 1]) -> [363, MBSize 0]
Validating --> HL1.t = Times(HL1.W[512, 363], featNorm[363, MBSize 0]) -> [512, MBSize 0]
Validating --> HL1.b = LearnableParameter -> [512, 1]
Validating --> HL1.z = Plus(HL1.t[512, MBSize 0], HL1.b[512, 1]) -> [512, MBSize 0]
Validating --> HL1.y = Sigmoid(HL1.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL2.t = Times(HL2.W[512, 512], HL1.y[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL2.b = LearnableParameter -> [512, 1]
Validating --> HL2.z = Plus(HL2.t[512, MBSize 0], HL2.b[512, 1]) -> [512, MBSize 0]
Validating --> HL2.y = Sigmoid(HL2.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> OL.t = Times(OL.W[132, 512], HL2.y[512, MBSize 0]) -> [132, MBSize 0]
Validating --> OL.b = LearnableParameter -> [132, 1]
Validating --> OL.z = Plus(OL.t[132, MBSize 0], OL.b[132, 1]) -> [132, MBSize 0]
Validating --> err = ErrorPrediction(labels[132, MBSize 0], OL.z[132, MBSize 0]) -> [1, 1]

Validating for node err, final verification.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> OL.W = LearnableParameter -> [132, 512]
Validating --> HL2.W = LearnableParameter -> [512, 512]
Validating --> HL1.W = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> globalMean = LearnableParameter -> [363, 1]
Validating --> globalInvStd = LearnableParameter -> [363, 1]
Validating --> featNorm = PerDimMeanVarNormalization(features[363, MBSize 0], globalMean[363, 1], globalInvStd[363, 1]) -> [363, MBSize 0]
Validating --> HL1.t = Times(HL1.W[512, 363], featNorm[363, MBSize 0]) -> [512, MBSize 0]
Validating --> HL1.b = LearnableParameter -> [512, 1]
Validating --> HL1.z = Plus(HL1.t[512, MBSize 0], HL1.b[512, 1]) -> [512, MBSize 0]
Validating --> HL1.y = Sigmoid(HL1.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL2.t = Times(HL2.W[512, 512], HL1.y[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL2.b = LearnableParameter -> [512, 1]
Validating --> HL2.z = Plus(HL2.t[512, MBSize 0], HL2.b[512, 1]) -> [512, MBSize 0]
Validating --> HL2.y = Sigmoid(HL2.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> OL.t = Times(OL.W[132, 512], HL2.y[512, MBSize 0]) -> [132, MBSize 0]
Validating --> OL.b = LearnableParameter -> [132, 1]
Validating --> OL.z = Plus(OL.t[132, MBSize 0], OL.b[132, 1]) -> [132, MBSize 0]
Validating --> err = ErrorPrediction(labels[132, MBSize 0], OL.z[132, MBSize 0]) -> [1, 1]

9 out of 20 nodes do not share the minibatch layout with the input data.

Post-processing network complete.

SGD using CPU.

Training criterion node(s):
	cr = CrossEntropyWithSoftmax

Evaluation criterion node(s):
	err = ErrorPrediction


Allocating matrices for forward and/or backward propagation.
No PreCompute nodes found, skipping PreCompute step
Set Max Temp Mem Size For Convolution Nodes to 0 samples.
Starting Epoch 1: learning rate per sample = 0.003125  effective momentum = 0.900000  momentum as time constant = 2429.8 samples
minibatchiterator: epoch 0: frames [0..81920] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms

Starting minibatch loop.
 Epoch[ 1 of 2]-Minibatch[   1-  10, 3.12%]: SamplesSeen = 2560; TrainLossPerSample =  5.03521500; EvalErr[0]PerSample = 0.83554688; TotalTime = 0.1166s; SamplesPerSecond = 21953.1
 Epoch[ 1 of 2]-Minibatch[  11-  20, 6.25%]: SamplesSeen = 2560; TrainLossPerSample =  2.84799118; EvalErr[0]PerSample = 0.70156250; TotalTime = 0.1130s; SamplesPerSecond = 22664.3
 Epoch[ 1 of 2]-Minibatch[  21-  30, 9.38%]: SamplesSeen = 2560; TrainLossPerSample =  2.43217316; EvalErr[0]PerSample = 0.63007813; TotalTime = 0.1130s; SamplesPerSecond = 22645.4
 Epoch[ 1 of 2]-Minibatch[  31-  40, 12.50%]: SamplesSeen = 2560; TrainLossPerSample =  2.05319138; EvalErr[0]PerSample = 0.57929688; TotalTime = 0.1129s; SamplesPerSecond = 22670.1
 Epoch[ 1 of 2]-Minibatch[  41-  50, 15.62%]: SamplesSeen = 2560; TrainLossPerSample =  1.81479416; EvalErr[0]PerSample = 0.50507813; TotalTime = 0.1130s; SamplesPerSecond = 22656.5
 Epoch[ 1 of 2]-Minibatch[  51-  60, 18.75%]: SamplesSeen = 2560; TrainLossPerSample =  1.65699310; EvalErr[0]PerSample = 0.47656250; TotalTime = 0.1130s; SamplesPerSecond = 22653.1
 Epoch[ 1 of 2]-Minibatch[  61-  70, 21.88%]: SamplesSeen = 2560; TrainLossPerSample =  1.60449066; EvalErr[0]PerSample = 0.46406250; TotalTime = 0.1131s; SamplesPerSecond = 22631.2
 Epoch[ 1 of 2]-Minibatch[  71-  80, 25.00%]: SamplesSeen = 2560; TrainLossPerSample =  1.54690704; EvalErr[0]PerSample = 0.44570312; TotalTime = 0.1131s; SamplesPerSecond = 22628.2
 Epoch[ 1 of 2]-Minibatch[  81-  90, 28.12%]: SamplesSeen = 2560; TrainLossPerSample =  1.45256042; EvalErr[0]PerSample = 0.43671875; TotalTime = 0.1131s; SamplesPerSecond = 22630.0
 Epoch[ 1 of 2]-Minibatch[  91- 100, 31.25%]: SamplesSeen = 2560; TrainLossPerSample =  1.48195496; EvalErr[0]PerSample = 0.44882813; TotalTime = 0.1132s; SamplesPerSecond = 22611.4
 Epoch[ 1 of 2]-Minibatch[ 101- 110, 34.38%]: SamplesSeen = 2560; TrainLossPerSample =  1.39197998; EvalErr[0]PerSample = 0.41718750; TotalTime = 0.1145s; SamplesPerSecond = 22363.9
 Epoch[ 1 of 2]-Minibatch[ 111- 120, 37.50%]: SamplesSeen = 2560; TrainLossPerSample =  1.38458710; EvalErr[0]PerSample = 0.39726563; TotalTime = 0.1132s; SamplesPerSecond = 22605.9
 Epoch[ 1 of 2]-Minibatch[ 121- 130, 40.62%]: SamplesSeen = 2560; TrainLossPerSample =  1.32102051; EvalErr[0]PerSample = 0.39218750; TotalTime = 0.1131s; SamplesPerSecond = 22635.2
 Epoch[ 1 of 2]-Minibatch[ 131- 140, 43.75%]: SamplesSeen = 2560; TrainLossPerSample =  1.28715210; EvalErr[0]PerSample = 0.39609375; TotalTime = 0.1132s; SamplesPerSecond = 22621.8
 Epoch[ 1 of 2]-Minibatch[ 141- 150, 46.88%]: SamplesSeen = 2560; TrainLossPerSample =  1.30798645; EvalErr[0]PerSample = 0.38554688; TotalTime = 0.1162s; SamplesPerSecond = 22026.1
 Epoch[ 1 of 2]-Minibatch[ 151- 160, 50.00%]: SamplesSeen = 2560; TrainLossPerSample =  1.31445618; EvalErr[0]PerSample = 0.38984375; TotalTime = 0.1131s; SamplesPerSecond = 22632.2
 Epoch[ 1 of 2]-Minibatch[ 161- 170, 53.12%]: SamplesSeen = 2560; TrainLossPerSample =  1.26487427; EvalErr[0]PerSample = 0.36875000; TotalTime = 0.1131s; SamplesPerSecond = 22635.0
 Epoch[ 1 of 2]-Minibatch[ 171- 180, 56.25%]: SamplesSeen = 2560; TrainLossPerSample =  1.29167786; EvalErr[0]PerSample = 0.37460938; TotalTime = 0.1131s; SamplesPerSecond = 22640.2
 Epoch[ 1 of 2]-Minibatch[ 181- 190, 59.38%]: SamplesSeen = 2560; TrainLossPerSample =  1.24710999; EvalErr[0]PerSample = 0.37656250; TotalTime = 0.1132s; SamplesPerSecond = 22612.6
 Epoch[ 1 of 2]-Minibatch[ 191- 200, 62.50%]: SamplesSeen = 2560; TrainLossPerSample =  1.27827454; EvalErr[0]PerSample = 0.39023438; TotalTime = 0.1131s; SamplesPerSecond = 22633.6
 Epoch[ 1 of 2]-Minibatch[ 201- 210, 65.62%]: SamplesSeen = 2560; TrainLossPerSample =  1.25323792; EvalErr[0]PerSample = 0.37421875; TotalTime = 0.1132s; SamplesPerSecond = 22621.2
 Epoch[ 1 of 2]-Minibatch[ 211- 220, 68.75%]: SamplesSeen = 2560; TrainLossPerSample =  1.29031677; EvalErr[0]PerSample = 0.37695312; TotalTime = 0.1132s; SamplesPerSecond = 22617.2
 Epoch[ 1 of 2]-Minibatch[ 221- 230, 71.88%]: SamplesSeen = 2560; TrainLossPerSample =  1.21824341; EvalErr[0]PerSample = 0.36562500; TotalTime = 0.1131s; SamplesPerSecond = 22644.2
 Epoch[ 1 of 2]-Minibatch[ 231- 240, 75.00%]: SamplesSeen = 2560; TrainLossPerSample =  1.25034180; EvalErr[0]PerSample = 0.37304688; TotalTime = 0.1131s; SamplesPerSecond = 22637.8
 Epoch[ 1 of 2]-Minibatch[ 241- 250, 78.12%]: SamplesSeen = 2560; TrainLossPerSample =  1.24739075; EvalErr[0]PerSample = 0.37890625; TotalTime = 0.1131s; SamplesPerSecond = 22632.4
 Epoch[ 1 of 2]-Minibatch[ 251- 260, 81.25%]: SamplesSeen = 2560; TrainLossPerSample =  1.22057800; EvalErr[0]PerSample = 0.37929687; TotalTime = 0.1132s; SamplesPerSecond = 22612.6
 Epoch[ 1 of 2]-Minibatch[ 261- 270, 84.38%]: SamplesSeen = 2560; TrainLossPerSample =  1.20379944; EvalErr[0]PerSample = 0.37265625; TotalTime = 0.1132s; SamplesPerSecond = 22609.4
 Epoch[ 1 of 2]-Minibatch[ 271- 280, 87.50%]: SamplesSeen = 2560; TrainLossPerSample =  1.19783020; EvalErr[0]PerSample = 0.36992188; TotalTime = 0.1131s; SamplesPerSecond = 22639.2
 Epoch[ 1 of 2]-Minibatch[ 281- 290, 90.62%]: SamplesSeen = 2560; TrainLossPerSample =  1.19216309; EvalErr[0]PerSample = 0.36367187; TotalTime = 0.1131s; SamplesPerSecond = 22630.8
 Epoch[ 1 of 2]-Minibatch[ 291- 300, 93.75%]: SamplesSeen = 2560; TrainLossPerSample =  1.17020264; EvalErr[0]PerSample = 0.35546875; TotalTime = 0.1132s; SamplesPerSecond = 22609.6
 Epoch[ 1 of 2]-Minibatch[ 301- 310, 96.88%]: SamplesSeen = 2560; TrainLossPerSample =  1.20345154; EvalErr[0]PerSample = 0.36562500; TotalTime = 0.1131s; SamplesPerSecond = 22628.8
 Epoch[ 1 of 2]-Minibatch[ 311- 320, 100.00%]: SamplesSeen = 2560; TrainLossPerSample =  1.17263489; EvalErr[0]PerSample = 0.36718750; TotalTime = 0.1124s; SamplesPerSecond = 22766.7
Finished Epoch[ 1 of 2]: [Training Set] TrainLossPerSample = 1.5511119; EvalErrPerSample = 0.43294677; AvgLearningRatePerSample = 0.003125; EpochTime=3.73971
Starting Epoch 2: learning rate per sample = 0.003125  effective momentum = 0.900000  momentum as time constant = 2429.8 samples
minibatchiterator: epoch 1: frames [81920..163840] (first utterance at frame 81920), data subset 0 of 1, with 1 datapasses

Starting minibatch loop.
 Epoch[ 2 of 2]-Minibatch[   1-  10, 3.12%]: SamplesSeen = 2560; TrainLossPerSample =  1.18681622; EvalErr[0]PerSample = 0.36289063; TotalTime = 0.1131s; SamplesPerSecond = 22633.4
 Epoch[ 2 of 2]-Minibatch[  11-  20, 6.25%]: SamplesSeen = 2560; TrainLossPerSample =  1.20656300; EvalErr[0]PerSample = 0.37031250; TotalTime = 0.1132s; SamplesPerSecond = 22624.6
 Epoch[ 2 of 2]-Minibatch[  21-  30, 9.38%]: SamplesSeen = 2560; TrainLossPerSample =  1.18077774; EvalErr[0]PerSample = 0.35937500; TotalTime = 0.1131s; SamplesPerSecond = 22638.2
 Epoch[ 2 of 2]-Minibatch[  31-  40, 12.50%]: SamplesSeen = 2560; TrainLossPerSample =  1.16997910; EvalErr[0]PerSample = 0.35117188; TotalTime = 0.1132s; SamplesPerSecond = 22610.6
 Epoch[ 2 of 2]-Minibatch[  41-  50, 15.62%]: SamplesSeen = 2560; TrainLossPerSample =  1.19292183; EvalErr[0]PerSample = 0.34843750; TotalTime = 0.1137s; SamplesPerSecond = 22513.8
 Epoch[ 2 of 2]-Minibatch[  51-  60, 18.75%]: SamplesSeen = 2560; TrainLossPerSample =  1.14131966; EvalErr[0]PerSample = 0.35546875; TotalTime = 0.1133s; SamplesPerSecond = 22588.3
 Epoch[ 2 of 2]-Minibatch[  61-  70, 21.88%]: SamplesSeen = 2560; TrainLossPerSample =  1.15585327; EvalErr[0]PerSample = 0.35429688; TotalTime = 0.1130s; SamplesPerSecond = 22649.7
 Epoch[ 2 of 2]-Minibatch[  71-  80, 25.00%]: SamplesSeen = 2560; TrainLossPerSample =  1.16749725; EvalErr[0]PerSample = 0.35937500; TotalTime = 0.1131s; SamplesPerSecond = 22631.4
 Epoch[ 2 of 2]-Minibatch[  81-  90, 28.12%]: SamplesSeen = 2560; TrainLossPerSample =  1.19115524; EvalErr[0]PerSample = 0.36523438; TotalTime = 0.1132s; SamplesPerSecond = 22620.8
 Epoch[ 2 of 2]-Minibatch[  91- 100, 31.25%]: SamplesSeen = 2560; TrainLossPerSample =  1.15414658; EvalErr[0]PerSample = 0.34960938; TotalTime = 0.1131s; SamplesPerSecond = 22629.8
 Epoch[ 2 of 2]-Minibatch[ 101- 110, 34.38%]: SamplesSeen = 2560; TrainLossPerSample =  1.14885178; EvalErr[0]PerSample = 0.35312500; TotalTime = 0.1131s; SamplesPerSecond = 22625.8
 Epoch[ 2 of 2]-Minibatch[ 111- 120, 37.50%]: SamplesSeen = 2560; TrainLossPerSample =  1.13697357; EvalErr[0]PerSample = 0.34414062; TotalTime = 0.1130s; SamplesPerSecond = 22650.3
 Epoch[ 2 of 2]-Minibatch[ 121- 130, 40.62%]: SamplesSeen = 2560; TrainLossPerSample =  1.14294739; EvalErr[0]PerSample = 0.33398438; TotalTime = 0.1134s; SamplesPerSecond = 22578.5
 Epoch[ 2 of 2]-Minibatch[ 131- 140, 43.75%]: SamplesSeen = 2560; TrainLossPerSample =  1.11870117; EvalErr[0]PerSample = 0.35039063; TotalTime = 0.1132s; SamplesPerSecond = 22609.0
 Epoch[ 2 of 2]-Minibatch[ 141- 150, 46.88%]: SamplesSeen = 2560; TrainLossPerSample =  1.09258270; EvalErr[0]PerSample = 0.32812500; TotalTime = 0.1132s; SamplesPerSecond = 22612.4
 Epoch[ 2 of 2]-Minibatch[ 151- 160, 50.00%]: SamplesSeen = 2560; TrainLossPerSample =  1.08270874; EvalErr[0]PerSample = 0.33710937; TotalTime = 0.1131s; SamplesPerSecond = 22636.2
 Epoch[ 2 of 2]-Minibatch[ 161- 170, 53.12%]: SamplesSeen = 2560; TrainLossPerSample =  1.09057159; EvalErr[0]PerSample = 0.33906250; TotalTime = 0.1131s; SamplesPerSecond = 22625.4
 Epoch[ 2 of 2]-Minibatch[ 171- 180, 56.25%]: SamplesSeen = 2560; TrainLossPerSample =  1.09904175; EvalErr[0]PerSample = 0.32890625; TotalTime = 0.1131s; SamplesPerSecond = 22626.4
 Epoch[ 2 of 2]-Minibatch[ 181- 190, 59.38%]: SamplesSeen = 2560; TrainLossPerSample =  1.07942047; EvalErr[0]PerSample = 0.32734375; TotalTime = 0.1131s; SamplesPerSecond = 22632.4
 Epoch[ 2 of 2]-Minibatch[ 191- 200, 62.50%]: SamplesSeen = 2560; TrainLossPerSample =  1.07688904; EvalErr[0]PerSample = 0.32539062; TotalTime = 0.1132s; SamplesPerSecond = 22623.6
 Epoch[ 2 of 2]-Minibatch[ 201- 210, 65.62%]: SamplesSeen = 2560; TrainLossPerSample =  1.07583466; EvalErr[0]PerSample = 0.33632812; TotalTime = 0.1133s; SamplesPerSecond = 22590.1
 Epoch[ 2 of 2]-Minibatch[ 211- 220, 68.75%]: SamplesSeen = 2560; TrainLossPerSample =  1.06828156; EvalErr[0]PerSample = 0.32109375; TotalTime = 0.1131s; SamplesPerSecond = 22627.2
 Epoch[ 2 of 2]-Minibatch[ 221- 230, 71.88%]: SamplesSeen = 2560; TrainLossPerSample =  1.08527069; EvalErr[0]PerSample = 0.33125000; TotalTime = 0.1132s; SamplesPerSecond = 22617.2
 Epoch[ 2 of 2]-Minibatch[ 231- 240, 75.00%]: SamplesSeen = 2560; TrainLossPerSample =  1.08339844; EvalErr[0]PerSample = 0.32968750; TotalTime = 0.1132s; SamplesPerSecond = 22607.7
 Epoch[ 2 of 2]-Minibatch[ 241- 250, 78.12%]: SamplesSeen = 2560; TrainLossPerSample =  1.03799438; EvalErr[0]PerSample = 0.31523438; TotalTime = 0.1132s; SamplesPerSecond = 22614.0
 Epoch[ 2 of 2]-Minibatch[ 251- 260, 81.25%]: SamplesSeen = 2560; TrainLossPerSample =  1.11759033; EvalErr[0]PerSample = 0.33125000; TotalTime = 0.1153s; SamplesPerSecond = 22211.8
 Epoch[ 2 of 2]-Minibatch[ 261- 270, 84.38%]: SamplesSeen = 2560; TrainLossPerSample =  1.11881714; EvalErr[0]PerSample = 0.33476563; TotalTime = 0.1144s; SamplesPerSecond = 22382.7
 Epoch[ 2 of 2]-Minibatch[ 271- 280, 87.50%]: SamplesSeen = 2560; TrainLossPerSample =  1.11436768; EvalErr[0]PerSample = 0.34257813; TotalTime = 0.1133s; SamplesPerSecond = 22590.3
 Epoch[ 2 of 2]-Minibatch[ 281- 290, 90.62%]: SamplesSeen = 2560; TrainLossPerSample =  1.07169495; EvalErr[0]PerSample = 0.31914063; TotalTime = 0.1132s; SamplesPerSecond = 22613.4
 Epoch[ 2 of 2]-Minibatch[ 291- 300, 93.75%]: SamplesSeen = 2560; TrainLossPerSample =  1.06234131; EvalErr[0]PerSample = 0.32148437; TotalTime = 0.1132s; SamplesPerSecond = 22617.4
 Epoch[ 2 of 2]-Minibatch[ 301- 310, 96.88%]: SamplesSeen = 2560; TrainLossPerSample =  1.12825012; EvalErr[0]PerSample = 0.32695313; TotalTime = 0.1130s; SamplesPerSecond = 22663.1
 Epoch[ 2 of 2]-Minibatch[ 311- 320, 100.00%]: SamplesSeen = 2560; TrainLossPerSample =  1.03787231; EvalErr[0]PerSample = 0.32343750; TotalTime = 0.1126s; SamplesPerSecond = 22738.6
Finished Epoch[ 2 of 2]: [Training Set] TrainLossPerSample = 1.1192948; EvalErrPerSample = 0.33990479; AvgLearningRatePerSample = 0.003125; EpochTime=3.63218
CNTKCommandTrainEnd: dptPre2

Post-processing network...

3 roots:
	cr = CrossEntropyWithSoftmax
	err = ErrorPrediction
	scaledLogLikelihood = Minus
FormNestedNetwork: WARNING: Was called twice for cr CrossEntropyWithSoftmax operation
FormNestedNetwork: WARNING: Was called twice for err ErrorPrediction operation
FormNestedNetwork: WARNING: Was called twice for scaledLogLikelihood Minus operation


Validating for node cr. 20 nodes to process in pass 1.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> OL.W = LearnableParameter -> [132, 512]
Validating --> HL2.W = LearnableParameter -> [512, 512]
Validating --> HL1.W = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> globalMean = LearnableParameter -> [363, 1]
Validating --> globalInvStd = LearnableParameter -> [363, 1]
Validating --> featNorm = PerDimMeanVarNormalization(features[363, MBSize 0], globalMean[363, 1], globalInvStd[363, 1]) -> [363, MBSize 0]
Validating --> HL1.t = Times(HL1.W[512, 363], featNorm[363, MBSize 0]) -> [512, MBSize 0]
Validating --> HL1.b = LearnableParameter -> [512, 1]
Validating --> HL1.z = Plus(HL1.t[512, MBSize 0], HL1.b[512, 1]) -> [512, MBSize 0]
Validating --> HL1.y = Sigmoid(HL1.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL2.t = Times(HL2.W[512, 512], HL1.y[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL2.b = LearnableParameter -> [512, 1]
Validating --> HL2.z = Plus(HL2.t[512, MBSize 0], HL2.b[512, 1]) -> [512, MBSize 0]
Validating --> HL2.y = Sigmoid(HL2.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> OL.t = Times(OL.W[132, 512], HL2.y[512, MBSize 0]) -> [132, MBSize 0]
Validating --> OL.b = LearnableParameter -> [132, 1]
Validating --> OL.z = Plus(OL.t[132, MBSize 0], OL.b[132, 1]) -> [132, MBSize 0]
Validating --> cr = CrossEntropyWithSoftmax(labels[132, MBSize 0], OL.z[132, MBSize 0]) -> [1, 1]

Validating for node cr. 10 nodes to process in pass 2.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> OL.W = LearnableParameter -> [132, 512]
Validating --> HL2.W = LearnableParameter -> [512, 512]
Validating --> HL1.W = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> globalMean = LearnableParameter -> [363, 1]
Validating --> globalInvStd = LearnableParameter -> [363, 1]
Validating --> featNorm = PerDimMeanVarNormalization(features[363, MBSize 0], globalMean[363, 1], globalInvStd[363, 1]) -> [363, MBSize 0]
Validating --> HL1.t = Times(HL1.W[512, 363], featNorm[363, MBSize 0]) -> [512, MBSize 0]
Validating --> HL1.b = LearnableParameter -> [512, 1]
Validating --> HL1.z = Plus(HL1.t[512, MBSize 0], HL1.b[512, 1]) -> [512, MBSize 0]
Validating --> HL1.y = Sigmoid(HL1.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL2.t = Times(HL2.W[512, 512], HL1.y[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL2.b = LearnableParameter -> [512, 1]
Validating --> HL2.z = Plus(HL2.t[512, MBSize 0], HL2.b[512, 1]) -> [512, MBSize 0]
Validating --> HL2.y = Sigmoid(HL2.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> OL.t = Times(OL.W[132, 512], HL2.y[512, MBSize 0]) -> [132, MBSize 0]
Validating --> OL.b = LearnableParameter -> [132, 1]
Validating --> OL.z = Plus(OL.t[132, MBSize 0], OL.b[132, 1]) -> [132, MBSize 0]
Validating --> cr = CrossEntropyWithSoftmax(labels[132, MBSize 0], OL.z[132, MBSize 0]) -> [1, 1]

Validating for node cr, final verification.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> OL.W = LearnableParameter -> [132, 512]
Validating --> HL2.W = LearnableParameter -> [512, 512]
Validating --> HL1.W = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> globalMean = LearnableParameter -> [363, 1]
Validating --> globalInvStd = LearnableParameter -> [363, 1]
Validating --> featNorm = PerDimMeanVarNormalization(features[363, MBSize 0], globalMean[363, 1], globalInvStd[363, 1]) -> [363, MBSize 0]
Validating --> HL1.t = Times(HL1.W[512, 363], featNorm[363, MBSize 0]) -> [512, MBSize 0]
Validating --> HL1.b = LearnableParameter -> [512, 1]
Validating --> HL1.z = Plus(HL1.t[512, MBSize 0], HL1.b[512, 1]) -> [512, MBSize 0]
Validating --> HL1.y = Sigmoid(HL1.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL2.t = Times(HL2.W[512, 512], HL1.y[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL2.b = LearnableParameter -> [512, 1]
Validating --> HL2.z = Plus(HL2.t[512, MBSize 0], HL2.b[512, 1]) -> [512, MBSize 0]
Validating --> HL2.y = Sigmoid(HL2.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> OL.t = Times(OL.W[132, 512], HL2.y[512, MBSize 0]) -> [132, MBSize 0]
Validating --> OL.b = LearnableParameter -> [132, 1]
Validating --> OL.z = Plus(OL.t[132, MBSize 0], OL.b[132, 1]) -> [132, MBSize 0]
Validating --> cr = CrossEntropyWithSoftmax(labels[132, MBSize 0], OL.z[132, MBSize 0]) -> [1, 1]

9 out of 20 nodes do not share the minibatch layout with the input data.


Validating for node err. 20 nodes to process in pass 1.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> OL.W = LearnableParameter -> [132, 512]
Validating --> HL2.W = LearnableParameter -> [512, 512]
Validating --> HL1.W = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> globalMean = LearnableParameter -> [363, 1]
Validating --> globalInvStd = LearnableParameter -> [363, 1]
Validating --> featNorm = PerDimMeanVarNormalization(features[363, MBSize 0], globalMean[363, 1], globalInvStd[363, 1]) -> [363, MBSize 0]
Validating --> HL1.t = Times(HL1.W[512, 363], featNorm[363, MBSize 0]) -> [512, MBSize 0]
Validating --> HL1.b = LearnableParameter -> [512, 1]
Validating --> HL1.z = Plus(HL1.t[512, MBSize 0], HL1.b[512, 1]) -> [512, MBSize 0]
Validating --> HL1.y = Sigmoid(HL1.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL2.t = Times(HL2.W[512, 512], HL1.y[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL2.b = LearnableParameter -> [512, 1]
Validating --> HL2.z = Plus(HL2.t[512, MBSize 0], HL2.b[512, 1]) -> [512, MBSize 0]
Validating --> HL2.y = Sigmoid(HL2.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> OL.t = Times(OL.W[132, 512], HL2.y[512, MBSize 0]) -> [132, MBSize 0]
Validating --> OL.b = LearnableParameter -> [132, 1]
Validating --> OL.z = Plus(OL.t[132, MBSize 0], OL.b[132, 1]) -> [132, MBSize 0]
Validating --> err = ErrorPrediction(labels[132, MBSize 0], OL.z[132, MBSize 0]) -> [1, 1]

Validating for node err. 9 nodes to process in pass 2.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> OL.W = LearnableParameter -> [132, 512]
Validating --> HL2.W = LearnableParameter -> [512, 512]
Validating --> HL1.W = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> globalMean = LearnableParameter -> [363, 1]
Validating --> globalInvStd = LearnableParameter -> [363, 1]
Validating --> featNorm = PerDimMeanVarNormalization(features[363, MBSize 0], globalMean[363, 1], globalInvStd[363, 1]) -> [363, MBSize 0]
Validating --> HL1.t = Times(HL1.W[512, 363], featNorm[363, MBSize 0]) -> [512, MBSize 0]
Validating --> HL1.b = LearnableParameter -> [512, 1]
Validating --> HL1.z = Plus(HL1.t[512, MBSize 0], HL1.b[512, 1]) -> [512, MBSize 0]
Validating --> HL1.y = Sigmoid(HL1.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL2.t = Times(HL2.W[512, 512], HL1.y[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL2.b = LearnableParameter -> [512, 1]
Validating --> HL2.z = Plus(HL2.t[512, MBSize 0], HL2.b[512, 1]) -> [512, MBSize 0]
Validating --> HL2.y = Sigmoid(HL2.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> OL.t = Times(OL.W[132, 512], HL2.y[512, MBSize 0]) -> [132, MBSize 0]
Validating --> OL.b = LearnableParameter -> [132, 1]
Validating --> OL.z = Plus(OL.t[132, MBSize 0], OL.b[132, 1]) -> [132, MBSize 0]
Validating --> err = ErrorPrediction(labels[132, MBSize 0], OL.z[132, MBSize 0]) -> [1, 1]

Validating for node err, final verification.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> OL.W = LearnableParameter -> [132, 512]
Validating --> HL2.W = LearnableParameter -> [512, 512]
Validating --> HL1.W = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> globalMean = LearnableParameter -> [363, 1]
Validating --> globalInvStd = LearnableParameter -> [363, 1]
Validating --> featNorm = PerDimMeanVarNormalization(features[363, MBSize 0], globalMean[363, 1], globalInvStd[363, 1]) -> [363, MBSize 0]
Validating --> HL1.t = Times(HL1.W[512, 363], featNorm[363, MBSize 0]) -> [512, MBSize 0]
Validating --> HL1.b = LearnableParameter -> [512, 1]
Validating --> HL1.z = Plus(HL1.t[512, MBSize 0], HL1.b[512, 1]) -> [512, MBSize 0]
Validating --> HL1.y = Sigmoid(HL1.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL2.t = Times(HL2.W[512, 512], HL1.y[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL2.b = LearnableParameter -> [512, 1]
Validating --> HL2.z = Plus(HL2.t[512, MBSize 0], HL2.b[512, 1]) -> [512, MBSize 0]
Validating --> HL2.y = Sigmoid(HL2.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> OL.t = Times(OL.W[132, 512], HL2.y[512, MBSize 0]) -> [132, MBSize 0]
Validating --> OL.b = LearnableParameter -> [132, 1]
Validating --> OL.z = Plus(OL.t[132, MBSize 0], OL.b[132, 1]) -> [132, MBSize 0]
Validating --> err = ErrorPrediction(labels[132, MBSize 0], OL.z[132, MBSize 0]) -> [1, 1]

9 out of 20 nodes do not share the minibatch layout with the input data.


Validating for node scaledLogLikelihood. 21 nodes to process in pass 1.

Validating --> OL.W = LearnableParameter -> [132, 512]
Validating --> HL2.W = LearnableParameter -> [512, 512]
Validating --> HL1.W = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> globalMean = LearnableParameter -> [363, 1]
Validating --> globalInvStd = LearnableParameter -> [363, 1]
Validating --> featNorm = PerDimMeanVarNormalization(features[363, MBSize 0], globalMean[363, 1], globalInvStd[363, 1]) -> [363, MBSize 0]
Validating --> HL1.t = Times(HL1.W[512, 363], featNorm[363, MBSize 0]) -> [512, MBSize 0]
Validating --> HL1.b = LearnableParameter -> [512, 1]
Validating --> HL1.z = Plus(HL1.t[512, MBSize 0], HL1.b[512, 1]) -> [512, MBSize 0]
Validating --> HL1.y = Sigmoid(HL1.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL2.t = Times(HL2.W[512, 512], HL1.y[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL2.b = LearnableParameter -> [512, 1]
Validating --> HL2.z = Plus(HL2.t[512, MBSize 0], HL2.b[512, 1]) -> [512, MBSize 0]
Validating --> HL2.y = Sigmoid(HL2.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> OL.t = Times(OL.W[132, 512], HL2.y[512, MBSize 0]) -> [132, MBSize 0]
Validating --> OL.b = LearnableParameter -> [132, 1]
Validating --> OL.z = Plus(OL.t[132, MBSize 0], OL.b[132, 1]) -> [132, MBSize 0]
Validating --> globalPrior = LearnableParameter -> [132, 1]
Validating --> logPrior = Log(globalPrior[132, 1]) -> [132, 1]
Validating --> scaledLogLikelihood = Minus(OL.z[132, MBSize 0], logPrior[132, 1]) -> [132, MBSize 0]

Validating for node scaledLogLikelihood. 10 nodes to process in pass 2.

Validating --> OL.W = LearnableParameter -> [132, 512]
Validating --> HL2.W = LearnableParameter -> [512, 512]
Validating --> HL1.W = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> globalMean = LearnableParameter -> [363, 1]
Validating --> globalInvStd = LearnableParameter -> [363, 1]
Validating --> featNorm = PerDimMeanVarNormalization(features[363, MBSize 0], globalMean[363, 1], globalInvStd[363, 1]) -> [363, MBSize 0]
Validating --> HL1.t = Times(HL1.W[512, 363], featNorm[363, MBSize 0]) -> [512, MBSize 0]
Validating --> HL1.b = LearnableParameter -> [512, 1]
Validating --> HL1.z = Plus(HL1.t[512, MBSize 0], HL1.b[512, 1]) -> [512, MBSize 0]
Validating --> HL1.y = Sigmoid(HL1.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL2.t = Times(HL2.W[512, 512], HL1.y[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL2.b = LearnableParameter -> [512, 1]
Validating --> HL2.z = Plus(HL2.t[512, MBSize 0], HL2.b[512, 1]) -> [512, MBSize 0]
Validating --> HL2.y = Sigmoid(HL2.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> OL.t = Times(OL.W[132, 512], HL2.y[512, MBSize 0]) -> [132, MBSize 0]
Validating --> OL.b = LearnableParameter -> [132, 1]
Validating --> OL.z = Plus(OL.t[132, MBSize 0], OL.b[132, 1]) -> [132, MBSize 0]
Validating --> globalPrior = LearnableParameter -> [132, 1]
Validating --> logPrior = Log(globalPrior[132, 1]) -> [132, 1]
Validating --> scaledLogLikelihood = Minus(OL.z[132, MBSize 0], logPrior[132, 1]) -> [132, MBSize 0]

Validating for node scaledLogLikelihood, final verification.

Validating --> OL.W = LearnableParameter -> [132, 512]
Validating --> HL2.W = LearnableParameter -> [512, 512]
Validating --> HL1.W = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> globalMean = LearnableParameter -> [363, 1]
Validating --> globalInvStd = LearnableParameter -> [363, 1]
Validating --> featNorm = PerDimMeanVarNormalization(features[363, MBSize 0], globalMean[363, 1], globalInvStd[363, 1]) -> [363, MBSize 0]
Validating --> HL1.t = Times(HL1.W[512, 363], featNorm[363, MBSize 0]) -> [512, MBSize 0]
Validating --> HL1.b = LearnableParameter -> [512, 1]
Validating --> HL1.z = Plus(HL1.t[512, MBSize 0], HL1.b[512, 1]) -> [512, MBSize 0]
Validating --> HL1.y = Sigmoid(HL1.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL2.t = Times(HL2.W[512, 512], HL1.y[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL2.b = LearnableParameter -> [512, 1]
Validating --> HL2.z = Plus(HL2.t[512, MBSize 0], HL2.b[512, 1]) -> [512, MBSize 0]
Validating --> HL2.y = Sigmoid(HL2.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> OL.t = Times(OL.W[132, 512], HL2.y[512, MBSize 0]) -> [132, MBSize 0]
Validating --> OL.b = LearnableParameter -> [132, 1]
Validating --> OL.z = Plus(OL.t[132, MBSize 0], OL.b[132, 1]) -> [132, MBSize 0]
Validating --> globalPrior = LearnableParameter -> [132, 1]
Validating --> logPrior = Log(globalPrior[132, 1]) -> [132, 1]
Validating --> scaledLogLikelihood = Minus(OL.z[132, MBSize 0], logPrior[132, 1]) -> [132, MBSize 0]

10 out of 21 nodes do not share the minibatch layout with the input data.

Post-processing network complete.
CNTKCommandTrainBegin: speechTrain
NDLBuilder Using CPU
reading script file /tmp/cntk-test-20151216094712.720058/Speech/DNN_SequenceTraining@release_cpu/TestData/glob_0000.scp ... 948 entries
total 132 state names in state list /tmp/cntk-test-20151216094712.720058/Speech/DNN_SequenceTraining@release_cpu/TestData/state.list
htkmlfreader: reading MLF file /tmp/cntk-test-20151216094712.720058/Speech/DNN_SequenceTraining@release_cpu/TestData/glob_0000.mlf ... total 948 entries
...............................................................................................feature set 0: 252734 frames in 948 out of 948 utterances
label set 0: 129 classes
minibatchutterancesource: 948 utterances grouped into 3 chunks, av. chunk size: 316.0 utterances, 84244.7 frames
Starting from checkpoint. Load Network From File /tmp/cntk-test-20151216094712.720058/Speech/DNN_SequenceTraining@release_cpu/models/cntkSpeech.0.

Post-processing network...

3 roots:
	scaledLogLikelihood = Minus
	err = ErrorPrediction
	cr = CrossEntropyWithSoftmax
FormNestedNetwork: WARNING: Was called twice for scaledLogLikelihood Minus operation
FormNestedNetwork: WARNING: Was called twice for err ErrorPrediction operation
FormNestedNetwork: WARNING: Was called twice for cr CrossEntropyWithSoftmax operation


Validating for node scaledLogLikelihood. 26 nodes to process in pass 1.

Validating --> OL.W = LearnableParameter -> [132, 512]
Validating --> HL3.W = LearnableParameter -> [512, 512]
Validating --> HL2.W = LearnableParameter -> [512, 512]
Validating --> HL1.W = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> globalMean = LearnableParameter -> [363, 1]
Validating --> globalInvStd = LearnableParameter -> [363, 1]
Validating --> featNorm = PerDimMeanVarNormalization(features[363, MBSize 0], globalMean[363, 1], globalInvStd[363, 1]) -> [363, MBSize 0]
Validating --> HL1.t = Times(HL1.W[512, 363], featNorm[363, MBSize 0]) -> [512, MBSize 0]
Validating --> HL1.b = LearnableParameter -> [512, 1]
Validating --> HL1.z = Plus(HL1.t[512, MBSize 0], HL1.b[512, 1]) -> [512, MBSize 0]
Validating --> HL1.y = Sigmoid(HL1.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL2.t = Times(HL2.W[512, 512], HL1.y[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL2.b = LearnableParameter -> [512, 1]
Validating --> HL2.z = Plus(HL2.t[512, MBSize 0], HL2.b[512, 1]) -> [512, MBSize 0]
Validating --> HL2.y = Sigmoid(HL2.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL3.t = Times(HL3.W[512, 512], HL2.y[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL3.b = LearnableParameter -> [512, 1]
Validating --> HL3.z = Plus(HL3.t[512, MBSize 0], HL3.b[512, 1]) -> [512, MBSize 0]
Validating --> HL3.y = Sigmoid(HL3.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> OL.t = Times(OL.W[132, 512], HL3.y[512, MBSize 0]) -> [132, MBSize 0]
Validating --> OL.b = LearnableParameter -> [132, 1]
Validating --> OL.z = Plus(OL.t[132, MBSize 0], OL.b[132, 1]) -> [132, MBSize 0]
Validating --> globalPrior = LearnableParameter -> [132, 1]
Validating --> logPrior = Log(globalPrior[132, 1]) -> [132, 1]
Validating --> scaledLogLikelihood = Minus(OL.z[132, MBSize 0], logPrior[132, 1]) -> [132, MBSize 0]

Validating for node scaledLogLikelihood. 14 nodes to process in pass 2.

Validating --> OL.W = LearnableParameter -> [132, 512]
Validating --> HL3.W = LearnableParameter -> [512, 512]
Validating --> HL2.W = LearnableParameter -> [512, 512]
Validating --> HL1.W = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> globalMean = LearnableParameter -> [363, 1]
Validating --> globalInvStd = LearnableParameter -> [363, 1]
Validating --> featNorm = PerDimMeanVarNormalization(features[363, MBSize 0], globalMean[363, 1], globalInvStd[363, 1]) -> [363, MBSize 0]
Validating --> HL1.t = Times(HL1.W[512, 363], featNorm[363, MBSize 0]) -> [512, MBSize 0]
Validating --> HL1.b = LearnableParameter -> [512, 1]
Validating --> HL1.z = Plus(HL1.t[512, MBSize 0], HL1.b[512, 1]) -> [512, MBSize 0]
Validating --> HL1.y = Sigmoid(HL1.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL2.t = Times(HL2.W[512, 512], HL1.y[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL2.b = LearnableParameter -> [512, 1]
Validating --> HL2.z = Plus(HL2.t[512, MBSize 0], HL2.b[512, 1]) -> [512, MBSize 0]
Validating --> HL2.y = Sigmoid(HL2.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL3.t = Times(HL3.W[512, 512], HL2.y[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL3.b = LearnableParameter -> [512, 1]
Validating --> HL3.z = Plus(HL3.t[512, MBSize 0], HL3.b[512, 1]) -> [512, MBSize 0]
Validating --> HL3.y = Sigmoid(HL3.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> OL.t = Times(OL.W[132, 512], HL3.y[512, MBSize 0]) -> [132, MBSize 0]
Validating --> OL.b = LearnableParameter -> [132, 1]
Validating --> OL.z = Plus(OL.t[132, MBSize 0], OL.b[132, 1]) -> [132, MBSize 0]
Validating --> globalPrior = LearnableParameter -> [132, 1]
Validating --> logPrior = Log(globalPrior[132, 1]) -> [132, 1]
Validating --> scaledLogLikelihood = Minus(OL.z[132, MBSize 0], logPrior[132, 1]) -> [132, MBSize 0]

Validating for node scaledLogLikelihood, final verification.

Validating --> OL.W = LearnableParameter -> [132, 512]
Validating --> HL3.W = LearnableParameter -> [512, 512]
Validating --> HL2.W = LearnableParameter -> [512, 512]
Validating --> HL1.W = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> globalMean = LearnableParameter -> [363, 1]
Validating --> globalInvStd = LearnableParameter -> [363, 1]
Validating --> featNorm = PerDimMeanVarNormalization(features[363, MBSize 0], globalMean[363, 1], globalInvStd[363, 1]) -> [363, MBSize 0]
Validating --> HL1.t = Times(HL1.W[512, 363], featNorm[363, MBSize 0]) -> [512, MBSize 0]
Validating --> HL1.b = LearnableParameter -> [512, 1]
Validating --> HL1.z = Plus(HL1.t[512, MBSize 0], HL1.b[512, 1]) -> [512, MBSize 0]
Validating --> HL1.y = Sigmoid(HL1.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL2.t = Times(HL2.W[512, 512], HL1.y[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL2.b = LearnableParameter -> [512, 1]
Validating --> HL2.z = Plus(HL2.t[512, MBSize 0], HL2.b[512, 1]) -> [512, MBSize 0]
Validating --> HL2.y = Sigmoid(HL2.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL3.t = Times(HL3.W[512, 512], HL2.y[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL3.b = LearnableParameter -> [512, 1]
Validating --> HL3.z = Plus(HL3.t[512, MBSize 0], HL3.b[512, 1]) -> [512, MBSize 0]
Validating --> HL3.y = Sigmoid(HL3.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> OL.t = Times(OL.W[132, 512], HL3.y[512, MBSize 0]) -> [132, MBSize 0]
Validating --> OL.b = LearnableParameter -> [132, 1]
Validating --> OL.z = Plus(OL.t[132, MBSize 0], OL.b[132, 1]) -> [132, MBSize 0]
Validating --> globalPrior = LearnableParameter -> [132, 1]
Validating --> logPrior = Log(globalPrior[132, 1]) -> [132, 1]
Validating --> scaledLogLikelihood = Minus(OL.z[132, MBSize 0], logPrior[132, 1]) -> [132, MBSize 0]

12 out of 26 nodes do not share the minibatch layout with the input data.


Validating for node err. 25 nodes to process in pass 1.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> OL.W = LearnableParameter -> [132, 512]
Validating --> HL3.W = LearnableParameter -> [512, 512]
Validating --> HL2.W = LearnableParameter -> [512, 512]
Validating --> HL1.W = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> globalMean = LearnableParameter -> [363, 1]
Validating --> globalInvStd = LearnableParameter -> [363, 1]
Validating --> featNorm = PerDimMeanVarNormalization(features[363, MBSize 0], globalMean[363, 1], globalInvStd[363, 1]) -> [363, MBSize 0]
Validating --> HL1.t = Times(HL1.W[512, 363], featNorm[363, MBSize 0]) -> [512, MBSize 0]
Validating --> HL1.b = LearnableParameter -> [512, 1]
Validating --> HL1.z = Plus(HL1.t[512, MBSize 0], HL1.b[512, 1]) -> [512, MBSize 0]
Validating --> HL1.y = Sigmoid(HL1.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL2.t = Times(HL2.W[512, 512], HL1.y[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL2.b = LearnableParameter -> [512, 1]
Validating --> HL2.z = Plus(HL2.t[512, MBSize 0], HL2.b[512, 1]) -> [512, MBSize 0]
Validating --> HL2.y = Sigmoid(HL2.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL3.t = Times(HL3.W[512, 512], HL2.y[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL3.b = LearnableParameter -> [512, 1]
Validating --> HL3.z = Plus(HL3.t[512, MBSize 0], HL3.b[512, 1]) -> [512, MBSize 0]
Validating --> HL3.y = Sigmoid(HL3.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> OL.t = Times(OL.W[132, 512], HL3.y[512, MBSize 0]) -> [132, MBSize 0]
Validating --> OL.b = LearnableParameter -> [132, 1]
Validating --> OL.z = Plus(OL.t[132, MBSize 0], OL.b[132, 1]) -> [132, MBSize 0]
Validating --> err = ErrorPrediction(labels[132, MBSize 0], OL.z[132, MBSize 0]) -> [1, 1]

Validating for node err. 12 nodes to process in pass 2.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> OL.W = LearnableParameter -> [132, 512]
Validating --> HL3.W = LearnableParameter -> [512, 512]
Validating --> HL2.W = LearnableParameter -> [512, 512]
Validating --> HL1.W = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> globalMean = LearnableParameter -> [363, 1]
Validating --> globalInvStd = LearnableParameter -> [363, 1]
Validating --> featNorm = PerDimMeanVarNormalization(features[363, MBSize 0], globalMean[363, 1], globalInvStd[363, 1]) -> [363, MBSize 0]
Validating --> HL1.t = Times(HL1.W[512, 363], featNorm[363, MBSize 0]) -> [512, MBSize 0]
Validating --> HL1.b = LearnableParameter -> [512, 1]
Validating --> HL1.z = Plus(HL1.t[512, MBSize 0], HL1.b[512, 1]) -> [512, MBSize 0]
Validating --> HL1.y = Sigmoid(HL1.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL2.t = Times(HL2.W[512, 512], HL1.y[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL2.b = LearnableParameter -> [512, 1]
Validating --> HL2.z = Plus(HL2.t[512, MBSize 0], HL2.b[512, 1]) -> [512, MBSize 0]
Validating --> HL2.y = Sigmoid(HL2.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL3.t = Times(HL3.W[512, 512], HL2.y[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL3.b = LearnableParameter -> [512, 1]
Validating --> HL3.z = Plus(HL3.t[512, MBSize 0], HL3.b[512, 1]) -> [512, MBSize 0]
Validating --> HL3.y = Sigmoid(HL3.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> OL.t = Times(OL.W[132, 512], HL3.y[512, MBSize 0]) -> [132, MBSize 0]
Validating --> OL.b = LearnableParameter -> [132, 1]
Validating --> OL.z = Plus(OL.t[132, MBSize 0], OL.b[132, 1]) -> [132, MBSize 0]
Validating --> err = ErrorPrediction(labels[132, MBSize 0], OL.z[132, MBSize 0]) -> [1, 1]

Validating for node err, final verification.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> OL.W = LearnableParameter -> [132, 512]
Validating --> HL3.W = LearnableParameter -> [512, 512]
Validating --> HL2.W = LearnableParameter -> [512, 512]
Validating --> HL1.W = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> globalMean = LearnableParameter -> [363, 1]
Validating --> globalInvStd = LearnableParameter -> [363, 1]
Validating --> featNorm = PerDimMeanVarNormalization(features[363, MBSize 0], globalMean[363, 1], globalInvStd[363, 1]) -> [363, MBSize 0]
Validating --> HL1.t = Times(HL1.W[512, 363], featNorm[363, MBSize 0]) -> [512, MBSize 0]
Validating --> HL1.b = LearnableParameter -> [512, 1]
Validating --> HL1.z = Plus(HL1.t[512, MBSize 0], HL1.b[512, 1]) -> [512, MBSize 0]
Validating --> HL1.y = Sigmoid(HL1.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL2.t = Times(HL2.W[512, 512], HL1.y[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL2.b = LearnableParameter -> [512, 1]
Validating --> HL2.z = Plus(HL2.t[512, MBSize 0], HL2.b[512, 1]) -> [512, MBSize 0]
Validating --> HL2.y = Sigmoid(HL2.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL3.t = Times(HL3.W[512, 512], HL2.y[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL3.b = LearnableParameter -> [512, 1]
Validating --> HL3.z = Plus(HL3.t[512, MBSize 0], HL3.b[512, 1]) -> [512, MBSize 0]
Validating --> HL3.y = Sigmoid(HL3.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> OL.t = Times(OL.W[132, 512], HL3.y[512, MBSize 0]) -> [132, MBSize 0]
Validating --> OL.b = LearnableParameter -> [132, 1]
Validating --> OL.z = Plus(OL.t[132, MBSize 0], OL.b[132, 1]) -> [132, MBSize 0]
Validating --> err = ErrorPrediction(labels[132, MBSize 0], OL.z[132, MBSize 0]) -> [1, 1]

11 out of 25 nodes do not share the minibatch layout with the input data.


Validating for node cr. 25 nodes to process in pass 1.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> OL.W = LearnableParameter -> [132, 512]
Validating --> HL3.W = LearnableParameter -> [512, 512]
Validating --> HL2.W = LearnableParameter -> [512, 512]
Validating --> HL1.W = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> globalMean = LearnableParameter -> [363, 1]
Validating --> globalInvStd = LearnableParameter -> [363, 1]
Validating --> featNorm = PerDimMeanVarNormalization(features[363, MBSize 0], globalMean[363, 1], globalInvStd[363, 1]) -> [363, MBSize 0]
Validating --> HL1.t = Times(HL1.W[512, 363], featNorm[363, MBSize 0]) -> [512, MBSize 0]
Validating --> HL1.b = LearnableParameter -> [512, 1]
Validating --> HL1.z = Plus(HL1.t[512, MBSize 0], HL1.b[512, 1]) -> [512, MBSize 0]
Validating --> HL1.y = Sigmoid(HL1.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL2.t = Times(HL2.W[512, 512], HL1.y[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL2.b = LearnableParameter -> [512, 1]
Validating --> HL2.z = Plus(HL2.t[512, MBSize 0], HL2.b[512, 1]) -> [512, MBSize 0]
Validating --> HL2.y = Sigmoid(HL2.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL3.t = Times(HL3.W[512, 512], HL2.y[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL3.b = LearnableParameter -> [512, 1]
Validating --> HL3.z = Plus(HL3.t[512, MBSize 0], HL3.b[512, 1]) -> [512, MBSize 0]
Validating --> HL3.y = Sigmoid(HL3.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> OL.t = Times(OL.W[132, 512], HL3.y[512, MBSize 0]) -> [132, MBSize 0]
Validating --> OL.b = LearnableParameter -> [132, 1]
Validating --> OL.z = Plus(OL.t[132, MBSize 0], OL.b[132, 1]) -> [132, MBSize 0]
Validating --> cr = CrossEntropyWithSoftmax(labels[132, MBSize 0], OL.z[132, MBSize 0]) -> [1, 1]

Validating for node cr. 12 nodes to process in pass 2.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> OL.W = LearnableParameter -> [132, 512]
Validating --> HL3.W = LearnableParameter -> [512, 512]
Validating --> HL2.W = LearnableParameter -> [512, 512]
Validating --> HL1.W = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> globalMean = LearnableParameter -> [363, 1]
Validating --> globalInvStd = LearnableParameter -> [363, 1]
Validating --> featNorm = PerDimMeanVarNormalization(features[363, MBSize 0], globalMean[363, 1], globalInvStd[363, 1]) -> [363, MBSize 0]
Validating --> HL1.t = Times(HL1.W[512, 363], featNorm[363, MBSize 0]) -> [512, MBSize 0]
Validating --> HL1.b = LearnableParameter -> [512, 1]
Validating --> HL1.z = Plus(HL1.t[512, MBSize 0], HL1.b[512, 1]) -> [512, MBSize 0]
Validating --> HL1.y = Sigmoid(HL1.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL2.t = Times(HL2.W[512, 512], HL1.y[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL2.b = LearnableParameter -> [512, 1]
Validating --> HL2.z = Plus(HL2.t[512, MBSize 0], HL2.b[512, 1]) -> [512, MBSize 0]
Validating --> HL2.y = Sigmoid(HL2.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL3.t = Times(HL3.W[512, 512], HL2.y[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL3.b = LearnableParameter -> [512, 1]
Validating --> HL3.z = Plus(HL3.t[512, MBSize 0], HL3.b[512, 1]) -> [512, MBSize 0]
Validating --> HL3.y = Sigmoid(HL3.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> OL.t = Times(OL.W[132, 512], HL3.y[512, MBSize 0]) -> [132, MBSize 0]
Validating --> OL.b = LearnableParameter -> [132, 1]
Validating --> OL.z = Plus(OL.t[132, MBSize 0], OL.b[132, 1]) -> [132, MBSize 0]
Validating --> cr = CrossEntropyWithSoftmax(labels[132, MBSize 0], OL.z[132, MBSize 0]) -> [1, 1]

Validating for node cr, final verification.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> OL.W = LearnableParameter -> [132, 512]
Validating --> HL3.W = LearnableParameter -> [512, 512]
Validating --> HL2.W = LearnableParameter -> [512, 512]
Validating --> HL1.W = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> globalMean = LearnableParameter -> [363, 1]
Validating --> globalInvStd = LearnableParameter -> [363, 1]
Validating --> featNorm = PerDimMeanVarNormalization(features[363, MBSize 0], globalMean[363, 1], globalInvStd[363, 1]) -> [363, MBSize 0]
Validating --> HL1.t = Times(HL1.W[512, 363], featNorm[363, MBSize 0]) -> [512, MBSize 0]
Validating --> HL1.b = LearnableParameter -> [512, 1]
Validating --> HL1.z = Plus(HL1.t[512, MBSize 0], HL1.b[512, 1]) -> [512, MBSize 0]
Validating --> HL1.y = Sigmoid(HL1.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL2.t = Times(HL2.W[512, 512], HL1.y[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL2.b = LearnableParameter -> [512, 1]
Validating --> HL2.z = Plus(HL2.t[512, MBSize 0], HL2.b[512, 1]) -> [512, MBSize 0]
Validating --> HL2.y = Sigmoid(HL2.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL3.t = Times(HL3.W[512, 512], HL2.y[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL3.b = LearnableParameter -> [512, 1]
Validating --> HL3.z = Plus(HL3.t[512, MBSize 0], HL3.b[512, 1]) -> [512, MBSize 0]
Validating --> HL3.y = Sigmoid(HL3.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> OL.t = Times(OL.W[132, 512], HL3.y[512, MBSize 0]) -> [132, MBSize 0]
Validating --> OL.b = LearnableParameter -> [132, 1]
Validating --> OL.z = Plus(OL.t[132, MBSize 0], OL.b[132, 1]) -> [132, MBSize 0]
Validating --> cr = CrossEntropyWithSoftmax(labels[132, MBSize 0], OL.z[132, MBSize 0]) -> [1, 1]

11 out of 25 nodes do not share the minibatch layout with the input data.

Post-processing network complete.

SGD using CPU.

Training criterion node(s):
	cr = CrossEntropyWithSoftmax

Evaluation criterion node(s):
	err = ErrorPrediction


Allocating matrices for forward and/or backward propagation.
No PreCompute nodes found, skipping PreCompute step
Set Max Temp Mem Size For Convolution Nodes to 0 samples.
Starting Epoch 1: learning rate per sample = 0.003125  effective momentum = 0.900117  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 0: frames [0..81920] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms

Starting minibatch loop.
 Epoch[ 1 of 4]-Minibatch[   1-  10, 3.12%]: SamplesSeen = 2560; TrainLossPerSample =  4.07459412; EvalErr[0]PerSample = 0.83046875; TotalTime = 0.1712s; SamplesPerSecond = 14952.5
 Epoch[ 1 of 4]-Minibatch[  11-  20, 6.25%]: SamplesSeen = 2560; TrainLossPerSample =  2.50037994; EvalErr[0]PerSample = 0.62343750; TotalTime = 0.1693s; SamplesPerSecond = 15121.5
 Epoch[ 1 of 4]-Minibatch[  21-  30, 9.38%]: SamplesSeen = 2560; TrainLossPerSample =  2.11056366; EvalErr[0]PerSample = 0.56679687; TotalTime = 0.1693s; SamplesPerSecond = 15123.5
 Epoch[ 1 of 4]-Minibatch[  31-  40, 12.50%]: SamplesSeen = 2560; TrainLossPerSample =  1.76141739; EvalErr[0]PerSample = 0.49101563; TotalTime = 0.1693s; SamplesPerSecond = 15125.4
 Epoch[ 1 of 4]-Minibatch[  41-  50, 15.62%]: SamplesSeen = 2560; TrainLossPerSample =  1.57761765; EvalErr[0]PerSample = 0.45937500; TotalTime = 0.1691s; SamplesPerSecond = 15135.0
 Epoch[ 1 of 4]-Minibatch[  51-  60, 18.75%]: SamplesSeen = 2560; TrainLossPerSample =  1.46414337; EvalErr[0]PerSample = 0.42500000; TotalTime = 0.1692s; SamplesPerSecond = 15132.4
 Epoch[ 1 of 4]-Minibatch[  61-  70, 21.88%]: SamplesSeen = 2560; TrainLossPerSample =  1.43758545; EvalErr[0]PerSample = 0.42382812; TotalTime = 0.1698s; SamplesPerSecond = 15072.9
 Epoch[ 1 of 4]-Minibatch[  71-  80, 25.00%]: SamplesSeen = 2560; TrainLossPerSample =  1.40687408; EvalErr[0]PerSample = 0.40742187; TotalTime = 0.1694s; SamplesPerSecond = 15113.8
 Epoch[ 1 of 4]-Minibatch[  81-  90, 28.12%]: SamplesSeen = 2560; TrainLossPerSample =  1.32321014; EvalErr[0]PerSample = 0.39687500; TotalTime = 0.1692s; SamplesPerSecond = 15133.8
 Epoch[ 1 of 4]-Minibatch[  91- 100, 31.25%]: SamplesSeen = 2560; TrainLossPerSample =  1.32419281; EvalErr[0]PerSample = 0.39687500; TotalTime = 0.1695s; SamplesPerSecond = 15105.7
 Epoch[ 1 of 4]-Minibatch[ 101- 110, 34.38%]: SamplesSeen = 2560; TrainLossPerSample =  1.27560730; EvalErr[0]PerSample = 0.38281250; TotalTime = 0.1693s; SamplesPerSecond = 15124.0
 Epoch[ 1 of 4]-Minibatch[ 111- 120, 37.50%]: SamplesSeen = 2560; TrainLossPerSample =  1.28661041; EvalErr[0]PerSample = 0.38359375; TotalTime = 0.1693s; SamplesPerSecond = 15122.0
 Epoch[ 1 of 4]-Minibatch[ 121- 130, 40.62%]: SamplesSeen = 2560; TrainLossPerSample =  1.21722565; EvalErr[0]PerSample = 0.35976562; TotalTime = 0.1693s; SamplesPerSecond = 15119.1
 Epoch[ 1 of 4]-Minibatch[ 131- 140, 43.75%]: SamplesSeen = 2560; TrainLossPerSample =  1.18934326; EvalErr[0]PerSample = 0.36562500; TotalTime = 0.1691s; SamplesPerSecond = 15137.1
 Epoch[ 1 of 4]-Minibatch[ 141- 150, 46.88%]: SamplesSeen = 2560; TrainLossPerSample =  1.22049561; EvalErr[0]PerSample = 0.37109375; TotalTime = 0.1693s; SamplesPerSecond = 15119.6
 Epoch[ 1 of 4]-Minibatch[ 151- 160, 50.00%]: SamplesSeen = 2560; TrainLossPerSample =  1.24593201; EvalErr[0]PerSample = 0.37773438; TotalTime = 0.1693s; SamplesPerSecond = 15118.4
 Epoch[ 1 of 4]-Minibatch[ 161- 170, 53.12%]: SamplesSeen = 2560; TrainLossPerSample =  1.19860229; EvalErr[0]PerSample = 0.36171875; TotalTime = 0.1692s; SamplesPerSecond = 15126.9
 Epoch[ 1 of 4]-Minibatch[ 171- 180, 56.25%]: SamplesSeen = 2560; TrainLossPerSample =  1.20980530; EvalErr[0]PerSample = 0.35429688; TotalTime = 0.1693s; SamplesPerSecond = 15124.8
 Epoch[ 1 of 4]-Minibatch[ 181- 190, 59.38%]: SamplesSeen = 2560; TrainLossPerSample =  1.16387939; EvalErr[0]PerSample = 0.35820313; TotalTime = 0.1693s; SamplesPerSecond = 15124.4
 Epoch[ 1 of 4]-Minibatch[ 191- 200, 62.50%]: SamplesSeen = 2560; TrainLossPerSample =  1.19475403; EvalErr[0]PerSample = 0.36250000; TotalTime = 0.1693s; SamplesPerSecond = 15117.8
 Epoch[ 1 of 4]-Minibatch[ 201- 210, 65.62%]: SamplesSeen = 2560; TrainLossPerSample =  1.20151978; EvalErr[0]PerSample = 0.36835937; TotalTime = 0.1693s; SamplesPerSecond = 15123.6
 Epoch[ 1 of 4]-Minibatch[ 211- 220, 68.75%]: SamplesSeen = 2560; TrainLossPerSample =  1.21634521; EvalErr[0]PerSample = 0.36289063; TotalTime = 0.1694s; SamplesPerSecond = 15108.2
 Epoch[ 1 of 4]-Minibatch[ 221- 230, 71.88%]: SamplesSeen = 2560; TrainLossPerSample =  1.14917908; EvalErr[0]PerSample = 0.35273437; TotalTime = 0.1693s; SamplesPerSecond = 15121.6
 Epoch[ 1 of 4]-Minibatch[ 231- 240, 75.00%]: SamplesSeen = 2560; TrainLossPerSample =  1.18493958; EvalErr[0]PerSample = 0.35546875; TotalTime = 0.1734s; SamplesPerSecond = 14764.6
 Epoch[ 1 of 4]-Minibatch[ 241- 250, 78.12%]: SamplesSeen = 2560; TrainLossPerSample =  1.17961426; EvalErr[0]PerSample = 0.36015625; TotalTime = 0.1701s; SamplesPerSecond = 15053.3
 Epoch[ 1 of 4]-Minibatch[ 251- 260, 81.25%]: SamplesSeen = 2560; TrainLossPerSample =  1.16185913; EvalErr[0]PerSample = 0.35820313; TotalTime = 0.1693s; SamplesPerSecond = 15116.8
 Epoch[ 1 of 4]-Minibatch[ 261- 270, 84.38%]: SamplesSeen = 2560; TrainLossPerSample =  1.13928528; EvalErr[0]PerSample = 0.35859375; TotalTime = 0.1692s; SamplesPerSecond = 15126.3
 Epoch[ 1 of 4]-Minibatch[ 271- 280, 87.50%]: SamplesSeen = 2560; TrainLossPerSample =  1.12674561; EvalErr[0]PerSample = 0.34960938; TotalTime = 0.1694s; SamplesPerSecond = 15114.3
 Epoch[ 1 of 4]-Minibatch[ 281- 290, 90.62%]: SamplesSeen = 2560; TrainLossPerSample =  1.12367554; EvalErr[0]PerSample = 0.34101562; TotalTime = 0.1693s; SamplesPerSecond = 15123.4
 Epoch[ 1 of 4]-Minibatch[ 291- 300, 93.75%]: SamplesSeen = 2560; TrainLossPerSample =  1.11361084; EvalErr[0]PerSample = 0.33750000; TotalTime = 0.1692s; SamplesPerSecond = 15129.0
 Epoch[ 1 of 4]-Minibatch[ 301- 310, 96.88%]: SamplesSeen = 2560; TrainLossPerSample =  1.13889771; EvalErr[0]PerSample = 0.35859375; TotalTime = 0.1693s; SamplesPerSecond = 15122.4
 Epoch[ 1 of 4]-Minibatch[ 311- 320, 100.00%]: SamplesSeen = 2560; TrainLossPerSample =  1.14187012; EvalErr[0]PerSample = 0.34648438; TotalTime = 0.1686s; SamplesPerSecond = 15187.7
Finished Epoch[ 1 of 4]: [Training Set] TrainLossPerSample = 1.4081367; EvalErrPerSample = 0.40462646; AvgLearningRatePerSample = 0.003125; EpochTime=5.50331
Starting Epoch 2: learning rate per sample = 0.003125  effective momentum = 0.810210  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 1: frames [81920..163840] (first utterance at frame 81920), data subset 0 of 1, with 1 datapasses

Starting minibatch loop.
 Epoch[ 2 of 4]-Minibatch[   1-  10, 6.25%]: SamplesSeen = 5120; TrainLossPerSample =  1.24151039; EvalErr[0]PerSample = 0.37578125; TotalTime = 0.3128s; SamplesPerSecond = 16370.1
 Epoch[ 2 of 4]-Minibatch[  11-  20, 12.50%]: SamplesSeen = 5120; TrainLossPerSample =  1.18116150; EvalErr[0]PerSample = 0.35937500; TotalTime = 0.3099s; SamplesPerSecond = 16520.0
 Epoch[ 2 of 4]-Minibatch[  21-  30, 18.75%]: SamplesSeen = 5120; TrainLossPerSample =  1.17582817; EvalErr[0]PerSample = 0.35683594; TotalTime = 0.3097s; SamplesPerSecond = 16530.3
 Epoch[ 2 of 4]-Minibatch[  31-  40, 25.00%]: SamplesSeen = 5120; TrainLossPerSample =  1.16649361; EvalErr[0]PerSample = 0.35585937; TotalTime = 0.3099s; SamplesPerSecond = 16520.7
 Epoch[ 2 of 4]-Minibatch[  41-  50, 31.25%]: SamplesSeen = 5120; TrainLossPerSample =  1.16477623; EvalErr[0]PerSample = 0.35292969; TotalTime = 0.3099s; SamplesPerSecond = 16520.5
 Epoch[ 2 of 4]-Minibatch[  51-  60, 37.50%]: SamplesSeen = 5120; TrainLossPerSample =  1.13575516; EvalErr[0]PerSample = 0.35136719; TotalTime = 0.3097s; SamplesPerSecond = 16532.7
 Epoch[ 2 of 4]-Minibatch[  61-  70, 43.75%]: SamplesSeen = 5120; TrainLossPerSample =  1.16274414; EvalErr[0]PerSample = 0.35468750; TotalTime = 0.3099s; SamplesPerSecond = 16520.8
 Epoch[ 2 of 4]-Minibatch[  71-  80, 50.00%]: SamplesSeen = 5120; TrainLossPerSample =  1.12048340; EvalErr[0]PerSample = 0.34042969; TotalTime = 0.3099s; SamplesPerSecond = 16523.4
 Epoch[ 2 of 4]-Minibatch[  81-  90, 56.25%]: SamplesSeen = 5120; TrainLossPerSample =  1.13913651; EvalErr[0]PerSample = 0.34570312; TotalTime = 0.3097s; SamplesPerSecond = 16529.6
 Epoch[ 2 of 4]-Minibatch[  91- 100, 62.50%]: SamplesSeen = 5120; TrainLossPerSample =  1.07811508; EvalErr[0]PerSample = 0.33105469; TotalTime = 0.3099s; SamplesPerSecond = 16523.9
 Epoch[ 2 of 4]-Minibatch[ 101- 110, 68.75%]: SamplesSeen = 5120; TrainLossPerSample =  1.06469193; EvalErr[0]PerSample = 0.32812500; TotalTime = 0.3098s; SamplesPerSecond = 16526.8
 Epoch[ 2 of 4]-Minibatch[ 111- 120, 75.00%]: SamplesSeen = 5120; TrainLossPerSample =  1.07235565; EvalErr[0]PerSample = 0.33085938; TotalTime = 0.3138s; SamplesPerSecond = 16314.4
 Epoch[ 2 of 4]-Minibatch[ 121- 130, 81.25%]: SamplesSeen = 5120; TrainLossPerSample =  1.05898132; EvalErr[0]PerSample = 0.32128906; TotalTime = 0.3100s; SamplesPerSecond = 16517.7
 Epoch[ 2 of 4]-Minibatch[ 131- 140, 87.50%]: SamplesSeen = 5120; TrainLossPerSample =  1.12796021; EvalErr[0]PerSample = 0.34589844; TotalTime = 0.3102s; SamplesPerSecond = 16506.0
 Epoch[ 2 of 4]-Minibatch[ 141- 150, 93.75%]: SamplesSeen = 5120; TrainLossPerSample =  1.07443848; EvalErr[0]PerSample = 0.32734375; TotalTime = 0.3097s; SamplesPerSecond = 16531.6
 Epoch[ 2 of 4]-Minibatch[ 151- 160, 100.00%]: SamplesSeen = 5120; TrainLossPerSample =  1.09533539; EvalErr[0]PerSample = 0.33125000; TotalTime = 0.3085s; SamplesPerSecond = 16597.5
Finished Epoch[ 2 of 4]: [Training Set] TrainLossPerSample = 1.1287354; EvalErrPerSample = 0.34429932; AvgLearningRatePerSample = 0.003125; EpochTime=4.96841
Starting Epoch 3: learning rate per sample = 0.003125  effective momentum = 0.810210  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 2: frames [163840..245760] (first utterance at frame 163840), data subset 0 of 1, with 1 datapasses

Starting minibatch loop.
 Epoch[ 3 of 4]-Minibatch[   1-  10, 6.25%]: SamplesSeen = 5120; TrainLossPerSample =  1.10176105; EvalErr[0]PerSample = 0.34277344; TotalTime = 0.3097s; SamplesPerSecond = 16533.8
 Epoch[ 3 of 4]-Minibatch[  11-  20, 12.50%]: SamplesSeen = 5120; TrainLossPerSample =  1.16201744; EvalErr[0]PerSample = 0.35625000; TotalTime = 0.3104s; SamplesPerSecond = 16493.4
 Epoch[ 3 of 4]-Minibatch[  21-  30, 18.75%]: SamplesSeen = 5120; TrainLossPerSample =  1.10433636; EvalErr[0]PerSample = 0.34218750; TotalTime = 0.3099s; SamplesPerSecond = 16521.3
 Epoch[ 3 of 4]-Minibatch[  31-  40, 25.00%]: SamplesSeen = 5120; TrainLossPerSample =  1.05510216; EvalErr[0]PerSample = 0.32890625; TotalTime = 0.3099s; SamplesPerSecond = 16523.2
 Epoch[ 3 of 4]-Minibatch[  41-  50, 31.25%]: SamplesSeen = 5120; TrainLossPerSample =  1.05669708; EvalErr[0]PerSample = 0.33574219; TotalTime = 0.3098s; SamplesPerSecond = 16528.0
 Epoch[ 3 of 4]-Minibatch[  51-  60, 37.50%]: SamplesSeen = 5120; TrainLossPerSample =  1.06401596; EvalErr[0]PerSample = 0.33261719; TotalTime = 0.3097s; SamplesPerSecond = 16531.5
 Epoch[ 3 of 4]-Minibatch[  61-  70, 43.75%]: SamplesSeen = 5120; TrainLossPerSample =  1.07696609; EvalErr[0]PerSample = 0.33183594; TotalTime = 0.3097s; SamplesPerSecond = 16531.1
 Epoch[ 3 of 4]-Minibatch[  71-  80, 50.00%]: SamplesSeen = 5120; TrainLossPerSample =  1.00777740; EvalErr[0]PerSample = 0.31757812; TotalTime = 0.3100s; SamplesPerSecond = 16516.8
 Epoch[ 3 of 4]-Minibatch[  81-  90, 56.25%]: SamplesSeen = 5120; TrainLossPerSample =  1.06549988; EvalErr[0]PerSample = 0.32460937; TotalTime = 0.3100s; SamplesPerSecond = 16516.9
 Epoch[ 3 of 4]-Minibatch[  91- 100, 62.50%]: SamplesSeen = 5120; TrainLossPerSample =  1.10392532; EvalErr[0]PerSample = 0.33886719; TotalTime = 0.3101s; SamplesPerSecond = 16510.6
 Epoch[ 3 of 4]-Minibatch[ 101- 110, 68.75%]: SamplesSeen = 5120; TrainLossPerSample =  1.06218948; EvalErr[0]PerSample = 0.32890625; TotalTime = 0.3107s; SamplesPerSecond = 16480.5
 Epoch[ 3 of 4]-Minibatch[ 111- 120, 75.00%]: SamplesSeen = 5120; TrainLossPerSample =  1.05725784; EvalErr[0]PerSample = 0.33476563; TotalTime = 0.3161s; SamplesPerSecond = 16195.1
 Epoch[ 3 of 4]-Minibatch[ 121- 130, 81.25%]: SamplesSeen = 5120; TrainLossPerSample =  1.03517914; EvalErr[0]PerSample = 0.32050781; TotalTime = 0.3103s; SamplesPerSecond = 16499.0
 Epoch[ 3 of 4]-Minibatch[ 131- 140, 87.50%]: SamplesSeen = 5120; TrainLossPerSample =  1.02237244; EvalErr[0]PerSample = 0.31464844; TotalTime = 0.3099s; SamplesPerSecond = 16520.8
 Epoch[ 3 of 4]-Minibatch[ 141- 150, 93.75%]: SamplesSeen = 5120; TrainLossPerSample =  1.06224976; EvalErr[0]PerSample = 0.32910156; TotalTime = 0.3100s; SamplesPerSecond = 16518.0
 Epoch[ 3 of 4]-Minibatch[ 151- 160, 100.00%]: SamplesSeen = 5120; TrainLossPerSample =  1.06768646; EvalErr[0]PerSample = 0.33652344; TotalTime = 0.3086s; SamplesPerSecond = 16588.5
Finished Epoch[ 3 of 4]: [Training Set] TrainLossPerSample = 1.0690646; EvalErrPerSample = 0.33223876; AvgLearningRatePerSample = 0.003125; EpochTime=4.96973
Starting Epoch 4: learning rate per sample = 0.003125  effective momentum = 0.810210  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 3: frames [245760..327680] (first utterance at frame 245760), data subset 0 of 1, with 1 datapasses

Starting minibatch loop.
 Epoch[ 4 of 4]-Minibatch[   1-  10, 6.25%]: SamplesSeen = 5120; TrainLossPerSample =  1.05605412; EvalErr[0]PerSample = 0.33027344; TotalTime = 0.3099s; SamplesPerSecond = 16523.6
 Epoch[ 4 of 4]-Minibatch[  11-  20, 12.50%]: SamplesSeen = 4926; TrainLossPerSample =  1.03406768; EvalErr[0]PerSample = 0.32034105; TotalTime = 0.3416s; SamplesPerSecond = 14421.8
 Epoch[ 4 of 4]-Minibatch[  21-  30, 18.75%]: SamplesSeen = 5120; TrainLossPerSample =  1.02853432; EvalErr[0]PerSample = 0.32636719; TotalTime = 0.3098s; SamplesPerSecond = 16524.7
 Epoch[ 4 of 4]-Minibatch[  31-  40, 25.00%]: SamplesSeen = 5120; TrainLossPerSample =  0.98784370; EvalErr[0]PerSample = 0.30488281; TotalTime = 0.3101s; SamplesPerSecond = 16510.0
 Epoch[ 4 of 4]-Minibatch[  41-  50, 31.25%]: SamplesSeen = 5120; TrainLossPerSample =  1.02745323; EvalErr[0]PerSample = 0.31601563; TotalTime = 0.3098s; SamplesPerSecond = 16529.2
 Epoch[ 4 of 4]-Minibatch[  51-  60, 37.50%]: SamplesSeen = 5120; TrainLossPerSample =  0.99942627; EvalErr[0]PerSample = 0.30996094; TotalTime = 0.3098s; SamplesPerSecond = 16524.5
 Epoch[ 4 of 4]-Minibatch[  61-  70, 43.75%]: SamplesSeen = 5120; TrainLossPerSample =  1.02917633; EvalErr[0]PerSample = 0.32460937; TotalTime = 0.3103s; SamplesPerSecond = 16502.0
 Epoch[ 4 of 4]-Minibatch[  71-  80, 50.00%]: SamplesSeen = 5120; TrainLossPerSample =  0.99381027; EvalErr[0]PerSample = 0.31308594; TotalTime = 0.3100s; SamplesPerSecond = 16518.2
 Epoch[ 4 of 4]-Minibatch[  81-  90, 56.25%]: SamplesSeen = 5120; TrainLossPerSample =  0.98878403; EvalErr[0]PerSample = 0.31035156; TotalTime = 0.3103s; SamplesPerSecond = 16497.6
 Epoch[ 4 of 4]-Minibatch[  91- 100, 62.50%]: SamplesSeen = 5120; TrainLossPerSample =  1.01263962; EvalErr[0]PerSample = 0.31347656; TotalTime = 0.3104s; SamplesPerSecond = 16495.3
 Epoch[ 4 of 4]-Minibatch[ 101- 110, 68.75%]: SamplesSeen = 5120; TrainLossPerSample =  1.00671692; EvalErr[0]PerSample = 0.30976562; TotalTime = 0.3111s; SamplesPerSecond = 16457.4
 Epoch[ 4 of 4]-Minibatch[ 111- 120, 75.00%]: SamplesSeen = 5120; TrainLossPerSample =  1.02811584; EvalErr[0]PerSample = 0.31972656; TotalTime = 0.3099s; SamplesPerSecond = 16522.6
 Epoch[ 4 of 4]-Minibatch[ 121- 130, 81.25%]: SamplesSeen = 5120; TrainLossPerSample =  0.99318237; EvalErr[0]PerSample = 0.30898437; TotalTime = 0.3102s; SamplesPerSecond = 16505.5
 Epoch[ 4 of 4]-Minibatch[ 131- 140, 87.50%]: SamplesSeen = 5120; TrainLossPerSample =  1.00085297; EvalErr[0]PerSample = 0.31757812; TotalTime = 0.3101s; SamplesPerSecond = 16513.4
 Epoch[ 4 of 4]-Minibatch[ 141- 150, 93.75%]: SamplesSeen = 5120; TrainLossPerSample =  1.01911316; EvalErr[0]PerSample = 0.31621094; TotalTime = 0.3100s; SamplesPerSecond = 16517.8
 Epoch[ 4 of 4]-Minibatch[ 151- 160, 100.00%]: SamplesSeen = 5120; TrainLossPerSample =  0.95961304; EvalErr[0]PerSample = 0.30605469; TotalTime = 0.3094s; SamplesPerSecond = 16549.2
Finished Epoch[ 4 of 4]: [Training Set] TrainLossPerSample = 1.0102775; EvalErrPerSample = 0.31549072; AvgLearningRatePerSample = 0.003125; EpochTime=5.01027
CNTKCommandTrainEnd: speechTrain

Post-processing network...

3 roots:
	cr = CrossEntropyWithSoftmax
	err = ErrorPrediction
	scaledLogLikelihood = Minus
FormNestedNetwork: WARNING: Was called twice for cr CrossEntropyWithSoftmax operation
FormNestedNetwork: WARNING: Was called twice for err ErrorPrediction operation
FormNestedNetwork: WARNING: Was called twice for scaledLogLikelihood Minus operation


Validating for node cr. 25 nodes to process in pass 1.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> OL.W = LearnableParameter -> [132, 512]
Validating --> HL3.W = LearnableParameter -> [512, 512]
Validating --> HL2.W = LearnableParameter -> [512, 512]
Validating --> HL1.W = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> globalMean = LearnableParameter -> [363, 1]
Validating --> globalInvStd = LearnableParameter -> [363, 1]
Validating --> featNorm = PerDimMeanVarNormalization(features[363, MBSize 0], globalMean[363, 1], globalInvStd[363, 1]) -> [363, MBSize 0]
Validating --> HL1.t = Times(HL1.W[512, 363], featNorm[363, MBSize 0]) -> [512, MBSize 0]
Validating --> HL1.b = LearnableParameter -> [512, 1]
Validating --> HL1.z = Plus(HL1.t[512, MBSize 0], HL1.b[512, 1]) -> [512, MBSize 0]
Validating --> HL1.y = Sigmoid(HL1.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL2.t = Times(HL2.W[512, 512], HL1.y[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL2.b = LearnableParameter -> [512, 1]
Validating --> HL2.z = Plus(HL2.t[512, MBSize 0], HL2.b[512, 1]) -> [512, MBSize 0]
Validating --> HL2.y = Sigmoid(HL2.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL3.t = Times(HL3.W[512, 512], HL2.y[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL3.b = LearnableParameter -> [512, 1]
Validating --> HL3.z = Plus(HL3.t[512, MBSize 0], HL3.b[512, 1]) -> [512, MBSize 0]
Validating --> HL3.y = Sigmoid(HL3.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> OL.t = Times(OL.W[132, 512], HL3.y[512, MBSize 0]) -> [132, MBSize 0]
Validating --> OL.b = LearnableParameter -> [132, 1]
Validating --> OL.z = Plus(OL.t[132, MBSize 0], OL.b[132, 1]) -> [132, MBSize 0]
Validating --> cr = CrossEntropyWithSoftmax(labels[132, MBSize 0], OL.z[132, MBSize 0]) -> [1, 1]

Validating for node cr. 13 nodes to process in pass 2.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> OL.W = LearnableParameter -> [132, 512]
Validating --> HL3.W = LearnableParameter -> [512, 512]
Validating --> HL2.W = LearnableParameter -> [512, 512]
Validating --> HL1.W = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> globalMean = LearnableParameter -> [363, 1]
Validating --> globalInvStd = LearnableParameter -> [363, 1]
Validating --> featNorm = PerDimMeanVarNormalization(features[363, MBSize 0], globalMean[363, 1], globalInvStd[363, 1]) -> [363, MBSize 0]
Validating --> HL1.t = Times(HL1.W[512, 363], featNorm[363, MBSize 0]) -> [512, MBSize 0]
Validating --> HL1.b = LearnableParameter -> [512, 1]
Validating --> HL1.z = Plus(HL1.t[512, MBSize 0], HL1.b[512, 1]) -> [512, MBSize 0]
Validating --> HL1.y = Sigmoid(HL1.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL2.t = Times(HL2.W[512, 512], HL1.y[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL2.b = LearnableParameter -> [512, 1]
Validating --> HL2.z = Plus(HL2.t[512, MBSize 0], HL2.b[512, 1]) -> [512, MBSize 0]
Validating --> HL2.y = Sigmoid(HL2.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL3.t = Times(HL3.W[512, 512], HL2.y[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL3.b = LearnableParameter -> [512, 1]
Validating --> HL3.z = Plus(HL3.t[512, MBSize 0], HL3.b[512, 1]) -> [512, MBSize 0]
Validating --> HL3.y = Sigmoid(HL3.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> OL.t = Times(OL.W[132, 512], HL3.y[512, MBSize 0]) -> [132, MBSize 0]
Validating --> OL.b = LearnableParameter -> [132, 1]
Validating --> OL.z = Plus(OL.t[132, MBSize 0], OL.b[132, 1]) -> [132, MBSize 0]
Validating --> cr = CrossEntropyWithSoftmax(labels[132, MBSize 0], OL.z[132, MBSize 0]) -> [1, 1]

Validating for node cr, final verification.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> OL.W = LearnableParameter -> [132, 512]
Validating --> HL3.W = LearnableParameter -> [512, 512]
Validating --> HL2.W = LearnableParameter -> [512, 512]
Validating --> HL1.W = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> globalMean = LearnableParameter -> [363, 1]
Validating --> globalInvStd = LearnableParameter -> [363, 1]
Validating --> featNorm = PerDimMeanVarNormalization(features[363, MBSize 0], globalMean[363, 1], globalInvStd[363, 1]) -> [363, MBSize 0]
Validating --> HL1.t = Times(HL1.W[512, 363], featNorm[363, MBSize 0]) -> [512, MBSize 0]
Validating --> HL1.b = LearnableParameter -> [512, 1]
Validating --> HL1.z = Plus(HL1.t[512, MBSize 0], HL1.b[512, 1]) -> [512, MBSize 0]
Validating --> HL1.y = Sigmoid(HL1.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL2.t = Times(HL2.W[512, 512], HL1.y[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL2.b = LearnableParameter -> [512, 1]
Validating --> HL2.z = Plus(HL2.t[512, MBSize 0], HL2.b[512, 1]) -> [512, MBSize 0]
Validating --> HL2.y = Sigmoid(HL2.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL3.t = Times(HL3.W[512, 512], HL2.y[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL3.b = LearnableParameter -> [512, 1]
Validating --> HL3.z = Plus(HL3.t[512, MBSize 0], HL3.b[512, 1]) -> [512, MBSize 0]
Validating --> HL3.y = Sigmoid(HL3.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> OL.t = Times(OL.W[132, 512], HL3.y[512, MBSize 0]) -> [132, MBSize 0]
Validating --> OL.b = LearnableParameter -> [132, 1]
Validating --> OL.z = Plus(OL.t[132, MBSize 0], OL.b[132, 1]) -> [132, MBSize 0]
Validating --> cr = CrossEntropyWithSoftmax(labels[132, MBSize 0], OL.z[132, MBSize 0]) -> [1, 1]

11 out of 25 nodes do not share the minibatch layout with the input data.


Validating for node err. 25 nodes to process in pass 1.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> OL.W = LearnableParameter -> [132, 512]
Validating --> HL3.W = LearnableParameter -> [512, 512]
Validating --> HL2.W = LearnableParameter -> [512, 512]
Validating --> HL1.W = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> globalMean = LearnableParameter -> [363, 1]
Validating --> globalInvStd = LearnableParameter -> [363, 1]
Validating --> featNorm = PerDimMeanVarNormalization(features[363, MBSize 0], globalMean[363, 1], globalInvStd[363, 1]) -> [363, MBSize 0]
Validating --> HL1.t = Times(HL1.W[512, 363], featNorm[363, MBSize 0]) -> [512, MBSize 0]
Validating --> HL1.b = LearnableParameter -> [512, 1]
Validating --> HL1.z = Plus(HL1.t[512, MBSize 0], HL1.b[512, 1]) -> [512, MBSize 0]
Validating --> HL1.y = Sigmoid(HL1.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL2.t = Times(HL2.W[512, 512], HL1.y[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL2.b = LearnableParameter -> [512, 1]
Validating --> HL2.z = Plus(HL2.t[512, MBSize 0], HL2.b[512, 1]) -> [512, MBSize 0]
Validating --> HL2.y = Sigmoid(HL2.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL3.t = Times(HL3.W[512, 512], HL2.y[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL3.b = LearnableParameter -> [512, 1]
Validating --> HL3.z = Plus(HL3.t[512, MBSize 0], HL3.b[512, 1]) -> [512, MBSize 0]
Validating --> HL3.y = Sigmoid(HL3.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> OL.t = Times(OL.W[132, 512], HL3.y[512, MBSize 0]) -> [132, MBSize 0]
Validating --> OL.b = LearnableParameter -> [132, 1]
Validating --> OL.z = Plus(OL.t[132, MBSize 0], OL.b[132, 1]) -> [132, MBSize 0]
Validating --> err = ErrorPrediction(labels[132, MBSize 0], OL.z[132, MBSize 0]) -> [1, 1]

Validating for node err. 12 nodes to process in pass 2.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> OL.W = LearnableParameter -> [132, 512]
Validating --> HL3.W = LearnableParameter -> [512, 512]
Validating --> HL2.W = LearnableParameter -> [512, 512]
Validating --> HL1.W = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> globalMean = LearnableParameter -> [363, 1]
Validating --> globalInvStd = LearnableParameter -> [363, 1]
Validating --> featNorm = PerDimMeanVarNormalization(features[363, MBSize 0], globalMean[363, 1], globalInvStd[363, 1]) -> [363, MBSize 0]
Validating --> HL1.t = Times(HL1.W[512, 363], featNorm[363, MBSize 0]) -> [512, MBSize 0]
Validating --> HL1.b = LearnableParameter -> [512, 1]
Validating --> HL1.z = Plus(HL1.t[512, MBSize 0], HL1.b[512, 1]) -> [512, MBSize 0]
Validating --> HL1.y = Sigmoid(HL1.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL2.t = Times(HL2.W[512, 512], HL1.y[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL2.b = LearnableParameter -> [512, 1]
Validating --> HL2.z = Plus(HL2.t[512, MBSize 0], HL2.b[512, 1]) -> [512, MBSize 0]
Validating --> HL2.y = Sigmoid(HL2.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL3.t = Times(HL3.W[512, 512], HL2.y[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL3.b = LearnableParameter -> [512, 1]
Validating --> HL3.z = Plus(HL3.t[512, MBSize 0], HL3.b[512, 1]) -> [512, MBSize 0]
Validating --> HL3.y = Sigmoid(HL3.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> OL.t = Times(OL.W[132, 512], HL3.y[512, MBSize 0]) -> [132, MBSize 0]
Validating --> OL.b = LearnableParameter -> [132, 1]
Validating --> OL.z = Plus(OL.t[132, MBSize 0], OL.b[132, 1]) -> [132, MBSize 0]
Validating --> err = ErrorPrediction(labels[132, MBSize 0], OL.z[132, MBSize 0]) -> [1, 1]

Validating for node err, final verification.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> OL.W = LearnableParameter -> [132, 512]
Validating --> HL3.W = LearnableParameter -> [512, 512]
Validating --> HL2.W = LearnableParameter -> [512, 512]
Validating --> HL1.W = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> globalMean = LearnableParameter -> [363, 1]
Validating --> globalInvStd = LearnableParameter -> [363, 1]
Validating --> featNorm = PerDimMeanVarNormalization(features[363, MBSize 0], globalMean[363, 1], globalInvStd[363, 1]) -> [363, MBSize 0]
Validating --> HL1.t = Times(HL1.W[512, 363], featNorm[363, MBSize 0]) -> [512, MBSize 0]
Validating --> HL1.b = LearnableParameter -> [512, 1]
Validating --> HL1.z = Plus(HL1.t[512, MBSize 0], HL1.b[512, 1]) -> [512, MBSize 0]
Validating --> HL1.y = Sigmoid(HL1.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL2.t = Times(HL2.W[512, 512], HL1.y[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL2.b = LearnableParameter -> [512, 1]
Validating --> HL2.z = Plus(HL2.t[512, MBSize 0], HL2.b[512, 1]) -> [512, MBSize 0]
Validating --> HL2.y = Sigmoid(HL2.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL3.t = Times(HL3.W[512, 512], HL2.y[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL3.b = LearnableParameter -> [512, 1]
Validating --> HL3.z = Plus(HL3.t[512, MBSize 0], HL3.b[512, 1]) -> [512, MBSize 0]
Validating --> HL3.y = Sigmoid(HL3.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> OL.t = Times(OL.W[132, 512], HL3.y[512, MBSize 0]) -> [132, MBSize 0]
Validating --> OL.b = LearnableParameter -> [132, 1]
Validating --> OL.z = Plus(OL.t[132, MBSize 0], OL.b[132, 1]) -> [132, MBSize 0]
Validating --> err = ErrorPrediction(labels[132, MBSize 0], OL.z[132, MBSize 0]) -> [1, 1]

11 out of 25 nodes do not share the minibatch layout with the input data.


Validating for node scaledLogLikelihood. 26 nodes to process in pass 1.

Validating --> OL.W = LearnableParameter -> [132, 512]
Validating --> HL3.W = LearnableParameter -> [512, 512]
Validating --> HL2.W = LearnableParameter -> [512, 512]
Validating --> HL1.W = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> globalMean = LearnableParameter -> [363, 1]
Validating --> globalInvStd = LearnableParameter -> [363, 1]
Validating --> featNorm = PerDimMeanVarNormalization(features[363, MBSize 0], globalMean[363, 1], globalInvStd[363, 1]) -> [363, MBSize 0]
Validating --> HL1.t = Times(HL1.W[512, 363], featNorm[363, MBSize 0]) -> [512, MBSize 0]
Validating --> HL1.b = LearnableParameter -> [512, 1]
Validating --> HL1.z = Plus(HL1.t[512, MBSize 0], HL1.b[512, 1]) -> [512, MBSize 0]
Validating --> HL1.y = Sigmoid(HL1.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL2.t = Times(HL2.W[512, 512], HL1.y[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL2.b = LearnableParameter -> [512, 1]
Validating --> HL2.z = Plus(HL2.t[512, MBSize 0], HL2.b[512, 1]) -> [512, MBSize 0]
Validating --> HL2.y = Sigmoid(HL2.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL3.t = Times(HL3.W[512, 512], HL2.y[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL3.b = LearnableParameter -> [512, 1]
Validating --> HL3.z = Plus(HL3.t[512, MBSize 0], HL3.b[512, 1]) -> [512, MBSize 0]
Validating --> HL3.y = Sigmoid(HL3.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> OL.t = Times(OL.W[132, 512], HL3.y[512, MBSize 0]) -> [132, MBSize 0]
Validating --> OL.b = LearnableParameter -> [132, 1]
Validating --> OL.z = Plus(OL.t[132, MBSize 0], OL.b[132, 1]) -> [132, MBSize 0]
Validating --> globalPrior = LearnableParameter -> [132, 1]
Validating --> logPrior = Log(globalPrior[132, 1]) -> [132, 1]
Validating --> scaledLogLikelihood = Minus(OL.z[132, MBSize 0], logPrior[132, 1]) -> [132, MBSize 0]

Validating for node scaledLogLikelihood. 13 nodes to process in pass 2.

Validating --> OL.W = LearnableParameter -> [132, 512]
Validating --> HL3.W = LearnableParameter -> [512, 512]
Validating --> HL2.W = LearnableParameter -> [512, 512]
Validating --> HL1.W = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> globalMean = LearnableParameter -> [363, 1]
Validating --> globalInvStd = LearnableParameter -> [363, 1]
Validating --> featNorm = PerDimMeanVarNormalization(features[363, MBSize 0], globalMean[363, 1], globalInvStd[363, 1]) -> [363, MBSize 0]
Validating --> HL1.t = Times(HL1.W[512, 363], featNorm[363, MBSize 0]) -> [512, MBSize 0]
Validating --> HL1.b = LearnableParameter -> [512, 1]
Validating --> HL1.z = Plus(HL1.t[512, MBSize 0], HL1.b[512, 1]) -> [512, MBSize 0]
Validating --> HL1.y = Sigmoid(HL1.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL2.t = Times(HL2.W[512, 512], HL1.y[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL2.b = LearnableParameter -> [512, 1]
Validating --> HL2.z = Plus(HL2.t[512, MBSize 0], HL2.b[512, 1]) -> [512, MBSize 0]
Validating --> HL2.y = Sigmoid(HL2.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL3.t = Times(HL3.W[512, 512], HL2.y[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL3.b = LearnableParameter -> [512, 1]
Validating --> HL3.z = Plus(HL3.t[512, MBSize 0], HL3.b[512, 1]) -> [512, MBSize 0]
Validating --> HL3.y = Sigmoid(HL3.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> OL.t = Times(OL.W[132, 512], HL3.y[512, MBSize 0]) -> [132, MBSize 0]
Validating --> OL.b = LearnableParameter -> [132, 1]
Validating --> OL.z = Plus(OL.t[132, MBSize 0], OL.b[132, 1]) -> [132, MBSize 0]
Validating --> globalPrior = LearnableParameter -> [132, 1]
Validating --> logPrior = Log(globalPrior[132, 1]) -> [132, 1]
Validating --> scaledLogLikelihood = Minus(OL.z[132, MBSize 0], logPrior[132, 1]) -> [132, MBSize 0]

Validating for node scaledLogLikelihood, final verification.

Validating --> OL.W = LearnableParameter -> [132, 512]
Validating --> HL3.W = LearnableParameter -> [512, 512]
Validating --> HL2.W = LearnableParameter -> [512, 512]
Validating --> HL1.W = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> globalMean = LearnableParameter -> [363, 1]
Validating --> globalInvStd = LearnableParameter -> [363, 1]
Validating --> featNorm = PerDimMeanVarNormalization(features[363, MBSize 0], globalMean[363, 1], globalInvStd[363, 1]) -> [363, MBSize 0]
Validating --> HL1.t = Times(HL1.W[512, 363], featNorm[363, MBSize 0]) -> [512, MBSize 0]
Validating --> HL1.b = LearnableParameter -> [512, 1]
Validating --> HL1.z = Plus(HL1.t[512, MBSize 0], HL1.b[512, 1]) -> [512, MBSize 0]
Validating --> HL1.y = Sigmoid(HL1.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL2.t = Times(HL2.W[512, 512], HL1.y[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL2.b = LearnableParameter -> [512, 1]
Validating --> HL2.z = Plus(HL2.t[512, MBSize 0], HL2.b[512, 1]) -> [512, MBSize 0]
Validating --> HL2.y = Sigmoid(HL2.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL3.t = Times(HL3.W[512, 512], HL2.y[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL3.b = LearnableParameter -> [512, 1]
Validating --> HL3.z = Plus(HL3.t[512, MBSize 0], HL3.b[512, 1]) -> [512, MBSize 0]
Validating --> HL3.y = Sigmoid(HL3.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> OL.t = Times(OL.W[132, 512], HL3.y[512, MBSize 0]) -> [132, MBSize 0]
Validating --> OL.b = LearnableParameter -> [132, 1]
Validating --> OL.z = Plus(OL.t[132, MBSize 0], OL.b[132, 1]) -> [132, MBSize 0]
Validating --> globalPrior = LearnableParameter -> [132, 1]
Validating --> logPrior = Log(globalPrior[132, 1]) -> [132, 1]
Validating --> scaledLogLikelihood = Minus(OL.z[132, MBSize 0], logPrior[132, 1]) -> [132, MBSize 0]

12 out of 26 nodes do not share the minibatch layout with the input data.

Post-processing network complete.
CNTKCommandTrainBegin: sequenceTrain
NDLBuilder Using CPU
simplesenonehmm: reading '/tmp/cntk-test-20151216094712.720058/Speech/DNN_SequenceTraining@release_cpu/TestData/model.overalltying', '/tmp/cntk-test-20151216094712.720058/Speech/DNN_SequenceTraining@release_cpu/TestData/state.list', '/tmp/cntk-test-20151216094712.720058/Speech/DNN_SequenceTraining@release_cpu/TestData/model.transprob'
simplesenonehmm: 83253 units with 45 unique HMMs, 132 tied states, and 45 trans matrices read
reading script file /tmp/cntk-test-20151216094712.720058/Speech/DNN_SequenceTraining@release_cpu/TestData/glob_0000.scp ... 948 entries
trainlayer: OOV-exclusion code enabled, but no unigram specified to derive the word set from, so you won't get OOV exclusion
total 132 state names in state list /tmp/cntk-test-20151216094712.720058/Speech/DNN_SequenceTraining@release_cpu/TestData/state.list
htkmlfreader: reading MLF file /tmp/cntk-test-20151216094712.720058/Speech/DNN_SequenceTraining@release_cpu/TestData/glob_0000.mlf ... total 948 entries
archive: opening 80 lattice-archive TOC files ('/tmp/cntk-test-20151216094712.720058/Speech/DNN_SequenceTraining@release_cpu/TestData/CY2SCH010061231_1369712653.numden.lats.toc' etc.).................................................................................. 923 total lattices referenced in 80 archive files
. [no lattice for An4/454/454/an70-meht-b]....... [no lattice for An4/89/89/an6-fjmd-b].. [no lattice for An4/683/683/an364-mmkw-b].. [no lattice for An4/476/476/an256-mewl-b].... [no lattice for An4/2/2/an253-fash-b]...............................................................................feature set 0: 250814 frames in 923 out of 948 utterances
minibatchutterancesource: out of 948 files, 0 files not found in label set and 25 have no lattice
label set 0: 129 classes
minibatchutterancesource: 923 utterances grouped into 3 chunks, av. chunk size: 307.7 utterances, 83604.7 frames
Starting from checkpoint. Load Network From File /tmp/cntk-test-20151216094712.720058/Speech/DNN_SequenceTraining@release_cpu/models/cntkSpeech.sequence.0.

Post-processing network...

3 roots:
	scaledLogLikelihood = Minus
	err = ErrorPrediction
	seWithSoftmax = SequenceWithSoftmax
FormNestedNetwork: WARNING: Was called twice for scaledLogLikelihood Minus operation
FormNestedNetwork: WARNING: Was called twice for err ErrorPrediction operation
FormNestedNetwork: WARNING: Was called twice for seWithSoftmax SequenceWithSoftmax operation


Validating for node scaledLogLikelihood. 26 nodes to process in pass 1.

Validating --> OL.W = LearnableParameter -> [132, 512]
Validating --> HL3.W = LearnableParameter -> [512, 512]
Validating --> HL2.W = LearnableParameter -> [512, 512]
Validating --> HL1.W = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> globalMean = LearnableParameter -> [363, 1]
Validating --> globalInvStd = LearnableParameter -> [363, 1]
Validating --> featNorm = PerDimMeanVarNormalization(features[363, MBSize 0], globalMean[363, 1], globalInvStd[363, 1]) -> [363, MBSize 0]
Validating --> HL1.t = Times(HL1.W[512, 363], featNorm[363, MBSize 0]) -> [512, MBSize 0]
Validating --> HL1.b = LearnableParameter -> [512, 1]
Validating --> HL1.z = Plus(HL1.t[512, MBSize 0], HL1.b[512, 1]) -> [512, MBSize 0]
Validating --> HL1.y = Sigmoid(HL1.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL2.t = Times(HL2.W[512, 512], HL1.y[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL2.b = LearnableParameter -> [512, 1]
Validating --> HL2.z = Plus(HL2.t[512, MBSize 0], HL2.b[512, 1]) -> [512, MBSize 0]
Validating --> HL2.y = Sigmoid(HL2.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL3.t = Times(HL3.W[512, 512], HL2.y[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL3.b = LearnableParameter -> [512, 1]
Validating --> HL3.z = Plus(HL3.t[512, MBSize 0], HL3.b[512, 1]) -> [512, MBSize 0]
Validating --> HL3.y = Sigmoid(HL3.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> OL.t = Times(OL.W[132, 512], HL3.y[512, MBSize 0]) -> [132, MBSize 0]
Validating --> OL.b = LearnableParameter -> [132, 1]
Validating --> OL.z = Plus(OL.t[132, MBSize 0], OL.b[132, 1]) -> [132, MBSize 0]
Validating --> globalPrior = LearnableParameter -> [132, 1]
Validating --> logPrior = Log(globalPrior[132, 1]) -> [132, 1]
Validating --> scaledLogLikelihood = Minus(OL.z[132, MBSize 0], logPrior[132, 1]) -> [132, MBSize 0]

Validating for node scaledLogLikelihood. 14 nodes to process in pass 2.

Validating --> OL.W = LearnableParameter -> [132, 512]
Validating --> HL3.W = LearnableParameter -> [512, 512]
Validating --> HL2.W = LearnableParameter -> [512, 512]
Validating --> HL1.W = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> globalMean = LearnableParameter -> [363, 1]
Validating --> globalInvStd = LearnableParameter -> [363, 1]
Validating --> featNorm = PerDimMeanVarNormalization(features[363, MBSize 0], globalMean[363, 1], globalInvStd[363, 1]) -> [363, MBSize 0]
Validating --> HL1.t = Times(HL1.W[512, 363], featNorm[363, MBSize 0]) -> [512, MBSize 0]
Validating --> HL1.b = LearnableParameter -> [512, 1]
Validating --> HL1.z = Plus(HL1.t[512, MBSize 0], HL1.b[512, 1]) -> [512, MBSize 0]
Validating --> HL1.y = Sigmoid(HL1.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL2.t = Times(HL2.W[512, 512], HL1.y[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL2.b = LearnableParameter -> [512, 1]
Validating --> HL2.z = Plus(HL2.t[512, MBSize 0], HL2.b[512, 1]) -> [512, MBSize 0]
Validating --> HL2.y = Sigmoid(HL2.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL3.t = Times(HL3.W[512, 512], HL2.y[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL3.b = LearnableParameter -> [512, 1]
Validating --> HL3.z = Plus(HL3.t[512, MBSize 0], HL3.b[512, 1]) -> [512, MBSize 0]
Validating --> HL3.y = Sigmoid(HL3.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> OL.t = Times(OL.W[132, 512], HL3.y[512, MBSize 0]) -> [132, MBSize 0]
Validating --> OL.b = LearnableParameter -> [132, 1]
Validating --> OL.z = Plus(OL.t[132, MBSize 0], OL.b[132, 1]) -> [132, MBSize 0]
Validating --> globalPrior = LearnableParameter -> [132, 1]
Validating --> logPrior = Log(globalPrior[132, 1]) -> [132, 1]
Validating --> scaledLogLikelihood = Minus(OL.z[132, MBSize 0], logPrior[132, 1]) -> [132, MBSize 0]

Validating for node scaledLogLikelihood, final verification.

Validating --> OL.W = LearnableParameter -> [132, 512]
Validating --> HL3.W = LearnableParameter -> [512, 512]
Validating --> HL2.W = LearnableParameter -> [512, 512]
Validating --> HL1.W = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> globalMean = LearnableParameter -> [363, 1]
Validating --> globalInvStd = LearnableParameter -> [363, 1]
Validating --> featNorm = PerDimMeanVarNormalization(features[363, MBSize 0], globalMean[363, 1], globalInvStd[363, 1]) -> [363, MBSize 0]
Validating --> HL1.t = Times(HL1.W[512, 363], featNorm[363, MBSize 0]) -> [512, MBSize 0]
Validating --> HL1.b = LearnableParameter -> [512, 1]
Validating --> HL1.z = Plus(HL1.t[512, MBSize 0], HL1.b[512, 1]) -> [512, MBSize 0]
Validating --> HL1.y = Sigmoid(HL1.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL2.t = Times(HL2.W[512, 512], HL1.y[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL2.b = LearnableParameter -> [512, 1]
Validating --> HL2.z = Plus(HL2.t[512, MBSize 0], HL2.b[512, 1]) -> [512, MBSize 0]
Validating --> HL2.y = Sigmoid(HL2.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL3.t = Times(HL3.W[512, 512], HL2.y[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL3.b = LearnableParameter -> [512, 1]
Validating --> HL3.z = Plus(HL3.t[512, MBSize 0], HL3.b[512, 1]) -> [512, MBSize 0]
Validating --> HL3.y = Sigmoid(HL3.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> OL.t = Times(OL.W[132, 512], HL3.y[512, MBSize 0]) -> [132, MBSize 0]
Validating --> OL.b = LearnableParameter -> [132, 1]
Validating --> OL.z = Plus(OL.t[132, MBSize 0], OL.b[132, 1]) -> [132, MBSize 0]
Validating --> globalPrior = LearnableParameter -> [132, 1]
Validating --> logPrior = Log(globalPrior[132, 1]) -> [132, 1]
Validating --> scaledLogLikelihood = Minus(OL.z[132, MBSize 0], logPrior[132, 1]) -> [132, MBSize 0]

12 out of 26 nodes do not share the minibatch layout with the input data.


Validating for node err. 25 nodes to process in pass 1.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> OL.W = LearnableParameter -> [132, 512]
Validating --> HL3.W = LearnableParameter -> [512, 512]
Validating --> HL2.W = LearnableParameter -> [512, 512]
Validating --> HL1.W = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> globalMean = LearnableParameter -> [363, 1]
Validating --> globalInvStd = LearnableParameter -> [363, 1]
Validating --> featNorm = PerDimMeanVarNormalization(features[363, MBSize 0], globalMean[363, 1], globalInvStd[363, 1]) -> [363, MBSize 0]
Validating --> HL1.t = Times(HL1.W[512, 363], featNorm[363, MBSize 0]) -> [512, MBSize 0]
Validating --> HL1.b = LearnableParameter -> [512, 1]
Validating --> HL1.z = Plus(HL1.t[512, MBSize 0], HL1.b[512, 1]) -> [512, MBSize 0]
Validating --> HL1.y = Sigmoid(HL1.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL2.t = Times(HL2.W[512, 512], HL1.y[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL2.b = LearnableParameter -> [512, 1]
Validating --> HL2.z = Plus(HL2.t[512, MBSize 0], HL2.b[512, 1]) -> [512, MBSize 0]
Validating --> HL2.y = Sigmoid(HL2.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL3.t = Times(HL3.W[512, 512], HL2.y[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL3.b = LearnableParameter -> [512, 1]
Validating --> HL3.z = Plus(HL3.t[512, MBSize 0], HL3.b[512, 1]) -> [512, MBSize 0]
Validating --> HL3.y = Sigmoid(HL3.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> OL.t = Times(OL.W[132, 512], HL3.y[512, MBSize 0]) -> [132, MBSize 0]
Validating --> OL.b = LearnableParameter -> [132, 1]
Validating --> OL.z = Plus(OL.t[132, MBSize 0], OL.b[132, 1]) -> [132, MBSize 0]
Validating --> err = ErrorPrediction(labels[132, MBSize 0], OL.z[132, MBSize 0]) -> [1, 1]

Validating for node err. 12 nodes to process in pass 2.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> OL.W = LearnableParameter -> [132, 512]
Validating --> HL3.W = LearnableParameter -> [512, 512]
Validating --> HL2.W = LearnableParameter -> [512, 512]
Validating --> HL1.W = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> globalMean = LearnableParameter -> [363, 1]
Validating --> globalInvStd = LearnableParameter -> [363, 1]
Validating --> featNorm = PerDimMeanVarNormalization(features[363, MBSize 0], globalMean[363, 1], globalInvStd[363, 1]) -> [363, MBSize 0]
Validating --> HL1.t = Times(HL1.W[512, 363], featNorm[363, MBSize 0]) -> [512, MBSize 0]
Validating --> HL1.b = LearnableParameter -> [512, 1]
Validating --> HL1.z = Plus(HL1.t[512, MBSize 0], HL1.b[512, 1]) -> [512, MBSize 0]
Validating --> HL1.y = Sigmoid(HL1.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL2.t = Times(HL2.W[512, 512], HL1.y[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL2.b = LearnableParameter -> [512, 1]
Validating --> HL2.z = Plus(HL2.t[512, MBSize 0], HL2.b[512, 1]) -> [512, MBSize 0]
Validating --> HL2.y = Sigmoid(HL2.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL3.t = Times(HL3.W[512, 512], HL2.y[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL3.b = LearnableParameter -> [512, 1]
Validating --> HL3.z = Plus(HL3.t[512, MBSize 0], HL3.b[512, 1]) -> [512, MBSize 0]
Validating --> HL3.y = Sigmoid(HL3.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> OL.t = Times(OL.W[132, 512], HL3.y[512, MBSize 0]) -> [132, MBSize 0]
Validating --> OL.b = LearnableParameter -> [132, 1]
Validating --> OL.z = Plus(OL.t[132, MBSize 0], OL.b[132, 1]) -> [132, MBSize 0]
Validating --> err = ErrorPrediction(labels[132, MBSize 0], OL.z[132, MBSize 0]) -> [1, 1]

Validating for node err, final verification.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> OL.W = LearnableParameter -> [132, 512]
Validating --> HL3.W = LearnableParameter -> [512, 512]
Validating --> HL2.W = LearnableParameter -> [512, 512]
Validating --> HL1.W = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> globalMean = LearnableParameter -> [363, 1]
Validating --> globalInvStd = LearnableParameter -> [363, 1]
Validating --> featNorm = PerDimMeanVarNormalization(features[363, MBSize 0], globalMean[363, 1], globalInvStd[363, 1]) -> [363, MBSize 0]
Validating --> HL1.t = Times(HL1.W[512, 363], featNorm[363, MBSize 0]) -> [512, MBSize 0]
Validating --> HL1.b = LearnableParameter -> [512, 1]
Validating --> HL1.z = Plus(HL1.t[512, MBSize 0], HL1.b[512, 1]) -> [512, MBSize 0]
Validating --> HL1.y = Sigmoid(HL1.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL2.t = Times(HL2.W[512, 512], HL1.y[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL2.b = LearnableParameter -> [512, 1]
Validating --> HL2.z = Plus(HL2.t[512, MBSize 0], HL2.b[512, 1]) -> [512, MBSize 0]
Validating --> HL2.y = Sigmoid(HL2.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL3.t = Times(HL3.W[512, 512], HL2.y[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL3.b = LearnableParameter -> [512, 1]
Validating --> HL3.z = Plus(HL3.t[512, MBSize 0], HL3.b[512, 1]) -> [512, MBSize 0]
Validating --> HL3.y = Sigmoid(HL3.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> OL.t = Times(OL.W[132, 512], HL3.y[512, MBSize 0]) -> [132, MBSize 0]
Validating --> OL.b = LearnableParameter -> [132, 1]
Validating --> OL.z = Plus(OL.t[132, MBSize 0], OL.b[132, 1]) -> [132, MBSize 0]
Validating --> err = ErrorPrediction(labels[132, MBSize 0], OL.z[132, MBSize 0]) -> [1, 1]

11 out of 25 nodes do not share the minibatch layout with the input data.


Validating for node seWithSoftmax. 28 nodes to process in pass 1.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> OL.W = LearnableParameter -> [132, 512]
Validating --> HL3.W = LearnableParameter -> [512, 512]
Validating --> HL2.W = LearnableParameter -> [512, 512]
Validating --> HL1.W = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> globalMean = LearnableParameter -> [363, 1]
Validating --> globalInvStd = LearnableParameter -> [363, 1]
Validating --> featNorm = PerDimMeanVarNormalization(features[363, MBSize 0], globalMean[363, 1], globalInvStd[363, 1]) -> [363, MBSize 0]
Validating --> HL1.t = Times(HL1.W[512, 363], featNorm[363, MBSize 0]) -> [512, MBSize 0]
Validating --> HL1.b = LearnableParameter -> [512, 1]
Validating --> HL1.z = Plus(HL1.t[512, MBSize 0], HL1.b[512, 1]) -> [512, MBSize 0]
Validating --> HL1.y = Sigmoid(HL1.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL2.t = Times(HL2.W[512, 512], HL1.y[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL2.b = LearnableParameter -> [512, 1]
Validating --> HL2.z = Plus(HL2.t[512, MBSize 0], HL2.b[512, 1]) -> [512, MBSize 0]
Validating --> HL2.y = Sigmoid(HL2.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL3.t = Times(HL3.W[512, 512], HL2.y[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL3.b = LearnableParameter -> [512, 1]
Validating --> HL3.z = Plus(HL3.t[512, MBSize 0], HL3.b[512, 1]) -> [512, MBSize 0]
Validating --> HL3.y = Sigmoid(HL3.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> OL.t = Times(OL.W[132, 512], HL3.y[512, MBSize 0]) -> [132, MBSize 0]
Validating --> OL.b = LearnableParameter -> [132, 1]
Validating --> OL.z = Plus(OL.t[132, MBSize 0], OL.b[132, 1]) -> [132, MBSize 0]
Validating --> globalPrior = LearnableParameter -> [132, 1]
Validating --> logPrior = Log(globalPrior[132, 1]) -> [132, 1]
Validating --> scaledLogLikelihood = Minus(OL.z[132, MBSize 0], logPrior[132, 1]) -> [132, MBSize 0]
Validating --> seWithSoftmax = SequenceWithSoftmax(labels[132, MBSize 0], OL.z[132, MBSize 0], scaledLogLikelihood[132, MBSize 0]) -> [1, 1]

Validating for node seWithSoftmax. 14 nodes to process in pass 2.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> OL.W = LearnableParameter -> [132, 512]
Validating --> HL3.W = LearnableParameter -> [512, 512]
Validating --> HL2.W = LearnableParameter -> [512, 512]
Validating --> HL1.W = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> globalMean = LearnableParameter -> [363, 1]
Validating --> globalInvStd = LearnableParameter -> [363, 1]
Validating --> featNorm = PerDimMeanVarNormalization(features[363, MBSize 0], globalMean[363, 1], globalInvStd[363, 1]) -> [363, MBSize 0]
Validating --> HL1.t = Times(HL1.W[512, 363], featNorm[363, MBSize 0]) -> [512, MBSize 0]
Validating --> HL1.b = LearnableParameter -> [512, 1]
Validating --> HL1.z = Plus(HL1.t[512, MBSize 0], HL1.b[512, 1]) -> [512, MBSize 0]
Validating --> HL1.y = Sigmoid(HL1.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL2.t = Times(HL2.W[512, 512], HL1.y[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL2.b = LearnableParameter -> [512, 1]
Validating --> HL2.z = Plus(HL2.t[512, MBSize 0], HL2.b[512, 1]) -> [512, MBSize 0]
Validating --> HL2.y = Sigmoid(HL2.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL3.t = Times(HL3.W[512, 512], HL2.y[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL3.b = LearnableParameter -> [512, 1]
Validating --> HL3.z = Plus(HL3.t[512, MBSize 0], HL3.b[512, 1]) -> [512, MBSize 0]
Validating --> HL3.y = Sigmoid(HL3.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> OL.t = Times(OL.W[132, 512], HL3.y[512, MBSize 0]) -> [132, MBSize 0]
Validating --> OL.b = LearnableParameter -> [132, 1]
Validating --> OL.z = Plus(OL.t[132, MBSize 0], OL.b[132, 1]) -> [132, MBSize 0]
Validating --> globalPrior = LearnableParameter -> [132, 1]
Validating --> logPrior = Log(globalPrior[132, 1]) -> [132, 1]
Validating --> scaledLogLikelihood = Minus(OL.z[132, MBSize 0], logPrior[132, 1]) -> [132, MBSize 0]
Validating --> seWithSoftmax = SequenceWithSoftmax(labels[132, MBSize 0], OL.z[132, MBSize 0], scaledLogLikelihood[132, MBSize 0]) -> [1, 1]

Validating for node seWithSoftmax, final verification.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> OL.W = LearnableParameter -> [132, 512]
Validating --> HL3.W = LearnableParameter -> [512, 512]
Validating --> HL2.W = LearnableParameter -> [512, 512]
Validating --> HL1.W = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> globalMean = LearnableParameter -> [363, 1]
Validating --> globalInvStd = LearnableParameter -> [363, 1]
Validating --> featNorm = PerDimMeanVarNormalization(features[363, MBSize 0], globalMean[363, 1], globalInvStd[363, 1]) -> [363, MBSize 0]
Validating --> HL1.t = Times(HL1.W[512, 363], featNorm[363, MBSize 0]) -> [512, MBSize 0]
Validating --> HL1.b = LearnableParameter -> [512, 1]
Validating --> HL1.z = Plus(HL1.t[512, MBSize 0], HL1.b[512, 1]) -> [512, MBSize 0]
Validating --> HL1.y = Sigmoid(HL1.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL2.t = Times(HL2.W[512, 512], HL1.y[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL2.b = LearnableParameter -> [512, 1]
Validating --> HL2.z = Plus(HL2.t[512, MBSize 0], HL2.b[512, 1]) -> [512, MBSize 0]
Validating --> HL2.y = Sigmoid(HL2.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL3.t = Times(HL3.W[512, 512], HL2.y[512, MBSize 0]) -> [512, MBSize 0]
Validating --> HL3.b = LearnableParameter -> [512, 1]
Validating --> HL3.z = Plus(HL3.t[512, MBSize 0], HL3.b[512, 1]) -> [512, MBSize 0]
Validating --> HL3.y = Sigmoid(HL3.z[512, MBSize 0]) -> [512, MBSize 0]
Validating --> OL.t = Times(OL.W[132, 512], HL3.y[512, MBSize 0]) -> [132, MBSize 0]
Validating --> OL.b = LearnableParameter -> [132, 1]
Validating --> OL.z = Plus(OL.t[132, MBSize 0], OL.b[132, 1]) -> [132, MBSize 0]
Validating --> globalPrior = LearnableParameter -> [132, 1]
Validating --> logPrior = Log(globalPrior[132, 1]) -> [132, 1]
Validating --> scaledLogLikelihood = Minus(OL.z[132, MBSize 0], logPrior[132, 1]) -> [132, MBSize 0]
Validating --> seWithSoftmax = SequenceWithSoftmax(labels[132, MBSize 0], OL.z[132, MBSize 0], scaledLogLikelihood[132, MBSize 0]) -> [1, 1]

13 out of 28 nodes do not share the minibatch layout with the input data.

Post-processing network complete.

SGD using CPU.

Training criterion node(s):
	seWithSoftmax = SequenceWithSoftmax

Evaluation criterion node(s):
	err = ErrorPrediction


Allocating matrices for forward and/or backward propagation.
No PreCompute nodes found, skipping PreCompute step
Set Max Temp Mem Size For Convolution Nodes to 0 samples.
Setting Hsmoothing weight to 0.95 and frame-dropping threshhold to 1e-10
Starting Epoch 1: learning rate per sample = 0.000002  effective momentum = 0.995898  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 0: frames [0..81920] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms
getcachedidmap: reading 'CY2SCH100112501_1779035656.numden.lats.symlist'
getcachedidmap: reading 'CY2SCH060091323_1311139777.numden.lats.symlist'
getcachedidmap: reading 'CY2SCH050080342_1705448690.numden.lats.symlist'
getcachedidmap: reading 'CY2SCH040081222_2063295388.numden.lats.symlist'
getcachedidmap: reading 'CY2SCH060050506_415705324.numden.lats.symlist'
getcachedidmap: reading 'CY2SCH050070531_1705536174.numden.lats.symlist'
getcachedidmap: reading 'CY2SCH060032122_1764296812.numden.lats.symlist'
getcachedidmap: reading 'CY2SCH050081506_1705673846.numden.lats.symlist'
getcachedidmap: reading 'CY2SCH080062603_966497326.numden.lats.symlist'
getcachedidmap: reading 'CY2SCH040081012_2063351544.numden.lats.symlist'
getcachedidmap: reading 'CY2SCH060062605_1536194576.numden.lats.symlist'
getcachedidmap: reading 'CY2SCH110070817_767763687.numden.lats.symlist'
getcachedidmap: reading 'CY2SCH110070803_1061569312.numden.lats.symlist'
getcachedidmap: reading 'CY2SCH090121023_160495828.numden.lats.symlist'
getcachedidmap: reading 'CY2SCH110071501_1059265218.numden.lats.symlist'
getcachedidmap: reading 'CY2SCH050121418_1697698502.numden.lats.symlist'
getcachedidmap: reading 'CY2SCH080071106_1143001388.numden.lats.symlist'
getcachedidmap: reading 'CY2SCH020071229_644244140.numden.lats.symlist'
getcachedidmap: reading 'CY2SCH070062507_2087712345.numden.lats.symlist'
getcachedidmap: reading 'CY2SCH060082605_403727641.numden.lats.symlist'
getcachedidmap: reading 'CY2SCH050121330_1705081299.numden.lats.symlist'
getcachedidmap: reading 'CY2SCH040121540_2063741403.numden.lats.symlist'
getcachedidmap: reading 'CY2SCH080110609_1362153092.numden.lats.symlist'
getcachedidmap: reading 'CY2SCH110121120_1050992515.numden.lats.symlist'
getcachedidmap: reading 'CY2SCH070101111_1071091997.numden.lats.symlist'
getcachedidmap: reading 'CY2SCH070081604_866394296.numden.lats.symlist'
getcachedidmap: reading 'CY2SCH010061231_1369712653.numden.lats.symlist'
getcachedidmap: reading 'CY2SCH060121820_1476601534.numden.lats.symlist'
getcachedidmap: reading 'CY2SCH050111321_1705093424.numden.lats.symlist'
getcachedidmap: reading 'CY2SCH040120646_805508469.numden.lats.symlist'
getcachedidmap: reading 'CY2SCH080071106_1143018888.numden.lats.symlist'
getcachedidmap: reading 'CY2SCH040080404_2063355153.numden.lats.symlist'
getcachedidmap: reading 'CY2SCH100092303_1769985203.numden.lats.symlist'
getcachedidmap: reading 'CY2SCH050051513_1110722876.numden.lats.symlist'
getcachedidmap: reading 'CY2SCH010080244_1211145048.numden.lats.symlist'
getcachedidmap: reading 'CY2SCH090100302_1080239467.numden.lats.symlist'
getcachedidmap: reading 'CY2SCH070081708_1067766888.numden.lats.symlist'
getcachedidmap: reading 'CY2SCH040030304_1783125393.numden.lats.symlist'
getcachedidmap: reading 'CY2SCH070061608_1068884372.numden.lats.symlist'
getcachedidmap: reading 'CY2SCH090052313_1116838701.numden.lats.symlist'
getcachedidmap: reading 'CY2SCH030121606_1629053528.numden.lats.symlist'
getcachedidmap: reading 'CY2SCH080061318_1080287029.numden.lats.symlist'
getcachedidmap: reading 'CY2SCH070061523_1068809263.numden.lats.symlist'
getcachedidmap: reading 'CY2SCH040051114_2063220700.numden.lats.symlist'
getcachedidmap: reading 'CY2SCH040080519_2063294856.numden.lats.symlist'
getcachedidmap: reading 'CY2SCH060042707_1939966343.numden.lats.symlist'
getcachedidmap: reading 'CY2SCH080041801_1024690842.numden.lats.symlist'
getcachedidmap: reading 'CY2SCH090081411_995585687.numden.lats.symlist'
getcachedidmap: reading 'CY2SCH080040406_982069998.numden.lats.symlist'
getcachedidmap: reading 'CY2SCH050111011_1704954393.numden.lats.symlist'
getcachedidmap: reading 'CY2SCH090090404_1123576357.numden.lats.symlist'
getcachedidmap: reading 'CY2SCH070060121_1068947138.numden.lats.symlist'
getcachedidmap: reading 'CY2SCH040121221_2063738606.numden.lats.symlist'
getcachedidmap: reading 'CY2SCH070111908_1069919341.numden.lats.symlist'
getcachedidmap: reading 'CY2SCH050120821_1705096268.numden.lats.symlist'
getcachedidmap: reading 'CY2SCH050091619_1705363705.numden.lats.symlist'
getcachedidmap: reading 'CY2SCH040070546_2063363669.numden.lats.symlist'
getcachedidmap: reading 'CY2SCH040090837_1205589951.numden.lats.symlist'
getcachedidmap: reading 'CY2SCH070040324_1092265200.numden.lats.symlist'
getcachedidmap: reading 'CY2SCH050090827_1393311596.numden.lats.symlist'
getcachedidmap: reading 'CY2SCH070110213_1069879356.numden.lats.symlist'
getcachedidmap: reading 'CY2SCH050051308_1443335642.numden.lats.symlist'
getcachedidmap: reading 'CY2SCH040120414_2063653575.numden.lats.symlist'
getcachedidmap: reading 'CY2SCH060062620_1679599206.numden.lats.symlist'
getcachedidmap: reading 'CY2SCH070032203_1093924684.numden.lats.symlist'
getcachedidmap: reading 'CY2SCH010061544_691164888.numden.lats.symlist'
getcachedidmap: reading 'CY2SCH090090208_1064021467.numden.lats.symlist'
getcachedidmap: reading 'CY2SCH040011112_1027256127.numden.lats.symlist'
getcachedidmap: reading 'CY2SCH030061032_1628532606.numden.lats.symlist'
getcachedidmap: reading 'CY2SCH100092119_1769162281.numden.lats.symlist'
getcachedidmap: reading 'CY2SCH070080320_1067791763.numden.lats.symlist'
getcachedidmap: reading 'CY2SCH050090541_1705321237.numden.lats.symlist'
getcachedidmap: reading 'CY2SCH060050603_416427387.numden.lats.symlist'
getcachedidmap: reading 'CY2SCH050110617_547221844.numden.lats.symlist'
getcachedidmap: reading 'CY2SCH040031340_1350166299.numden.lats.symlist'
getcachedidmap: reading 'CY2SCH040121314_2063679450.numden.lats.symlist'
getcachedidmap: reading 'CY2SCH050120722_1705080393.numden.lats.symlist'
getcachedidmap: reading 'CY2SCH100090709_1765693687.numden.lats.symlist'
getcachedidmap: reading 'CY2SCH060060407_1233548343.numden.lats.symlist'
getcachedidmap: reading 'CY2SCH060091920_1713759019.numden.lats.symlist'

Starting minibatch loop.
backpointers: 32.2% edges have at least one /sil/ unit inside
forwardbackward: 16.667% non-zero state posteriors
dengamma value 1.032323
backpointers: 30.4% edges have at least one /sil/ unit inside
forwardbackward: 18.066% non-zero state posteriors
dengamma value 1.047921
backpointers: 26.6% edges have at least one /sil/ unit inside
forwardbackward: 19.902% non-zero state posteriors
dengamma value 1.052672
backpointers: 41.3% edges have at least one /sil/ unit inside
forwardbackward: 14.307% non-zero state posteriors
dengamma value 1.058229
backpointers: 33.8% edges have at least one /sil/ unit inside
forwardbackward: 22.007% non-zero state posteriors
dengamma value 0.966483
backpointers: 27.5% edges have at least one /sil/ unit inside
forwardbackward: 19.978% non-zero state posteriors
dengamma value 0.983361
backpointers: 32.5% edges have at least one /sil/ unit inside
forwardbackward: 21.389% non-zero state posteriors
dengamma value 1.015852
backpointers: 35.0% edges have at least one /sil/ unit inside
forwardbackward: 15.584% non-zero state posteriors
dengamma value 1.011610
backpointers: 32.6% edges have at least one /sil/ unit inside
forwardbackward: 19.766% non-zero state posteriors
dengamma value 1.007235
backpointers: 40.3% edges have at least one /sil/ unit inside
forwardbackward: 13.931% non-zero state posteriors
dengamma value 0.930374
backpointers: 38.8% edges have at least one /sil/ unit inside
forwardbackward: 14.189% non-zero state posteriors
dengamma value 0.982145
backpointers: 36.6% edges have at least one /sil/ unit inside
forwardbackward: 18.537% non-zero state posteriors
dengamma value 0.983914
backpointers: 38.0% edges have at least one /sil/ unit inside
forwardbackward: 14.021% non-zero state posteriors
dengamma value 0.958123
backpointers: 29.8% edges have at least one /sil/ unit inside
forwardbackward: 17.337% non-zero state posteriors
dengamma value 0.942329
backpointers: 28.7% edges have at least one /sil/ unit inside
forwardbackward: 21.455% non-zero state posteriors
dengamma value 1.029684
backpointers: 29.4% edges have at least one /sil/ unit inside
forwardbackward: 22.804% non-zero state posteriors
dengamma value 1.053509
backpointers: 33.0% edges have at least one /sil/ unit inside
forwardbackward: 17.373% non-zero state posteriors
dengamma value 1.037562
backpointers: 37.0% edges have at least one /sil/ unit inside
forwardbackward: 13.798% non-zero state posteriors
dengamma value 1.018906
backpointers: 34.2% edges have at least one /sil/ unit inside
forwardbackward: 20.991% non-zero state posteriors
dengamma value 1.033661
backpointers: 40.5% edges have at least one /sil/ unit inside
forwardbackward: 16.021% non-zero state posteriors
dengamma value 0.964023
backpointers: 25.8% edges have at least one /sil/ unit inside
forwardbackward: 14.902% non-zero state posteriors
dengamma value 0.941885
 Epoch[ 1 of 3]-Minibatch[   1-  10, 0.12%]: SamplesSeen = 5648; TrainLossPerSample =  0.08265285; EvalErr[0]PerSample = 0.37907224; TotalTime = 3.5427s; SamplesPerSecond = 1594.3
backpointers: 33.4% edges have at least one /sil/ unit inside
forwardbackward: 19.043% non-zero state posteriors
dengamma value 1.005221
backpointers: 36.6% edges have at least one /sil/ unit inside
forwardbackward: 16.989% non-zero state posteriors
dengamma value 0.965036
backpointers: 34.3% edges have at least one /sil/ unit inside
forwardbackward: 17.656% non-zero state posteriors
dengamma value 1.001514
backpointers: 36.6% edges have at least one /sil/ unit inside
forwardbackward: 18.689% non-zero state posteriors
dengamma value 1.023263
backpointers: 31.7% edges have at least one /sil/ unit inside
forwardbackward: 20.174% non-zero state posteriors
dengamma value 0.995457
backpointers: 33.7% edges have at least one /sil/ unit inside
forwardbackward: 20.770% non-zero state posteriors
dengamma value 1.015284
backpointers: 35.1% edges have at least one /sil/ unit inside
forwardbackward: 17.027% non-zero state posteriors
dengamma value 0.982218
backpointers: 34.5% edges have at least one /sil/ unit inside
forwardbackward: 16.528% non-zero state posteriors
dengamma value 1.046538
backpointers: 33.7% edges have at least one /sil/ unit inside
forwardbackward: 19.013% non-zero state posteriors
dengamma value 1.020596
backpointers: 36.2% edges have at least one /sil/ unit inside
forwardbackward: 15.796% non-zero state posteriors
dengamma value 1.013270
backpointers: 32.7% edges have at least one /sil/ unit inside
forwardbackward: 16.886% non-zero state posteriors
dengamma value 1.005085
backpointers: 34.2% edges have at least one /sil/ unit inside
forwardbackward: 21.574% non-zero state posteriors
dengamma value 1.050579
backpointers: 37.8% edges have at least one /sil/ unit inside
forwardbackward: 16.698% non-zero state posteriors
dengamma value 0.940657
backpointers: 30.2% edges have at least one /sil/ unit inside
forwardbackward: 17.594% non-zero state posteriors
dengamma value 0.995691
backpointers: 30.4% edges have at least one /sil/ unit inside
forwardbackward: 16.686% non-zero state posteriors
dengamma value 1.049674
backpointers: 29.7% edges have at least one /sil/ unit inside
forwardbackward: 20.435% non-zero state posteriors
dengamma value 1.000259
backpointers: 24.7% edges have at least one /sil/ unit inside
forwardbackward: 21.736% non-zero state posteriors
dengamma value 0.978718
backpointers: 29.3% edges have at least one /sil/ unit inside
forwardbackward: 22.651% non-zero state posteriors
dengamma value 1.080875
backpointers: 42.5% edges have at least one /sil/ unit inside
forwardbackward: 15.069% non-zero state posteriors
dengamma value 0.938322
backpointers: 36.1% edges have at least one /sil/ unit inside
forwardbackward: 12.237% non-zero state posteriors
dengamma value 1.044450
backpointers: 31.0% edges have at least one /sil/ unit inside
forwardbackward: 15.343% non-zero state posteriors
dengamma value 0.991685
backpointers: 38.0% edges have at least one /sil/ unit inside
forwardbackward: 20.671% non-zero state posteriors
dengamma value 0.927130
 Epoch[ 1 of 3]-Minibatch[  11-  20, 0.24%]: SamplesSeen = 5726; TrainLossPerSample =  0.07769845; EvalErr[0]PerSample = 0.36430318; TotalTime = 3.7694s; SamplesPerSecond = 1519.1
backpointers: 37.1% edges have at least one /sil/ unit inside
forwardbackward: 17.548% non-zero state posteriors
dengamma value 0.968366
backpointers: 29.2% edges have at least one /sil/ unit inside
forwardbackward: 17.640% non-zero state posteriors
dengamma value 1.104832
backpointers: 35.2% edges have at least one /sil/ unit inside
forwardbackward: 12.879% non-zero state posteriors
dengamma value 1.027472
backpointers: 28.3% edges have at least one /sil/ unit inside
forwardbackward: 17.493% non-zero state posteriors
dengamma value 1.006404
backpointers: 27.1% edges have at least one /sil/ unit inside
forwardbackward: 21.948% non-zero state posteriors
dengamma value 1.026662
backpointers: 35.6% edges have at least one /sil/ unit inside
forwardbackward: 15.104% non-zero state posteriors
dengamma value 0.997832
backpointers: 35.3% edges have at least one /sil/ unit inside
forwardbackward: 21.426% non-zero state posteriors
dengamma value 1.093270
backpointers: 31.7% edges have at least one /sil/ unit inside
forwardbackward: 23.799% non-zero state posteriors
dengamma value 1.096699
backpointers: 26.9% edges have at least one /sil/ unit inside
forwardbackward: 24.322% non-zero state posteriors
dengamma value 1.058637
backpointers: 28.5% edges have at least one /sil/ unit inside
forwardbackward: 23.232% non-zero state posteriors
dengamma value 1.018179
backpointers: 29.3% edges have at least one /sil/ unit inside
forwardbackward: 23.545% non-zero state posteriors
dengamma value 1.101746
backpointers: 22.7% edges have at least one /sil/ unit inside
forwardbackward: 26.176% non-zero state posteriors
dengamma value 1.047153
backpointers: 36.2% edges have at least one /sil/ unit inside
forwardbackward: 17.348% non-zero state posteriors
dengamma value 0.999325
backpointers: 37.2% edges have at least one /sil/ unit inside
forwardbackward: 17.951% non-zero state posteriors
dengamma value 0.978274
backpointers: 28.1% edges have at least one /sil/ unit inside
forwardbackward: 20.805% non-zero state posteriors
dengamma value 1.030969
backpointers: 35.4% edges have at least one /sil/ unit inside
forwardbackward: 16.225% non-zero state posteriors
dengamma value 0.991151
backpointers: 39.1% edges have at least one /sil/ unit inside
forwardbackward: 15.132% non-zero state posteriors
dengamma value 0.963692
backpointers: 34.3% edges have at least one /sil/ unit inside
forwardbackward: 17.634% non-zero state posteriors
dengamma value 1.021332
backpointers: 35.3% edges have at least one /sil/ unit inside
forwardbackward: 17.320% non-zero state posteriors
dengamma value 0.990503
backpointers: 30.3% edges have at least one /sil/ unit inside
forwardbackward: 11.706% non-zero state posteriors
dengamma value 1.032181
backpointers: 34.8% edges have at least one /sil/ unit inside
forwardbackward: 15.022% non-zero state posteriors
dengamma value 0.994275
backpointers: 36.9% edges have at least one /sil/ unit inside
forwardbackward: 17.171% non-zero state posteriors
dengamma value 1.008022
backpointers: 35.0% edges have at least one /sil/ unit inside
forwardbackward: 13.380% non-zero state posteriors
dengamma value 0.991823
 Epoch[ 1 of 3]-Minibatch[  21-  30, 0.37%]: SamplesSeen = 6694; TrainLossPerSample =  0.06676549; EvalErr[0]PerSample = 0.36196594; TotalTime = 4.4014s; SamplesPerSecond = 1520.9
backpointers: 34.7% edges have at least one /sil/ unit inside
forwardbackward: 19.511% non-zero state posteriors
dengamma value 0.992719
backpointers: 36.8% edges have at least one /sil/ unit inside
forwardbackward: 15.530% non-zero state posteriors
dengamma value 0.967383
backpointers: 34.8% edges have at least one /sil/ unit inside
forwardbackward: 20.789% non-zero state posteriors
dengamma value 0.950276
backpointers: 28.4% edges have at least one /sil/ unit inside
forwardbackward: 21.743% non-zero state posteriors
dengamma value 1.071118
backpointers: 32.7% edges have at least one /sil/ unit inside
forwardbackward: 13.086% non-zero state posteriors
dengamma value 1.025801
backpointers: 37.4% edges have at least one /sil/ unit inside
forwardbackward: 14.015% non-zero state posteriors
dengamma value 0.985523
backpointers: 34.5% edges have at least one /sil/ unit inside
forwardbackward: 14.127% non-zero state posteriors
dengamma value 0.993028
backpointers: 33.2% edges have at least one /sil/ unit inside
forwardbackward: 22.060% non-zero state posteriors
dengamma value 1.043526
backpointers: 34.0% edges have at least one /sil/ unit inside
forwardbackward: 16.862% non-zero state posteriors
dengamma value 1.045341
backpointers: 22.9% edges have at least one /sil/ unit inside
forwardbackward: 21.384% non-zero state posteriors
dengamma value 1.034751
backpointers: 27.7% edges have at least one /sil/ unit inside
forwardbackward: 18.300% non-zero state posteriors
dengamma value 1.025268
backpointers: 35.0% edges have at least one /sil/ unit inside
forwardbackward: 18.422% non-zero state posteriors
dengamma value 0.978745
backpointers: 27.6% edges have at least one /sil/ unit inside
forwardbackward: 21.285% non-zero state posteriors
dengamma value 1.085311
backpointers: 42.5% edges have at least one /sil/ unit inside
forwardbackward: 12.941% non-zero state posteriors
dengamma value 0.987796
backpointers: 29.6% edges have at least one /sil/ unit inside
forwardbackward: 18.378% non-zero state posteriors
dengamma value 1.021021
backpointers: 31.9% edges have at least one /sil/ unit inside
forwardbackward: 16.736% non-zero state posteriors
dengamma value 0.971949
backpointers: 29.3% edges have at least one /sil/ unit inside
forwardbackward: 20.798% non-zero state posteriors
dengamma value 0.994026
backpointers: 37.2% edges have at least one /sil/ unit inside
forwardbackward: 11.485% non-zero state posteriors
dengamma value 1.006191
backpointers: 40.8% edges have at least one /sil/ unit inside
forwardbackward: 17.136% non-zero state posteriors
dengamma value 1.009492
backpointers: 33.9% edges have at least one /sil/ unit inside
forwardbackward: 18.493% non-zero state posteriors
dengamma value 1.013319
backpointers: 39.3% edges have at least one /sil/ unit inside
forwardbackward: 12.412% non-zero state posteriors
dengamma value 0.999581
backpointers: 31.4% edges have at least one /sil/ unit inside
forwardbackward: 17.006% non-zero state posteriors
dengamma value 0.996699
backpointers: 41.2% edges have at least one /sil/ unit inside
forwardbackward: 16.969% non-zero state posteriors
dengamma value 1.001714
 Epoch[ 1 of 3]-Minibatch[  31-  40, 0.49%]: SamplesSeen = 6054; TrainLossPerSample =  0.07804326; EvalErr[0]PerSample = 0.35480674; TotalTime = 3.7058s; SamplesPerSecond = 1633.6
backpointers: 37.8% edges have at least one /sil/ unit inside
forwardbackward: 17.683% non-zero state posteriors
dengamma value 0.970981
backpointers: 35.8% edges have at least one /sil/ unit inside
forwardbackward: 15.033% non-zero state posteriors
dengamma value 1.010931
backpointers: 33.0% edges have at least one /sil/ unit inside
forwardbackward: 17.792% non-zero state posteriors
dengamma value 1.053185
backpointers: 31.7% edges have at least one /sil/ unit inside
forwardbackward: 23.393% non-zero state posteriors
dengamma value 1.055676
backpointers: 32.0% edges have at least one /sil/ unit inside
forwardbackward: 16.500% non-zero state posteriors
dengamma value 1.081471
backpointers: 25.2% edges have at least one /sil/ unit inside
forwardbackward: 20.857% non-zero state posteriors
dengamma value 1.032781
backpointers: 37.5% edges have at least one /sil/ unit inside
forwardbackward: 16.176% non-zero state posteriors
dengamma value 1.004237
backpointers: 32.7% edges have at least one /sil/ unit inside
forwardbackward: 20.462% non-zero state posteriors
dengamma value 1.052020
backpointers: 45.6% edges have at least one /sil/ unit inside
forwardbackward: 11.657% non-zero state posteriors
dengamma value 0.964527
backpointers: 33.0% edges have at least one /sil/ unit inside
forwardbackward: 20.528% non-zero state posteriors
dengamma value 0.977009
backpointers: 35.4% edges have at least one /sil/ unit inside
forwardbackward: 15.123% non-zero state posteriors
dengamma value 1.046651
backpointers: 28.0% edges have at least one /sil/ unit inside
forwardbackward: 22.608% non-zero state posteriors
dengamma value 1.064938
backpointers: 34.0% edges have at least one /sil/ unit inside
forwardbackward: 17.371% non-zero state posteriors
dengamma value 1.006277
backpointers: 37.9% edges have at least one /sil/ unit inside
forwardbackward: 12.647% non-zero state posteriors
dengamma value 1.059577
backpointers: 40.5% edges have at least one /sil/ unit inside
forwardbackward: 7.541% non-zero state posteriors
dengamma value 1.093890
backpointers: 40.0% edges have at least one /sil/ unit inside
forwardbackward: 15.110% non-zero state posteriors
dengamma value 0.955711
backpointers: 37.0% edges have at least one /sil/ unit inside
forwardbackward: 16.338% non-zero state posteriors
dengamma value 0.924226
backpointers: 31.5% edges have at least one /sil/ unit inside
forwardbackward: 20.334% non-zero state posteriors
dengamma value 0.990277
backpointers: 37.9% edges have at least one /sil/ unit inside
forwardbackward: 16.493% non-zero state posteriors
dengamma value 0.982300
backpointers: 32.0% edges have at least one /sil/ unit inside
forwardbackward: 19.568% non-zero state posteriors
dengamma value 1.081645
backpointers: 39.0% edges have at least one /sil/ unit inside
forwardbackward: 10.992% non-zero state posteriors
dengamma value 1.062106
 Epoch[ 1 of 3]-Minibatch[  41-  50, 0.61%]: SamplesSeen = 5768; TrainLossPerSample =  0.07449464; EvalErr[0]PerSample = 0.37656033; TotalTime = 3.4509s; SamplesPerSecond = 1671.4
backpointers: 33.8% edges have at least one /sil/ unit inside
forwardbackward: 15.394% non-zero state posteriors
dengamma value 0.978753
backpointers: 39.2% edges have at least one /sil/ unit inside
forwardbackward: 16.776% non-zero state posteriors
dengamma value 0.993426
backpointers: 57.9% edges have at least one /sil/ unit inside
forwardbackward: 7.792% non-zero state posteriors
dengamma value 1.097363
backpointers: 34.7% edges have at least one /sil/ unit inside
forwardbackward: 20.822% non-zero state posteriors
dengamma value 1.005536
backpointers: 36.2% edges have at least one /sil/ unit inside
forwardbackward: 19.642% non-zero state posteriors
dengamma value 1.044500
backpointers: 29.6% edges have at least one /sil/ unit inside
forwardbackward: 20.715% non-zero state posteriors
dengamma value 1.029872
backpointers: 39.5% edges have at least one /sil/ unit inside
forwardbackward: 14.742% non-zero state posteriors
dengamma value 0.970651
backpointers: 29.8% edges have at least one /sil/ unit inside
forwardbackward: 18.437% non-zero state posteriors
dengamma value 1.098752
backpointers: 30.7% edges have at least one /sil/ unit inside
forwardbackward: 22.132% non-zero state posteriors
dengamma value 1.041134
backpointers: 27.7% edges have at least one /sil/ unit inside
forwardbackward: 18.890% non-zero state posteriors
dengamma value 1.081337
backpointers: 40.7% edges have at least one /sil/ unit inside
forwardbackward: 12.836% non-zero state posteriors
dengamma value 0.974843
backpointers: 34.3% edges have at least one /sil/ unit inside
forwardbackward: 23.927% non-zero state posteriors
dengamma value 1.045179
backpointers: 32.6% edges have at least one /sil/ unit inside
forwardbackward: 10.860% non-zero state posteriors
dengamma value 0.983682
backpointers: 28.9% edges have at least one /sil/ unit inside
forwardbackward: 22.575% non-zero state posteriors
dengamma value 1.060002
backpointers: 35.0% edges have at least one /sil/ unit inside
forwardbackward: 22.241% non-zero state posteriors
dengamma value 0.981566
backpointers: 36.3% edges have at least one /sil/ unit inside
forwardbackward: 19.890% non-zero state posteriors
dengamma value 1.024494
backpointers: 34.4% edges have at least one /sil/ unit inside
forwardbackward: 16.233% non-zero state posteriors
dengamma value 0.968467
backpointers: 31.1% edges have at least one /sil/ unit inside
forwardbackward: 18.168% non-zero state posteriors
dengamma value 1.022631
backpointers: 26.6% edges have at least one /sil/ unit inside
forwardbackward: 23.270% non-zero state posteriors
dengamma value 1.036136
backpointers: 36.0% edges have at least one /sil/ unit inside
forwardbackward: 17.244% non-zero state posteriors
dengamma value 0.991551
backpointers: 28.6% edges have at least one /sil/ unit inside
forwardbackward: 15.453% non-zero state posteriors
dengamma value 1.042760
backpointers: 34.4% edges have at least one /sil/ unit inside
forwardbackward: 22.502% non-zero state posteriors
dengamma value 1.008120
backpointers: 29.6% edges have at least one /sil/ unit inside
forwardbackward: 15.737% non-zero state posteriors
dengamma value 0.994277
backpointers: 38.6% edges have at least one /sil/ unit inside
forwardbackward: 17.868% non-zero state posteriors
dengamma value 0.890849
 Epoch[ 1 of 3]-Minibatch[  51-  60, 0.73%]: SamplesSeen = 5712; TrainLossPerSample =  0.08009813; EvalErr[0]PerSample = 0.36467087; TotalTime = 3.4452s; SamplesPerSecond = 1658.0
backpointers: 29.4% edges have at least one /sil/ unit inside
forwardbackward: 20.594% non-zero state posteriors
dengamma value 0.922602
backpointers: 29.4% edges have at least one /sil/ unit inside
forwardbackward: 18.071% non-zero state posteriors
dengamma value 1.038503
backpointers: 38.3% edges have at least one /sil/ unit inside
forwardbackward: 16.503% non-zero state posteriors
dengamma value 0.990575
backpointers: 31.1% edges have at least one /sil/ unit inside
forwardbackward: 19.391% non-zero state posteriors
dengamma value 0.966842
backpointers: 36.0% edges have at least one /sil/ unit inside
forwardbackward: 16.272% non-zero state posteriors
dengamma value 0.942525
backpointers: 37.0% edges have at least one /sil/ unit inside
forwardbackward: 18.628% non-zero state posteriors
dengamma value 1.007300
backpointers: 35.4% edges have at least one /sil/ unit inside
forwardbackward: 18.401% non-zero state posteriors
dengamma value 0.996272
backpointers: 28.0% edges have at least one /sil/ unit inside
forwardbackward: 23.405% non-zero state posteriors
dengamma value 1.070342
backpointers: 30.1% edges have at least one /sil/ unit inside
forwardbackward: 21.534% non-zero state posteriors
dengamma value 1.005254
backpointers: 37.2% edges have at least one /sil/ unit inside
forwardbackward: 15.389% non-zero state posteriors
dengamma value 1.025978
backpointers: 27.8% edges have at least one /sil/ unit inside
forwardbackward: 15.796% non-zero state posteriors
dengamma value 1.028597
backpointers: 28.5% edges have at least one /sil/ unit inside
forwardbackward: 21.992% non-zero state posteriors
dengamma value 0.914548
backpointers: 38.8% edges have at least one /sil/ unit inside
forwardbackward: 14.188% non-zero state posteriors
dengamma value 0.978967
backpointers: 34.6% edges have at least one /sil/ unit inside
forwardbackward: 12.511% non-zero state posteriors
dengamma value 0.980898
backpointers: 29.1% edges have at least one /sil/ unit inside
forwardbackward: 20.310% non-zero state posteriors
dengamma value 0.972159
backpointers: 35.8% edges have at least one /sil/ unit inside
forwardbackward: 17.448% non-zero state posteriors
dengamma value 1.039656
backpointers: 36.9% edges have at least one /sil/ unit inside
forwardbackward: 16.953% non-zero state posteriors
dengamma value 0.963684
backpointers: 34.3% edges have at least one /sil/ unit inside
forwardbackward: 20.058% non-zero state posteriors
dengamma value 1.048526
backpointers: 26.4% edges have at least one /sil/ unit inside
forwardbackward: 16.726% non-zero state posteriors
dengamma value 1.076553
backpointers: 36.9% edges have at least one /sil/ unit inside
forwardbackward: 18.564% non-zero state posteriors
dengamma value 1.033792
backpointers: 30.9% edges have at least one /sil/ unit inside
forwardbackward: 23.940% non-zero state posteriors
dengamma value 1.008449
backpointers: 33.7% edges have at least one /sil/ unit inside
forwardbackward: 16.784% non-zero state posteriors
dengamma value 1.014626
backpointers: 33.2% edges have at least one /sil/ unit inside
forwardbackward: 20.069% non-zero state posteriors
dengamma value 1.038646
backpointers: 31.5% edges have at least one /sil/ unit inside
forwardbackward: 16.896% non-zero state posteriors
dengamma value 1.006740
 Epoch[ 1 of 3]-Minibatch[  61-  70, 0.85%]: SamplesSeen = 5542; TrainLossPerSample =  0.07522333; EvalErr[0]PerSample = 0.35925659; TotalTime = 3.5690s; SamplesPerSecond = 1552.8
backpointers: 40.8% edges have at least one /sil/ unit inside
forwardbackward: 14.861% non-zero state posteriors
dengamma value 1.005421
backpointers: 31.3% edges have at least one /sil/ unit inside
forwardbackward: 14.436% non-zero state posteriors
dengamma value 0.961523
backpointers: 30.5% edges have at least one /sil/ unit inside
forwardbackward: 23.213% non-zero state posteriors
dengamma value 1.068380
backpointers: 31.2% edges have at least one /sil/ unit inside
forwardbackward: 21.396% non-zero state posteriors
dengamma value 1.077667
backpointers: 21.9% edges have at least one /sil/ unit inside
forwardbackward: 20.902% non-zero state posteriors
dengamma value 1.053101
backpointers: 33.6% edges have at least one /sil/ unit inside
forwardbackward: 18.522% non-zero state posteriors
dengamma value 0.963811
backpointers: 28.7% edges have at least one /sil/ unit inside
forwardbackward: 19.734% non-zero state posteriors
dengamma value 1.072820
backpointers: 29.1% edges have at least one /sil/ unit inside
forwardbackward: 22.609% non-zero state posteriors
dengamma value 1.098199
backpointers: 22.5% edges have at least one /sil/ unit inside
forwardbackward: 26.001% non-zero state posteriors
dengamma value 1.089826
backpointers: 26.3% edges have at least one /sil/ unit inside
forwardbackward: 21.919% non-zero state posteriors
dengamma value 0.946290
backpointers: 34.9% edges have at least one /sil/ unit inside
forwardbackward: 19.741% non-zero state posteriors
dengamma value 1.053820
backpointers: 24.2% edges have at least one /sil/ unit inside
forwardbackward: 25.235% non-zero state posteriors
dengamma value 1.079916
backpointers: 26.3% edges have at least one /sil/ unit inside
forwardbackward: 14.378% non-zero state posteriors
dengamma value 0.956262
backpointers: 36.5% edges have at least one /sil/ unit inside
forwardbackward: 18.385% non-zero state posteriors
dengamma value 1.058179
backpointers: 27.5% edges have at least one /sil/ unit inside
forwardbackward: 22.880% non-zero state posteriors
dengamma value 0.983350
backpointers: 28.0% edges have at least one /sil/ unit inside
forwardbackward: 15.982% non-zero state posteriors
dengamma value 1.027257
backpointers: 29.1% edges have at least one /sil/ unit inside
forwardbackward: 18.226% non-zero state posteriors
dengamma value 1.078257
backpointers: 32.6% edges have at least one /sil/ unit inside
forwardbackward: 18.243% non-zero state posteriors
dengamma value 1.044841
backpointers: 36.4% edges have at least one /sil/ unit inside
forwardbackward: 17.129% non-zero state posteriors
dengamma value 1.019264
backpointers: 35.6% edges have at least one /sil/ unit inside
forwardbackward: 16.928% non-zero state posteriors
dengamma value 0.997988
backpointers: 38.0% edges have at least one /sil/ unit inside
forwardbackward: 11.031% non-zero state posteriors
dengamma value 1.008915
backpointers: 35.8% edges have at least one /sil/ unit inside
forwardbackward: 15.995% non-zero state posteriors
dengamma value 0.955650
backpointers: 28.8% edges have at least one /sil/ unit inside
forwardbackward: 18.808% non-zero state posteriors
dengamma value 1.060823
 Epoch[ 1 of 3]-Minibatch[  71-  80, 0.98%]: SamplesSeen = 6224; TrainLossPerSample =  0.06823538; EvalErr[0]PerSample = 0.34174165; TotalTime = 4.3474s; SamplesPerSecond = 1431.7
backpointers: 35.6% edges have at least one /sil/ unit inside
forwardbackward: 17.295% non-zero state posteriors
dengamma value 1.077945
backpointers: 32.7% edges have at least one /sil/ unit inside
forwardbackward: 21.587% non-zero state posteriors
dengamma value 0.972533
backpointers: 33.3% edges have at least one /sil/ unit inside
forwardbackward: 21.250% non-zero state posteriors
dengamma value 1.035519
backpointers: 35.7% edges have at least one /sil/ unit inside
forwardbackward: 16.269% non-zero state posteriors
dengamma value 1.086263
backpointers: 34.7% edges have at least one /sil/ unit inside
forwardbackward: 15.147% non-zero state posteriors
dengamma value 1.034109
backpointers: 31.1% edges have at least one /sil/ unit inside
forwardbackward: 25.000% non-zero state posteriors
dengamma value 1.006159
backpointers: 26.3% edges have at least one /sil/ unit inside
forwardbackward: 22.065% non-zero state posteriors
dengamma value 1.022724
backpointers: 29.4% edges have at least one /sil/ unit inside
forwardbackward: 17.835% non-zero state posteriors
dengamma value 1.032996
backpointers: 33.8% edges have at least one /sil/ unit inside
forwardbackward: 18.506% non-zero state posteriors
dengamma value 1.031749
backpointers: 34.3% edges have at least one /sil/ unit inside
forwardbackward: 17.244% non-zero state posteriors
dengamma value 1.025556
backpointers: 27.2% edges have at least one /sil/ unit inside
forwardbackward: 23.698% non-zero state posteriors
dengamma value 1.053598
backpointers: 44.8% edges have at least one /sil/ unit inside
forwardbackward: 13.487% non-zero state posteriors
dengamma value 1.070593
backpointers: 31.7% edges have at least one /sil/ unit inside
forwardbackward: 17.011% non-zero state posteriors
dengamma value 1.015120
backpointers: 29.2% edges have at least one /sil/ unit inside
forwardbackward: 20.757% non-zero state posteriors
dengamma value 0.992877
backpointers: 34.7% edges have at least one /sil/ unit inside
forwardbackward: 17.074% non-zero state posteriors
dengamma value 1.067365
backpointers: 34.3% edges have at least one /sil/ unit inside
forwardbackward: 17.792% non-zero state posteriors
dengamma value 0.953252
backpointers: 36.4% edges have at least one /sil/ unit inside
forwardbackward: 12.313% non-zero state posteriors
dengamma value 1.050386
backpointers: 34.2% edges have at least one /sil/ unit inside
forwardbackward: 20.708% non-zero state posteriors
dengamma value 0.955190
backpointers: 26.6% edges have at least one /sil/ unit inside
forwardbackward: 13.528% non-zero state posteriors
dengamma value 0.985419
backpointers: 36.2% edges have at least one /sil/ unit inside
forwardbackward: 18.768% non-zero state posteriors
dengamma value 0.928568
backpointers: 34.6% edges have at least one /sil/ unit inside
forwardbackward: 15.762% non-zero state posteriors
dengamma value 1.007233
backpointers: 36.0% edges have at least one /sil/ unit inside
forwardbackward: 15.596% non-zero state posteriors
dengamma value 0.925069
backpointers: 35.5% edges have at least one /sil/ unit inside
forwardbackward: 18.202% non-zero state posteriors
dengamma value 0.970528
 Epoch[ 1 of 3]-Minibatch[  81-  90, 1.10%]: SamplesSeen = 6254; TrainLossPerSample =  0.07559994; EvalErr[0]PerSample = 0.37288136; TotalTime = 4.1057s; SamplesPerSecond = 1523.3
backpointers: 36.2% edges have at least one /sil/ unit inside
forwardbackward: 17.901% non-zero state posteriors
dengamma value 0.923313
backpointers: 25.9% edges have at least one /sil/ unit inside
forwardbackward: 22.014% non-zero state posteriors
dengamma value 1.049552
backpointers: 31.9% edges have at least one /sil/ unit inside
forwardbackward: 18.439% non-zero state posteriors
dengamma value 1.072176
backpointers: 33.2% edges have at least one /sil/ unit inside
forwardbackward: 18.359% non-zero state posteriors
dengamma value 0.973947
backpointers: 28.3% edges have at least one /sil/ unit inside
forwardbackward: 23.346% non-zero state posteriors
dengamma value 1.037178
backpointers: 37.9% edges have at least one /sil/ unit inside
forwardbackward: 15.315% non-zero state posteriors
dengamma value 0.976129
backpointers: 41.1% edges have at least one /sil/ unit inside
forwardbackward: 17.254% non-zero state posteriors
dengamma value 0.977419
backpointers: 27.9% edges have at least one /sil/ unit inside
forwardbackward: 22.226% non-zero state posteriors
dengamma value 1.058792
backpointers: 34.9% edges have at least one /sil/ unit inside
forwardbackward: 16.910% non-zero state posteriors
dengamma value 1.025702
backpointers: 32.7% edges have at least one /sil/ unit inside
forwardbackward: 20.210% non-zero state posteriors
dengamma value 0.996007
backpointers: 27.9% edges have at least one /sil/ unit inside
forwardbackward: 19.910% non-zero state posteriors
dengamma value 0.993052
backpointers: 34.0% edges have at least one /sil/ unit inside
forwardbackward: 22.712% non-zero state posteriors
dengamma value 1.047164
backpointers: 26.1% edges have at least one /sil/ unit inside
forwardbackward: 23.132% non-zero state posteriors
dengamma value 0.966118
backpointers: 31.6% edges have at least one /sil/ unit inside
forwardbackward: 13.428% non-zero state posteriors
dengamma value 1.016380
backpointers: 30.5% edges have at least one /sil/ unit inside
forwardbackward: 17.637% non-zero state posteriors
dengamma value 0.958829
backpointers: 36.0% edges have at least one /sil/ unit inside
forwardbackward: 17.383% non-zero state posteriors
dengamma value 1.026942
backpointers: 28.0% edges have at least one /sil/ unit inside
forwardbackward: 26.081% non-zero state posteriors
dengamma value 1.035196
backpointers: 35.3% edges have at least one /sil/ unit inside
forwardbackward: 15.985% non-zero state posteriors
dengamma value 1.031170
backpointers: 30.1% edges have at least one /sil/ unit inside
forwardbackward: 19.442% non-zero state posteriors
dengamma value 1.075754
backpointers: 33.9% edges have at least one /sil/ unit inside
forwardbackward: 17.980% non-zero state posteriors
dengamma value 0.994008
backpointers: 32.5% edges have at least one /sil/ unit inside
forwardbackward: 19.783% non-zero state posteriors
dengamma value 0.949732
backpointers: 24.9% edges have at least one /sil/ unit inside
forwardbackward: 19.911% non-zero state posteriors
dengamma value 1.023908
backpointers: 41.5% edges have at least one /sil/ unit inside
forwardbackward: 8.473% non-zero state posteriors
dengamma value 1.012382
 Epoch[ 1 of 3]-Minibatch[  91- 100, 1.22%]: SamplesSeen = 5624; TrainLossPerSample =  0.08072420; EvalErr[0]PerSample = 0.36753201; TotalTime = 3.6717s; SamplesPerSecond = 1531.7
backpointers: 30.9% edges have at least one /sil/ unit inside
forwardbackward: 19.330% non-zero state posteriors
dengamma value 0.987837
backpointers: 33.5% edges have at least one /sil/ unit inside
forwardbackward: 20.660% non-zero state posteriors
dengamma value 1.028476
backpointers: 30.2% edges have at least one /sil/ unit inside
forwardbackward: 21.055% non-zero state posteriors
dengamma value 1.034127
backpointers: 31.0% edges have at least one /sil/ unit inside
forwardbackward: 21.275% non-zero state posteriors
dengamma value 1.043881
backpointers: 35.6% edges have at least one /sil/ unit inside
forwardbackward: 17.767% non-zero state posteriors
dengamma value 1.016074
backpointers: 32.4% edges have at least one /sil/ unit inside
forwardbackward: 19.907% non-zero state posteriors
dengamma value 0.981337
backpointers: 26.4% edges have at least one /sil/ unit inside
forwardbackward: 17.541% non-zero state posteriors
dengamma value 1.027293
backpointers: 32.7% edges have at least one /sil/ unit inside
forwardbackward: 16.654% non-zero state posteriors
dengamma value 0.998679
backpointers: 30.9% edges have at least one /sil/ unit inside
forwardbackward: 19.203% non-zero state posteriors
dengamma value 1.053376
backpointers: 31.8% edges have at least one /sil/ unit inside
forwardbackward: 20.237% non-zero state posteriors
dengamma value 0.985148
backpointers: 39.1% edges have at least one /sil/ unit inside
forwardbackward: 15.714% non-zero state posteriors
dengamma value 1.050041
backpointers: 37.1% edges have at least one /sil/ unit inside
forwardbackward: 14.663% non-zero state posteriors
dengamma value 0.979928
backpointers: 30.6% edges have at least one /sil/ unit inside
forwardbackward: 18.694% non-zero state posteriors
dengamma value 1.047370
backpointers: 34.0% edges have at least one /sil/ unit inside
forwardbackward: 16.554% non-zero state posteriors
dengamma value 0.942312
backpointers: 33.4% edges have at least one /sil/ unit inside
forwardbackward: 17.979% non-zero state posteriors
dengamma value 0.982209
backpointers: 35.4% edges have at least one /sil/ unit inside
forwardbackward: 19.215% non-zero state posteriors
dengamma value 0.982914
backpointers: 34.6% edges have at least one /sil/ unit inside
forwardbackward: 14.533% non-zero state posteriors
dengamma value 1.030884
backpointers: 30.2% edges have at least one /sil/ unit inside
forwardbackward: 15.009% non-zero state posteriors
dengamma value 1.087948
backpointers: 34.1% edges have at least one /sil/ unit inside
forwardbackward: 16.248% non-zero state posteriors
dengamma value 1.009982
backpointers: 29.2% edges have at least one /sil/ unit inside
forwardbackward: 19.384% non-zero state posteriors
dengamma value 1.011709
backpointers: 33.3% edges have at least one /sil/ unit inside
forwardbackward: 21.185% non-zero state posteriors
dengamma value 1.054302
backpointers: 34.6% edges have at least one /sil/ unit inside
forwardbackward: 20.710% non-zero state posteriors
dengamma value 1.116350
backpointers: 32.1% edges have at least one /sil/ unit inside
forwardbackward: 19.527% non-zero state posteriors
dengamma value 1.026982
backpointers: 33.7% edges have at least one /sil/ unit inside
forwardbackward: 17.124% non-zero state posteriors
dengamma value 1.028002
 Epoch[ 1 of 3]-Minibatch[ 101- 110, 1.34%]: SamplesSeen = 6902; TrainLossPerSample =  0.07659889; EvalErr[0]PerSample = 0.35699797; TotalTime = 4.5216s; SamplesPerSecond = 1526.5
backpointers: 46.8% edges have at least one /sil/ unit inside
forwardbackward: 15.530% non-zero state posteriors
dengamma value 0.856843
backpointers: 33.9% edges have at least one /sil/ unit inside
forwardbackward: 19.003% non-zero state posteriors
dengamma value 1.005582
backpointers: 39.7% edges have at least one /sil/ unit inside
forwardbackward: 14.193% non-zero state posteriors
dengamma value 0.990116
backpointers: 42.6% edges have at least one /sil/ unit inside
forwardbackward: 14.620% non-zero state posteriors
dengamma value 0.960895
backpointers: 28.6% edges have at least one /sil/ unit inside
forwardbackward: 23.263% non-zero state posteriors
dengamma value 0.983882
backpointers: 27.4% edges have at least one /sil/ unit inside
forwardbackward: 20.746% non-zero state posteriors
dengamma value 1.033865
backpointers: 40.1% edges have at least one /sil/ unit inside
forwardbackward: 15.970% non-zero state posteriors
dengamma value 0.941537
backpointers: 33.7% edges have at least one /sil/ unit inside
forwardbackward: 16.895% non-zero state posteriors
dengamma value 0.994223
backpointers: 27.2% edges have at least one /sil/ unit inside
forwardbackward: 16.202% non-zero state posteriors
dengamma value 1.040699
backpointers: 33.9% edges have at least one /sil/ unit inside
forwardbackward: 17.789% non-zero state posteriors
dengamma value 1.030465
backpointers: 32.9% edges have at least one /sil/ unit inside
forwardbackward: 15.639% non-zero state posteriors
dengamma value 0.964792
backpointers: 26.4% edges have at least one /sil/ unit inside
forwardbackward: 21.940% non-zero state posteriors
dengamma value 1.044386
backpointers: 37.1% edges have at least one /sil/ unit inside
forwardbackward: 12.360% non-zero state posteriors
dengamma value 0.985185
backpointers: 34.7% edges have at least one /sil/ unit inside
forwardbackward: 19.183% non-zero state posteriors
dengamma value 1.021710
backpointers: 39.1% edges have at least one /sil/ unit inside
forwardbackward: 14.843% non-zero state posteriors
dengamma value 1.035627
backpointers: 40.5% edges have at least one /sil/ unit inside
forwardbackward: 8.760% non-zero state posteriors
dengamma value 1.009459
backpointers: 27.3% edges have at least one /sil/ unit inside
forwardbackward: 21.318% non-zero state posteriors
dengamma value 1.100250
backpointers: 41.9% edges have at least one /sil/ unit inside
forwardbackward: 11.789% non-zero state posteriors
dengamma value 0.972546
backpointers: 29.7% edges have at least one /sil/ unit inside
forwardbackward: 15.985% non-zero state posteriors
dengamma value 1.065383
backpointers: 35.5% edges have at least one /sil/ unit inside
forwardbackward: 20.053% non-zero state posteriors
dengamma value 0.954430
backpointers: 30.7% edges have at least one /sil/ unit inside
forwardbackward: 22.705% non-zero state posteriors
dengamma value 1.016358
backpointers: 31.5% edges have at least one /sil/ unit inside
forwardbackward: 21.122% non-zero state posteriors
dengamma value 1.025227
 Epoch[ 1 of 3]-Minibatch[ 111- 120, 1.46%]: SamplesSeen = 6596; TrainLossPerSample =  0.06740369; EvalErr[0]PerSample = 0.39417829; TotalTime = 3.9890s; SamplesPerSecond = 1653.5
backpointers: 35.3% edges have at least one /sil/ unit inside
forwardbackward: 14.942% non-zero state posteriors
dengamma value 0.991076
backpointers: 32.1% edges have at least one /sil/ unit inside
forwardbackward: 19.195% non-zero state posteriors
dengamma value 0.961624
backpointers: 27.8% edges have at least one /sil/ unit inside
forwardbackward: 21.159% non-zero state posteriors
dengamma value 1.057825
backpointers: 40.0% edges have at least one /sil/ unit inside
forwardbackward: 11.911% non-zero state posteriors
dengamma value 0.998999
backpointers: 31.2% edges have at least one /sil/ unit inside
forwardbackward: 17.953% non-zero state posteriors
dengamma value 1.006214
backpointers: 25.1% edges have at least one /sil/ unit inside
forwardbackward: 24.235% non-zero state posteriors
dengamma value 1.077464
backpointers: 34.4% edges have at least one /sil/ unit inside
forwardbackward: 18.657% non-zero state posteriors
dengamma value 1.022636
backpointers: 24.6% edges have at least one /sil/ unit inside
forwardbackward: 23.133% non-zero state posteriors
dengamma value 1.041346
backpointers: 32.2% edges have at least one /sil/ unit inside
forwardbackward: 19.363% non-zero state posteriors
dengamma value 1.023361
backpointers: 41.7% edges have at least one /sil/ unit inside
forwardbackward: 13.297% non-zero state posteriors
dengamma value 0.992799
backpointers: 42.5% edges have at least one /sil/ unit inside
forwardbackward: 8.049% non-zero state posteriors
dengamma value 0.986714
backpointers: 37.9% edges have at least one /sil/ unit inside
forwardbackward: 19.919% non-zero state posteriors
dengamma value 1.063199
backpointers: 37.7% edges have at least one /sil/ unit inside
forwardbackward: 17.800% non-zero state posteriors
dengamma value 0.948993
backpointers: 41.3% edges have at least one /sil/ unit inside
forwardbackward: 16.357% non-zero state posteriors
dengamma value 0.977330
backpointers: 29.8% edges have at least one /sil/ unit inside
forwardbackward: 20.693% non-zero state posteriors
dengamma value 0.982972
backpointers: 30.5% edges have at least one /sil/ unit inside
forwardbackward: 20.699% non-zero state posteriors
dengamma value 0.998173
backpointers: 28.6% edges have at least one /sil/ unit inside
forwardbackward: 20.764% non-zero state posteriors
dengamma value 1.006978
backpointers: 36.1% edges have at least one /sil/ unit inside
forwardbackward: 14.888% non-zero state posteriors
dengamma value 0.983873
backpointers: 30.0% edges have at least one /sil/ unit inside
forwardbackward: 21.664% non-zero state posteriors
dengamma value 0.969055
backpointers: 34.2% edges have at least one /sil/ unit inside
forwardbackward: 18.893% non-zero state posteriors
dengamma value 1.000205
backpointers: 30.0% edges have at least one /sil/ unit inside
forwardbackward: 17.412% non-zero state posteriors
dengamma value 1.044114
backpointers: 34.3% edges have at least one /sil/ unit inside
forwardbackward: 17.471% non-zero state posteriors
dengamma value 0.963900
 Epoch[ 1 of 3]-Minibatch[ 121- 130, 1.59%]: SamplesSeen = 5776; TrainLossPerSample =  0.07630113; EvalErr[0]PerSample = 0.36426593; TotalTime = 3.8252s; SamplesPerSecond = 1510.0
backpointers: 30.7% edges have at least one /sil/ unit inside
forwardbackward: 21.623% non-zero state posteriors
dengamma value 1.098565
backpointers: 28.7% edges have at least one /sil/ unit inside
forwardbackward: 22.511% non-zero state posteriors
dengamma value 1.045350
backpointers: 25.0% edges have at least one /sil/ unit inside
forwardbackward: 20.548% non-zero state posteriors
dengamma value 1.002945
backpointers: 22.0% edges have at least one /sil/ unit inside
forwardbackward: 21.573% non-zero state posteriors
dengamma value 0.997646
backpointers: 44.1% edges have at least one /sil/ unit inside
forwardbackward: 12.630% non-zero state posteriors
dengamma value 1.013276
backpointers: 23.9% edges have at least one /sil/ unit inside
forwardbackward: 23.112% non-zero state posteriors
dengamma value 1.083382
backpointers: 29.2% edges have at least one /sil/ unit inside
forwardbackward: 20.949% non-zero state posteriors
dengamma value 0.982646
backpointers: 28.6% edges have at least one /sil/ unit inside
forwardbackward: 22.184% non-zero state posteriors
dengamma value 1.060602
backpointers: 34.5% edges have at least one /sil/ unit inside
forwardbackward: 15.822% non-zero state posteriors
dengamma value 1.057436
backpointers: 37.4% edges have at least one /sil/ unit inside
forwardbackward: 18.241% non-zero state posteriors
dengamma value 0.984100
backpointers: 27.0% edges have at least one /sil/ unit inside
forwardbackward: 19.313% non-zero state posteriors
dengamma value 1.033565
backpointers: 24.8% edges have at least one /sil/ unit inside
forwardbackward: 21.448% non-zero state posteriors
dengamma value 1.055537
Finished Epoch[ 1 of 3]: [Training Set] TrainLossPerSample = 0.075086512; EvalErrPerSample = 0.36384439; AvgLearningRatePerSample = 2e-06; EpochTime=56.9622
Starting Epoch 2: learning rate per sample = 0.000002  effective momentum = 0.995898  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 1: frames [81920..163840] (first utterance at frame 82156), data subset 0 of 1, with 1 datapasses

Starting minibatch loop.
backpointers: 31.6% edges have at least one /sil/ unit inside
forwardbackward: 19.627% non-zero state posteriors
dengamma value 0.944829
backpointers: 37.4% edges have at least one /sil/ unit inside
forwardbackward: 17.857% non-zero state posteriors
dengamma value 0.977586
backpointers: 27.4% edges have at least one /sil/ unit inside
forwardbackward: 18.351% non-zero state posteriors
dengamma value 1.017833
backpointers: 36.8% edges have at least one /sil/ unit inside
forwardbackward: 13.899% non-zero state posteriors
dengamma value 0.931201
backpointers: 28.8% edges have at least one /sil/ unit inside
forwardbackward: 12.531% non-zero state posteriors
dengamma value 0.982309
backpointers: 29.7% edges have at least one /sil/ unit inside
forwardbackward: 18.548% non-zero state posteriors
dengamma value 1.065846
backpointers: 27.7% edges have at least one /sil/ unit inside
forwardbackward: 20.931% non-zero state posteriors
dengamma value 1.035498
backpointers: 30.7% edges have at least one /sil/ unit inside
forwardbackward: 20.440% non-zero state posteriors
dengamma value 1.005242
backpointers: 39.7% edges have at least one /sil/ unit inside
forwardbackward: 17.119% non-zero state posteriors
dengamma value 1.045846
backpointers: 37.3% edges have at least one /sil/ unit inside
forwardbackward: 20.080% non-zero state posteriors
dengamma value 0.966353
backpointers: 38.0% edges have at least one /sil/ unit inside
forwardbackward: 13.544% non-zero state posteriors
dengamma value 1.000160
backpointers: 39.0% edges have at least one /sil/ unit inside
forwardbackward: 14.620% non-zero state posteriors
dengamma value 1.004697
backpointers: 33.8% edges have at least one /sil/ unit inside
forwardbackward: 17.592% non-zero state posteriors
dengamma value 1.033568
backpointers: 30.1% edges have at least one /sil/ unit inside
forwardbackward: 20.855% non-zero state posteriors
dengamma value 1.049747
backpointers: 34.8% edges have at least one /sil/ unit inside
forwardbackward: 14.906% non-zero state posteriors
dengamma value 0.999018
backpointers: 26.2% edges have at least one /sil/ unit inside
forwardbackward: 19.725% non-zero state posteriors
dengamma value 1.014390
backpointers: 27.6% edges have at least one /sil/ unit inside
forwardbackward: 20.465% non-zero state posteriors
dengamma value 0.936574
backpointers: 23.3% edges have at least one /sil/ unit inside
forwardbackward: 21.655% non-zero state posteriors
dengamma value 1.071290
backpointers: 32.0% edges have at least one /sil/ unit inside
forwardbackward: 18.426% non-zero state posteriors
dengamma value 1.021941
backpointers: 30.2% edges have at least one /sil/ unit inside
forwardbackward: 26.641% non-zero state posteriors
dengamma value 1.039606
backpointers: 32.6% edges have at least one /sil/ unit inside
forwardbackward: 14.300% non-zero state posteriors
dengamma value 1.003461
 Epoch[ 2 of 3]-Minibatch[   1-  10, 0.12%]: SamplesSeen = 6098; TrainLossPerSample =  0.08338481; EvalErr[0]PerSample = 0.34995080; TotalTime = 4.0787s; SamplesPerSecond = 1495.1
backpointers: 33.7% edges have at least one /sil/ unit inside
forwardbackward: 13.231% non-zero state posteriors
dengamma value 1.058759
backpointers: 31.7% edges have at least one /sil/ unit inside
forwardbackward: 22.974% non-zero state posteriors
dengamma value 1.043124
backpointers: 33.1% edges have at least one /sil/ unit inside
forwardbackward: 18.653% non-zero state posteriors
dengamma value 0.993263
backpointers: 36.7% edges have at least one /sil/ unit inside
forwardbackward: 18.032% non-zero state posteriors
dengamma value 0.904352
backpointers: 34.5% edges have at least one /sil/ unit inside
forwardbackward: 17.688% non-zero state posteriors
dengamma value 1.029944
backpointers: 26.7% edges have at least one /sil/ unit inside
forwardbackward: 20.574% non-zero state posteriors
dengamma value 1.076775
backpointers: 31.2% edges have at least one /sil/ unit inside
forwardbackward: 21.651% non-zero state posteriors
dengamma value 0.971937
backpointers: 28.3% edges have at least one /sil/ unit inside
forwardbackward: 19.664% non-zero state posteriors
dengamma value 0.963727
backpointers: 26.6% edges have at least one /sil/ unit inside
forwardbackward: 18.996% non-zero state posteriors
dengamma value 1.047101
backpointers: 33.7% edges have at least one /sil/ unit inside
forwardbackward: 15.465% non-zero state posteriors
dengamma value 1.031203
backpointers: 28.5% edges have at least one /sil/ unit inside
forwardbackward: 24.940% non-zero state posteriors
dengamma value 1.043352
backpointers: 31.5% edges have at least one /sil/ unit inside
forwardbackward: 21.190% non-zero state posteriors
dengamma value 1.021992
backpointers: 34.7% edges have at least one /sil/ unit inside
forwardbackward: 15.842% non-zero state posteriors
dengamma value 0.970772
backpointers: 32.6% edges have at least one /sil/ unit inside
forwardbackward: 22.016% non-zero state posteriors
dengamma value 1.029215
backpointers: 30.9% edges have at least one /sil/ unit inside
forwardbackward: 17.512% non-zero state posteriors
dengamma value 1.058597
backpointers: 35.6% edges have at least one /sil/ unit inside
forwardbackward: 17.060% non-zero state posteriors
dengamma value 1.000536
backpointers: 31.1% edges have at least one /sil/ unit inside
forwardbackward: 19.195% non-zero state posteriors
dengamma value 1.097865
backpointers: 25.8% edges have at least one /sil/ unit inside
forwardbackward: 15.789% non-zero state posteriors
dengamma value 0.964595
backpointers: 32.9% edges have at least one /sil/ unit inside
forwardbackward: 21.286% non-zero state posteriors
dengamma value 0.971056
backpointers: 37.3% edges have at least one /sil/ unit inside
forwardbackward: 16.403% non-zero state posteriors
dengamma value 1.005460
backpointers: 28.4% edges have at least one /sil/ unit inside
forwardbackward: 25.365% non-zero state posteriors
dengamma value 1.013613
backpointers: 35.5% edges have at least one /sil/ unit inside
forwardbackward: 18.136% non-zero state posteriors
dengamma value 0.949509
backpointers: 37.7% edges have at least one /sil/ unit inside
forwardbackward: 17.603% non-zero state posteriors
dengamma value 0.982987
backpointers: 30.6% edges have at least one /sil/ unit inside
forwardbackward: 18.053% non-zero state posteriors
dengamma value 1.041837
 Epoch[ 2 of 3]-Minibatch[  11-  20, 0.24%]: SamplesSeen = 6692; TrainLossPerSample =  0.07734362; EvalErr[0]PerSample = 0.36431560; TotalTime = 4.4521s; SamplesPerSecond = 1503.1
backpointers: 34.5% edges have at least one /sil/ unit inside
forwardbackward: 19.981% non-zero state posteriors
dengamma value 0.960979
backpointers: 27.9% edges have at least one /sil/ unit inside
forwardbackward: 18.271% non-zero state posteriors
dengamma value 1.015837
backpointers: 29.4% edges have at least one /sil/ unit inside
forwardbackward: 20.896% non-zero state posteriors
dengamma value 1.028805
backpointers: 38.2% edges have at least one /sil/ unit inside
forwardbackward: 12.552% non-zero state posteriors
dengamma value 1.020572
backpointers: 37.7% edges have at least one /sil/ unit inside
forwardbackward: 16.594% non-zero state posteriors
dengamma value 1.042197
backpointers: 24.1% edges have at least one /sil/ unit inside
forwardbackward: 22.522% non-zero state posteriors
dengamma value 1.050037
backpointers: 37.3% edges have at least one /sil/ unit inside
forwardbackward: 15.158% non-zero state posteriors
dengamma value 1.013862
backpointers: 32.8% edges have at least one /sil/ unit inside
forwardbackward: 16.039% non-zero state posteriors
dengamma value 0.965689
backpointers: 26.4% edges have at least one /sil/ unit inside
forwardbackward: 15.832% non-zero state posteriors
dengamma value 0.975817
backpointers: 39.1% edges have at least one /sil/ unit inside
forwardbackward: 17.632% non-zero state posteriors
dengamma value 1.038982
backpointers: 29.3% edges have at least one /sil/ unit inside
forwardbackward: 18.686% non-zero state posteriors
dengamma value 0.977962
backpointers: 26.2% edges have at least one /sil/ unit inside
forwardbackward: 20.078% non-zero state posteriors
dengamma value 1.030805
backpointers: 41.0% edges have at least one /sil/ unit inside
forwardbackward: 16.947% non-zero state posteriors
dengamma value 0.931898
backpointers: 33.2% edges have at least one /sil/ unit inside
forwardbackward: 24.805% non-zero state posteriors
dengamma value 1.073561
backpointers: 37.9% edges have at least one /sil/ unit inside
forwardbackward: 16.843% non-zero state posteriors
dengamma value 0.931206
backpointers: 38.7% edges have at least one /sil/ unit inside
forwardbackward: 14.850% non-zero state posteriors
dengamma value 1.086549
backpointers: 29.8% edges have at least one /sil/ unit inside
forwardbackward: 13.967% non-zero state posteriors
dengamma value 0.962698
backpointers: 35.4% edges have at least one /sil/ unit inside
forwardbackward: 15.328% non-zero state posteriors
dengamma value 1.015355
backpointers: 31.8% edges have at least one /sil/ unit inside
forwardbackward: 16.857% non-zero state posteriors
dengamma value 0.973932
backpointers: 29.8% edges have at least one /sil/ unit inside
forwardbackward: 24.698% non-zero state posteriors
dengamma value 1.050583
backpointers: 28.2% edges have at least one /sil/ unit inside
forwardbackward: 18.259% non-zero state posteriors
dengamma value 0.954379
backpointers: 23.3% edges have at least one /sil/ unit inside
forwardbackward: 20.229% non-zero state posteriors
dengamma value 1.024927
 Epoch[ 2 of 3]-Minibatch[  21-  30, 0.37%]: SamplesSeen = 5836; TrainLossPerSample =  0.07892710; EvalErr[0]PerSample = 0.36446196; TotalTime = 3.8533s; SamplesPerSecond = 1514.5
backpointers: 34.6% edges have at least one /sil/ unit inside
forwardbackward: 15.485% non-zero state posteriors
dengamma value 1.021329
backpointers: 44.4% edges have at least one /sil/ unit inside
forwardbackward: 13.312% non-zero state posteriors
dengamma value 0.906000
backpointers: 27.2% edges have at least one /sil/ unit inside
forwardbackward: 22.191% non-zero state posteriors
dengamma value 1.017068
backpointers: 35.1% edges have at least one /sil/ unit inside
forwardbackward: 15.598% non-zero state posteriors
dengamma value 0.994648
backpointers: 38.0% edges have at least one /sil/ unit inside
forwardbackward: 14.866% non-zero state posteriors
dengamma value 0.939806
backpointers: 30.0% edges have at least one /sil/ unit inside
forwardbackward: 17.579% non-zero state posteriors
dengamma value 0.948363
backpointers: 31.9% edges have at least one /sil/ unit inside
forwardbackward: 19.659% non-zero state posteriors
dengamma value 1.037662
backpointers: 27.8% edges have at least one /sil/ unit inside
forwardbackward: 24.194% non-zero state posteriors
dengamma value 1.073067
backpointers: 34.0% edges have at least one /sil/ unit inside
forwardbackward: 15.493% non-zero state posteriors
dengamma value 0.999307
backpointers: 33.1% edges have at least one /sil/ unit inside
forwardbackward: 19.888% non-zero state posteriors
dengamma value 1.050697
backpointers: 37.4% edges have at least one /sil/ unit inside
forwardbackward: 20.142% non-zero state posteriors
dengamma value 0.953868
backpointers: 28.3% edges have at least one /sil/ unit inside
forwardbackward: 20.253% non-zero state posteriors
dengamma value 1.030444
backpointers: 40.3% edges have at least one /sil/ unit inside
forwardbackward: 14.806% non-zero state posteriors
dengamma value 0.993620
backpointers: 35.0% edges have at least one /sil/ unit inside
forwardbackward: 17.676% non-zero state posteriors
dengamma value 1.047169
backpointers: 32.7% edges have at least one /sil/ unit inside
forwardbackward: 17.249% non-zero state posteriors
dengamma value 1.063586
backpointers: 38.2% edges have at least one /sil/ unit inside
forwardbackward: 20.433% non-zero state posteriors
dengamma value 0.993750
backpointers: 31.5% edges have at least one /sil/ unit inside
forwardbackward: 24.309% non-zero state posteriors
dengamma value 1.056333
backpointers: 24.9% edges have at least one /sil/ unit inside
forwardbackward: 26.510% non-zero state posteriors
dengamma value 1.005822
backpointers: 28.8% edges have at least one /sil/ unit inside
forwardbackward: 16.843% non-zero state posteriors
dengamma value 1.027364
backpointers: 31.1% edges have at least one /sil/ unit inside
forwardbackward: 22.974% non-zero state posteriors
dengamma value 1.046345
backpointers: 40.9% edges have at least one /sil/ unit inside
forwardbackward: 10.616% non-zero state posteriors
dengamma value 1.035812
backpointers: 39.8% edges have at least one /sil/ unit inside
forwardbackward: 17.640% non-zero state posteriors
dengamma value 0.945110
backpointers: 27.4% edges have at least one /sil/ unit inside
forwardbackward: 13.542% non-zero state posteriors
dengamma value 0.918708
backpointers: 29.3% edges have at least one /sil/ unit inside
forwardbackward: 18.629% non-zero state posteriors
dengamma value 1.035684
backpointers: 33.1% edges have at least one /sil/ unit inside
forwardbackward: 19.258% non-zero state posteriors
dengamma value 0.989689
backpointers: 29.6% edges have at least one /sil/ unit inside
forwardbackward: 14.822% non-zero state posteriors
dengamma value 1.021039
backpointers: 42.1% edges have at least one /sil/ unit inside
forwardbackward: 4.785% non-zero state posteriors
dengamma value 1.040645
 Epoch[ 2 of 3]-Minibatch[  31-  40, 0.49%]: SamplesSeen = 6966; TrainLossPerSample =  0.07396478; EvalErr[0]PerSample = 0.35156474; TotalTime = 4.1170s; SamplesPerSecond = 1692.0
backpointers: 32.6% edges have at least one /sil/ unit inside
forwardbackward: 21.664% non-zero state posteriors
dengamma value 1.067249
backpointers: 31.4% edges have at least one /sil/ unit inside
forwardbackward: 21.175% non-zero state posteriors
dengamma value 1.029483
backpointers: 28.7% edges have at least one /sil/ unit inside
forwardbackward: 16.999% non-zero state posteriors
dengamma value 0.977287
backpointers: 26.7% edges have at least one /sil/ unit inside
forwardbackward: 19.953% non-zero state posteriors
dengamma value 1.014902
backpointers: 28.9% edges have at least one /sil/ unit inside
forwardbackward: 20.438% non-zero state posteriors
dengamma value 0.999240
backpointers: 36.7% edges have at least one /sil/ unit inside
forwardbackward: 17.261% non-zero state posteriors
dengamma value 0.940688
backpointers: 40.0% edges have at least one /sil/ unit inside
forwardbackward: 15.950% non-zero state posteriors
dengamma value 0.977489
backpointers: 26.7% edges have at least one /sil/ unit inside
forwardbackward: 25.804% non-zero state posteriors
dengamma value 1.088396
backpointers: 30.0% edges have at least one /sil/ unit inside
forwardbackward: 14.559% non-zero state posteriors
dengamma value 1.078637
backpointers: 38.2% edges have at least one /sil/ unit inside
forwardbackward: 20.662% non-zero state posteriors
dengamma value 0.975848
backpointers: 32.1% edges have at least one /sil/ unit inside
forwardbackward: 18.826% non-zero state posteriors
dengamma value 0.960920
backpointers: 39.7% edges have at least one /sil/ unit inside
forwardbackward: 14.360% non-zero state posteriors
dengamma value 0.969357
backpointers: 33.7% edges have at least one /sil/ unit inside
forwardbackward: 19.788% non-zero state posteriors
dengamma value 1.025034
backpointers: 40.2% edges have at least one /sil/ unit inside
forwardbackward: 16.951% non-zero state posteriors
dengamma value 1.001999
backpointers: 44.4% edges have at least one /sil/ unit inside
forwardbackward: 16.651% non-zero state posteriors
dengamma value 1.005783
backpointers: 31.1% edges have at least one /sil/ unit inside
forwardbackward: 19.558% non-zero state posteriors
dengamma value 1.000309
backpointers: 27.8% edges have at least one /sil/ unit inside
forwardbackward: 15.638% non-zero state posteriors
dengamma value 1.107344
backpointers: 24.4% edges have at least one /sil/ unit inside
forwardbackward: 25.368% non-zero state posteriors
dengamma value 1.075959
backpointers: 30.9% edges have at least one /sil/ unit inside
forwardbackward: 19.195% non-zero state posteriors
dengamma value 1.017451
backpointers: 34.7% edges have at least one /sil/ unit inside
forwardbackward: 19.499% non-zero state posteriors
dengamma value 0.934450
backpointers: 35.1% edges have at least one /sil/ unit inside
forwardbackward: 19.623% non-zero state posteriors
dengamma value 1.032729
backpointers: 31.3% edges have at least one /sil/ unit inside
forwardbackward: 18.692% non-zero state posteriors
dengamma value 0.957486
 Epoch[ 2 of 3]-Minibatch[  41-  50, 0.61%]: SamplesSeen = 5716; TrainLossPerSample =  0.08481390; EvalErr[0]PerSample = 0.36529041; TotalTime = 3.6700s; SamplesPerSecond = 1557.5
backpointers: 35.2% edges have at least one /sil/ unit inside
forwardbackward: 17.033% non-zero state posteriors
dengamma value 1.002623
backpointers: 34.9% edges have at least one /sil/ unit inside
forwardbackward: 17.248% non-zero state posteriors
dengamma value 0.944117
backpointers: 30.4% edges have at least one /sil/ unit inside
forwardbackward: 18.692% non-zero state posteriors
dengamma value 1.009950
backpointers: 28.5% edges have at least one /sil/ unit inside
forwardbackward: 22.432% non-zero state posteriors
dengamma value 1.066390
backpointers: 35.1% edges have at least one /sil/ unit inside
forwardbackward: 15.604% non-zero state posteriors
dengamma value 0.991151
backpointers: 32.8% edges have at least one /sil/ unit inside
forwardbackward: 20.354% non-zero state posteriors
dengamma value 1.029653
backpointers: 37.2% edges have at least one /sil/ unit inside
forwardbackward: 17.092% non-zero state posteriors
dengamma value 0.982745
backpointers: 38.6% edges have at least one /sil/ unit inside
forwardbackward: 17.282% non-zero state posteriors
dengamma value 0.987840
backpointers: 27.4% edges have at least one /sil/ unit inside
forwardbackward: 18.381% non-zero state posteriors
dengamma value 1.004265
backpointers: 29.7% edges have at least one /sil/ unit inside
forwardbackward: 19.420% non-zero state posteriors
dengamma value 1.030022
backpointers: 20.7% edges have at least one /sil/ unit inside
forwardbackward: 22.037% non-zero state posteriors
dengamma value 1.059720
backpointers: 35.4% edges have at least one /sil/ unit inside
forwardbackward: 16.673% non-zero state posteriors
dengamma value 0.984609
backpointers: 29.6% edges have at least one /sil/ unit inside
forwardbackward: 19.543% non-zero state posteriors
dengamma value 0.920457
backpointers: 28.7% edges have at least one /sil/ unit inside
forwardbackward: 18.841% non-zero state posteriors
dengamma value 1.001540
backpointers: 34.0% edges have at least one /sil/ unit inside
forwardbackward: 17.880% non-zero state posteriors
dengamma value 1.018137
backpointers: 27.0% edges have at least one /sil/ unit inside
forwardbackward: 22.311% non-zero state posteriors
dengamma value 1.014206
backpointers: 28.3% edges have at least one /sil/ unit inside
forwardbackward: 16.531% non-zero state posteriors
dengamma value 0.989598
backpointers: 32.2% edges have at least one /sil/ unit inside
forwardbackward: 17.519% non-zero state posteriors
dengamma value 0.938843
backpointers: 35.4% edges have at least one /sil/ unit inside
forwardbackward: 15.508% non-zero state posteriors
dengamma value 0.985098
backpointers: 41.6% edges have at least one /sil/ unit inside
forwardbackward: 13.076% non-zero state posteriors
dengamma value 1.002706
backpointers: 29.7% edges have at least one /sil/ unit inside
forwardbackward: 27.262% non-zero state posteriors
dengamma value 1.062003
backpointers: 32.0% edges have at least one /sil/ unit inside
forwardbackward: 14.770% non-zero state posteriors
dengamma value 1.014974
 Epoch[ 2 of 3]-Minibatch[  51-  60, 0.73%]: SamplesSeen = 5556; TrainLossPerSample =  0.08746417; EvalErr[0]PerSample = 0.37544996; TotalTime = 3.4024s; SamplesPerSecond = 1633.0
backpointers: 32.4% edges have at least one /sil/ unit inside
forwardbackward: 18.762% non-zero state posteriors
dengamma value 1.067597
backpointers: 30.8% edges have at least one /sil/ unit inside
forwardbackward: 20.726% non-zero state posteriors
dengamma value 1.045570
backpointers: 34.5% edges have at least one /sil/ unit inside
forwardbackward: 21.799% non-zero state posteriors
dengamma value 0.998305
backpointers: 36.3% edges have at least one /sil/ unit inside
forwardbackward: 17.859% non-zero state posteriors
dengamma value 1.003158
backpointers: 30.1% edges have at least one /sil/ unit inside
forwardbackward: 21.992% non-zero state posteriors
dengamma value 1.022376
backpointers: 36.2% edges have at least one /sil/ unit inside
forwardbackward: 20.547% non-zero state posteriors
dengamma value 1.018354
backpointers: 26.6% edges have at least one /sil/ unit inside
forwardbackward: 19.431% non-zero state posteriors
dengamma value 1.057140
backpointers: 37.2% edges have at least one /sil/ unit inside
forwardbackward: 21.989% non-zero state posteriors
dengamma value 1.011509
backpointers: 34.0% edges have at least one /sil/ unit inside
forwardbackward: 14.745% non-zero state posteriors
dengamma value 1.034293
backpointers: 33.4% edges have at least one /sil/ unit inside
forwardbackward: 18.727% non-zero state posteriors
dengamma value 1.026405
backpointers: 34.5% edges have at least one /sil/ unit inside
forwardbackward: 20.712% non-zero state posteriors
dengamma value 0.992428
backpointers: 30.2% edges have at least one /sil/ unit inside
forwardbackward: 22.335% non-zero state posteriors
dengamma value 1.046698
backpointers: 22.4% edges have at least one /sil/ unit inside
forwardbackward: 17.024% non-zero state posteriors
dengamma value 0.994489
backpointers: 31.8% edges have at least one /sil/ unit inside
forwardbackward: 19.496% non-zero state posteriors
dengamma value 1.022863
backpointers: 30.5% edges have at least one /sil/ unit inside
forwardbackward: 12.436% non-zero state posteriors
dengamma value 1.051162
backpointers: 32.5% edges have at least one /sil/ unit inside
forwardbackward: 19.838% non-zero state posteriors
dengamma value 0.992955
backpointers: 32.8% edges have at least one /sil/ unit inside
forwardbackward: 17.042% non-zero state posteriors
dengamma value 0.984226
backpointers: 34.5% edges have at least one /sil/ unit inside
forwardbackward: 14.459% non-zero state posteriors
dengamma value 1.028885
backpointers: 32.3% edges have at least one /sil/ unit inside
forwardbackward: 18.449% non-zero state posteriors
dengamma value 0.980069
backpointers: 29.9% edges have at least one /sil/ unit inside
forwardbackward: 18.819% non-zero state posteriors
dengamma value 1.002463
backpointers: 37.4% edges have at least one /sil/ unit inside
forwardbackward: 11.656% non-zero state posteriors
dengamma value 1.007095
 Epoch[ 2 of 3]-Minibatch[  61-  70, 0.85%]: SamplesSeen = 5478; TrainLossPerSample =  0.07100120; EvalErr[0]PerSample = 0.36692223; TotalTime = 3.2757s; SamplesPerSecond = 1672.3
backpointers: 22.6% edges have at least one /sil/ unit inside
forwardbackward: 19.322% non-zero state posteriors
dengamma value 1.084487
backpointers: 33.6% edges have at least one /sil/ unit inside
forwardbackward: 19.258% non-zero state posteriors
dengamma value 0.969171
backpointers: 30.9% edges have at least one /sil/ unit inside
forwardbackward: 20.185% non-zero state posteriors
dengamma value 1.052924
backpointers: 34.6% edges have at least one /sil/ unit inside
forwardbackward: 16.671% non-zero state posteriors
dengamma value 1.038825
backpointers: 28.8% edges have at least one /sil/ unit inside
forwardbackward: 17.270% non-zero state posteriors
dengamma value 1.008584
backpointers: 33.8% edges have at least one /sil/ unit inside
forwardbackward: 16.804% non-zero state posteriors
dengamma value 0.977523
backpointers: 27.7% edges have at least one /sil/ unit inside
forwardbackward: 18.202% non-zero state posteriors
dengamma value 0.966139
backpointers: 32.9% edges have at least one /sil/ unit inside
forwardbackward: 19.276% non-zero state posteriors
dengamma value 1.028209
backpointers: 33.1% edges have at least one /sil/ unit inside
forwardbackward: 17.999% non-zero state posteriors
dengamma value 1.012838
backpointers: 34.3% edges have at least one /sil/ unit inside
forwardbackward: 17.578% non-zero state posteriors
dengamma value 1.052769
backpointers: 46.1% edges have at least one /sil/ unit inside
forwardbackward: 12.346% non-zero state posteriors
dengamma value 1.006172
backpointers: 42.7% edges have at least one /sil/ unit inside
forwardbackward: 11.308% non-zero state posteriors
dengamma value 0.958484
backpointers: 29.7% edges have at least one /sil/ unit inside
forwardbackward: 18.227% non-zero state posteriors
dengamma value 0.985442
backpointers: 35.4% edges have at least one /sil/ unit inside
forwardbackward: 14.030% non-zero state posteriors
dengamma value 1.012952
backpointers: 27.7% edges have at least one /sil/ unit inside
forwardbackward: 22.084% non-zero state posteriors
dengamma value 1.066421
backpointers: 33.1% edges have at least one /sil/ unit inside
forwardbackward: 20.710% non-zero state posteriors
dengamma value 1.005108
backpointers: 21.4% edges have at least one /sil/ unit inside
forwardbackward: 23.727% non-zero state posteriors
dengamma value 1.058572
backpointers: 29.4% edges have at least one /sil/ unit inside
forwardbackward: 18.525% non-zero state posteriors
dengamma value 1.045288
backpointers: 39.5% edges have at least one /sil/ unit inside
forwardbackward: 16.400% non-zero state posteriors
dengamma value 0.976902
backpointers: 36.1% edges have at least one /sil/ unit inside
forwardbackward: 13.226% non-zero state posteriors
dengamma value 1.027757
backpointers: 30.8% edges have at least one /sil/ unit inside
forwardbackward: 20.238% non-zero state posteriors
dengamma value 1.019378
backpointers: 35.0% edges have at least one /sil/ unit inside
forwardbackward: 17.200% non-zero state posteriors
dengamma value 1.008697
backpointers: 32.3% edges have at least one /sil/ unit inside
forwardbackward: 19.508% non-zero state posteriors
dengamma value 0.990188
backpointers: 38.5% edges have at least one /sil/ unit inside
forwardbackward: 15.190% non-zero state posteriors
dengamma value 1.014283
backpointers: 25.7% edges have at least one /sil/ unit inside
forwardbackward: 22.039% non-zero state posteriors
dengamma value 0.992677
backpointers: 37.4% edges have at least one /sil/ unit inside
forwardbackward: 17.797% non-zero state posteriors
dengamma value 1.079582
 Epoch[ 2 of 3]-Minibatch[  71-  80, 0.98%]: SamplesSeen = 7648; TrainLossPerSample =  0.06966917; EvalErr[0]PerSample = 0.37068515; TotalTime = 4.7873s; SamplesPerSecond = 1597.6
backpointers: 24.5% edges have at least one /sil/ unit inside
forwardbackward: 19.955% non-zero state posteriors
dengamma value 1.046972
backpointers: 28.6% edges have at least one /sil/ unit inside
forwardbackward: 21.556% non-zero state posteriors
dengamma value 1.027184
backpointers: 27.6% edges have at least one /sil/ unit inside
forwardbackward: 19.825% non-zero state posteriors
dengamma value 1.043282
backpointers: 33.2% edges have at least one /sil/ unit inside
forwardbackward: 18.736% non-zero state posteriors
dengamma value 1.059329
backpointers: 24.8% edges have at least one /sil/ unit inside
forwardbackward: 17.786% non-zero state posteriors
dengamma value 1.015849
backpointers: 30.4% edges have at least one /sil/ unit inside
forwardbackward: 20.431% non-zero state posteriors
dengamma value 1.050745
backpointers: 26.8% edges have at least one /sil/ unit inside
forwardbackward: 23.333% non-zero state posteriors
dengamma value 1.004155
backpointers: 34.6% edges have at least one /sil/ unit inside
forwardbackward: 19.287% non-zero state posteriors
dengamma value 0.958369
backpointers: 33.0% edges have at least one /sil/ unit inside
forwardbackward: 18.605% non-zero state posteriors
dengamma value 1.059498
backpointers: 22.0% edges have at least one /sil/ unit inside
forwardbackward: 21.170% non-zero state posteriors
dengamma value 1.049217
backpointers: 35.5% edges have at least one /sil/ unit inside
forwardbackward: 16.817% non-zero state posteriors
dengamma value 0.998632
backpointers: 34.4% edges have at least one /sil/ unit inside
forwardbackward: 15.890% non-zero state posteriors
dengamma value 1.008028
backpointers: 35.0% edges have at least one /sil/ unit inside
forwardbackward: 17.302% non-zero state posteriors
dengamma value 0.995841
backpointers: 28.4% edges have at least one /sil/ unit inside
forwardbackward: 23.396% non-zero state posteriors
dengamma value 1.043541
backpointers: 27.6% edges have at least one /sil/ unit inside
forwardbackward: 22.144% non-zero state posteriors
dengamma value 1.029194
backpointers: 37.0% edges have at least one /sil/ unit inside
forwardbackward: 14.203% non-zero state posteriors
dengamma value 1.011595
backpointers: 33.4% edges have at least one /sil/ unit inside
forwardbackward: 19.406% non-zero state posteriors
dengamma value 0.974787
backpointers: 37.5% edges have at least one /sil/ unit inside
forwardbackward: 16.175% non-zero state posteriors
dengamma value 1.015161
backpointers: 43.6% edges have at least one /sil/ unit inside
forwardbackward: 11.178% non-zero state posteriors
dengamma value 0.927670
backpointers: 33.3% edges have at least one /sil/ unit inside
forwardbackward: 15.766% non-zero state posteriors
dengamma value 1.047797
backpointers: 42.7% edges have at least one /sil/ unit inside
forwardbackward: 10.948% non-zero state posteriors
dengamma value 0.956795
backpointers: 33.7% edges have at least one /sil/ unit inside
forwardbackward: 19.096% non-zero state posteriors
dengamma value 1.031488
backpointers: 32.7% edges have at least one /sil/ unit inside
forwardbackward: 20.829% non-zero state posteriors
dengamma value 1.005754
backpointers: 30.8% edges have at least one /sil/ unit inside
forwardbackward: 21.216% non-zero state posteriors
dengamma value 1.039603
 Epoch[ 2 of 3]-Minibatch[  81-  90, 1.10%]: SamplesSeen = 7252; TrainLossPerSample =  0.08130199; EvalErr[0]PerSample = 0.34666299; TotalTime = 4.8145s; SamplesPerSecond = 1506.3
backpointers: 31.0% edges have at least one /sil/ unit inside
forwardbackward: 20.315% non-zero state posteriors
dengamma value 0.985880
backpointers: 29.5% edges have at least one /sil/ unit inside
forwardbackward: 19.302% non-zero state posteriors
dengamma value 1.036929
backpointers: 34.3% edges have at least one /sil/ unit inside
forwardbackward: 18.824% non-zero state posteriors
dengamma value 0.996235
backpointers: 21.8% edges have at least one /sil/ unit inside
forwardbackward: 23.853% non-zero state posteriors
dengamma value 1.066465
backpointers: 40.5% edges have at least one /sil/ unit inside
forwardbackward: 16.320% non-zero state posteriors
dengamma value 0.954259
backpointers: 39.4% edges have at least one /sil/ unit inside
forwardbackward: 11.316% non-zero state posteriors
dengamma value 1.024415
backpointers: 34.6% edges have at least one /sil/ unit inside
forwardbackward: 16.745% non-zero state posteriors
dengamma value 0.969281
backpointers: 35.3% edges have at least one /sil/ unit inside
forwardbackward: 15.447% non-zero state posteriors
dengamma value 1.087077
backpointers: 37.2% edges have at least one /sil/ unit inside
forwardbackward: 17.539% non-zero state posteriors
dengamma value 1.021475
backpointers: 26.2% edges have at least one /sil/ unit inside
forwardbackward: 20.831% non-zero state posteriors
dengamma value 1.039017
backpointers: 32.6% edges have at least one /sil/ unit inside
forwardbackward: 17.961% non-zero state posteriors
dengamma value 1.032365
backpointers: 34.8% edges have at least one /sil/ unit inside
forwardbackward: 20.152% non-zero state posteriors
dengamma value 0.985131
backpointers: 29.4% edges have at least one /sil/ unit inside
forwardbackward: 22.147% non-zero state posteriors
dengamma value 1.032522
backpointers: 35.2% edges have at least one /sil/ unit inside
forwardbackward: 18.282% non-zero state posteriors
dengamma value 0.985288
backpointers: 22.5% edges have at least one /sil/ unit inside
forwardbackward: 25.363% non-zero state posteriors
dengamma value 1.070622
backpointers: 40.0% edges have at least one /sil/ unit inside
forwardbackward: 15.603% non-zero state posteriors
dengamma value 0.947870
backpointers: 26.9% edges have at least one /sil/ unit inside
forwardbackward: 19.503% non-zero state posteriors
dengamma value 1.036691
backpointers: 28.6% edges have at least one /sil/ unit inside
forwardbackward: 16.160% non-zero state posteriors
dengamma value 0.938559
backpointers: 28.4% edges have at least one /sil/ unit inside
forwardbackward: 22.727% non-zero state posteriors
dengamma value 1.050910
backpointers: 29.9% edges have at least one /sil/ unit inside
forwardbackward: 18.074% non-zero state posteriors
dengamma value 1.029382
backpointers: 36.9% edges have at least one /sil/ unit inside
forwardbackward: 16.514% non-zero state posteriors
dengamma value 1.007848
backpointers: 38.2% edges have at least one /sil/ unit inside
forwardbackward: 19.620% non-zero state posteriors
dengamma value 1.002269
backpointers: 30.3% edges have at least one /sil/ unit inside
forwardbackward: 24.463% non-zero state posteriors
dengamma value 1.009387
backpointers: 28.9% edges have at least one /sil/ unit inside
forwardbackward: 18.139% non-zero state posteriors
dengamma value 1.068273
backpointers: 41.3% edges have at least one /sil/ unit inside
forwardbackward: 15.066% non-zero state posteriors
dengamma value 0.928679
 Epoch[ 2 of 3]-Minibatch[  91- 100, 1.22%]: SamplesSeen = 7370; TrainLossPerSample =  0.08062232; EvalErr[0]PerSample = 0.33921303; TotalTime = 4.9972s; SamplesPerSecond = 1474.8
backpointers: 41.8% edges have at least one /sil/ unit inside
forwardbackward: 14.161% non-zero state posteriors
dengamma value 0.986252
backpointers: 30.8% edges have at least one /sil/ unit inside
forwardbackward: 16.189% non-zero state posteriors
dengamma value 1.069692
backpointers: 37.8% edges have at least one /sil/ unit inside
forwardbackward: 14.790% non-zero state posteriors
dengamma value 0.971952
backpointers: 30.8% edges have at least one /sil/ unit inside
forwardbackward: 21.537% non-zero state posteriors
dengamma value 1.025264
backpointers: 37.0% edges have at least one /sil/ unit inside
forwardbackward: 21.661% non-zero state posteriors
dengamma value 1.033342
backpointers: 35.7% edges have at least one /sil/ unit inside
forwardbackward: 14.235% non-zero state posteriors
dengamma value 1.051348
backpointers: 32.9% edges have at least one /sil/ unit inside
forwardbackward: 18.317% non-zero state posteriors
dengamma value 0.975668
backpointers: 20.7% edges have at least one /sil/ unit inside
forwardbackward: 20.984% non-zero state posteriors
dengamma value 1.049693
backpointers: 41.0% edges have at least one /sil/ unit inside
forwardbackward: 16.352% non-zero state posteriors
dengamma value 0.985004
backpointers: 28.6% edges have at least one /sil/ unit inside
forwardbackward: 17.200% non-zero state posteriors
dengamma value 1.033615
backpointers: 31.5% edges have at least one /sil/ unit inside
forwardbackward: 17.681% non-zero state posteriors
dengamma value 0.980632
backpointers: 32.0% edges have at least one /sil/ unit inside
forwardbackward: 18.718% non-zero state posteriors
dengamma value 1.042472
backpointers: 34.7% edges have at least one /sil/ unit inside
forwardbackward: 23.029% non-zero state posteriors
dengamma value 1.030791
backpointers: 29.7% edges have at least one /sil/ unit inside
forwardbackward: 21.060% non-zero state posteriors
dengamma value 1.081433
backpointers: 31.6% edges have at least one /sil/ unit inside
forwardbackward: 18.767% non-zero state posteriors
dengamma value 0.992093
backpointers: 31.8% edges have at least one /sil/ unit inside
forwardbackward: 18.822% non-zero state posteriors
dengamma value 1.026714
backpointers: 30.3% edges have at least one /sil/ unit inside
forwardbackward: 20.034% non-zero state posteriors
dengamma value 1.054249
backpointers: 25.8% edges have at least one /sil/ unit inside
forwardbackward: 21.151% non-zero state posteriors
dengamma value 0.997079
backpointers: 31.6% edges have at least one /sil/ unit inside
forwardbackward: 17.581% non-zero state posteriors
dengamma value 0.987307
backpointers: 30.7% edges have at least one /sil/ unit inside
forwardbackward: 21.505% non-zero state posteriors
dengamma value 1.060347
backpointers: 38.3% edges have at least one /sil/ unit inside
forwardbackward: 17.717% non-zero state posteriors
dengamma value 1.005420
backpointers: 30.1% edges have at least one /sil/ unit inside
forwardbackward: 21.267% non-zero state posteriors
dengamma value 1.052876
backpointers: 27.8% edges have at least one /sil/ unit inside
forwardbackward: 24.492% non-zero state posteriors
dengamma value 1.035627
backpointers: 33.2% edges have at least one /sil/ unit inside
forwardbackward: 18.532% non-zero state posteriors
dengamma value 0.899056
 Epoch[ 2 of 3]-Minibatch[ 101- 110, 1.34%]: SamplesSeen = 6002; TrainLossPerSample =  0.07535078; EvalErr[0]PerSample = 0.35654782; TotalTime = 3.9282s; SamplesPerSecond = 1527.9
backpointers: 34.3% edges have at least one /sil/ unit inside
forwardbackward: 19.879% non-zero state posteriors
dengamma value 0.978256
backpointers: 27.2% edges have at least one /sil/ unit inside
forwardbackward: 11.387% non-zero state posteriors
dengamma value 1.093860
backpointers: 35.1% edges have at least one /sil/ unit inside
forwardbackward: 17.285% non-zero state posteriors
dengamma value 0.990802
backpointers: 29.9% edges have at least one /sil/ unit inside
forwardbackward: 18.568% non-zero state posteriors
dengamma value 1.016953
backpointers: 31.4% edges have at least one /sil/ unit inside
forwardbackward: 25.115% non-zero state posteriors
dengamma value 1.043551
backpointers: 30.6% edges have at least one /sil/ unit inside
forwardbackward: 13.622% non-zero state posteriors
dengamma value 1.010633
backpointers: 29.3% edges have at least one /sil/ unit inside
forwardbackward: 19.140% non-zero state posteriors
dengamma value 1.027782
backpointers: 38.1% edges have at least one /sil/ unit inside
forwardbackward: 15.271% non-zero state posteriors
dengamma value 1.001734
backpointers: 27.8% edges have at least one /sil/ unit inside
forwardbackward: 14.054% non-zero state posteriors
dengamma value 0.965143
backpointers: 33.8% edges have at least one /sil/ unit inside
forwardbackward: 16.253% non-zero state posteriors
dengamma value 0.968359
backpointers: 27.5% edges have at least one /sil/ unit inside
forwardbackward: 21.446% non-zero state posteriors
dengamma value 1.017367
backpointers: 33.5% edges have at least one /sil/ unit inside
forwardbackward: 19.796% non-zero state posteriors
dengamma value 0.999749
backpointers: 28.7% edges have at least one /sil/ unit inside
forwardbackward: 17.011% non-zero state posteriors
dengamma value 1.019783
backpointers: 33.7% edges have at least one /sil/ unit inside
forwardbackward: 20.015% non-zero state posteriors
dengamma value 0.976882
backpointers: 30.2% edges have at least one /sil/ unit inside
forwardbackward: 19.467% non-zero state posteriors
dengamma value 1.046309
backpointers: 35.2% edges have at least one /sil/ unit inside
forwardbackward: 13.155% non-zero state posteriors
dengamma value 1.039405
backpointers: 36.4% edges have at least one /sil/ unit inside
forwardbackward: 18.517% non-zero state posteriors
dengamma value 1.034975
backpointers: 38.5% edges have at least one /sil/ unit inside
forwardbackward: 16.867% non-zero state posteriors
dengamma value 0.901606
backpointers: 30.6% edges have at least one /sil/ unit inside
forwardbackward: 22.352% non-zero state posteriors
dengamma value 1.007164
backpointers: 35.1% edges have at least one /sil/ unit inside
forwardbackward: 17.663% non-zero state posteriors
dengamma value 1.021899
backpointers: 32.2% edges have at least one /sil/ unit inside
forwardbackward: 16.789% non-zero state posteriors
dengamma value 0.974447
backpointers: 36.1% edges have at least one /sil/ unit inside
forwardbackward: 14.423% non-zero state posteriors
dengamma value 1.019469
backpointers: 33.3% edges have at least one /sil/ unit inside
forwardbackward: 20.154% non-zero state posteriors
dengamma value 1.012408
backpointers: 36.8% edges have at least one /sil/ unit inside
forwardbackward: 12.247% non-zero state posteriors
dengamma value 1.040741
 Epoch[ 2 of 3]-Minibatch[ 111- 120, 1.46%]: SamplesSeen = 7222; TrainLossPerSample =  0.06968393; EvalErr[0]PerSample = 0.37607311; TotalTime = 4.7066s; SamplesPerSecond = 1534.4
backpointers: 30.9% edges have at least one /sil/ unit inside
forwardbackward: 16.915% non-zero state posteriors
dengamma value 1.060312
backpointers: 29.1% edges have at least one /sil/ unit inside
forwardbackward: 22.198% non-zero state posteriors
dengamma value 0.995789
backpointers: 29.8% edges have at least one /sil/ unit inside
forwardbackward: 16.004% non-zero state posteriors
dengamma value 1.010737
backpointers: 32.7% edges have at least one /sil/ unit inside
forwardbackward: 15.025% non-zero state posteriors
dengamma value 1.045742
backpointers: 34.6% edges have at least one /sil/ unit inside
forwardbackward: 17.934% non-zero state posteriors
dengamma value 1.062369
backpointers: 29.3% edges have at least one /sil/ unit inside
forwardbackward: 18.334% non-zero state posteriors
dengamma value 1.016857
backpointers: 41.7% edges have at least one /sil/ unit inside
forwardbackward: 12.446% non-zero state posteriors
dengamma value 0.980822
backpointers: 34.7% edges have at least one /sil/ unit inside
forwardbackward: 19.976% non-zero state posteriors
dengamma value 1.020059
backpointers: 34.4% edges have at least one /sil/ unit inside
forwardbackward: 18.297% non-zero state posteriors
dengamma value 1.026889
backpointers: 30.1% edges have at least one /sil/ unit inside
forwardbackward: 20.286% non-zero state posteriors
dengamma value 0.982899
backpointers: 32.9% edges have at least one /sil/ unit inside
forwardbackward: 17.007% non-zero state posteriors
dengamma value 0.988006
backpointers: 34.2% edges have at least one /sil/ unit inside
forwardbackward: 17.783% non-zero state posteriors
dengamma value 1.042750
backpointers: 35.0% edges have at least one /sil/ unit inside
forwardbackward: 17.009% non-zero state posteriors
dengamma value 0.989422
Finished Epoch[ 2 of 3]: [Training Set] TrainLossPerSample = 0.07695549; EvalErrPerSample = 0.36105958; AvgLearningRatePerSample = 2e-06; EpochTime=52.6236
Starting Epoch 3: learning rate per sample = 0.000002  effective momentum = 0.995898  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 2: frames [163840..245760] (first utterance at frame 164076), data subset 0 of 1, with 1 datapasses

Starting minibatch loop.
backpointers: 32.0% edges have at least one /sil/ unit inside
forwardbackward: 17.894% non-zero state posteriors
dengamma value 1.039633
backpointers: 26.6% edges have at least one /sil/ unit inside
forwardbackward: 22.470% non-zero state posteriors
dengamma value 1.074283
backpointers: 35.7% edges have at least one /sil/ unit inside
forwardbackward: 19.275% non-zero state posteriors
dengamma value 0.975925
backpointers: 40.0% edges have at least one /sil/ unit inside
forwardbackward: 13.439% non-zero state posteriors
dengamma value 0.990618
backpointers: 26.1% edges have at least one /sil/ unit inside
forwardbackward: 18.285% non-zero state posteriors
dengamma value 1.078577
backpointers: 32.7% edges have at least one /sil/ unit inside
forwardbackward: 22.114% non-zero state posteriors
dengamma value 1.021567
backpointers: 30.2% edges have at least one /sil/ unit inside
forwardbackward: 14.399% non-zero state posteriors
dengamma value 1.017293
backpointers: 29.8% edges have at least one /sil/ unit inside
forwardbackward: 10.305% non-zero state posteriors
dengamma value 0.986993
backpointers: 28.1% edges have at least one /sil/ unit inside
forwardbackward: 21.806% non-zero state posteriors
dengamma value 1.029772
backpointers: 39.4% edges have at least one /sil/ unit inside
forwardbackward: 14.500% non-zero state posteriors
dengamma value 0.929541
backpointers: 36.6% edges have at least one /sil/ unit inside
forwardbackward: 21.283% non-zero state posteriors
dengamma value 0.968705
backpointers: 30.1% edges have at least one /sil/ unit inside
forwardbackward: 20.233% non-zero state posteriors
dengamma value 1.019005
backpointers: 37.3% edges have at least one /sil/ unit inside
forwardbackward: 18.116% non-zero state posteriors
dengamma value 1.050297
backpointers: 32.0% edges have at least one /sil/ unit inside
forwardbackward: 16.618% non-zero state posteriors
dengamma value 0.940144
backpointers: 24.2% edges have at least one /sil/ unit inside
forwardbackward: 24.180% non-zero state posteriors
dengamma value 1.005113
backpointers: 26.3% edges have at least one /sil/ unit inside
forwardbackward: 19.534% non-zero state posteriors
dengamma value 1.023653
backpointers: 34.2% edges have at least one /sil/ unit inside
forwardbackward: 18.524% non-zero state posteriors
dengamma value 0.970325
backpointers: 33.6% edges have at least one /sil/ unit inside
forwardbackward: 17.305% non-zero state posteriors
dengamma value 1.000977
backpointers: 33.8% edges have at least one /sil/ unit inside
forwardbackward: 14.404% non-zero state posteriors
dengamma value 0.945999
backpointers: 33.3% edges have at least one /sil/ unit inside
forwardbackward: 20.306% non-zero state posteriors
dengamma value 1.047164
backpointers: 29.4% edges have at least one /sil/ unit inside
forwardbackward: 20.315% non-zero state posteriors
dengamma value 1.031513
 Epoch[ 3 of 3]-Minibatch[   1-  10, 0.12%]: SamplesSeen = 5718; TrainLossPerSample =  0.07041449; EvalErr[0]PerSample = 0.38090241; TotalTime = 3.6953s; SamplesPerSecond = 1547.4
backpointers: 34.0% edges have at least one /sil/ unit inside
forwardbackward: 14.555% non-zero state posteriors
dengamma value 0.999484
backpointers: 35.0% edges have at least one /sil/ unit inside
forwardbackward: 16.082% non-zero state posteriors
dengamma value 1.026875
backpointers: 21.0% edges have at least one /sil/ unit inside
forwardbackward: 19.210% non-zero state posteriors
dengamma value 0.978815
backpointers: 29.8% edges have at least one /sil/ unit inside
forwardbackward: 21.141% non-zero state posteriors
dengamma value 0.986448
backpointers: 36.4% edges have at least one /sil/ unit inside
forwardbackward: 22.420% non-zero state posteriors
dengamma value 0.997014
backpointers: 33.3% edges have at least one /sil/ unit inside
forwardbackward: 18.613% non-zero state posteriors
dengamma value 1.006623
backpointers: 30.6% edges have at least one /sil/ unit inside
forwardbackward: 14.120% non-zero state posteriors
dengamma value 1.025177
backpointers: 23.3% edges have at least one /sil/ unit inside
forwardbackward: 25.703% non-zero state posteriors
dengamma value 1.055777
backpointers: 43.3% edges have at least one /sil/ unit inside
forwardbackward: 13.418% non-zero state posteriors
dengamma value 1.021327
backpointers: 22.6% edges have at least one /sil/ unit inside
forwardbackward: 18.503% non-zero state posteriors
dengamma value 0.989313
backpointers: 31.4% edges have at least one /sil/ unit inside
forwardbackward: 15.258% non-zero state posteriors
dengamma value 0.990850
backpointers: 28.5% edges have at least one /sil/ unit inside
forwardbackward: 20.931% non-zero state posteriors
dengamma value 0.990840
backpointers: 33.4% edges have at least one /sil/ unit inside
forwardbackward: 16.449% non-zero state posteriors
dengamma value 1.023819
backpointers: 30.6% edges have at least one /sil/ unit inside
forwardbackward: 18.051% non-zero state posteriors
dengamma value 1.028066
backpointers: 28.7% edges have at least one /sil/ unit inside
forwardbackward: 19.140% non-zero state posteriors
dengamma value 1.034465
backpointers: 30.1% edges have at least one /sil/ unit inside
forwardbackward: 18.870% non-zero state posteriors
dengamma value 1.022678
backpointers: 35.1% edges have at least one /sil/ unit inside
forwardbackward: 14.916% non-zero state posteriors
dengamma value 1.046022
backpointers: 29.1% edges have at least one /sil/ unit inside
forwardbackward: 23.274% non-zero state posteriors
dengamma value 0.984351
backpointers: 42.5% edges have at least one /sil/ unit inside
forwardbackward: 12.631% non-zero state posteriors
dengamma value 0.974296
backpointers: 34.5% edges have at least one /sil/ unit inside
forwardbackward: 14.583% non-zero state posteriors
dengamma value 1.025630
backpointers: 35.6% edges have at least one /sil/ unit inside
forwardbackward: 18.994% non-zero state posteriors
dengamma value 0.968312
backpointers: 35.0% edges have at least one /sil/ unit inside
forwardbackward: 17.966% non-zero state posteriors
dengamma value 0.935207
backpointers: 37.0% edges have at least one /sil/ unit inside
forwardbackward: 15.769% non-zero state posteriors
dengamma value 0.997099
backpointers: 30.4% edges have at least one /sil/ unit inside
forwardbackward: 25.132% non-zero state posteriors
dengamma value 1.007276
 Epoch[ 3 of 3]-Minibatch[  11-  20, 0.24%]: SamplesSeen = 6722; TrainLossPerSample =  0.07239579; EvalErr[0]PerSample = 0.37503719; TotalTime = 4.2236s; SamplesPerSecond = 1591.5
backpointers: 36.1% edges have at least one /sil/ unit inside
forwardbackward: 16.411% non-zero state posteriors
dengamma value 1.005495
backpointers: 27.5% edges have at least one /sil/ unit inside
forwardbackward: 15.269% non-zero state posteriors
dengamma value 0.977465
backpointers: 33.2% edges have at least one /sil/ unit inside
forwardbackward: 19.642% non-zero state posteriors
dengamma value 1.025678
backpointers: 33.6% edges have at least one /sil/ unit inside
forwardbackward: 17.216% non-zero state posteriors
dengamma value 1.034474
backpointers: 32.5% edges have at least one /sil/ unit inside
forwardbackward: 21.670% non-zero state posteriors
dengamma value 1.050934
backpointers: 35.1% edges have at least one /sil/ unit inside
forwardbackward: 18.579% non-zero state posteriors
dengamma value 1.038740
backpointers: 27.1% edges have at least one /sil/ unit inside
forwardbackward: 20.997% non-zero state posteriors
dengamma value 1.048952
backpointers: 35.2% edges have at least one /sil/ unit inside
forwardbackward: 15.945% non-zero state posteriors
dengamma value 0.977346
backpointers: 25.8% edges have at least one /sil/ unit inside
forwardbackward: 22.944% non-zero state posteriors
dengamma value 1.033660
backpointers: 25.4% edges have at least one /sil/ unit inside
forwardbackward: 26.021% non-zero state posteriors
dengamma value 1.023166
backpointers: 29.8% edges have at least one /sil/ unit inside
forwardbackward: 15.823% non-zero state posteriors
dengamma value 0.963767
backpointers: 31.2% edges have at least one /sil/ unit inside
forwardbackward: 18.405% non-zero state posteriors
dengamma value 0.990582
backpointers: 37.6% edges have at least one /sil/ unit inside
forwardbackward: 22.560% non-zero state posteriors
dengamma value 0.968439
backpointers: 36.9% edges have at least one /sil/ unit inside
forwardbackward: 17.192% non-zero state posteriors
dengamma value 1.002363
backpointers: 29.3% edges have at least one /sil/ unit inside
forwardbackward: 23.117% non-zero state posteriors
dengamma value 1.028405
backpointers: 25.8% edges have at least one /sil/ unit inside
forwardbackward: 20.500% non-zero state posteriors
dengamma value 1.054308
backpointers: 32.7% edges have at least one /sil/ unit inside
forwardbackward: 22.482% non-zero state posteriors
dengamma value 1.079194
backpointers: 33.7% edges have at least one /sil/ unit inside
forwardbackward: 13.881% non-zero state posteriors
dengamma value 1.047324
backpointers: 31.8% edges have at least one /sil/ unit inside
forwardbackward: 19.659% non-zero state posteriors
dengamma value 1.015319
backpointers: 33.0% edges have at least one /sil/ unit inside
forwardbackward: 19.242% non-zero state posteriors
dengamma value 1.030461
backpointers: 35.8% edges have at least one /sil/ unit inside
forwardbackward: 16.466% non-zero state posteriors
dengamma value 1.004221
backpointers: 31.3% edges have at least one /sil/ unit inside
forwardbackward: 18.227% non-zero state posteriors
dengamma value 1.038515
 Epoch[ 3 of 3]-Minibatch[  21-  30, 0.37%]: SamplesSeen = 5366; TrainLossPerSample =  0.08347871; EvalErr[0]PerSample = 0.36153559; TotalTime = 3.7660s; SamplesPerSecond = 1424.9
backpointers: 29.7% edges have at least one /sil/ unit inside
forwardbackward: 18.762% non-zero state posteriors
dengamma value 0.994807
backpointers: 25.9% edges have at least one /sil/ unit inside
forwardbackward: 21.329% non-zero state posteriors
dengamma value 1.069263
backpointers: 40.1% edges have at least one /sil/ unit inside
forwardbackward: 13.335% non-zero state posteriors
dengamma value 0.949073
backpointers: 40.6% edges have at least one /sil/ unit inside
forwardbackward: 13.890% non-zero state posteriors
dengamma value 0.919265
backpointers: 31.6% edges have at least one /sil/ unit inside
forwardbackward: 17.654% non-zero state posteriors
dengamma value 0.872749
backpointers: 33.7% edges have at least one /sil/ unit inside
forwardbackward: 15.748% non-zero state posteriors
dengamma value 0.978129
backpointers: 35.6% edges have at least one /sil/ unit inside
forwardbackward: 15.126% non-zero state posteriors
dengamma value 1.005659
backpointers: 36.9% edges have at least one /sil/ unit inside
forwardbackward: 16.978% non-zero state posteriors
dengamma value 0.947456
backpointers: 35.9% edges have at least one /sil/ unit inside
forwardbackward: 16.542% non-zero state posteriors
dengamma value 0.993521
backpointers: 31.0% edges have at least one /sil/ unit inside
forwardbackward: 18.351% non-zero state posteriors
dengamma value 0.970267
backpointers: 37.7% edges have at least one /sil/ unit inside
forwardbackward: 16.462% non-zero state posteriors
dengamma value 0.890775
backpointers: 31.6% edges have at least one /sil/ unit inside
forwardbackward: 19.060% non-zero state posteriors
dengamma value 0.957198
backpointers: 37.0% edges have at least one /sil/ unit inside
forwardbackward: 15.263% non-zero state posteriors
dengamma value 1.039421
backpointers: 36.5% edges have at least one /sil/ unit inside
forwardbackward: 16.013% non-zero state posteriors
dengamma value 0.914610
backpointers: 32.2% edges have at least one /sil/ unit inside
forwardbackward: 20.376% non-zero state posteriors
dengamma value 1.096469
backpointers: 39.5% edges have at least one /sil/ unit inside
forwardbackward: 19.261% non-zero state posteriors
dengamma value 1.003550
backpointers: 35.8% edges have at least one /sil/ unit inside
forwardbackward: 18.678% non-zero state posteriors
dengamma value 0.980459
backpointers: 33.2% edges have at least one /sil/ unit inside
forwardbackward: 19.724% non-zero state posteriors
dengamma value 1.062277
backpointers: 35.7% edges have at least one /sil/ unit inside
forwardbackward: 16.705% non-zero state posteriors
dengamma value 0.922401
backpointers: 27.7% edges have at least one /sil/ unit inside
forwardbackward: 16.033% non-zero state posteriors
dengamma value 1.029898
backpointers: 23.8% edges have at least one /sil/ unit inside
forwardbackward: 22.118% non-zero state posteriors
dengamma value 1.068591
backpointers: 43.6% edges have at least one /sil/ unit inside
forwardbackward: 13.504% non-zero state posteriors
dengamma value 0.910372
backpointers: 30.5% edges have at least one /sil/ unit inside
forwardbackward: 21.491% non-zero state posteriors
dengamma value 1.000463
 Epoch[ 3 of 3]-Minibatch[  31-  40, 0.49%]: SamplesSeen = 6244; TrainLossPerSample =  0.07292385; EvalErr[0]PerSample = 0.41672005; TotalTime = 3.8251s; SamplesPerSecond = 1632.4
backpointers: 35.0% edges have at least one /sil/ unit inside
forwardbackward: 14.292% non-zero state posteriors
dengamma value 1.108863
backpointers: 37.1% edges have at least one /sil/ unit inside
forwardbackward: 16.139% non-zero state posteriors
dengamma value 0.994599
backpointers: 32.5% edges have at least one /sil/ unit inside
forwardbackward: 19.699% non-zero state posteriors
dengamma value 1.024113
backpointers: 34.1% edges have at least one /sil/ unit inside
forwardbackward: 17.377% non-zero state posteriors
dengamma value 1.057919
backpointers: 42.5% edges have at least one /sil/ unit inside
forwardbackward: 14.299% non-zero state posteriors
dengamma value 1.039854
backpointers: 28.0% edges have at least one /sil/ unit inside
forwardbackward: 20.209% non-zero state posteriors
dengamma value 1.056383
backpointers: 36.8% edges have at least one /sil/ unit inside
forwardbackward: 20.552% non-zero state posteriors
dengamma value 1.007207
backpointers: 35.5% edges have at least one /sil/ unit inside
forwardbackward: 16.095% non-zero state posteriors
dengamma value 1.005010
backpointers: 40.8% edges have at least one /sil/ unit inside
forwardbackward: 21.366% non-zero state posteriors
dengamma value 1.003415
backpointers: 39.2% edges have at least one /sil/ unit inside
forwardbackward: 15.002% non-zero state posteriors
dengamma value 0.959026
backpointers: 33.9% edges have at least one /sil/ unit inside
forwardbackward: 16.017% non-zero state posteriors
dengamma value 1.007573
backpointers: 36.3% edges have at least one /sil/ unit inside
forwardbackward: 8.523% non-zero state posteriors
dengamma value 1.066828
backpointers: 43.6% edges have at least one /sil/ unit inside
forwardbackward: 15.001% non-zero state posteriors
dengamma value 0.959018
backpointers: 24.4% edges have at least one /sil/ unit inside
forwardbackward: 18.090% non-zero state posteriors
dengamma value 0.978267
backpointers: 22.8% edges have at least one /sil/ unit inside
forwardbackward: 22.328% non-zero state posteriors
dengamma value 1.063423
backpointers: 27.4% edges have at least one /sil/ unit inside
forwardbackward: 15.259% non-zero state posteriors
dengamma value 1.042888
backpointers: 45.2% edges have at least one /sil/ unit inside
forwardbackward: 13.585% non-zero state posteriors
dengamma value 0.995778
backpointers: 40.1% edges have at least one /sil/ unit inside
forwardbackward: 17.937% non-zero state posteriors
dengamma value 0.970537
backpointers: 30.6% edges have at least one /sil/ unit inside
forwardbackward: 15.860% non-zero state posteriors
dengamma value 0.966177
backpointers: 38.1% edges have at least one /sil/ unit inside
forwardbackward: 17.394% non-zero state posteriors
dengamma value 1.047961
backpointers: 34.9% edges have at least one /sil/ unit inside
forwardbackward: 15.290% non-zero state posteriors
dengamma value 0.905251
backpointers: 33.9% edges have at least one /sil/ unit inside
forwardbackward: 14.328% non-zero state posteriors
dengamma value 0.984906
backpointers: 35.2% edges have at least one /sil/ unit inside
forwardbackward: 16.874% non-zero state posteriors
dengamma value 0.961751
 Epoch[ 3 of 3]-Minibatch[  41-  50, 0.61%]: SamplesSeen = 6544; TrainLossPerSample =  0.06789736; EvalErr[0]PerSample = 0.39807457; TotalTime = 3.6946s; SamplesPerSecond = 1771.2
backpointers: 41.9% edges have at least one /sil/ unit inside
forwardbackward: 10.784% non-zero state posteriors
dengamma value 0.889906
backpointers: 34.6% edges have at least one /sil/ unit inside
forwardbackward: 15.112% non-zero state posteriors
dengamma value 0.911062
backpointers: 38.4% edges have at least one /sil/ unit inside
forwardbackward: 8.704% non-zero state posteriors
dengamma value 1.055247
backpointers: 24.2% edges have at least one /sil/ unit inside
forwardbackward: 21.617% non-zero state posteriors
dengamma value 1.072297
backpointers: 37.1% edges have at least one /sil/ unit inside
forwardbackward: 18.622% non-zero state posteriors
dengamma value 1.016728
backpointers: 27.8% edges have at least one /sil/ unit inside
forwardbackward: 20.977% non-zero state posteriors
dengamma value 1.018531
backpointers: 31.0% edges have at least one /sil/ unit inside
forwardbackward: 18.253% non-zero state posteriors
dengamma value 0.963953
backpointers: 28.7% edges have at least one /sil/ unit inside
forwardbackward: 18.850% non-zero state posteriors
dengamma value 1.032848
backpointers: 35.4% edges have at least one /sil/ unit inside
forwardbackward: 17.424% non-zero state posteriors
dengamma value 0.976640
backpointers: 36.9% edges have at least one /sil/ unit inside
forwardbackward: 20.198% non-zero state posteriors
dengamma value 0.994733
backpointers: 28.0% edges have at least one /sil/ unit inside
forwardbackward: 21.508% non-zero state posteriors
dengamma value 0.990332
backpointers: 35.5% edges have at least one /sil/ unit inside
forwardbackward: 18.936% non-zero state posteriors
dengamma value 0.988526
backpointers: 35.9% edges have at least one /sil/ unit inside
forwardbackward: 17.665% non-zero state posteriors
dengamma value 0.932752
backpointers: 32.5% edges have at least one /sil/ unit inside
forwardbackward: 19.007% non-zero state posteriors
dengamma value 1.055388
backpointers: 36.8% edges have at least one /sil/ unit inside
forwardbackward: 21.882% non-zero state posteriors
dengamma value 0.991949
backpointers: 39.3% edges have at least one /sil/ unit inside
forwardbackward: 13.664% non-zero state posteriors
dengamma value 0.919267
backpointers: 32.0% edges have at least one /sil/ unit inside
forwardbackward: 18.840% non-zero state posteriors
dengamma value 1.062065
backpointers: 37.3% edges have at least one /sil/ unit inside
forwardbackward: 18.632% non-zero state posteriors
dengamma value 0.987227
backpointers: 32.1% edges have at least one /sil/ unit inside
forwardbackward: 17.108% non-zero state posteriors
dengamma value 0.983142
backpointers: 29.0% edges have at least one /sil/ unit inside
forwardbackward: 11.070% non-zero state posteriors
dengamma value 1.040576
backpointers: 44.5% edges have at least one /sil/ unit inside
forwardbackward: 12.546% non-zero state posteriors
dengamma value 1.010644
backpointers: 32.3% edges have at least one /sil/ unit inside
forwardbackward: 16.062% non-zero state posteriors
dengamma value 0.983431
backpointers: 27.8% edges have at least one /sil/ unit inside
forwardbackward: 21.485% non-zero state posteriors
dengamma value 0.993048
backpointers: 30.6% edges have at least one /sil/ unit inside
forwardbackward: 17.084% non-zero state posteriors
dengamma value 0.920395
backpointers: 45.2% edges have at least one /sil/ unit inside
forwardbackward: 10.195% non-zero state posteriors
dengamma value 0.921420
 Epoch[ 3 of 3]-Minibatch[  51-  60, 0.73%]: SamplesSeen = 5990; TrainLossPerSample =  0.07992337; EvalErr[0]PerSample = 0.40550918; TotalTime = 3.7086s; SamplesPerSecond = 1615.2
backpointers: 27.9% edges have at least one /sil/ unit inside
forwardbackward: 23.769% non-zero state posteriors
dengamma value 1.054971
backpointers: 34.4% edges have at least one /sil/ unit inside
forwardbackward: 18.243% non-zero state posteriors
dengamma value 0.927954
backpointers: 34.9% edges have at least one /sil/ unit inside
forwardbackward: 18.690% non-zero state posteriors
dengamma value 0.974734
backpointers: 31.3% edges have at least one /sil/ unit inside
forwardbackward: 15.674% non-zero state posteriors
dengamma value 1.015928
backpointers: 29.2% edges have at least one /sil/ unit inside
forwardbackward: 17.695% non-zero state posteriors
dengamma value 1.023674
backpointers: 40.8% edges have at least one /sil/ unit inside
forwardbackward: 14.957% non-zero state posteriors
dengamma value 1.021645
backpointers: 30.3% edges have at least one /sil/ unit inside
forwardbackward: 20.038% non-zero state posteriors
dengamma value 1.035692
backpointers: 29.1% edges have at least one /sil/ unit inside
forwardbackward: 16.434% non-zero state posteriors
dengamma value 0.971339
backpointers: 32.5% edges have at least one /sil/ unit inside
forwardbackward: 20.080% non-zero state posteriors
dengamma value 1.013421
backpointers: 41.3% edges have at least one /sil/ unit inside
forwardbackward: 13.173% non-zero state posteriors
dengamma value 0.977271
backpointers: 23.0% edges have at least one /sil/ unit inside
forwardbackward: 22.508% non-zero state posteriors
dengamma value 1.085021
backpointers: 38.4% edges have at least one /sil/ unit inside
forwardbackward: 21.382% non-zero state posteriors
dengamma value 1.015707
backpointers: 30.7% edges have at least one /sil/ unit inside
forwardbackward: 18.854% non-zero state posteriors
dengamma value 1.013090
backpointers: 27.7% edges have at least one /sil/ unit inside
forwardbackward: 21.327% non-zero state posteriors
dengamma value 1.032174
backpointers: 35.8% edges have at least one /sil/ unit inside
forwardbackward: 16.472% non-zero state posteriors
dengamma value 0.976797
backpointers: 26.8% edges have at least one /sil/ unit inside
forwardbackward: 18.684% non-zero state posteriors
dengamma value 0.982836
backpointers: 35.7% edges have at least one /sil/ unit inside
forwardbackward: 12.386% non-zero state posteriors
dengamma value 0.998465
backpointers: 34.8% edges have at least one /sil/ unit inside
forwardbackward: 13.965% non-zero state posteriors
dengamma value 1.000492
backpointers: 38.3% edges have at least one /sil/ unit inside
forwardbackward: 17.942% non-zero state posteriors
dengamma value 0.983673
backpointers: 31.6% edges have at least one /sil/ unit inside
forwardbackward: 16.437% non-zero state posteriors
dengamma value 1.051922
backpointers: 20.9% edges have at least one /sil/ unit inside
forwardbackward: 21.263% non-zero state posteriors
dengamma value 1.054059
backpointers: 33.8% edges have at least one /sil/ unit inside
forwardbackward: 15.935% non-zero state posteriors
dengamma value 1.041422
backpointers: 34.1% edges have at least one /sil/ unit inside
forwardbackward: 16.114% non-zero state posteriors
dengamma value 1.029916
backpointers: 25.3% edges have at least one /sil/ unit inside
forwardbackward: 17.909% non-zero state posteriors
dengamma value 0.946899
backpointers: 27.6% edges have at least one /sil/ unit inside
forwardbackward: 23.164% non-zero state posteriors
dengamma value 1.031639
backpointers: 39.7% edges have at least one /sil/ unit inside
forwardbackward: 14.928% non-zero state posteriors
dengamma value 0.981951
 Epoch[ 3 of 3]-Minibatch[  61-  70, 0.85%]: SamplesSeen = 7018; TrainLossPerSample =  0.07497872; EvalErr[0]PerSample = 0.35722428; TotalTime = 4.4373s; SamplesPerSecond = 1581.6
backpointers: 27.2% edges have at least one /sil/ unit inside
forwardbackward: 21.991% non-zero state posteriors
dengamma value 0.971901
backpointers: 29.4% edges have at least one /sil/ unit inside
forwardbackward: 16.787% non-zero state posteriors
dengamma value 0.977996
backpointers: 33.2% edges have at least one /sil/ unit inside
forwardbackward: 20.569% non-zero state posteriors
dengamma value 1.009591
backpointers: 26.6% edges have at least one /sil/ unit inside
forwardbackward: 19.889% non-zero state posteriors
dengamma value 1.095419
backpointers: 31.8% edges have at least one /sil/ unit inside
forwardbackward: 20.124% non-zero state posteriors
dengamma value 0.982223
backpointers: 31.4% edges have at least one /sil/ unit inside
forwardbackward: 19.097% non-zero state posteriors
dengamma value 1.009286
backpointers: 37.3% edges have at least one /sil/ unit inside
forwardbackward: 18.320% non-zero state posteriors
dengamma value 0.971823
backpointers: 28.7% edges have at least one /sil/ unit inside
forwardbackward: 22.480% non-zero state posteriors
dengamma value 1.042746
backpointers: 39.6% edges have at least one /sil/ unit inside
forwardbackward: 15.591% non-zero state posteriors
dengamma value 0.946719
backpointers: 28.7% edges have at least one /sil/ unit inside
forwardbackward: 14.201% non-zero state posteriors
dengamma value 1.009013
backpointers: 32.8% edges have at least one /sil/ unit inside
forwardbackward: 17.920% non-zero state posteriors
dengamma value 1.058315
backpointers: 31.9% edges have at least one /sil/ unit inside
forwardbackward: 17.152% non-zero state posteriors
dengamma value 1.031433
backpointers: 35.0% edges have at least one /sil/ unit inside
forwardbackward: 21.930% non-zero state posteriors
dengamma value 1.014554
backpointers: 25.5% edges have at least one /sil/ unit inside
forwardbackward: 26.883% non-zero state posteriors
dengamma value 1.011524
backpointers: 27.6% edges have at least one /sil/ unit inside
forwardbackward: 13.232% non-zero state posteriors
dengamma value 1.027013
backpointers: 34.1% edges have at least one /sil/ unit inside
forwardbackward: 16.460% non-zero state posteriors
dengamma value 1.020668
backpointers: 32.7% edges have at least one /sil/ unit inside
forwardbackward: 22.657% non-zero state posteriors
dengamma value 0.937126
backpointers: 35.6% edges have at least one /sil/ unit inside
forwardbackward: 13.926% non-zero state posteriors
dengamma value 0.997265
backpointers: 40.3% edges have at least one /sil/ unit inside
forwardbackward: 13.499% non-zero state posteriors
dengamma value 0.952476
backpointers: 38.7% edges have at least one /sil/ unit inside
forwardbackward: 14.575% non-zero state posteriors
dengamma value 0.967284
backpointers: 35.9% edges have at least one /sil/ unit inside
forwardbackward: 21.855% non-zero state posteriors
dengamma value 1.078110
backpointers: 35.4% edges have at least one /sil/ unit inside
forwardbackward: 16.733% non-zero state posteriors
dengamma value 0.977650
 Epoch[ 3 of 3]-Minibatch[  71-  80, 0.98%]: SamplesSeen = 5786; TrainLossPerSample =  0.07623989; EvalErr[0]PerSample = 0.37245074; TotalTime = 3.8962s; SamplesPerSecond = 1485.0
backpointers: 44.8% edges have at least one /sil/ unit inside
forwardbackward: 14.978% non-zero state posteriors
dengamma value 0.985283
backpointers: 34.4% edges have at least one /sil/ unit inside
forwardbackward: 16.601% non-zero state posteriors
dengamma value 1.019422
backpointers: 38.7% edges have at least one /sil/ unit inside
forwardbackward: 11.269% non-zero state posteriors
dengamma value 0.926442
backpointers: 27.1% edges have at least one /sil/ unit inside
forwardbackward: 22.066% non-zero state posteriors
dengamma value 1.070668
backpointers: 39.3% edges have at least one /sil/ unit inside
forwardbackward: 13.869% non-zero state posteriors
dengamma value 0.968253
backpointers: 40.7% edges have at least one /sil/ unit inside
forwardbackward: 12.967% non-zero state posteriors
dengamma value 0.943274
backpointers: 40.0% edges have at least one /sil/ unit inside
forwardbackward: 12.964% non-zero state posteriors
dengamma value 0.955694
backpointers: 36.6% edges have at least one /sil/ unit inside
forwardbackward: 18.411% non-zero state posteriors
dengamma value 0.942719
backpointers: 29.8% edges have at least one /sil/ unit inside
forwardbackward: 18.519% non-zero state posteriors
dengamma value 1.005138
backpointers: 41.4% edges have at least one /sil/ unit inside
forwardbackward: 13.994% non-zero state posteriors
dengamma value 0.946717
backpointers: 34.8% edges have at least one /sil/ unit inside
forwardbackward: 12.781% non-zero state posteriors
dengamma value 0.974310
backpointers: 37.8% edges have at least one /sil/ unit inside
forwardbackward: 7.494% non-zero state posteriors
dengamma value 1.142674
backpointers: 31.8% edges have at least one /sil/ unit inside
forwardbackward: 14.534% non-zero state posteriors
dengamma value 1.030479
backpointers: 29.0% edges have at least one /sil/ unit inside
forwardbackward: 22.023% non-zero state posteriors
dengamma value 1.024314
backpointers: 31.4% edges have at least one /sil/ unit inside
forwardbackward: 19.000% non-zero state posteriors
dengamma value 1.035170
backpointers: 33.1% edges have at least one /sil/ unit inside
forwardbackward: 14.962% non-zero state posteriors
dengamma value 1.013374
backpointers: 35.5% edges have at least one /sil/ unit inside
forwardbackward: 22.953% non-zero state posteriors
dengamma value 0.962945
backpointers: 36.2% edges have at least one /sil/ unit inside
forwardbackward: 14.359% non-zero state posteriors
dengamma value 1.143775
backpointers: 33.1% edges have at least one /sil/ unit inside
forwardbackward: 16.522% non-zero state posteriors
dengamma value 1.058482
backpointers: 39.6% edges have at least one /sil/ unit inside
forwardbackward: 15.869% non-zero state posteriors
dengamma value 1.004967
backpointers: 31.2% edges have at least one /sil/ unit inside
forwardbackward: 18.593% non-zero state posteriors
dengamma value 0.971625
backpointers: 34.6% edges have at least one /sil/ unit inside
forwardbackward: 17.014% non-zero state posteriors
dengamma value 1.039777
backpointers: 34.2% edges have at least one /sil/ unit inside
forwardbackward: 17.329% non-zero state posteriors
dengamma value 0.985207
 Epoch[ 3 of 3]-Minibatch[  81-  90, 1.10%]: SamplesSeen = 6304; TrainLossPerSample =  0.05832475; EvalErr[0]PerSample = 0.41545051; TotalTime = 3.1690s; SamplesPerSecond = 1989.3
backpointers: 33.5% edges have at least one /sil/ unit inside
forwardbackward: 16.421% non-zero state posteriors
dengamma value 1.019834
backpointers: 30.4% edges have at least one /sil/ unit inside
forwardbackward: 17.873% non-zero state posteriors
dengamma value 1.072611
backpointers: 28.8% edges have at least one /sil/ unit inside
forwardbackward: 15.986% non-zero state posteriors
dengamma value 1.092174
backpointers: 37.7% edges have at least one /sil/ unit inside
forwardbackward: 14.381% non-zero state posteriors
dengamma value 0.988667
backpointers: 34.1% edges have at least one /sil/ unit inside
forwardbackward: 18.750% non-zero state posteriors
dengamma value 0.986916
backpointers: 33.3% edges have at least one /sil/ unit inside
forwardbackward: 19.121% non-zero state posteriors
dengamma value 0.989916
backpointers: 30.1% edges have at least one /sil/ unit inside
forwardbackward: 8.841% non-zero state posteriors
dengamma value 0.996487
backpointers: 32.8% edges have at least one /sil/ unit inside
forwardbackward: 18.457% non-zero state posteriors
dengamma value 0.971318
backpointers: 29.9% edges have at least one /sil/ unit inside
forwardbackward: 20.111% non-zero state posteriors
dengamma value 1.009676
backpointers: 29.3% edges have at least one /sil/ unit inside
forwardbackward: 20.285% non-zero state posteriors
dengamma value 1.058029
backpointers: 36.4% edges have at least one /sil/ unit inside
forwardbackward: 15.244% non-zero state posteriors
dengamma value 1.059440
backpointers: 33.2% edges have at least one /sil/ unit inside
forwardbackward: 15.439% non-zero state posteriors
dengamma value 0.976855
backpointers: 25.0% edges have at least one /sil/ unit inside
forwardbackward: 17.927% non-zero state posteriors
dengamma value 0.963273
backpointers: 34.0% edges have at least one /sil/ unit inside
forwardbackward: 20.200% non-zero state posteriors
dengamma value 1.004843
backpointers: 35.1% edges have at least one /sil/ unit inside
forwardbackward: 17.313% non-zero state posteriors
dengamma value 0.962990
backpointers: 33.7% edges have at least one /sil/ unit inside
forwardbackward: 17.222% non-zero state posteriors
dengamma value 1.067249
backpointers: 38.2% edges have at least one /sil/ unit inside
forwardbackward: 13.080% non-zero state posteriors
dengamma value 0.933320
backpointers: 39.3% edges have at least one /sil/ unit inside
forwardbackward: 19.839% non-zero state posteriors
dengamma value 1.069617
backpointers: 30.0% edges have at least one /sil/ unit inside
forwardbackward: 19.828% non-zero state posteriors
dengamma value 0.998767
backpointers: 33.1% edges have at least one /sil/ unit inside
forwardbackward: 18.351% non-zero state posteriors
dengamma value 0.966656
backpointers: 33.4% edges have at least one /sil/ unit inside
forwardbackward: 12.244% non-zero state posteriors
dengamma value 0.994526
backpointers: 23.9% edges have at least one /sil/ unit inside
forwardbackward: 19.402% non-zero state posteriors
dengamma value 1.055697
backpointers: 30.8% edges have at least one /sil/ unit inside
forwardbackward: 18.448% non-zero state posteriors
dengamma value 0.998461
backpointers: 29.6% edges have at least one /sil/ unit inside
forwardbackward: 15.634% non-zero state posteriors
dengamma value 0.968990
 Epoch[ 3 of 3]-Minibatch[  91- 100, 1.22%]: SamplesSeen = 5482; TrainLossPerSample =  0.07875526; EvalErr[0]PerSample = 0.37686976; TotalTime = 3.1673s; SamplesPerSecond = 1730.8
backpointers: 31.6% edges have at least one /sil/ unit inside
forwardbackward: 18.908% non-zero state posteriors
dengamma value 1.021529
backpointers: 32.6% edges have at least one /sil/ unit inside
forwardbackward: 20.419% non-zero state posteriors
dengamma value 1.062875
backpointers: 32.5% edges have at least one /sil/ unit inside
forwardbackward: 11.310% non-zero state posteriors
dengamma value 1.032630
backpointers: 31.6% edges have at least one /sil/ unit inside
forwardbackward: 17.952% non-zero state posteriors
dengamma value 1.048452
backpointers: 26.8% edges have at least one /sil/ unit inside
forwardbackward: 19.878% non-zero state posteriors
dengamma value 0.969140
backpointers: 33.4% edges have at least one /sil/ unit inside
forwardbackward: 16.605% non-zero state posteriors
dengamma value 1.103034
backpointers: 35.9% edges have at least one /sil/ unit inside
forwardbackward: 15.816% non-zero state posteriors
dengamma value 0.956990
backpointers: 32.9% edges have at least one /sil/ unit inside
forwardbackward: 20.532% non-zero state posteriors
dengamma value 0.994699
backpointers: 38.4% edges have at least one /sil/ unit inside
forwardbackward: 15.644% non-zero state posteriors
dengamma value 0.986613
backpointers: 31.6% edges have at least one /sil/ unit inside
forwardbackward: 13.672% non-zero state posteriors
dengamma value 1.000161
backpointers: 19.9% edges have at least one /sil/ unit inside
forwardbackward: 23.541% non-zero state posteriors
dengamma value 1.058666
backpointers: 28.8% edges have at least one /sil/ unit inside
forwardbackward: 18.411% non-zero state posteriors
dengamma value 1.034549
backpointers: 44.8% edges have at least one /sil/ unit inside
forwardbackward: 10.568% non-zero state posteriors
dengamma value 0.978641
backpointers: 37.8% edges have at least one /sil/ unit inside
forwardbackward: 14.713% non-zero state posteriors
dengamma value 0.994611
backpointers: 31.5% edges have at least one /sil/ unit inside
forwardbackward: 17.709% non-zero state posteriors
dengamma value 1.049218
backpointers: 30.4% edges have at least one /sil/ unit inside
forwardbackward: 18.305% non-zero state posteriors
dengamma value 1.001317
backpointers: 26.9% edges have at least one /sil/ unit inside
forwardbackward: 20.725% non-zero state posteriors
dengamma value 1.028832
backpointers: 34.8% edges have at least one /sil/ unit inside
forwardbackward: 20.201% non-zero state posteriors
dengamma value 0.970147
backpointers: 41.0% edges have at least one /sil/ unit inside
forwardbackward: 13.406% non-zero state posteriors
dengamma value 1.014279
backpointers: 44.4% edges have at least one /sil/ unit inside
forwardbackward: 13.297% non-zero state posteriors
dengamma value 1.007467
backpointers: 26.0% edges have at least one /sil/ unit inside
forwardbackward: 26.379% non-zero state posteriors
dengamma value 1.058413
backpointers: 32.9% edges have at least one /sil/ unit inside
forwardbackward: 15.467% non-zero state posteriors
dengamma value 1.039481
backpointers: 25.9% edges have at least one /sil/ unit inside
forwardbackward: 21.323% non-zero state posteriors
dengamma value 1.060857
 Epoch[ 3 of 3]-Minibatch[ 101- 110, 1.34%]: SamplesSeen = 6974; TrainLossPerSample =  0.06461164; EvalErr[0]PerSample = 0.35833094; TotalTime = 4.4772s; SamplesPerSecond = 1557.7
backpointers: 32.4% edges have at least one /sil/ unit inside
forwardbackward: 18.843% non-zero state posteriors
dengamma value 0.975989
backpointers: 30.9% edges have at least one /sil/ unit inside
forwardbackward: 19.040% non-zero state posteriors
dengamma value 0.982310
backpointers: 35.4% edges have at least one /sil/ unit inside
forwardbackward: 13.942% non-zero state posteriors
dengamma value 0.975508
backpointers: 34.5% edges have at least one /sil/ unit inside
forwardbackward: 16.460% non-zero state posteriors
dengamma value 1.045030
backpointers: 36.2% edges have at least one /sil/ unit inside
forwardbackward: 15.890% non-zero state posteriors
dengamma value 0.985443
backpointers: 35.4% edges have at least one /sil/ unit inside
forwardbackward: 11.812% non-zero state posteriors
dengamma value 0.949522
backpointers: 31.3% edges have at least one /sil/ unit inside
forwardbackward: 20.086% non-zero state posteriors
dengamma value 1.069781
backpointers: 25.0% edges have at least one /sil/ unit inside
forwardbackward: 20.614% non-zero state posteriors
dengamma value 1.025791
backpointers: 26.9% edges have at least one /sil/ unit inside
forwardbackward: 22.409% non-zero state posteriors
dengamma value 1.011332
backpointers: 34.7% edges have at least one /sil/ unit inside
forwardbackward: 17.966% non-zero state posteriors
dengamma value 1.037024
backpointers: 31.6% edges have at least one /sil/ unit inside
forwardbackward: 17.621% non-zero state posteriors
dengamma value 0.943614
backpointers: 37.3% edges have at least one /sil/ unit inside
forwardbackward: 13.990% non-zero state posteriors
dengamma value 1.027573
backpointers: 36.1% edges have at least one /sil/ unit inside
forwardbackward: 17.377% non-zero state posteriors
dengamma value 1.075191
backpointers: 22.6% edges have at least one /sil/ unit inside
forwardbackward: 24.532% non-zero state posteriors
dengamma value 1.012444
backpointers: 29.1% edges have at least one /sil/ unit inside
forwardbackward: 22.817% non-zero state posteriors
dengamma value 1.062746
backpointers: 25.8% edges have at least one /sil/ unit inside
forwardbackward: 25.518% non-zero state posteriors
dengamma value 0.996866
backpointers: 33.4% edges have at least one /sil/ unit inside
forwardbackward: 13.426% non-zero state posteriors
dengamma value 1.016018
backpointers: 32.0% edges have at least one /sil/ unit inside
forwardbackward: 13.389% non-zero state posteriors
dengamma value 0.988856
backpointers: 33.8% edges have at least one /sil/ unit inside
forwardbackward: 18.468% non-zero state posteriors
dengamma value 1.012644
backpointers: 32.9% edges have at least one /sil/ unit inside
forwardbackward: 22.155% non-zero state posteriors
dengamma value 1.009146
backpointers: 36.3% edges have at least one /sil/ unit inside
forwardbackward: 16.272% non-zero state posteriors
dengamma value 1.064718
backpointers: 26.3% edges have at least one /sil/ unit inside
forwardbackward: 22.173% non-zero state posteriors
dengamma value 1.049129
 Epoch[ 3 of 3]-Minibatch[ 111- 120, 1.46%]: SamplesSeen = 6046; TrainLossPerSample =  0.07576880; EvalErr[0]PerSample = 0.35891499; TotalTime = 4.0566s; SamplesPerSecond = 1490.4
backpointers: 29.8% edges have at least one /sil/ unit inside
forwardbackward: 21.937% non-zero state posteriors
dengamma value 1.017177
backpointers: 53.7% edges have at least one /sil/ unit inside
forwardbackward: 9.113% non-zero state posteriors
dengamma value 0.995258
backpointers: 34.0% edges have at least one /sil/ unit inside
forwardbackward: 24.044% non-zero state posteriors
dengamma value 1.084597
backpointers: 38.6% edges have at least one /sil/ unit inside
forwardbackward: 16.996% non-zero state posteriors
dengamma value 1.063429
backpointers: 33.4% edges have at least one /sil/ unit inside
forwardbackward: 17.932% non-zero state posteriors
dengamma value 0.965916
backpointers: 38.1% edges have at least one /sil/ unit inside
forwardbackward: 16.082% non-zero state posteriors
dengamma value 1.031251
backpointers: 33.5% edges have at least one /sil/ unit inside
forwardbackward: 19.372% non-zero state posteriors
dengamma value 1.073415
backpointers: 30.8% edges have at least one /sil/ unit inside
forwardbackward: 17.683% non-zero state posteriors
dengamma value 0.993549
backpointers: 31.7% edges have at least one /sil/ unit inside
forwardbackward: 18.173% non-zero state posteriors
dengamma value 1.035143
backpointers: 31.4% edges have at least one /sil/ unit inside
forwardbackward: 21.369% non-zero state posteriors
dengamma value 0.973349
backpointers: 38.2% edges have at least one /sil/ unit inside
forwardbackward: 13.076% non-zero state posteriors
dengamma value 1.029502
backpointers: 38.2% edges have at least one /sil/ unit inside
forwardbackward: 13.777% non-zero state posteriors
dengamma value 1.065615
backpointers: 38.6% edges have at least one /sil/ unit inside
forwardbackward: 17.709% non-zero state posteriors
dengamma value 1.017712
backpointers: 37.2% edges have at least one /sil/ unit inside
forwardbackward: 14.598% non-zero state posteriors
dengamma value 1.000863
backpointers: 37.5% edges have at least one /sil/ unit inside
forwardbackward: 19.568% non-zero state posteriors
dengamma value 1.015665
backpointers: 29.9% edges have at least one /sil/ unit inside
forwardbackward: 21.456% non-zero state posteriors
dengamma value 1.056173
backpointers: 32.8% edges have at least one /sil/ unit inside
forwardbackward: 16.691% non-zero state posteriors
dengamma value 1.027903
backpointers: 34.1% edges have at least one /sil/ unit inside
forwardbackward: 21.436% non-zero state posteriors
dengamma value 1.083221
backpointers: 30.7% edges have at least one /sil/ unit inside
forwardbackward: 19.792% non-zero state posteriors
dengamma value 1.029501
backpointers: 35.3% edges have at least one /sil/ unit inside
forwardbackward: 14.630% non-zero state posteriors
dengamma value 0.938132
backpointers: 33.9% edges have at least one /sil/ unit inside
forwardbackward: 20.126% non-zero state posteriors
dengamma value 0.985676
backpointers: 33.3% edges have at least one /sil/ unit inside
forwardbackward: 14.262% non-zero state posteriors
dengamma value 1.021170
 Epoch[ 3 of 3]-Minibatch[ 121- 130, 1.59%]: SamplesSeen = 5926; TrainLossPerSample =  0.06992417; EvalErr[0]PerSample = 0.37478907; TotalTime = 3.9638s; SamplesPerSecond = 1495.0
backpointers: 35.8% edges have at least one /sil/ unit inside
forwardbackward: 14.887% non-zero state posteriors
dengamma value 1.027675
backpointers: 34.9% edges have at least one /sil/ unit inside
forwardbackward: 16.943% non-zero state posteriors
dengamma value 0.998924
backpointers: 40.3% edges have at least one /sil/ unit inside
forwardbackward: 12.872% non-zero state posteriors
dengamma value 0.973258
backpointers: 31.2% edges have at least one /sil/ unit inside
forwardbackward: 17.604% non-zero state posteriors
dengamma value 1.058437
backpointers: 37.8% edges have at least one /sil/ unit inside
forwardbackward: 15.329% non-zero state posteriors
dengamma value 1.038268
backpointers: 31.2% edges have at least one /sil/ unit inside
forwardbackward: 17.604% non-zero state posteriors
dengamma value 1.058437
Finished Epoch[ 3 of 3]: [Training Set] TrainLossPerSample = 0.072065845; EvalErrPerSample = 0.37949017; AvgLearningRatePerSample = 2e-06; EpochTime=51.4348
CNTKCommandTrainEnd: sequenceTrain
COMPLETED
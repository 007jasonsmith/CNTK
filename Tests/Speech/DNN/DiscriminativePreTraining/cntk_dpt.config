precision=float
deviceId=$DeviceId$
command=DPT_Pre1:AddLayer2:DPT_Pre2:AddLayer3:speechTrain

ndlMacros=$ConfigDir$/macros.txt

GlobalMean=GlobalStats/mean.363
GlobalInvStd=GlobalStats/var.363
GlobalPrior=GlobalStats/prior.132

traceLevel=1

# Default SGD value used for pre-training.
SGD=[
    epochSize=81920
    minibatchSize=256
    learningRatesPerMB=0.8
    numMBsToShowResult=10
    momentumPerMB=0.9
    dropoutRate=0.0
    maxEpochs=2
]

DPT_Pre1=[
    action=train
    modelPath=$RunDir$/models/Pre1/cntkSpeech

    NDLNetworkBuilder=[
        networkDescription=$ConfigDir$/dnn_1layer.txt
    ]
]

AddLayer2=[    
    action=edit
    CurrLayer=1
    NewLayer=2
    CurrModel=$RunDir$/models/Pre1/cntkSpeech
    NewModel=$RunDir$/models/Pre2/cntkSpeech.0
    editPath=$ConfigDir$/add_layer.mel
]

DPT_Pre2=[
    action=train
    modelPath=$RunDir$/models/Pre2/cntkSpeech

    NDLNetworkBuilder=[
        networkDescription=$ConfigDir$/dnn_1layer.txt
    ]
]

AddLayer3=[    
    action=edit
    CurrLayer=2
    NewLayer=3
    CurrModel=$RunDir$/models/Pre2/cntkSpeech
    NewModel=$RunDir$/models/cntkSpeech.0
    editPath=$ConfigDir$/add_layer.mel
]

speechTrain=[
    action=train
    modelPath=$RunDir$/models/cntkSpeech
    deviceId=$DeviceId$
    traceLevel=1

     NDLNetworkBuilder=[
        networkDescription=$ConfigDir$/dnn.txt
    ]
    
    SGD=[
        epochSize=81920
        minibatchSize=256:512
        learningRatesPerMB=0.8:1.6
        numMBsToShowResult=10
        momentumPerSample=0.999589
        dropoutRate=0.0
        maxEpochs=4
        
        gradUpdateType=None
        normWithAveMultiplier=true
        clippingThresholdPerSample=1#INF
    ]
]

reader=[
  readerType=HTKMLFReader
  readMethod=blockRandomize
  miniBatchMode=Partial
  randomize=Auto
  verbosity=0
  features=[
      dim=363
      type=Real
      scpFile=$DataDir$/glob_0000.scp
  ]
  
  labels=[
      mlfFile=$DataDir$/glob_0000.mlf
      labelMappingFile=$DataDir$/state.list
        
      labelDim=132
      labelType=Category
  ]
]

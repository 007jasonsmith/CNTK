=== Running /home/alrezni/src/cntk/build/release/bin/cntk configFile=/home/alrezni/src/cntk/Tests/Speech/SVD/cntk.config currentDirectory=/home/alrezni/src/cntk/Tests/Speech/Data RunDir=/tmp/cntk-test-20151215163714.581330/Speech_SVD@release_gpu DataDir=/home/alrezni/src/cntk/Tests/Speech/Data ConfigDir=/home/alrezni/src/cntk/Tests/Speech/SVD DeviceId=0
-------------------------------------------------------------------
Build info: 

		Built time: Dec 15 2015 16:32:52
		Last modified date: Tue Dec 15 16:31:42 2015
		Build type: release
		Math lib: acml
		CUDA_PATH: /usr/local/cuda-7.0
		CUB_PATH: /usr/local/cub-1.4.1
		Build Branch: master
		Build SHA1: 5e0017ac9c55c23d53cb524c8acb7d6d9bfd0269
-------------------------------------------------------------------
running on localhost at 2015/12/15 16:51:47
command line: 
/home/alrezni/src/cntk/build/release/bin/cntk configFile=/home/alrezni/src/cntk/Tests/Speech/SVD/cntk.config currentDirectory=/home/alrezni/src/cntk/Tests/Speech/Data RunDir=/tmp/cntk-test-20151215163714.581330/Speech_SVD@release_gpu DataDir=/home/alrezni/src/cntk/Tests/Speech/Data ConfigDir=/home/alrezni/src/cntk/Tests/Speech/SVD DeviceId=0 

>>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
precision=float
command=speechTrain:modelDecomposition:SVDTrain
deviceId=$DeviceId$
speechTrain=[
    action=train
    makeMode=false
    modelPath=$RunDir$/models/cntkSpeech.dnn
    deviceId=$DeviceId$
    traceLevel=1
    SimpleNetworkBuilder=[
        layerSizes=363:512:512:132
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ErrorPrediction
        layerTypes=Sigmoid
        applyMeanVarNorm=true
        initValueScale=1.0
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=20480
        minibatchSize=64:256:1024
        learningRatesPerMB=1.0:0.5:0.1
        numMBsToShowResult=10
        momentumPerMB=0.9:0.656119
        dropoutRate=0.0
        maxEpochs=3
        keepCheckPointFiles=false
        clippingThresholdPerSample=1#INF
    ]
]
reader=[
    readerType=HTKMLFReader
    readMethod=blockRandomize
    miniBatchMode=Partial
    randomize=Auto
    verbosity=0
    features=[
        dim=363
        type=Real
        scpFile=glob_0000.scp
    ]
    labels=[
        mlfFile=$DataDir$/glob_0000.mlf
        labelMappingFile=$DataDir$/state.list
        labelDim=132
        labelType=Category
    ]
]
modelDecomposition=[
    action=SVD
    modelPath=$RunDir$/models/cntkSpeech.dnn
    outputmodelPath=$RunDir$/models/cntkSpeech.svd.dnn.0
    KeepRatio=0.5
    NodeNameRegex=W.*
]
SVDTrain=[
    action=train
    makeMode=true
    modelPath=$RunDir$/models/cntkSpeech.svd.dnn
    deviceId=$DeviceId$
    traceLevel=1
    NDLNetworkBuilder=[
        NetworkDescription=$RunDir$/nonExistent.ndl
    ]
    SGD=[
        epochSize=20480
        minibatchSize=1024
        learningRatesPerMB=0.1
        numMBsToShowResult=10
        momentumPerMB=0.656119
        dropoutRate=0.0
        maxEpochs=2
        keepCheckPointFiles=false
        clippingThresholdPerSample=1#INF
    ]
]
currentDirectory=/home/alrezni/src/cntk/Tests/Speech/Data
RunDir=/tmp/cntk-test-20151215163714.581330/Speech_SVD@release_gpu
DataDir=/home/alrezni/src/cntk/Tests/Speech/Data
ConfigDir=/home/alrezni/src/cntk/Tests/Speech/SVD
DeviceId=0

<<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<

>>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
precision=float
command=speechTrain:modelDecomposition:SVDTrain
deviceId=0
speechTrain=[
    action=train
    makeMode=false
    modelPath=/tmp/cntk-test-20151215163714.581330/Speech_SVD@release_gpu/models/cntkSpeech.dnn
    deviceId=0
    traceLevel=1
    SimpleNetworkBuilder=[
        layerSizes=363:512:512:132
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ErrorPrediction
        layerTypes=Sigmoid
        applyMeanVarNorm=true
        initValueScale=1.0
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=20480
        minibatchSize=64:256:1024
        learningRatesPerMB=1.0:0.5:0.1
        numMBsToShowResult=10
        momentumPerMB=0.9:0.656119
        dropoutRate=0.0
        maxEpochs=3
        keepCheckPointFiles=false
        clippingThresholdPerSample=1#INF
    ]
]
reader=[
    readerType=HTKMLFReader
    readMethod=blockRandomize
    miniBatchMode=Partial
    randomize=Auto
    verbosity=0
    features=[
        dim=363
        type=Real
        scpFile=glob_0000.scp
    ]
    labels=[
        mlfFile=/home/alrezni/src/cntk/Tests/Speech/Data/glob_0000.mlf
        labelMappingFile=/home/alrezni/src/cntk/Tests/Speech/Data/state.list
        labelDim=132
        labelType=Category
    ]
]
modelDecomposition=[
    action=SVD
    modelPath=/tmp/cntk-test-20151215163714.581330/Speech_SVD@release_gpu/models/cntkSpeech.dnn
    outputmodelPath=/tmp/cntk-test-20151215163714.581330/Speech_SVD@release_gpu/models/cntkSpeech.svd.dnn.0
    KeepRatio=0.5
    NodeNameRegex=W.*
]
SVDTrain=[
    action=train
    makeMode=true
    modelPath=/tmp/cntk-test-20151215163714.581330/Speech_SVD@release_gpu/models/cntkSpeech.svd.dnn
    deviceId=0
    traceLevel=1
    NDLNetworkBuilder=[
        NetworkDescription=/tmp/cntk-test-20151215163714.581330/Speech_SVD@release_gpu/nonExistent.ndl
    ]
    SGD=[
        epochSize=20480
        minibatchSize=1024
        learningRatesPerMB=0.1
        numMBsToShowResult=10
        momentumPerMB=0.656119
        dropoutRate=0.0
        maxEpochs=2
        keepCheckPointFiles=false
        clippingThresholdPerSample=1#INF
    ]
]
currentDirectory=/home/alrezni/src/cntk/Tests/Speech/Data
RunDir=/tmp/cntk-test-20151215163714.581330/Speech_SVD@release_gpu
DataDir=/home/alrezni/src/cntk/Tests/Speech/Data
ConfigDir=/home/alrezni/src/cntk/Tests/Speech/SVD
DeviceId=0

<<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<

>>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
configparameters: cntk.config:command=speechTrain:modelDecomposition:SVDTrain
configparameters: cntk.config:ConfigDir=/home/alrezni/src/cntk/Tests/Speech/SVD
configparameters: cntk.config:currentDirectory=/home/alrezni/src/cntk/Tests/Speech/Data
configparameters: cntk.config:DataDir=/home/alrezni/src/cntk/Tests/Speech/Data
configparameters: cntk.config:deviceId=0
configparameters: cntk.config:modelDecomposition=[
    action=SVD
    modelPath=/tmp/cntk-test-20151215163714.581330/Speech_SVD@release_gpu/models/cntkSpeech.dnn
    outputmodelPath=/tmp/cntk-test-20151215163714.581330/Speech_SVD@release_gpu/models/cntkSpeech.svd.dnn.0
    KeepRatio=0.5
    NodeNameRegex=W.*
]

configparameters: cntk.config:precision=float
configparameters: cntk.config:reader=[
    readerType=HTKMLFReader
    readMethod=blockRandomize
    miniBatchMode=Partial
    randomize=Auto
    verbosity=0
    features=[
        dim=363
        type=Real
        scpFile=glob_0000.scp
    ]
    labels=[
        mlfFile=/home/alrezni/src/cntk/Tests/Speech/Data/glob_0000.mlf
        labelMappingFile=/home/alrezni/src/cntk/Tests/Speech/Data/state.list
        labelDim=132
        labelType=Category
    ]
]

configparameters: cntk.config:RunDir=/tmp/cntk-test-20151215163714.581330/Speech_SVD@release_gpu
configparameters: cntk.config:speechTrain=[
    action=train
    makeMode=false
    modelPath=/tmp/cntk-test-20151215163714.581330/Speech_SVD@release_gpu/models/cntkSpeech.dnn
    deviceId=0
    traceLevel=1
    SimpleNetworkBuilder=[
        layerSizes=363:512:512:132
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ErrorPrediction
        layerTypes=Sigmoid
        applyMeanVarNorm=true
        initValueScale=1.0
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=20480
        minibatchSize=64:256:1024
        learningRatesPerMB=1.0:0.5:0.1
        numMBsToShowResult=10
        momentumPerMB=0.9:0.656119
        dropoutRate=0.0
        maxEpochs=3
        keepCheckPointFiles=false
        clippingThresholdPerSample=1#INF
    ]
]

configparameters: cntk.config:SVDTrain=[
    action=train
    makeMode=true
    modelPath=/tmp/cntk-test-20151215163714.581330/Speech_SVD@release_gpu/models/cntkSpeech.svd.dnn
    deviceId=0
    traceLevel=1
    NDLNetworkBuilder=[
        NetworkDescription=/tmp/cntk-test-20151215163714.581330/Speech_SVD@release_gpu/nonExistent.ndl
    ]
    SGD=[
        epochSize=20480
        minibatchSize=1024
        learningRatesPerMB=0.1
        numMBsToShowResult=10
        momentumPerMB=0.656119
        dropoutRate=0.0
        maxEpochs=2
        keepCheckPointFiles=false
        clippingThresholdPerSample=1#INF
    ]
]

<<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
command: speechTrain modelDecomposition SVDTrain 
precision = float
CNTKModelPath: /tmp/cntk-test-20151215163714.581330/Speech_SVD@release_gpu/models/cntkSpeech.dnn
CNTKCommandTrainInfo: speechTrain : 3
CNTKModelPath: /tmp/cntk-test-20151215163714.581330/Speech_SVD@release_gpu/models/cntkSpeech.svd.dnn
CNTKCommandTrainInfo: SVDTrain : 2
CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 5
CNTKCommandTrainBegin: speechTrain
SimpleNetworkBuilder Using GPU 0
reading script file glob_0000.scp ... 948 entries
total 132 state names in state list /home/alrezni/src/cntk/Tests/Speech/Data/state.list
htkmlfreader: reading MLF file /home/alrezni/src/cntk/Tests/Speech/Data/glob_0000.mlf ... total 948 entries
...............................................................................................feature set 0: 252734 frames in 948 out of 948 utterances
label set 0: 129 classes
minibatchutterancesource: 948 utterances grouped into 3 chunks, av. chunk size: 316.0 utterances, 84244.7 frames
SetUniformRandomValue (GPU): creating curand object with seed 1, sizeof(ElemType)==4

Post-processing network...

7 roots:
	MeanOfFeatures = Mean
	InvStdOfFeatures = InvStdDev
	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax
	EvalErrorPrediction = ErrorPrediction
	Prior = Mean
	ScaledLogLikelihood = Minus
	PosteriorProb = Softmax
FormNestedNetwork: WARNING: Was called twice for MeanOfFeatures Mean operation
FormNestedNetwork: WARNING: Was called twice for InvStdOfFeatures InvStdDev operation
FormNestedNetwork: WARNING: Was called twice for CrossEntropyWithSoftmax CrossEntropyWithSoftmax operation
FormNestedNetwork: WARNING: Was called twice for EvalErrorPrediction ErrorPrediction operation
FormNestedNetwork: WARNING: Was called twice for Prior Mean operation
FormNestedNetwork: WARNING: Was called twice for ScaledLogLikelihood Minus operation
FormNestedNetwork: WARNING: Was called twice for PosteriorProb Softmax operation


Validating for node MeanOfFeatures. 2 nodes to process in pass 1.

Validating --> features = InputValue -> [363, MBSize 3]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 3]) -> [363, 1]

Validating for node MeanOfFeatures. 1 nodes to process in pass 2.

Validating --> features = InputValue -> [363, MBSize 3]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 3]) -> [363, 1]

Validating for node MeanOfFeatures, final verification.

Validating --> features = InputValue -> [363, MBSize 3]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 3]) -> [363, 1]

1 out of 2 nodes do not share the minibatch layout with the input data.


Validating for node InvStdOfFeatures. 2 nodes to process in pass 1.

Validating --> features = InputValue -> [363, MBSize 3]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 3]) -> [363, 1]

Validating for node InvStdOfFeatures. 1 nodes to process in pass 2.

Validating --> features = InputValue -> [363, MBSize 3]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 3]) -> [363, 1]

Validating for node InvStdOfFeatures, final verification.

Validating --> features = InputValue -> [363, MBSize 3]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 3]) -> [363, 1]

1 out of 2 nodes do not share the minibatch layout with the input data.


Validating for node CrossEntropyWithSoftmax. 20 nodes to process in pass 1.

Validating --> labels = InputValue -> [132, MBSize 3]
Validating --> W2 = LearnableParameter -> [132, 512]
Validating --> W1 = LearnableParameter -> [512, 512]
Validating --> W0 = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 3]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 3]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 3]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 3], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 3]
Validating --> W0*features = Times(W0[512, 363], MVNormalizedFeatures[363, MBSize 3]) -> [512, MBSize 3]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 3], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax(labels[132, MBSize 3], HLast[132, MBSize 0]) -> [1, 1]

Validating for node CrossEntropyWithSoftmax. 10 nodes to process in pass 2.

Validating --> labels = InputValue -> [132, MBSize 3]
Validating --> W2 = LearnableParameter -> [132, 512]
Validating --> W1 = LearnableParameter -> [512, 512]
Validating --> W0 = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 3]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 3]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 3]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 3], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 3]
Validating --> W0*features = Times(W0[512, 363], MVNormalizedFeatures[363, MBSize 3]) -> [512, MBSize 3]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 3], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax(labels[132, MBSize 3], HLast[132, MBSize 0]) -> [1, 1]

Validating for node CrossEntropyWithSoftmax, final verification.

Validating --> labels = InputValue -> [132, MBSize 3]
Validating --> W2 = LearnableParameter -> [132, 512]
Validating --> W1 = LearnableParameter -> [512, 512]
Validating --> W0 = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 3]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 3]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 3]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 3], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 3]
Validating --> W0*features = Times(W0[512, 363], MVNormalizedFeatures[363, MBSize 3]) -> [512, MBSize 3]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 3], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax(labels[132, MBSize 3], HLast[132, MBSize 0]) -> [1, 1]

9 out of 20 nodes do not share the minibatch layout with the input data.


Validating for node EvalErrorPrediction. 20 nodes to process in pass 1.

Validating --> labels = InputValue -> [132, MBSize 3]
Validating --> W2 = LearnableParameter -> [132, 512]
Validating --> W1 = LearnableParameter -> [512, 512]
Validating --> W0 = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 3]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 3]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 3]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 3], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 3]
Validating --> W0*features = Times(W0[512, 363], MVNormalizedFeatures[363, MBSize 3]) -> [512, MBSize 3]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 3], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> EvalErrorPrediction = ErrorPrediction(labels[132, MBSize 3], HLast[132, MBSize 0]) -> [1, 1]

Validating for node EvalErrorPrediction. 9 nodes to process in pass 2.

Validating --> labels = InputValue -> [132, MBSize 3]
Validating --> W2 = LearnableParameter -> [132, 512]
Validating --> W1 = LearnableParameter -> [512, 512]
Validating --> W0 = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 3]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 3]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 3]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 3], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 3]
Validating --> W0*features = Times(W0[512, 363], MVNormalizedFeatures[363, MBSize 3]) -> [512, MBSize 3]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 3], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> EvalErrorPrediction = ErrorPrediction(labels[132, MBSize 3], HLast[132, MBSize 0]) -> [1, 1]

Validating for node EvalErrorPrediction, final verification.

Validating --> labels = InputValue -> [132, MBSize 3]
Validating --> W2 = LearnableParameter -> [132, 512]
Validating --> W1 = LearnableParameter -> [512, 512]
Validating --> W0 = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 3]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 3]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 3]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 3], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 3]
Validating --> W0*features = Times(W0[512, 363], MVNormalizedFeatures[363, MBSize 3]) -> [512, MBSize 3]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 3], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> EvalErrorPrediction = ErrorPrediction(labels[132, MBSize 3], HLast[132, MBSize 0]) -> [1, 1]

9 out of 20 nodes do not share the minibatch layout with the input data.


Validating for node Prior. 2 nodes to process in pass 1.

Validating --> labels = InputValue -> [132, MBSize 3]
Validating --> Prior = Mean(labels[132, MBSize 3]) -> [132, 1]

Validating for node Prior. 1 nodes to process in pass 2.

Validating --> labels = InputValue -> [132, MBSize 3]
Validating --> Prior = Mean(labels[132, MBSize 3]) -> [132, 1]

Validating for node Prior, final verification.

Validating --> labels = InputValue -> [132, MBSize 3]
Validating --> Prior = Mean(labels[132, MBSize 3]) -> [132, 1]

1 out of 2 nodes do not share the minibatch layout with the input data.


Validating for node ScaledLogLikelihood. 22 nodes to process in pass 1.

Validating --> W2 = LearnableParameter -> [132, 512]
Validating --> W1 = LearnableParameter -> [512, 512]
Validating --> W0 = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 3]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 3]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 3]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 3], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 3]
Validating --> W0*features = Times(W0[512, 363], MVNormalizedFeatures[363, MBSize 3]) -> [512, MBSize 3]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 3], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> labels = InputValue -> [132, MBSize 3]
Validating --> Prior = Mean(labels[132, MBSize 3]) -> [132, 1]
Validating --> LogOfPrior = Log(Prior[132, 1]) -> [132, 1]
Validating --> ScaledLogLikelihood = Minus(HLast[132, MBSize 0], LogOfPrior[132, 1]) -> [132, MBSize 0]

Validating for node ScaledLogLikelihood. 10 nodes to process in pass 2.

Validating --> W2 = LearnableParameter -> [132, 512]
Validating --> W1 = LearnableParameter -> [512, 512]
Validating --> W0 = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 3]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 3]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 3]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 3], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 3]
Validating --> W0*features = Times(W0[512, 363], MVNormalizedFeatures[363, MBSize 3]) -> [512, MBSize 3]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 3], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> labels = InputValue -> [132, MBSize 3]
Validating --> Prior = Mean(labels[132, MBSize 3]) -> [132, 1]
Validating --> LogOfPrior = Log(Prior[132, 1]) -> [132, 1]
Validating --> ScaledLogLikelihood = Minus(HLast[132, MBSize 0], LogOfPrior[132, 1]) -> [132, MBSize 0]

Validating for node ScaledLogLikelihood, final verification.

Validating --> W2 = LearnableParameter -> [132, 512]
Validating --> W1 = LearnableParameter -> [512, 512]
Validating --> W0 = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 3]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 3]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 3]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 3], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 3]
Validating --> W0*features = Times(W0[512, 363], MVNormalizedFeatures[363, MBSize 3]) -> [512, MBSize 3]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 3], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> labels = InputValue -> [132, MBSize 3]
Validating --> Prior = Mean(labels[132, MBSize 3]) -> [132, 1]
Validating --> LogOfPrior = Log(Prior[132, 1]) -> [132, 1]
Validating --> ScaledLogLikelihood = Minus(HLast[132, MBSize 0], LogOfPrior[132, 1]) -> [132, MBSize 0]

10 out of 22 nodes do not share the minibatch layout with the input data.


Validating for node PosteriorProb. 19 nodes to process in pass 1.

Validating --> W2 = LearnableParameter -> [132, 512]
Validating --> W1 = LearnableParameter -> [512, 512]
Validating --> W0 = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 3]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 3]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 3]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 3], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 3]
Validating --> W0*features = Times(W0[512, 363], MVNormalizedFeatures[363, MBSize 3]) -> [512, MBSize 3]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 3], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> PosteriorProb = Softmax(HLast[132, MBSize 0]) -> [132, MBSize 0]

Validating for node PosteriorProb. 9 nodes to process in pass 2.

Validating --> W2 = LearnableParameter -> [132, 512]
Validating --> W1 = LearnableParameter -> [512, 512]
Validating --> W0 = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 3]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 3]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 3]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 3], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 3]
Validating --> W0*features = Times(W0[512, 363], MVNormalizedFeatures[363, MBSize 3]) -> [512, MBSize 3]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 3], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> PosteriorProb = Softmax(HLast[132, MBSize 0]) -> [132, MBSize 0]

Validating for node PosteriorProb, final verification.

Validating --> W2 = LearnableParameter -> [132, 512]
Validating --> W1 = LearnableParameter -> [512, 512]
Validating --> W0 = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 3]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 3]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 3]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 3], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 3]
Validating --> W0*features = Times(W0[512, 363], MVNormalizedFeatures[363, MBSize 3]) -> [512, MBSize 3]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 3], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> PosteriorProb = Softmax(HLast[132, MBSize 0]) -> [132, MBSize 0]

8 out of 19 nodes do not share the minibatch layout with the input data.

Post-processing network complete.

SGD using GPU 0.

Training criterion node(s):
	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax

Evaluation criterion node(s):
	EvalErrorPrediction = ErrorPrediction


Allocating matrices for forward and/or backward propagation.

Precomputing --> 3 PreCompute nodes found.

	NodeName: InvStdOfFeatures
	NodeName: MeanOfFeatures
	NodeName: Prior
minibatchiterator: epoch 0: frames [0..252734] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms

Precomputing --> Completed.

Set Max Temp Mem Size For Convolution Nodes to 0 samples.
Starting Epoch 1: learning rate per sample = 0.015625  effective momentum = 0.900000  momentum as time constant = 607.4 samples
minibatchiterator: epoch 0: frames [0..20480] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses

Starting minibatch loop.
 Epoch[ 1 of 3]-Minibatch[   1-  10, 3.12%]: SamplesSeen = 640; TrainLossPerSample =  4.57883224; EvalErr[0]PerSample = 0.91406250; TotalTime = 0.0872s; SamplesPerSecond = 7336.6
 Epoch[ 1 of 3]-Minibatch[  11-  20, 6.25%]: SamplesSeen = 640; TrainLossPerSample =  4.24617233; EvalErr[0]PerSample = 0.89687500; TotalTime = 0.0851s; SamplesPerSecond = 7516.3
 Epoch[ 1 of 3]-Minibatch[  21-  30, 9.38%]: SamplesSeen = 640; TrainLossPerSample =  4.05467224; EvalErr[0]PerSample = 0.89843750; TotalTime = 0.0852s; SamplesPerSecond = 7508.1
 Epoch[ 1 of 3]-Minibatch[  31-  40, 12.50%]: SamplesSeen = 640; TrainLossPerSample =  3.83654022; EvalErr[0]PerSample = 0.87031250; TotalTime = 0.0851s; SamplesPerSecond = 7517.6
 Epoch[ 1 of 3]-Minibatch[  41-  50, 15.62%]: SamplesSeen = 640; TrainLossPerSample =  3.71162415; EvalErr[0]PerSample = 0.87500000; TotalTime = 0.0851s; SamplesPerSecond = 7517.8
 Epoch[ 1 of 3]-Minibatch[  51-  60, 18.75%]: SamplesSeen = 640; TrainLossPerSample =  3.50715485; EvalErr[0]PerSample = 0.83906250; TotalTime = 0.0851s; SamplesPerSecond = 7518.3
 Epoch[ 1 of 3]-Minibatch[  61-  70, 21.88%]: SamplesSeen = 640; TrainLossPerSample =  3.60511627; EvalErr[0]PerSample = 0.82187500; TotalTime = 0.0855s; SamplesPerSecond = 7484.3
 Epoch[ 1 of 3]-Minibatch[  71-  80, 25.00%]: SamplesSeen = 640; TrainLossPerSample =  3.34199219; EvalErr[0]PerSample = 0.77500000; TotalTime = 0.0852s; SamplesPerSecond = 7515.1
 Epoch[ 1 of 3]-Minibatch[  81-  90, 28.12%]: SamplesSeen = 640; TrainLossPerSample =  3.50149536; EvalErr[0]PerSample = 0.82656250; TotalTime = 0.0850s; SamplesPerSecond = 7528.5
 Epoch[ 1 of 3]-Minibatch[  91- 100, 31.25%]: SamplesSeen = 640; TrainLossPerSample =  3.45998840; EvalErr[0]PerSample = 0.82343750; TotalTime = 0.0850s; SamplesPerSecond = 7528.7
WARNING: The same matrix with dim [1, 1] has been transferred between different devices for 20 times.
 Epoch[ 1 of 3]-Minibatch[ 101- 110, 34.38%]: SamplesSeen = 640; TrainLossPerSample =  3.39170532; EvalErr[0]PerSample = 0.82187500; TotalTime = 0.0853s; SamplesPerSecond = 7499.2
 Epoch[ 1 of 3]-Minibatch[ 111- 120, 37.50%]: SamplesSeen = 640; TrainLossPerSample =  3.23712463; EvalErr[0]PerSample = 0.80937500; TotalTime = 0.0851s; SamplesPerSecond = 7519.6
 Epoch[ 1 of 3]-Minibatch[ 121- 130, 40.62%]: SamplesSeen = 640; TrainLossPerSample =  3.21520996; EvalErr[0]PerSample = 0.80156250; TotalTime = 0.0851s; SamplesPerSecond = 7520.0
 Epoch[ 1 of 3]-Minibatch[ 131- 140, 43.75%]: SamplesSeen = 640; TrainLossPerSample =  3.10167236; EvalErr[0]PerSample = 0.77187500; TotalTime = 0.0851s; SamplesPerSecond = 7524.7
 Epoch[ 1 of 3]-Minibatch[ 141- 150, 46.88%]: SamplesSeen = 640; TrainLossPerSample =  3.02088013; EvalErr[0]PerSample = 0.72968750; TotalTime = 0.0851s; SamplesPerSecond = 7523.0
 Epoch[ 1 of 3]-Minibatch[ 151- 160, 50.00%]: SamplesSeen = 640; TrainLossPerSample =  3.00322876; EvalErr[0]PerSample = 0.72343750; TotalTime = 0.0854s; SamplesPerSecond = 7492.5
 Epoch[ 1 of 3]-Minibatch[ 161- 170, 53.12%]: SamplesSeen = 640; TrainLossPerSample =  2.85173340; EvalErr[0]PerSample = 0.69218750; TotalTime = 0.0851s; SamplesPerSecond = 7520.3
 Epoch[ 1 of 3]-Minibatch[ 171- 180, 56.25%]: SamplesSeen = 640; TrainLossPerSample =  2.81376343; EvalErr[0]PerSample = 0.68750000; TotalTime = 0.0850s; SamplesPerSecond = 7526.0
 Epoch[ 1 of 3]-Minibatch[ 181- 190, 59.38%]: SamplesSeen = 640; TrainLossPerSample =  2.79284058; EvalErr[0]PerSample = 0.70468750; TotalTime = 0.0851s; SamplesPerSecond = 7521.4
 Epoch[ 1 of 3]-Minibatch[ 191- 200, 62.50%]: SamplesSeen = 640; TrainLossPerSample =  2.69384155; EvalErr[0]PerSample = 0.66718750; TotalTime = 0.0855s; SamplesPerSecond = 7485.2
 Epoch[ 1 of 3]-Minibatch[ 201- 210, 65.62%]: SamplesSeen = 640; TrainLossPerSample =  2.68026733; EvalErr[0]PerSample = 0.66562500; TotalTime = 0.0851s; SamplesPerSecond = 7520.4
 Epoch[ 1 of 3]-Minibatch[ 211- 220, 68.75%]: SamplesSeen = 640; TrainLossPerSample =  2.51867065; EvalErr[0]PerSample = 0.62812500; TotalTime = 0.0850s; SamplesPerSecond = 7525.3
 Epoch[ 1 of 3]-Minibatch[ 221- 230, 71.88%]: SamplesSeen = 640; TrainLossPerSample =  2.46585693; EvalErr[0]PerSample = 0.67031250; TotalTime = 0.0851s; SamplesPerSecond = 7522.2
 Epoch[ 1 of 3]-Minibatch[ 231- 240, 75.00%]: SamplesSeen = 640; TrainLossPerSample =  2.32813110; EvalErr[0]PerSample = 0.60781250; TotalTime = 0.0851s; SamplesPerSecond = 7522.8
 Epoch[ 1 of 3]-Minibatch[ 241- 250, 78.12%]: SamplesSeen = 640; TrainLossPerSample =  2.31088257; EvalErr[0]PerSample = 0.61093750; TotalTime = 0.0855s; SamplesPerSecond = 7487.0
 Epoch[ 1 of 3]-Minibatch[ 251- 260, 81.25%]: SamplesSeen = 640; TrainLossPerSample =  2.41295776; EvalErr[0]PerSample = 0.63750000; TotalTime = 0.0851s; SamplesPerSecond = 7521.3
 Epoch[ 1 of 3]-Minibatch[ 261- 270, 84.38%]: SamplesSeen = 640; TrainLossPerSample =  2.54532471; EvalErr[0]PerSample = 0.66562500; TotalTime = 0.0851s; SamplesPerSecond = 7518.7
 Epoch[ 1 of 3]-Minibatch[ 271- 280, 87.50%]: SamplesSeen = 640; TrainLossPerSample =  2.35637207; EvalErr[0]PerSample = 0.64218750; TotalTime = 0.0850s; SamplesPerSecond = 7533.4
 Epoch[ 1 of 3]-Minibatch[ 281- 290, 90.62%]: SamplesSeen = 640; TrainLossPerSample =  2.19710693; EvalErr[0]PerSample = 0.56250000; TotalTime = 0.0855s; SamplesPerSecond = 7487.7
 Epoch[ 1 of 3]-Minibatch[ 291- 300, 93.75%]: SamplesSeen = 640; TrainLossPerSample =  2.27369385; EvalErr[0]PerSample = 0.59687500; TotalTime = 0.0851s; SamplesPerSecond = 7521.7
 Epoch[ 1 of 3]-Minibatch[ 301- 310, 96.88%]: SamplesSeen = 640; TrainLossPerSample =  2.21437378; EvalErr[0]PerSample = 0.61406250; TotalTime = 0.0850s; SamplesPerSecond = 7526.8
 Epoch[ 1 of 3]-Minibatch[ 311- 320, 100.00%]: SamplesSeen = 640; TrainLossPerSample =  2.19765625; EvalErr[0]PerSample = 0.58437500; TotalTime = 0.0850s; SamplesPerSecond = 7525.6
Finished Epoch[ 1 of 3]: [Training Set] TrainLossPerSample = 3.01459; EvalErrPerSample = 0.73237306; AvgLearningRatePerSample = 0.015625; EpochTime=2.73207
Starting Epoch 2: learning rate per sample = 0.001953  effective momentum = 0.656119  momentum as time constant = 607.5 samples
minibatchiterator: epoch 1: frames [20480..40960] (first utterance at frame 20480), data subset 0 of 1, with 1 datapasses

Starting minibatch loop.
 Epoch[ 2 of 3]-Minibatch[   1-  10, 12.50%]: SamplesSeen = 2560; TrainLossPerSample =  2.06978111; EvalErr[0]PerSample = 0.57382813; TotalTime = 0.1183s; SamplesPerSecond = 21645.6
 Epoch[ 2 of 3]-Minibatch[  11-  20, 25.00%]: SamplesSeen = 2560; TrainLossPerSample =  2.06690979; EvalErr[0]PerSample = 0.56445312; TotalTime = 0.1153s; SamplesPerSecond = 22195.4
 Epoch[ 2 of 3]-Minibatch[  21-  30, 37.50%]: SamplesSeen = 2560; TrainLossPerSample =  2.00655518; EvalErr[0]PerSample = 0.54609375; TotalTime = 0.1154s; SamplesPerSecond = 22182.2
 Epoch[ 2 of 3]-Minibatch[  31-  40, 50.00%]: SamplesSeen = 2560; TrainLossPerSample =  1.98024254; EvalErr[0]PerSample = 0.53242188; TotalTime = 0.1154s; SamplesPerSecond = 22180.8
 Epoch[ 2 of 3]-Minibatch[  41-  50, 62.50%]: SamplesSeen = 2560; TrainLossPerSample =  1.94628906; EvalErr[0]PerSample = 0.53828125; TotalTime = 0.1155s; SamplesPerSecond = 22172.0
 Epoch[ 2 of 3]-Minibatch[  51-  60, 75.00%]: SamplesSeen = 2560; TrainLossPerSample =  1.92739944; EvalErr[0]PerSample = 0.53945312; TotalTime = 0.1154s; SamplesPerSecond = 22192.4
 Epoch[ 2 of 3]-Minibatch[  61-  70, 87.50%]: SamplesSeen = 2560; TrainLossPerSample =  1.91814880; EvalErr[0]PerSample = 0.53515625; TotalTime = 0.1154s; SamplesPerSecond = 22177.2
 Epoch[ 2 of 3]-Minibatch[  71-  80, 100.00%]: SamplesSeen = 2560; TrainLossPerSample =  1.92855072; EvalErr[0]PerSample = 0.54140625; TotalTime = 0.1154s; SamplesPerSecond = 22177.9
Finished Epoch[ 2 of 3]: [Training Set] TrainLossPerSample = 1.9804846; EvalErrPerSample = 0.54638672; AvgLearningRatePerSample = 0.001953125; EpochTime=0.928717
Starting Epoch 3: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
minibatchiterator: epoch 2: frames [40960..61440] (first utterance at frame 40960), data subset 0 of 1, with 1 datapasses

Starting minibatch loop.
 Epoch[ 3 of 3]-Minibatch[   1-  10, 50.00%]: SamplesSeen = 10240; TrainLossPerSample =  1.91202354; EvalErr[0]PerSample = 0.52734375; TotalTime = 0.3474s; SamplesPerSecond = 29474.0
 Epoch[ 3 of 3]-Minibatch[  11-  20, 100.00%]: SamplesSeen = 10240; TrainLossPerSample =  1.91116600; EvalErr[0]PerSample = 0.52255859; TotalTime = 0.3393s; SamplesPerSecond = 30176.8
Finished Epoch[ 3 of 3]: [Training Set] TrainLossPerSample = 1.9115947; EvalErrPerSample = 0.52495116; AvgLearningRatePerSample = 9.7656251e-05; EpochTime=0.690762
CNTKCommandTrainEnd: speechTrain

Post-processing network...

7 roots:
	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax
	PosteriorProb = Softmax
	Prior = Mean
	InvStdOfFeatures = InvStdDev
	ScaledLogLikelihood = Minus
	EvalErrorPrediction = ErrorPrediction
	MeanOfFeatures = Mean
FormNestedNetwork: WARNING: Was called twice for CrossEntropyWithSoftmax CrossEntropyWithSoftmax operation
FormNestedNetwork: WARNING: Was called twice for PosteriorProb Softmax operation
FormNestedNetwork: WARNING: Was called twice for Prior Mean operation
FormNestedNetwork: WARNING: Was called twice for InvStdOfFeatures InvStdDev operation
FormNestedNetwork: WARNING: Was called twice for ScaledLogLikelihood Minus operation
FormNestedNetwork: WARNING: Was called twice for EvalErrorPrediction ErrorPrediction operation
FormNestedNetwork: WARNING: Was called twice for MeanOfFeatures Mean operation


Validating for node CrossEntropyWithSoftmax. 20 nodes to process in pass 1.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> W2 = LearnableParameter -> [132, 512]
Validating --> W1 = LearnableParameter -> [512, 512]
Validating --> W0 = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax(labels[132, MBSize 0], HLast[132, MBSize 0]) -> [1, 1]

Validating for node CrossEntropyWithSoftmax. 12 nodes to process in pass 2.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> W2 = LearnableParameter -> [132, 512]
Validating --> W1 = LearnableParameter -> [512, 512]
Validating --> W0 = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax(labels[132, MBSize 0], HLast[132, MBSize 0]) -> [1, 1]

Validating for node CrossEntropyWithSoftmax, final verification.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> W2 = LearnableParameter -> [132, 512]
Validating --> W1 = LearnableParameter -> [512, 512]
Validating --> W0 = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax(labels[132, MBSize 0], HLast[132, MBSize 0]) -> [1, 1]

9 out of 20 nodes do not share the minibatch layout with the input data.


Validating for node PosteriorProb. 19 nodes to process in pass 1.

Validating --> W2 = LearnableParameter -> [132, 512]
Validating --> W1 = LearnableParameter -> [512, 512]
Validating --> W0 = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> PosteriorProb = Softmax(HLast[132, MBSize 0]) -> [132, MBSize 0]

Validating for node PosteriorProb. 9 nodes to process in pass 2.

Validating --> W2 = LearnableParameter -> [132, 512]
Validating --> W1 = LearnableParameter -> [512, 512]
Validating --> W0 = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> PosteriorProb = Softmax(HLast[132, MBSize 0]) -> [132, MBSize 0]

Validating for node PosteriorProb, final verification.

Validating --> W2 = LearnableParameter -> [132, 512]
Validating --> W1 = LearnableParameter -> [512, 512]
Validating --> W0 = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> PosteriorProb = Softmax(HLast[132, MBSize 0]) -> [132, MBSize 0]

8 out of 19 nodes do not share the minibatch layout with the input data.


Validating for node Prior. 2 nodes to process in pass 1.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> Prior = Mean(labels[132, MBSize 0]) -> [132, 1]

Validating for node Prior. 1 nodes to process in pass 2.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> Prior = Mean(labels[132, MBSize 0]) -> [132, 1]

Validating for node Prior, final verification.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> Prior = Mean(labels[132, MBSize 0]) -> [132, 1]

1 out of 2 nodes do not share the minibatch layout with the input data.


Validating for node InvStdOfFeatures. 2 nodes to process in pass 1.

Validating --> features = InputValue -> [363, MBSize 0]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]

Validating for node InvStdOfFeatures, final verification.

Validating --> features = InputValue -> [363, MBSize 0]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]

1 out of 2 nodes do not share the minibatch layout with the input data.


Validating for node ScaledLogLikelihood. 22 nodes to process in pass 1.

Validating --> W2 = LearnableParameter -> [132, 512]
Validating --> W1 = LearnableParameter -> [512, 512]
Validating --> W0 = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> Prior = Mean(labels[132, MBSize 0]) -> [132, 1]
Validating --> LogOfPrior = Log(Prior[132, 1]) -> [132, 1]
Validating --> ScaledLogLikelihood = Minus(HLast[132, MBSize 0], LogOfPrior[132, 1]) -> [132, MBSize 0]

Validating for node ScaledLogLikelihood. 10 nodes to process in pass 2.

Validating --> W2 = LearnableParameter -> [132, 512]
Validating --> W1 = LearnableParameter -> [512, 512]
Validating --> W0 = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> Prior = Mean(labels[132, MBSize 0]) -> [132, 1]
Validating --> LogOfPrior = Log(Prior[132, 1]) -> [132, 1]
Validating --> ScaledLogLikelihood = Minus(HLast[132, MBSize 0], LogOfPrior[132, 1]) -> [132, MBSize 0]

Validating for node ScaledLogLikelihood, final verification.

Validating --> W2 = LearnableParameter -> [132, 512]
Validating --> W1 = LearnableParameter -> [512, 512]
Validating --> W0 = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> Prior = Mean(labels[132, MBSize 0]) -> [132, 1]
Validating --> LogOfPrior = Log(Prior[132, 1]) -> [132, 1]
Validating --> ScaledLogLikelihood = Minus(HLast[132, MBSize 0], LogOfPrior[132, 1]) -> [132, MBSize 0]

10 out of 22 nodes do not share the minibatch layout with the input data.


Validating for node EvalErrorPrediction. 20 nodes to process in pass 1.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> W2 = LearnableParameter -> [132, 512]
Validating --> W1 = LearnableParameter -> [512, 512]
Validating --> W0 = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> EvalErrorPrediction = ErrorPrediction(labels[132, MBSize 0], HLast[132, MBSize 0]) -> [1, 1]

Validating for node EvalErrorPrediction. 9 nodes to process in pass 2.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> W2 = LearnableParameter -> [132, 512]
Validating --> W1 = LearnableParameter -> [512, 512]
Validating --> W0 = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> EvalErrorPrediction = ErrorPrediction(labels[132, MBSize 0], HLast[132, MBSize 0]) -> [1, 1]

Validating for node EvalErrorPrediction, final verification.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> W2 = LearnableParameter -> [132, 512]
Validating --> W1 = LearnableParameter -> [512, 512]
Validating --> W0 = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> EvalErrorPrediction = ErrorPrediction(labels[132, MBSize 0], HLast[132, MBSize 0]) -> [1, 1]

9 out of 20 nodes do not share the minibatch layout with the input data.


Validating for node MeanOfFeatures. 2 nodes to process in pass 1.

Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]

Validating for node MeanOfFeatures, final verification.

Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]

1 out of 2 nodes do not share the minibatch layout with the input data.

Post-processing network complete.
--------------------------------------------------------------------------------------------
ParameterSVD: start to process group 0 with KeepRatio=0.50
--------------------------------------------------------------------------------------------
Performing SVD for a   512-by-363   matrix (node name: W0                  ) ---  computation time  0.10 secs ;  keep 50.0% energy ===> keep   104 svd values (reduce to 49.0% parameters) 
Performing SVD for a   512-by-512   matrix (node name: W1                  ) ---  computation time  0.15 secs ;  keep 50.0% energy ===> keep   128 svd values (reduce to 50.0% parameters) 
Performing SVD for a   132-by-512   matrix (node name: W2                  ) ---  computation time  0.02 secs ;  keep 50.0% energy ===> keep    32 svd values (reduce to 30.5% parameters) 

Post-processing network...

7 roots:
	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax
	PosteriorProb = Softmax
	Prior = Mean
	InvStdOfFeatures = InvStdDev
	ScaledLogLikelihood = Minus
	EvalErrorPrediction = ErrorPrediction
	MeanOfFeatures = Mean
FormNestedNetwork: WARNING: Was called twice for CrossEntropyWithSoftmax CrossEntropyWithSoftmax operation
FormNestedNetwork: WARNING: Was called twice for PosteriorProb Softmax operation
FormNestedNetwork: WARNING: Was called twice for Prior Mean operation
FormNestedNetwork: WARNING: Was called twice for InvStdOfFeatures InvStdDev operation
FormNestedNetwork: WARNING: Was called twice for ScaledLogLikelihood Minus operation
FormNestedNetwork: WARNING: Was called twice for EvalErrorPrediction ErrorPrediction operation
FormNestedNetwork: WARNING: Was called twice for MeanOfFeatures Mean operation


Validating for node CrossEntropyWithSoftmax. 26 nodes to process in pass 1.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> W2-U = LearnableParameter -> [132, 32]
Validating --> W2-V = LearnableParameter -> [32, 512]
Validating --> W2-SVD = Times(W2-U[132, 32], W2-V[32, 512]) -> [132, 512]
Validating --> W1-U = LearnableParameter -> [512, 128]
Validating --> W1-V = LearnableParameter -> [128, 512]
Validating --> W1-SVD = Times(W1-U[512, 128], W1-V[128, 512]) -> [512, 512]
Validating --> W0-U = LearnableParameter -> [512, 104]
Validating --> W0-V = LearnableParameter -> [104, 363]
Validating --> W0-SVD = Times(W0-U[512, 104], W0-V[104, 363]) -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0-SVD[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1-SVD[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2-SVD[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax(labels[132, MBSize 0], HLast[132, MBSize 0]) -> [1, 1]

Validating for node CrossEntropyWithSoftmax. 12 nodes to process in pass 2.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> W2-U = LearnableParameter -> [132, 32]
Validating --> W2-V = LearnableParameter -> [32, 512]
Validating --> W2-SVD = Times(W2-U[132, 32], W2-V[32, 512]) -> [132, 512]
Validating --> W1-U = LearnableParameter -> [512, 128]
Validating --> W1-V = LearnableParameter -> [128, 512]
Validating --> W1-SVD = Times(W1-U[512, 128], W1-V[128, 512]) -> [512, 512]
Validating --> W0-U = LearnableParameter -> [512, 104]
Validating --> W0-V = LearnableParameter -> [104, 363]
Validating --> W0-SVD = Times(W0-U[512, 104], W0-V[104, 363]) -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0-SVD[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1-SVD[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2-SVD[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax(labels[132, MBSize 0], HLast[132, MBSize 0]) -> [1, 1]

Validating for node CrossEntropyWithSoftmax, final verification.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> W2-U = LearnableParameter -> [132, 32]
Validating --> W2-V = LearnableParameter -> [32, 512]
Validating --> W2-SVD = Times(W2-U[132, 32], W2-V[32, 512]) -> [132, 512]
Validating --> W1-U = LearnableParameter -> [512, 128]
Validating --> W1-V = LearnableParameter -> [128, 512]
Validating --> W1-SVD = Times(W1-U[512, 128], W1-V[128, 512]) -> [512, 512]
Validating --> W0-U = LearnableParameter -> [512, 104]
Validating --> W0-V = LearnableParameter -> [104, 363]
Validating --> W0-SVD = Times(W0-U[512, 104], W0-V[104, 363]) -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0-SVD[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1-SVD[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2-SVD[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax(labels[132, MBSize 0], HLast[132, MBSize 0]) -> [1, 1]

15 out of 26 nodes do not share the minibatch layout with the input data.


Validating for node PosteriorProb. 25 nodes to process in pass 1.

Validating --> W2-U = LearnableParameter -> [132, 32]
Validating --> W2-V = LearnableParameter -> [32, 512]
Validating --> W2-SVD = Times(W2-U[132, 32], W2-V[32, 512]) -> [132, 512]
Validating --> W1-U = LearnableParameter -> [512, 128]
Validating --> W1-V = LearnableParameter -> [128, 512]
Validating --> W1-SVD = Times(W1-U[512, 128], W1-V[128, 512]) -> [512, 512]
Validating --> W0-U = LearnableParameter -> [512, 104]
Validating --> W0-V = LearnableParameter -> [104, 363]
Validating --> W0-SVD = Times(W0-U[512, 104], W0-V[104, 363]) -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0-SVD[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1-SVD[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2-SVD[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> PosteriorProb = Softmax(HLast[132, MBSize 0]) -> [132, MBSize 0]

Validating for node PosteriorProb. 12 nodes to process in pass 2.

Validating --> W2-U = LearnableParameter -> [132, 32]
Validating --> W2-V = LearnableParameter -> [32, 512]
Validating --> W2-SVD = Times(W2-U[132, 32], W2-V[32, 512]) -> [132, 512]
Validating --> W1-U = LearnableParameter -> [512, 128]
Validating --> W1-V = LearnableParameter -> [128, 512]
Validating --> W1-SVD = Times(W1-U[512, 128], W1-V[128, 512]) -> [512, 512]
Validating --> W0-U = LearnableParameter -> [512, 104]
Validating --> W0-V = LearnableParameter -> [104, 363]
Validating --> W0-SVD = Times(W0-U[512, 104], W0-V[104, 363]) -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0-SVD[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1-SVD[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2-SVD[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> PosteriorProb = Softmax(HLast[132, MBSize 0]) -> [132, MBSize 0]

Validating for node PosteriorProb, final verification.

Validating --> W2-U = LearnableParameter -> [132, 32]
Validating --> W2-V = LearnableParameter -> [32, 512]
Validating --> W2-SVD = Times(W2-U[132, 32], W2-V[32, 512]) -> [132, 512]
Validating --> W1-U = LearnableParameter -> [512, 128]
Validating --> W1-V = LearnableParameter -> [128, 512]
Validating --> W1-SVD = Times(W1-U[512, 128], W1-V[128, 512]) -> [512, 512]
Validating --> W0-U = LearnableParameter -> [512, 104]
Validating --> W0-V = LearnableParameter -> [104, 363]
Validating --> W0-SVD = Times(W0-U[512, 104], W0-V[104, 363]) -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0-SVD[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1-SVD[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2-SVD[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> PosteriorProb = Softmax(HLast[132, MBSize 0]) -> [132, MBSize 0]

14 out of 25 nodes do not share the minibatch layout with the input data.


Validating for node Prior. 2 nodes to process in pass 1.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> Prior = Mean(labels[132, MBSize 0]) -> [132, 1]

Validating for node Prior, final verification.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> Prior = Mean(labels[132, MBSize 0]) -> [132, 1]

1 out of 2 nodes do not share the minibatch layout with the input data.


Validating for node InvStdOfFeatures. 2 nodes to process in pass 1.

Validating --> features = InputValue -> [363, MBSize 0]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]

Validating for node InvStdOfFeatures, final verification.

Validating --> features = InputValue -> [363, MBSize 0]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]

1 out of 2 nodes do not share the minibatch layout with the input data.


Validating for node ScaledLogLikelihood. 28 nodes to process in pass 1.

Validating --> W2-U = LearnableParameter -> [132, 32]
Validating --> W2-V = LearnableParameter -> [32, 512]
Validating --> W2-SVD = Times(W2-U[132, 32], W2-V[32, 512]) -> [132, 512]
Validating --> W1-U = LearnableParameter -> [512, 128]
Validating --> W1-V = LearnableParameter -> [128, 512]
Validating --> W1-SVD = Times(W1-U[512, 128], W1-V[128, 512]) -> [512, 512]
Validating --> W0-U = LearnableParameter -> [512, 104]
Validating --> W0-V = LearnableParameter -> [104, 363]
Validating --> W0-SVD = Times(W0-U[512, 104], W0-V[104, 363]) -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0-SVD[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1-SVD[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2-SVD[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> Prior = Mean(labels[132, MBSize 0]) -> [132, 1]
Validating --> LogOfPrior = Log(Prior[132, 1]) -> [132, 1]
Validating --> ScaledLogLikelihood = Minus(HLast[132, MBSize 0], LogOfPrior[132, 1]) -> [132, MBSize 0]

Validating for node ScaledLogLikelihood. 12 nodes to process in pass 2.

Validating --> W2-U = LearnableParameter -> [132, 32]
Validating --> W2-V = LearnableParameter -> [32, 512]
Validating --> W2-SVD = Times(W2-U[132, 32], W2-V[32, 512]) -> [132, 512]
Validating --> W1-U = LearnableParameter -> [512, 128]
Validating --> W1-V = LearnableParameter -> [128, 512]
Validating --> W1-SVD = Times(W1-U[512, 128], W1-V[128, 512]) -> [512, 512]
Validating --> W0-U = LearnableParameter -> [512, 104]
Validating --> W0-V = LearnableParameter -> [104, 363]
Validating --> W0-SVD = Times(W0-U[512, 104], W0-V[104, 363]) -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0-SVD[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1-SVD[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2-SVD[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> Prior = Mean(labels[132, MBSize 0]) -> [132, 1]
Validating --> LogOfPrior = Log(Prior[132, 1]) -> [132, 1]
Validating --> ScaledLogLikelihood = Minus(HLast[132, MBSize 0], LogOfPrior[132, 1]) -> [132, MBSize 0]

Validating for node ScaledLogLikelihood, final verification.

Validating --> W2-U = LearnableParameter -> [132, 32]
Validating --> W2-V = LearnableParameter -> [32, 512]
Validating --> W2-SVD = Times(W2-U[132, 32], W2-V[32, 512]) -> [132, 512]
Validating --> W1-U = LearnableParameter -> [512, 128]
Validating --> W1-V = LearnableParameter -> [128, 512]
Validating --> W1-SVD = Times(W1-U[512, 128], W1-V[128, 512]) -> [512, 512]
Validating --> W0-U = LearnableParameter -> [512, 104]
Validating --> W0-V = LearnableParameter -> [104, 363]
Validating --> W0-SVD = Times(W0-U[512, 104], W0-V[104, 363]) -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0-SVD[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1-SVD[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2-SVD[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> Prior = Mean(labels[132, MBSize 0]) -> [132, 1]
Validating --> LogOfPrior = Log(Prior[132, 1]) -> [132, 1]
Validating --> ScaledLogLikelihood = Minus(HLast[132, MBSize 0], LogOfPrior[132, 1]) -> [132, MBSize 0]

16 out of 28 nodes do not share the minibatch layout with the input data.


Validating for node EvalErrorPrediction. 26 nodes to process in pass 1.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> W2-U = LearnableParameter -> [132, 32]
Validating --> W2-V = LearnableParameter -> [32, 512]
Validating --> W2-SVD = Times(W2-U[132, 32], W2-V[32, 512]) -> [132, 512]
Validating --> W1-U = LearnableParameter -> [512, 128]
Validating --> W1-V = LearnableParameter -> [128, 512]
Validating --> W1-SVD = Times(W1-U[512, 128], W1-V[128, 512]) -> [512, 512]
Validating --> W0-U = LearnableParameter -> [512, 104]
Validating --> W0-V = LearnableParameter -> [104, 363]
Validating --> W0-SVD = Times(W0-U[512, 104], W0-V[104, 363]) -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0-SVD[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1-SVD[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2-SVD[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> EvalErrorPrediction = ErrorPrediction(labels[132, MBSize 0], HLast[132, MBSize 0]) -> [1, 1]

Validating for node EvalErrorPrediction. 12 nodes to process in pass 2.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> W2-U = LearnableParameter -> [132, 32]
Validating --> W2-V = LearnableParameter -> [32, 512]
Validating --> W2-SVD = Times(W2-U[132, 32], W2-V[32, 512]) -> [132, 512]
Validating --> W1-U = LearnableParameter -> [512, 128]
Validating --> W1-V = LearnableParameter -> [128, 512]
Validating --> W1-SVD = Times(W1-U[512, 128], W1-V[128, 512]) -> [512, 512]
Validating --> W0-U = LearnableParameter -> [512, 104]
Validating --> W0-V = LearnableParameter -> [104, 363]
Validating --> W0-SVD = Times(W0-U[512, 104], W0-V[104, 363]) -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0-SVD[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1-SVD[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2-SVD[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> EvalErrorPrediction = ErrorPrediction(labels[132, MBSize 0], HLast[132, MBSize 0]) -> [1, 1]

Validating for node EvalErrorPrediction, final verification.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> W2-U = LearnableParameter -> [132, 32]
Validating --> W2-V = LearnableParameter -> [32, 512]
Validating --> W2-SVD = Times(W2-U[132, 32], W2-V[32, 512]) -> [132, 512]
Validating --> W1-U = LearnableParameter -> [512, 128]
Validating --> W1-V = LearnableParameter -> [128, 512]
Validating --> W1-SVD = Times(W1-U[512, 128], W1-V[128, 512]) -> [512, 512]
Validating --> W0-U = LearnableParameter -> [512, 104]
Validating --> W0-V = LearnableParameter -> [104, 363]
Validating --> W0-SVD = Times(W0-U[512, 104], W0-V[104, 363]) -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0-SVD[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1-SVD[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2-SVD[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> EvalErrorPrediction = ErrorPrediction(labels[132, MBSize 0], HLast[132, MBSize 0]) -> [1, 1]

15 out of 26 nodes do not share the minibatch layout with the input data.


Validating for node MeanOfFeatures. 2 nodes to process in pass 1.

Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]

Validating for node MeanOfFeatures, final verification.

Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]

1 out of 2 nodes do not share the minibatch layout with the input data.

Post-processing network complete.
CNTKCommandTrainBegin: SVDTrain
NDLBuilder Using GPU 0
reading script file glob_0000.scp ... 948 entries
total 132 state names in state list /home/alrezni/src/cntk/Tests/Speech/Data/state.list
htkmlfreader: reading MLF file /home/alrezni/src/cntk/Tests/Speech/Data/glob_0000.mlf ... total 948 entries
...............................................................................................feature set 0: 252734 frames in 948 out of 948 utterances
label set 0: 129 classes
minibatchutterancesource: 948 utterances grouped into 3 chunks, av. chunk size: 316.0 utterances, 84244.7 frames
Starting from checkpoint. Load Network From File /tmp/cntk-test-20151215163714.581330/Speech_SVD@release_gpu/models/cntkSpeech.svd.dnn.0.

Post-processing network...

7 roots:
	EvalErrorPrediction = ErrorPrediction
	Prior = Mean
	PosteriorProb = Softmax
	ScaledLogLikelihood = Minus
	InvStdOfFeatures = InvStdDev
	MeanOfFeatures = Mean
	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax
FormNestedNetwork: WARNING: Was called twice for EvalErrorPrediction ErrorPrediction operation
FormNestedNetwork: WARNING: Was called twice for Prior Mean operation
FormNestedNetwork: WARNING: Was called twice for PosteriorProb Softmax operation
FormNestedNetwork: WARNING: Was called twice for ScaledLogLikelihood Minus operation
FormNestedNetwork: WARNING: Was called twice for InvStdOfFeatures InvStdDev operation
FormNestedNetwork: WARNING: Was called twice for MeanOfFeatures Mean operation
FormNestedNetwork: WARNING: Was called twice for CrossEntropyWithSoftmax CrossEntropyWithSoftmax operation


Validating for node EvalErrorPrediction. 26 nodes to process in pass 1.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> W2-U = LearnableParameter -> [132, 32]
Validating --> W2-V = LearnableParameter -> [32, 512]
Validating --> W2-SVD = Times(W2-U[132, 32], W2-V[32, 512]) -> [132, 512]
Validating --> W1-U = LearnableParameter -> [512, 128]
Validating --> W1-V = LearnableParameter -> [128, 512]
Validating --> W1-SVD = Times(W1-U[512, 128], W1-V[128, 512]) -> [512, 512]
Validating --> W0-U = LearnableParameter -> [512, 104]
Validating --> W0-V = LearnableParameter -> [104, 363]
Validating --> W0-SVD = Times(W0-U[512, 104], W0-V[104, 363]) -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0-SVD[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1-SVD[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2-SVD[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> EvalErrorPrediction = ErrorPrediction(labels[132, MBSize 0], HLast[132, MBSize 0]) -> [1, 1]

Validating for node EvalErrorPrediction. 15 nodes to process in pass 2.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> W2-U = LearnableParameter -> [132, 32]
Validating --> W2-V = LearnableParameter -> [32, 512]
Validating --> W2-SVD = Times(W2-U[132, 32], W2-V[32, 512]) -> [132, 512]
Validating --> W1-U = LearnableParameter -> [512, 128]
Validating --> W1-V = LearnableParameter -> [128, 512]
Validating --> W1-SVD = Times(W1-U[512, 128], W1-V[128, 512]) -> [512, 512]
Validating --> W0-U = LearnableParameter -> [512, 104]
Validating --> W0-V = LearnableParameter -> [104, 363]
Validating --> W0-SVD = Times(W0-U[512, 104], W0-V[104, 363]) -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0-SVD[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1-SVD[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2-SVD[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> EvalErrorPrediction = ErrorPrediction(labels[132, MBSize 0], HLast[132, MBSize 0]) -> [1, 1]

Validating for node EvalErrorPrediction, final verification.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> W2-U = LearnableParameter -> [132, 32]
Validating --> W2-V = LearnableParameter -> [32, 512]
Validating --> W2-SVD = Times(W2-U[132, 32], W2-V[32, 512]) -> [132, 512]
Validating --> W1-U = LearnableParameter -> [512, 128]
Validating --> W1-V = LearnableParameter -> [128, 512]
Validating --> W1-SVD = Times(W1-U[512, 128], W1-V[128, 512]) -> [512, 512]
Validating --> W0-U = LearnableParameter -> [512, 104]
Validating --> W0-V = LearnableParameter -> [104, 363]
Validating --> W0-SVD = Times(W0-U[512, 104], W0-V[104, 363]) -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0-SVD[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1-SVD[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2-SVD[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> EvalErrorPrediction = ErrorPrediction(labels[132, MBSize 0], HLast[132, MBSize 0]) -> [1, 1]

15 out of 26 nodes do not share the minibatch layout with the input data.


Validating for node Prior. 2 nodes to process in pass 1.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> Prior = Mean(labels[132, MBSize 0]) -> [132, 1]

Validating for node Prior. 1 nodes to process in pass 2.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> Prior = Mean(labels[132, MBSize 0]) -> [132, 1]

Validating for node Prior, final verification.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> Prior = Mean(labels[132, MBSize 0]) -> [132, 1]

1 out of 2 nodes do not share the minibatch layout with the input data.


Validating for node PosteriorProb. 25 nodes to process in pass 1.

Validating --> W2-U = LearnableParameter -> [132, 32]
Validating --> W2-V = LearnableParameter -> [32, 512]
Validating --> W2-SVD = Times(W2-U[132, 32], W2-V[32, 512]) -> [132, 512]
Validating --> W1-U = LearnableParameter -> [512, 128]
Validating --> W1-V = LearnableParameter -> [128, 512]
Validating --> W1-SVD = Times(W1-U[512, 128], W1-V[128, 512]) -> [512, 512]
Validating --> W0-U = LearnableParameter -> [512, 104]
Validating --> W0-V = LearnableParameter -> [104, 363]
Validating --> W0-SVD = Times(W0-U[512, 104], W0-V[104, 363]) -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0-SVD[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1-SVD[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2-SVD[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> PosteriorProb = Softmax(HLast[132, MBSize 0]) -> [132, MBSize 0]

Validating for node PosteriorProb. 12 nodes to process in pass 2.

Validating --> W2-U = LearnableParameter -> [132, 32]
Validating --> W2-V = LearnableParameter -> [32, 512]
Validating --> W2-SVD = Times(W2-U[132, 32], W2-V[32, 512]) -> [132, 512]
Validating --> W1-U = LearnableParameter -> [512, 128]
Validating --> W1-V = LearnableParameter -> [128, 512]
Validating --> W1-SVD = Times(W1-U[512, 128], W1-V[128, 512]) -> [512, 512]
Validating --> W0-U = LearnableParameter -> [512, 104]
Validating --> W0-V = LearnableParameter -> [104, 363]
Validating --> W0-SVD = Times(W0-U[512, 104], W0-V[104, 363]) -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0-SVD[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1-SVD[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2-SVD[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> PosteriorProb = Softmax(HLast[132, MBSize 0]) -> [132, MBSize 0]

Validating for node PosteriorProb, final verification.

Validating --> W2-U = LearnableParameter -> [132, 32]
Validating --> W2-V = LearnableParameter -> [32, 512]
Validating --> W2-SVD = Times(W2-U[132, 32], W2-V[32, 512]) -> [132, 512]
Validating --> W1-U = LearnableParameter -> [512, 128]
Validating --> W1-V = LearnableParameter -> [128, 512]
Validating --> W1-SVD = Times(W1-U[512, 128], W1-V[128, 512]) -> [512, 512]
Validating --> W0-U = LearnableParameter -> [512, 104]
Validating --> W0-V = LearnableParameter -> [104, 363]
Validating --> W0-SVD = Times(W0-U[512, 104], W0-V[104, 363]) -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0-SVD[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1-SVD[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2-SVD[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> PosteriorProb = Softmax(HLast[132, MBSize 0]) -> [132, MBSize 0]

14 out of 25 nodes do not share the minibatch layout with the input data.


Validating for node ScaledLogLikelihood. 28 nodes to process in pass 1.

Validating --> W2-U = LearnableParameter -> [132, 32]
Validating --> W2-V = LearnableParameter -> [32, 512]
Validating --> W2-SVD = Times(W2-U[132, 32], W2-V[32, 512]) -> [132, 512]
Validating --> W1-U = LearnableParameter -> [512, 128]
Validating --> W1-V = LearnableParameter -> [128, 512]
Validating --> W1-SVD = Times(W1-U[512, 128], W1-V[128, 512]) -> [512, 512]
Validating --> W0-U = LearnableParameter -> [512, 104]
Validating --> W0-V = LearnableParameter -> [104, 363]
Validating --> W0-SVD = Times(W0-U[512, 104], W0-V[104, 363]) -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0-SVD[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1-SVD[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2-SVD[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> Prior = Mean(labels[132, MBSize 0]) -> [132, 1]
Validating --> LogOfPrior = Log(Prior[132, 1]) -> [132, 1]
Validating --> ScaledLogLikelihood = Minus(HLast[132, MBSize 0], LogOfPrior[132, 1]) -> [132, MBSize 0]

Validating for node ScaledLogLikelihood. 13 nodes to process in pass 2.

Validating --> W2-U = LearnableParameter -> [132, 32]
Validating --> W2-V = LearnableParameter -> [32, 512]
Validating --> W2-SVD = Times(W2-U[132, 32], W2-V[32, 512]) -> [132, 512]
Validating --> W1-U = LearnableParameter -> [512, 128]
Validating --> W1-V = LearnableParameter -> [128, 512]
Validating --> W1-SVD = Times(W1-U[512, 128], W1-V[128, 512]) -> [512, 512]
Validating --> W0-U = LearnableParameter -> [512, 104]
Validating --> W0-V = LearnableParameter -> [104, 363]
Validating --> W0-SVD = Times(W0-U[512, 104], W0-V[104, 363]) -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0-SVD[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1-SVD[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2-SVD[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> Prior = Mean(labels[132, MBSize 0]) -> [132, 1]
Validating --> LogOfPrior = Log(Prior[132, 1]) -> [132, 1]
Validating --> ScaledLogLikelihood = Minus(HLast[132, MBSize 0], LogOfPrior[132, 1]) -> [132, MBSize 0]

Validating for node ScaledLogLikelihood, final verification.

Validating --> W2-U = LearnableParameter -> [132, 32]
Validating --> W2-V = LearnableParameter -> [32, 512]
Validating --> W2-SVD = Times(W2-U[132, 32], W2-V[32, 512]) -> [132, 512]
Validating --> W1-U = LearnableParameter -> [512, 128]
Validating --> W1-V = LearnableParameter -> [128, 512]
Validating --> W1-SVD = Times(W1-U[512, 128], W1-V[128, 512]) -> [512, 512]
Validating --> W0-U = LearnableParameter -> [512, 104]
Validating --> W0-V = LearnableParameter -> [104, 363]
Validating --> W0-SVD = Times(W0-U[512, 104], W0-V[104, 363]) -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0-SVD[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1-SVD[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2-SVD[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> Prior = Mean(labels[132, MBSize 0]) -> [132, 1]
Validating --> LogOfPrior = Log(Prior[132, 1]) -> [132, 1]
Validating --> ScaledLogLikelihood = Minus(HLast[132, MBSize 0], LogOfPrior[132, 1]) -> [132, MBSize 0]

16 out of 28 nodes do not share the minibatch layout with the input data.


Validating for node InvStdOfFeatures. 2 nodes to process in pass 1.

Validating --> features = InputValue -> [363, MBSize 0]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]

Validating for node InvStdOfFeatures, final verification.

Validating --> features = InputValue -> [363, MBSize 0]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]

1 out of 2 nodes do not share the minibatch layout with the input data.


Validating for node MeanOfFeatures. 2 nodes to process in pass 1.

Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]

Validating for node MeanOfFeatures, final verification.

Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]

1 out of 2 nodes do not share the minibatch layout with the input data.


Validating for node CrossEntropyWithSoftmax. 26 nodes to process in pass 1.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> W2-U = LearnableParameter -> [132, 32]
Validating --> W2-V = LearnableParameter -> [32, 512]
Validating --> W2-SVD = Times(W2-U[132, 32], W2-V[32, 512]) -> [132, 512]
Validating --> W1-U = LearnableParameter -> [512, 128]
Validating --> W1-V = LearnableParameter -> [128, 512]
Validating --> W1-SVD = Times(W1-U[512, 128], W1-V[128, 512]) -> [512, 512]
Validating --> W0-U = LearnableParameter -> [512, 104]
Validating --> W0-V = LearnableParameter -> [104, 363]
Validating --> W0-SVD = Times(W0-U[512, 104], W0-V[104, 363]) -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0-SVD[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1-SVD[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2-SVD[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax(labels[132, MBSize 0], HLast[132, MBSize 0]) -> [1, 1]

Validating for node CrossEntropyWithSoftmax. 12 nodes to process in pass 2.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> W2-U = LearnableParameter -> [132, 32]
Validating --> W2-V = LearnableParameter -> [32, 512]
Validating --> W2-SVD = Times(W2-U[132, 32], W2-V[32, 512]) -> [132, 512]
Validating --> W1-U = LearnableParameter -> [512, 128]
Validating --> W1-V = LearnableParameter -> [128, 512]
Validating --> W1-SVD = Times(W1-U[512, 128], W1-V[128, 512]) -> [512, 512]
Validating --> W0-U = LearnableParameter -> [512, 104]
Validating --> W0-V = LearnableParameter -> [104, 363]
Validating --> W0-SVD = Times(W0-U[512, 104], W0-V[104, 363]) -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0-SVD[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1-SVD[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2-SVD[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax(labels[132, MBSize 0], HLast[132, MBSize 0]) -> [1, 1]

Validating for node CrossEntropyWithSoftmax, final verification.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> W2-U = LearnableParameter -> [132, 32]
Validating --> W2-V = LearnableParameter -> [32, 512]
Validating --> W2-SVD = Times(W2-U[132, 32], W2-V[32, 512]) -> [132, 512]
Validating --> W1-U = LearnableParameter -> [512, 128]
Validating --> W1-V = LearnableParameter -> [128, 512]
Validating --> W1-SVD = Times(W1-U[512, 128], W1-V[128, 512]) -> [512, 512]
Validating --> W0-U = LearnableParameter -> [512, 104]
Validating --> W0-V = LearnableParameter -> [104, 363]
Validating --> W0-SVD = Times(W0-U[512, 104], W0-V[104, 363]) -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0-SVD[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1-SVD[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2-SVD[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax(labels[132, MBSize 0], HLast[132, MBSize 0]) -> [1, 1]

15 out of 26 nodes do not share the minibatch layout with the input data.

Post-processing network complete.

SGD using GPU 0.

Training criterion node(s):
	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax

Evaluation criterion node(s):
	EvalErrorPrediction = ErrorPrediction


Allocating matrices for forward and/or backward propagation.
No PreCompute nodes found, skipping PreCompute step
Set Max Temp Mem Size For Convolution Nodes to 0 samples.
Starting Epoch 1: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
minibatchiterator: epoch 0: frames [0..20480] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms

Starting minibatch loop.
 Epoch[ 1 of 2]-Minibatch[   1-  10, 50.00%]: SamplesSeen = 10240; TrainLossPerSample =  1.89474258; EvalErr[0]PerSample = 0.52939453; TotalTime = 0.3959s; SamplesPerSecond = 25864.0
 Epoch[ 1 of 2]-Minibatch[  11-  20, 100.00%]: SamplesSeen = 10240; TrainLossPerSample =  1.85084114; EvalErr[0]PerSample = 0.51298828; TotalTime = 0.3877s; SamplesPerSecond = 26409.8
Finished Epoch[ 1 of 2]: [Training Set] TrainLossPerSample = 1.8727919; EvalErrPerSample = 0.52119142; AvgLearningRatePerSample = 9.7656251e-05; EpochTime=0.892369
Starting Epoch 2: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
minibatchiterator: epoch 1: frames [20480..40960] (first utterance at frame 20480), data subset 0 of 1, with 1 datapasses

Starting minibatch loop.
 Epoch[ 2 of 2]-Minibatch[   1-  10, 50.00%]: SamplesSeen = 10240; TrainLossPerSample =  1.85515900; EvalErr[0]PerSample = 0.51796875; TotalTime = 0.3911s; SamplesPerSecond = 26185.6
 Epoch[ 2 of 2]-Minibatch[  11-  20, 100.00%]: SamplesSeen = 10240; TrainLossPerSample =  1.82865601; EvalErr[0]PerSample = 0.51494141; TotalTime = 0.3870s; SamplesPerSecond = 26459.1
Finished Epoch[ 2 of 2]: [Training Set] TrainLossPerSample = 1.8419075; EvalErrPerSample = 0.51645511; AvgLearningRatePerSample = 9.7656251e-05; EpochTime=0.781703
CNTKCommandTrainEnd: SVDTrain
COMPLETED
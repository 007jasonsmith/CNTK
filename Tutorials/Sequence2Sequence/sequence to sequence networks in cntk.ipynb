{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence to Sequence Networks in CNTK\n",
    "\n",
    "## Background\n",
    "\n",
    "Traditional neural networks \n",
    "\n",
    "<img src=http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/RNN-unrolled.png width=500px>\n",
    "\n",
    "\n",
    "<img src=http://karpathy.github.io/assets/rnn/diags.jpeg width=750px>\n",
    "\n",
    "...\n",
    "\n",
    "<img src=pix/s2s.png width=700px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem: Grapheme-to-Phoneme Conversion\n",
    "\n",
    "The [grapheme](https://en.wikipedia.org/wiki/Grapheme) to [phoneme](https://en.wikipedia.org/wiki/Phoneme) problem is a translation task that takes the letters of a word as the input sequence (the graphemes are the smallest units of a writing system) and outputs the corresponding phonemes; that is, the units of sound that make up a language. In other words, the system aims to generate an unambigious representation of how to pronounce a given input word.\n",
    "\n",
    "### Example\n",
    "\n",
    "| Letters  | T | A | N | G | L | E |\n",
    "| --- | --- |\n",
    "| Phonemes | ~T | ~AE | ~NG | ~G | ~AHL | null |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem: English-to-French Translation\n",
    "\n",
    "The machine translation problem is well-known and easy to understand: given some English language sentence E (our input sequence), translate it to the equivalent French sentence F (our output sequence). MT researchers have been working on this problem for decades, coming up with ever-more complex systems to eke our the next fraction of a BLEU point. However, sequence-to-sequence networks have in some ways made a lot of their work antiquated (see, e.g. [Neural Machine Translation by Jointly Learning to Align and Translate](http://arxiv.org/abs/1409.0473)).\n",
    "\n",
    "\n",
    "### Data\n",
    "\n",
    "The Hansard...\n",
    "\n",
    "\n",
    "#### Example:\n",
    "| Language | Sentence | Source |\n",
    "| --- | --- | --- |\n",
    "| English | Fueling this growth in royalty revenues is the United States demand, which some day may place our Canadian domestic needs at risk. | hansard.36.2.house.debates.077.e |\n",
    "| French | Les États-Unis aimeraient bien transformer cette croissance en redevances, ce qui pourrait mettre nos propres besoins en périls. | hansard.36.2.house.debates.077.f |\n",
    "\n",
    "\n",
    "### Pre-processing and CNTKTextFormat\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: import all of the required functionality..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import math\n",
    "from cntk import Trainer, Axis, text_format_minibatch_source, StreamConfiguration\n",
    "from cntk.device import cpu, set_default_device\n",
    "from cntk.learner import momentum_sgd, momentum_schedule\n",
    "from cntk.ops import input_variable, cross_entropy_with_softmax, classification_error, sequence, slice\n",
    "from cntk.ops import past_value, future_value, element_select, plus, hardmax\n",
    "from cntk.ops.functions import CloneMethod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: setup the inputs and parameters\n",
    "\n",
    "### Dynamic axes in CNTK\n",
    "\n",
    "One of the important concepts in understanding CNTK is the idea of two types of axes: static axes, which are the traditional axes of a variable's shape, and dynamic axes, which have dimensions that are unknown until the variable is bound to real data at computation time. They are particularly important in the world of recurrent neural networks. Instead of having to decide a maximum sequence length ahead of time, padding your time to that size, and wasting computation, CNTK's dynamic axes allow for variable sequence lengths that are automatically padded in minibatches to be as efficient as possible.\n",
    "\n",
    "When setting up sequences, there are two dynamic axes that are important to consider. The first is the batch axis, which is the axis along which multiple sequences are batched. The second is the dynamic axis particular to that sequence. The latter is specific to a particular input because of variable sequence lengths in your data. For example, in sequence to sequence networks, we have two sequences: the input sequence, and the ouptput (or 'label') sequence. One of the things that makes this type of network so powerful is that the length of the input sequence and the output sequence do not have to correspond to each other. Therefore, both the input sequence and the output sequence require their own unique dynamic axis.\n",
    "\n",
    "When defining the input to a network, we set up the required dynamic axes and the shape of the input variables. Below, we define the shape (vocabulary size) of the inputs, create their dynamic axes, and finally create input variables that represent input nodes in our network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# in the g2p problem the vocabs are separate, but for simplicity we share the combined vocab\n",
    "input_vocab_dim = 69\n",
    "label_vocab_dim = 69\n",
    "\n",
    "# network complexity; higher allows network to be more expressive -- but look our for over-fitting\n",
    "hidden_dim = 128\n",
    "num_layers = 1\n",
    "\n",
    "# Source and target inputs to the model\n",
    "batch_axis = Axis.default_batch_axis()\n",
    "input_seq_axis = Axis('inputAxis') # create a new named axis for the input\n",
    "label_seq_axis = Axis('labelAxis') # create a new named axis for the output/label\n",
    "\n",
    "# Two additional dynamic axes (dynamic because they're only known when the variable is bound to actual data)\n",
    "# --> the batch axis (the axis along which multiple sequences are batched); and sequence axis (differfent)\n",
    "input_dynamic_axes = [batch_axis, input_seq_axis]\n",
    "raw_input = input_variable(shape=(input_vocab_dim), dynamic_axes=input_dynamic_axes, name='raw_input')\n",
    "\n",
    "label_dynamic_axes = [batch_axis, label_seq_axis]\n",
    "raw_labels = input_variable(shape=(label_vocab_dim), dynamic_axes=label_dynamic_axes, name='raw_labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "1. Why do the shapes of the input variables correspond to the size of our dictionaries in sequence to sequence networks?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: define the network\n",
    "\n",
    "As discussed before, the sequence-to-sequence network is, at its most basic, an RNN encoder followed by an RNN decoder, and a dense output layer. We could do this in a few lines with the layers library, but let's go through things in a little more detail without adding too much complexity.\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "For sequence-to-sequence networks, the loss we use is cross-entropy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it all together\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention\n",
    "\n",
    "An important extension to sequence-to-sequence models, especially when dealing with long sequences, is to use an attention mechanism. The idea behind attention is to allow the decoder, first, to look at any of the hidden state outputs from the encoder (instead of using only the final hidden state), and, second, to learn how much attention to pay to each of those hidden states given the context. This allows the outputted word at each time step `t` to depend not only on the final hidden state and the word that came before it, but instead on a weighted combination of *all* of the input hidden states!\n",
    "\n",
    "...\n",
    "\n",
    "The attention vector at output time $t$ over the input words $(1, ..., T_A)$ is defined as:\n",
    "\n",
    "$$u_i^t = v^T tanh( W_1 h_i + W_2 d_t)$$\n",
    "$$a_i^t = softmax(u_i^t)$$\n",
    "$$d'_t = \\sum_{i=1}^{T_A}{a_i^t h_i}$$\n",
    "\n",
    "...\n",
    "\n",
    "<img src=http://d3kbpzbmcynnmx.cloudfront.net/wp-content/uploads/2015/12/Screen-Shot-2015-12-30-at-1.23.48-PM.png width=550px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Greedy decoding\n",
    "\n",
    "Once we have a trained model, we want \n",
    "\n",
    "\n",
    "## Beam search decoding\n",
    "\n",
    "..."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:cntk-py34]",
   "language": "python",
   "name": "conda-env-cntk-py34-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

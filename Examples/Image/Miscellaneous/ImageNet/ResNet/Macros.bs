# basic components
ConvLayer {outChannels, kernelSize, strideSize} = 
    ConvolutionalLayer {outChannels, kernelSize, init = "heNormal", stride = strideSize, pad = true, bias = false}

BNLayer {} = 
    BatchNormalizationLayer {spatialRank = 2, normalizationTimeConstant = 0, useCntkEngine = false}

# assembly components
## Convolution + Batch Normalization
ConvBNLayer {outChannels, kernel, stride} = Sequential(
    ConvLayer {outChannels, kernel, stride} :
    BNLayer{}
)

## Convolution + Batch Normalization + Rectifier Linear
ConvBNReLULayer {outChannels, kernelSize, strideSize} = Sequential(
    ConvBNLayer {outChannels, kernelSize, strideSize} :
    ReLU
)

## Batch Normalization + Rectifier Linear + Convolution
BNReLUConvLayer {outChannels, kernelSize, strideSize} = Sequential(
    BNLayer{} :
    ReLU :
    ConvBNLayer {outChannels, kernelSize, strideSize}
)

# ResNet components
ResNetBottleneckInc (outChannels, interOutChannels, input, stride = 2, strideA = 2, strideB = 1) = {
    # Convolution
    b = Sequential (
        ConvBNReLULayer {interOutChannels, (1: 1), (strideA: strideA)} :
        ConvBNReLULayer {interOutChannels, (3: 3), (strideB: strideB)} :
        ConvBNLayer {outChannels, (1: 1), (1: 1)}) (input)

    # Shortcut
    s = ConvBNLayer {outChannels, (1: 1), (stride: stride)} (input)

    p = Plus(b, s)
    y = ReLU(p)
}.y

ResNetBottleneck (outChannels, interOutChannels, input) = {
    # Convolution
    b = Sequential (
        ConvBNReLULayer {interOutChannels, (1: 1), (1: 1)} :
        ConvBNReLULayer {interOutChannels, (3: 3), (1: 1)} :
        ConvBNLayer {outChannels, (1: 1), (1: 1)}) (input)

    p = Plus(b, input)
    y = ReLU(p)
}.y

ResNetIdentityMapInc (outChannels, interOutChannels, input, stride = 2, strideA = 2, strideB = 1) = {
    # pre-active
    t = Sequential (BNLayer {} : ReLU) (input)

    # convolution
    b = Sequential (
        ConvLayer {interOutChannels, (1: 1), (strideA: strideA)} :
        BNReLUConvLayer {interOutChannels, (3: 3), (strideB: strideB)} :
        BNReLUConvLayer {outChannels, (1: 1), (1: 1)}) (t)

    # shortcut
    s = ConvLayer {outChannels, (1: 1), (1: 1)} (t)

    p = Plus(b, t) 
}.p

ResNetIdentityMap (outChannels, interOutChannels, input) = {
    # convolution
    b = Sequential (
        BNReLUConvLayer {interOutChannels, (1: 1), (1: 1)} :
        BNReLUConvLayer {interOutChannels, (3: 3), (1: 1)} :
        BNReLUConvLayer {outChannels, (1: 1), (1: 1)}) (input)

    p = Plus(b, input)
}.p
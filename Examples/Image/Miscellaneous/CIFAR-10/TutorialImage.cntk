makeMode = false ; traceLevel = 1 ; deviceId = 0

RootDir = "."  # overridable from outside
DataDir  = "$RootDir$"
ModelDir = "$RootDir$/Output/Models"

# If set to true, always initialize the network on CPU, making initialization consistent across CPU and GPU targets (for testing).
initOnCPUOnly=true

command = Train:Test

modelPath = "$ModelDir$/01_Convolution"

Train = [
    action = "train"

    BrainScriptNetworkBuilder = [
        imageShape = 32:32:3
        labelDim = 10

        model (features) = {
            Subtract128 (x) = x - Constant (128)
            featScaled = Subtract128 (features)

            # conv1
            kW1 = 5
            kH1 = 5
            cMap1 = 32
            hStride1 = 1
            vStride1 = 1
            # weight[cMap1, kW1 * kH1 * ImageC]
            #conv1_act = ConvReLULayer1(cMap1, 75, kW1, kH1, hStride1, vStride1, 0.0043, 0) (featScaled)
            #conv1_act = ConvReLULayer1(featScaled, cMap1, 75, kW1, kH1, hStride1, vStride1, 0.0043, 0)
            conv1_act = ConvolutionalLayer {cMap1, (5:5), activation = ReLU, init = "gaussian", initValueScale = 0.0043} (featScaled)

ConvReLULayer(inp, outMap, inWCount, kW, kH, hStride, vStride, wScale, bValue) =
[
    #W = LearnableParameter(outMap, inWCount, init = "gaussian", initValueScale = wScale)
    W = LearnableParameter(0, 0, init = "gaussian", initValueScale = wScale)
    b = ParameterTensor(1:1:outMap, initValue  = bValue)
    c = Convolution(W, inp, kW:kH/*:(inWCount/kW/kH)*/, mapDims=outMap, stride=hStride:vStride/*:(inWCount/kW/kH)*/, autoPadding = true/*:true:false*/)
    p = Plus(c, b)
    y = RectifiedLinear(p)
].y
ConvReLULayer1(outMap, inWCount, kW, kH, hStride, vStride, wScale, bValue) =
[
    #W = LearnableParameter(outMap, inWCount, init = "gaussian", initValueScale = wScale)
    W = LearnableParameter(0, 0, init = "gaussian", initValueScale = wScale)
    b = ParameterTensor(1:1:outMap, initValue  = bValue)
    f(inp)= {
    c = Convolution(W, inp, kW:kH/*:(inWCount/kW/kH)*/, mapDims=outMap, stride=hStride:vStride/*:(inWCount/kW/kH)*/, autoPadding = true/*:true:false*/)
    p = Plus(c, b)
    y = RectifiedLinear(p)
    }.y
].f



            # pool1
            #pool1W = 3
            #pool1H = 3
            #pool1hStride = 2
            #pool1vStride = 2
            #pool1 = MaxPooling(conv1_act, pool1W, pool1H, pool1hStride, pool1vStride)
            pool1 = MaxPoolingLayer {(3:3), stride = (2:2)} (conv1_act)

            # conv2
            kW2 = 5
            kH2 = 5
            cMap2 = 32
            hStride2 = 1
            vStride2 = 1
            # weight[cMap2, kW2 * kH2 * cMap1]
            conv2_act = ConvReLULayer(pool1, cMap2, 800, kW2, kH2, hStride2, vStride2, 1.414, 0)
            #conv2_act = ConvolutionalLayer {cMap2, (5:5), activation = ReLU, init = "gaussian", initValueScale = 1.414} (featScaled)

            # pool2
            #pool2W = 3
            #pool2H = 3
            #pool2hStride = 2
            #pool2vStride = 2
            #pool2 = MaxPooling(conv2_act, pool2W, pool2H, pool2hStride, pool2vStride)
            pool2 = MaxPoolingLayer {(3:3), stride = (2:2)} (conv2_act)

            # conv3
            kW3 = 5
            kH3 = 5
            cMap3 = 64
            hStride3 = 1
            vStride3 = 1
            # weight[cMap3, kW3 * kH3 * cMap2]
            conv3_act = ConvReLULayer(pool2, cMap3, 800, kW3, kH3, hStride3, vStride3, 1.414, 0)
            #conv3_act = ConvolutionalLayer {cMap3, (5:5), activation = ReLU, init = "gaussian", initValueScale = 1.414} (featScaled)

            # pool3
            #pool3W = 3
            #pool3H = 3
            #pool3hStride = 2
            #pool3vStride = 2
            #pool3 = MaxPooling(conv3_act, pool3W, pool3H, pool3hStride, pool3vStride)
            pool3 = MaxPoolingLayer {(3:3), stride = (2:2)} (conv3_act)

            h1 = DenseLayer {64, activation = ReLU, init = "gaussian", initValueScale = 12} (pool3)
            h1_d = Dropout(h1)

            z = LinearLayer {labelDim, init = "gaussian", initValueScale = 1.5} (h1_d)
        }.z

        # inputs
        features = Input {imageShape}
        labels   = Input {labelDim}

        # apply model to features
        z = model (features)

        # connect to system
        ce   = CrossEntropyWithSoftmax (labels, z)
        errs = ErrorPrediction         (labels, z)

        featureNodes    = (features)
        labelNodes      = (labels)
        criterionNodes  = (ce)
        evaluationNodes = (errs)
        outputNodes     = (z)
    ]

    SGD = [
        epochSize = 49984
        minibatchSize = 64
        learningRatesPerMB = 0.01*10:0.003*10:0.001
        momentumPerMB = 0.9*20:0.99
        maxEpochs = 30
        L2RegWeight = 0.03
        dropoutRate = 0*5:0.5
        firstMBsToShowResult = 10
        numMBsToShowResult = 500
    ]

    reader = [
        readerType = "CNTKTextFormatReader"
        # See REAMDE.md for details on getting the data (Train_cntk_text.txt).
        file = "$DataDir$/Train_cntk_text.txt"
        input = [
            features = [ dim = 3072 ; format = "dense" ]
            labels   = [ dim = 10 ;   format = "dense" ]
        ]
    ]
]

Test = [
    action = "test"
    # Set minibatch size for testing.
    minibatchSize = 16

    reader = [
        readerType = "CNTKTextFormatReader"
        file = "$DataDir$/Test_cntk_text.txt"
        input = [
            features = [ dim = 3072 ; format = "dense" ]
            labels   = [ dim = 10 ;   format = "dense" ]
        ]
    ]
]
